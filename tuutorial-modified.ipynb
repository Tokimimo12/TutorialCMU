{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on CMU-Multimodal SDK\n",
    "\n",
    "This is a tutorial on using ***CMU-Multimodal SDK*** to load and process multimodal time-series datasets and training a simple late-fusion LSTM model on the processed data. \n",
    "\n",
    "For this tutorial, we specify some constants in `./constans/paths.py`. Please first take a look and modify the paths to point to the correct folders.\n",
    "\n",
    "## Downloading the data\n",
    "\n",
    "We start off by (down)loading the datasets. In the SDK each dataset has three sets of content: `highlevel`, `raw` and `labels`. `highlevel` contains the extracted features for each modality (Facet facial landmarks, COVAREP acoustic features) while `raw` contains the raw transctripts, phonemes. `labels` are self-explanatory. Note that some datasets have more than just one set of annotations so `labels` could also give you multiple files.\n",
    "\n",
    "Currently there's a caveat that the SDK will not automatically detect if you have downloaded the data already. In event of that it will throw a `RuntimeError`. We work around that by `try/except`. This is not ideal but it will work for now."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK_PATH: C:\\Users\\Viki\\Documents\\Thesis\\CMU-MultimodalSDK\n"
     ]
    }
   ],
   "source": [
    "from constants import SDK_PATH, DATA_PATH, WORD_EMB_PATH, CACHE_PATH\n",
    "import sys"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T11:20:42.025124500Z",
     "start_time": "2024-12-04T11:20:41.982912Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK path is set to C:\\Users\\Viki\\Documents\\Thesis\\CMU-MultimodalSDK\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if SDK_PATH is None:\n",
    "    print(\"SDK path is not specified! Please specify first in constants/paths.py\")\n",
    "    exit(0)\n",
    "else:\n",
    "    sys.path.append(SDK_PATH)\n",
    "    print(f\"SDK path is set to {SDK_PATH}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T11:20:42.425796Z",
     "start_time": "2024-12-04T11:20:42.350706800Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\JetBrains\\PyCharm 2023.3.2\\plugins\\python\\helpers-pro\\jupyter_debug\n",
      "C:\\Program Files\\JetBrains\\PyCharm 2023.3.2\\plugins\\python\\helpers\\pydev\n",
      "C:\\Users\\Viki\\Documents\\Thesis\\tryout3\n",
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\python310.zip\n",
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\DLLs\n",
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\n",
      "C:\\Users\\Viki\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\n",
      "C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\.venv\n",
      "\n",
      "C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\.venv\\lib\\site-packages\n",
      "C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\.venv\\lib\\site-packages\\win32\n",
      "C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\.venv\\lib\\site-packages\\win32\\lib\n",
      "C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\.venv\\lib\\site-packages\\Pythonwin\n",
      "C:\\Users\\Viki\\Documents\\Thesis\\CMU-MultimodalSDK\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "for path in sys.path:\n",
    "    print(path)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T11:20:42.984325700Z",
     "start_time": "2024-12-04T11:20:42.936131800Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "import mmsdk\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from mmsdk import mmdatasdk as md\n",
    "from subprocess import check_call, CalledProcessError"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T11:20:43.785514700Z",
     "start_time": "2024-12-04T11:20:43.328057500Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T11:20:43.968832900Z",
     "start_time": "2024-12-04T11:20:43.918888700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized destination path: C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu/CMU-MOSI/language/CMU_MOSI_TimestampedWordVectors.csd\n",
      "\u001B[91m\u001B[1m[2024-12-04 11:20:43.924] | Error   | \u001B[0mC:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu/CMU-MOSI/language/CMU_MOSI_TimestampedWordVectors.csd file already exists ...\n",
      "High-level features have been downloaded previously.\n",
      "Normalized destination path: C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu/CMU-MOSI/language/CMU_MOSI_TimestampedWords.csd\n",
      "\u001B[91m\u001B[1m[2024-12-04 11:20:43.925] | Error   | \u001B[0mC:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu/CMU-MOSI/language/CMU_MOSI_TimestampedWords.csd file already exists ...\n",
      "Raw data have been downloaded previously.\n",
      "Normalized destination path: C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu/CMU-MOSI/labels/CMU_MOSI_Opinion_Labels.csd\n",
      "\u001B[91m\u001B[1m[2024-12-04 11:20:43.925] | Error   | \u001B[0mC:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu/CMU-MOSI/labels/CMU_MOSI_Opinion_Labels.csd file already exists ...\n",
      "Labels have been downloaded previously.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# create folders for storing the data\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    check_call(' '.join(['mkdir', '-p', DATA_PATH]), shell=True)\n",
    "\n",
    "# download highlevel features, low-level (raw) data and labels for the dataset MOSI\n",
    "# if the files are already present, instead of downloading it you just load it yourself.\n",
    "# here we use CMU_MOSI dataset as example.\n",
    "\n",
    "DATASET = md.cmu_mosi\n",
    "\n",
    "try:\n",
    "    md.mmdataset(DATASET.highlevel, DATA_PATH)\n",
    "except RuntimeError:\n",
    "    print(\"High-level features have been downloaded previously.\")\n",
    "\n",
    "try:\n",
    "    md.mmdataset(DATASET.raw, DATA_PATH)\n",
    "except RuntimeError:\n",
    "    print(\"Raw data have been downloaded previously.\")\n",
    "    \n",
    "try:\n",
    "    md.mmdataset(DATASET.labels, DATA_PATH)\n",
    "except RuntimeError:\n",
    "    print(\"Labels have been downloaded previously.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the downloaded files\n",
    "\n",
    "We can print the files in the target data folder to see what files are there.\n",
    "\n",
    "We can observe a bunch of files ending with `.csd` extension. This stands for ***computational sequences***, which is the underlying data structure for all features in the SDK. We will come back to that later when we load the data. For now we just print out what computational sequences we have downloaded."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-12-04T11:20:46.908553Z",
     "start_time": "2024-12-04T11:20:46.844871900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding_and_mapping.pt\n",
      "http__immortal.multicomp.cs.cmu.edu\n"
     ]
    }
   ],
   "source": [
    "# list the directory contents... let's see what features there are\n",
    "data_files = os.listdir(DATA_PATH)\n",
    "print('\\n'.join(data_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a multimodal dataset\n",
    "\n",
    "Loading the dataset is as simple as telling the SDK what are the features you need and where are their computational sequences. You can construct a dictionary with format `{feature_name: csd_path}` and feed it to `mmdataset` object in the SDK."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\n",
      "  embedding_and_mapping.pt\n",
      "Directory: C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu\n",
      "Directory: C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu\\CMU-MOSI\n",
      "Directory: C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu\\CMU-MOSI\\acoustic\n",
      "  CMU_MOSI_COVAREP.csd\n",
      "  CMU_MOSI_OpenSmile_EB10.csd\n",
      "  CMU_MOSI_openSMILE_IS09.csd\n",
      "Directory: C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu\\CMU-MOSI\\labels\n",
      "  CMU_MOSI_Opinion_Labels.csd\n",
      "Directory: C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu\\CMU-MOSI\\language\n",
      "  CMU_MOSI_TimestampedPhones.csd\n",
      "  CMU_MOSI_TimestampedWords.csd\n",
      "  CMU_MOSI_TimestampedWordVectors.csd\n",
      "Directory: C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu\\CMU-MOSI\\visual\n",
      "  CMU_MOSI_Visual_Facet_41.csd\n",
      "  CMU_MOSI_Visual_Facet_42.csd\n",
      "  CMU_MOSI_Visual_OpenFace_1.csd\n",
      "  CMU_MOSI_Visual_OpenFace_2.csd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"C:\\\\Users\\\\Viki\\\\Documents\\\\Thesis\\\\tryout3\\\\data\"\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    print(f\"Directory: {root}\")\n",
    "    for file in files:\n",
    "        print(f\"  {file}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T11:20:48.934346Z",
     "start_time": "2024-12-04T11:20:48.891717200Z"
    }
   },
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define your different modalities - refer to the filenames of the CSD files\n",
    "visual_field_Facet41 = 'CMU_MOSI_Visual_Facet_41'\n",
    "visual_field_Facet42 = 'CMU_MOSI_Visual_Facet_42'\n",
    "visual_field_OpenFace1 = 'CMU_MOSI_Visual_OpenFace_1'\n",
    "\n",
    "\n",
    "# visual_field_OpenFace2 = 'CMU_MOSI_Visual_OpenFace_2'\n",
    "# [2024-11-24 21:59:03.886] | Error   | C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu\\http__immortal.multicomp.cs.cmu.edu\\CMU-MOSI\\visual\\CMU_MOSI_Visual_OpenFace_2.csd resource is not a valid hdf5 computational sequence format ...\n",
    "\n",
    "\n",
    "acoustic_field_COVAREP = 'CMU_MOSI_COVAREP'\n",
    "acoustic_field_OpenSmile_EB10 = 'CMU_MOSI_OpenSmile_EB10'\n",
    "acoustic_field_OpenSmile_IS09 = 'CMU_MOSI_openSMILE_IS09'\n",
    "\n",
    "\n",
    "\n",
    "text_field_Words = 'CMU_MOSI_TimestampedWords'\n",
    "text_field_Phones = 'CMU_MOSI_TimestampedPhones'\n",
    "text_field_WordVectors = 'CMU_MOSI_TimestampedWordVectors'\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T11:20:53.839291300Z",
     "start_time": "2024-12-04T11:20:53.786654Z"
    }
   },
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 8\u001B[0m\n\u001B[0;32m      1\u001B[0m feature1\u001B[38;5;241m=\u001B[39m[\n\u001B[0;32m      2\u001B[0m     text_field_Words,\n\u001B[0;32m      3\u001B[0m     visual_field_Facet41, \n\u001B[0;32m      4\u001B[0m     acoustic_field_COVAREP,\n\u001B[0;32m      5\u001B[0m ]\n\u001B[0;32m      7\u001B[0m recipe1 \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m----> 8\u001B[0m     text_field_Words: \u001B[43mos\u001B[49m\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(DATA_PATH, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttp__immortal.multicomp.cs.cmu.edu\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCMU-MOSI\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlanguage\u001B[39m\u001B[38;5;124m\"\u001B[39m, text_field_Words) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.csd\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      9\u001B[0m     \n\u001B[0;32m     10\u001B[0m     visual_field_Facet41: os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(DATA_PATH, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttp__immortal.multicomp.cs.cmu.edu\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCMU-MOSI\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvisual\u001B[39m\u001B[38;5;124m\"\u001B[39m, visual_field_Facet41) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.csd\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     11\u001B[0m     \n\u001B[0;32m     12\u001B[0m     acoustic_field_COVAREP: os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(DATA_PATH, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttp__immortal.multicomp.cs.cmu.edu\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCMU-MOSI\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124macoustic\u001B[39m\u001B[38;5;124m\"\u001B[39m, acoustic_field_COVAREP) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.csd\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     13\u001B[0m }\n",
      "\u001B[1;31mNameError\u001B[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "feature1=[\n",
    "    text_field_Words,\n",
    "    visual_field_Facet41, \n",
    "    acoustic_field_COVAREP,\n",
    "]\n",
    "\n",
    "recipe1 = {\n",
    "    text_field_Words: os.path.join(DATA_PATH, \"http__immortal.multicomp.cs.cmu.edu\", \"CMU-MOSI\", \"language\", text_field_Words) + '.csd',\n",
    "    \n",
    "    visual_field_Facet41: os.path.join(DATA_PATH, \"http__immortal.multicomp.cs.cmu.edu\", \"CMU-MOSI\", \"visual\", visual_field_Facet41) + '.csd',\n",
    "    \n",
    "    acoustic_field_COVAREP: os.path.join(DATA_PATH, \"http__immortal.multicomp.cs.cmu.edu\", \"CMU-MOSI\", \"acoustic\", acoustic_field_COVAREP) + '.csd',\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T11:20:35.771737200Z",
     "start_time": "2024-12-04T11:20:35.435023500Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-12-04T11:21:03.572651100Z",
     "start_time": "2024-12-04T11:21:02.735406900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CMU_MOSI_TimestampedWords': 'C:\\\\Users\\\\Viki\\\\Documents\\\\Thesis\\\\tryout3\\\\data\\\\http__immortal.multicomp.cs.cmu.edu\\\\CMU-MOSI\\\\language\\\\CMU_MOSI_TimestampedWords.csd', 'CMU_MOSI_TimestampedPhones': 'C:\\\\Users\\\\Viki\\\\Documents\\\\Thesis\\\\tryout3\\\\data\\\\http__immortal.multicomp.cs.cmu.edu\\\\CMU-MOSI\\\\language\\\\CMU_MOSI_TimestampedPhones.csd', 'CMU_MOSI_TimestampedWordVectors': 'C:\\\\Users\\\\Viki\\\\Documents\\\\Thesis\\\\tryout3\\\\data\\\\http__immortal.multicomp.cs.cmu.edu\\\\CMU-MOSI\\\\language\\\\CMU_MOSI_TimestampedWordVectors.csd', 'CMU_MOSI_Visual_Facet_41': 'C:\\\\Users\\\\Viki\\\\Documents\\\\Thesis\\\\tryout3\\\\data\\\\http__immortal.multicomp.cs.cmu.edu\\\\CMU-MOSI\\\\visual\\\\CMU_MOSI_Visual_Facet_41.csd', 'CMU_MOSI_Visual_Facet_42': 'C:\\\\Users\\\\Viki\\\\Documents\\\\Thesis\\\\tryout3\\\\data\\\\http__immortal.multicomp.cs.cmu.edu\\\\CMU-MOSI\\\\visual\\\\CMU_MOSI_Visual_Facet_42.csd', 'CMU_MOSI_Visual_OpenFace_1': 'C:\\\\Users\\\\Viki\\\\Documents\\\\Thesis\\\\tryout3\\\\data\\\\http__immortal.multicomp.cs.cmu.edu\\\\CMU-MOSI\\\\visual\\\\CMU_MOSI_Visual_OpenFace_1.csd', 'CMU_MOSI_COVAREP': 'C:\\\\Users\\\\Viki\\\\Documents\\\\Thesis\\\\tryout3\\\\data\\\\http__immortal.multicomp.cs.cmu.edu\\\\CMU-MOSI\\\\acoustic\\\\CMU_MOSI_COVAREP.csd', 'CMU_MOSI_OpenSmile_EB10': 'C:\\\\Users\\\\Viki\\\\Documents\\\\Thesis\\\\tryout3\\\\data\\\\http__immortal.multicomp.cs.cmu.edu\\\\CMU-MOSI\\\\acoustic\\\\CMU_MOSI_OpenSmile_EB10.csd', 'CMU_MOSI_openSMILE_IS09': 'C:\\\\Users\\\\Viki\\\\Documents\\\\Thesis\\\\tryout3\\\\data\\\\http__immortal.multicomp.cs.cmu.edu\\\\CMU-MOSI\\\\acoustic\\\\CMU_MOSI_openSMILE_IS09.csd'}\n",
      "\u001B[92m\u001B[1m[2024-12-04 11:21:02.737] | Success | \u001B[0mComputational sequence read from file C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu\\CMU-MOSI\\language\\CMU_MOSI_TimestampedWords.csd ...\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:02.763] | Status  | \u001B[0mChecking the integrity of the <words> computational sequence ...\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:02.763] | Status  | \u001B[0mChecking the format of the data in <words> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-04 11:21:02.842] | Success | \u001B[0m<words> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:02.842] | Status  | \u001B[0mChecking the format of the metadata in <words> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2024-12-04 11:21:02.842] | Warning | \u001B[0m<words> computational sequence does not have all the required metadata ... continuing \n",
      "\u001B[92m\u001B[1m[2024-12-04 11:21:02.843] | Success | \u001B[0mComputational sequence read from file C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu\\CMU-MOSI\\language\\CMU_MOSI_TimestampedPhones.csd ...\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:02.867] | Status  | \u001B[0mChecking the integrity of the <phoneme> computational sequence ...\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:02.867] | Status  | \u001B[0mChecking the format of the data in <phoneme> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-04 11:21:02.921] | Success | \u001B[0m<phoneme> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:02.922] | Status  | \u001B[0mChecking the format of the metadata in <phoneme> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2024-12-04 11:21:02.922] | Warning | \u001B[0m<phoneme> computational sequence does not have all the required metadata ... continuing \n",
      "\u001B[92m\u001B[1m[2024-12-04 11:21:02.923] | Success | \u001B[0mComputational sequence read from file C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu\\CMU-MOSI\\language\\CMU_MOSI_TimestampedWordVectors.csd ...\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:02.941] | Status  | \u001B[0mChecking the integrity of the <glove_vectors> computational sequence ...\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:02.941] | Status  | \u001B[0mChecking the format of the data in <glove_vectors> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-04 11:21:03.001] | Success | \u001B[0m<glove_vectors> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:03.001] | Status  | \u001B[0mChecking the format of the metadata in <glove_vectors> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2024-12-04 11:21:03.001] | Warning | \u001B[0m<glove_vectors> computational sequence does not have all the required metadata ... continuing \n",
      "\u001B[92m\u001B[1m[2024-12-04 11:21:03.002] | Success | \u001B[0mComputational sequence read from file C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu\\CMU-MOSI\\visual\\CMU_MOSI_Visual_Facet_41.csd ...\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:03.028] | Status  | \u001B[0mChecking the integrity of the <FACET_4.1> computational sequence ...\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:03.028] | Status  | \u001B[0mChecking the format of the data in <FACET_4.1> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-04 11:21:03.092] | Success | \u001B[0m<FACET_4.1> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:03.092] | Status  | \u001B[0mChecking the format of the metadata in <FACET_4.1> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2024-12-04 11:21:03.092] | Warning | \u001B[0m<FACET_4.1> computational sequence does not have all the required metadata ... continuing \n",
      "\u001B[92m\u001B[1m[2024-12-04 11:21:03.108] | Success | \u001B[0mComputational sequence read from file C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu\\CMU-MOSI\\visual\\CMU_MOSI_Visual_Facet_42.csd ...\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:03.135] | Status  | \u001B[0mChecking the integrity of the <FACET_4.2> computational sequence ...\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:03.136] | Status  | \u001B[0mChecking the format of the data in <FACET_4.2> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-04 11:21:03.202] | Success | \u001B[0m<FACET_4.2> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:03.202] | Status  | \u001B[0mChecking the format of the metadata in <FACET_4.2> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2024-12-04 11:21:03.202] | Warning | \u001B[0m<FACET_4.2> computational sequence does not have all the required metadata ... continuing \n",
      "\u001B[92m\u001B[1m[2024-12-04 11:21:03.204] | Success | \u001B[0mComputational sequence read from file C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu\\CMU-MOSI\\visual\\CMU_MOSI_Visual_OpenFace_1.csd ...\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:03.224] | Status  | \u001B[0mChecking the integrity of the <OpenFace_1> computational sequence ...\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:03.224] | Status  | \u001B[0mChecking the format of the data in <OpenFace_1> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-04 11:21:03.278] | Success | \u001B[0m<OpenFace_1> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:03.279] | Status  | \u001B[0mChecking the format of the metadata in <OpenFace_1> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2024-12-04 11:21:03.279] | Warning | \u001B[0m<OpenFace_1> computational sequence does not have all the required metadata ... continuing \n",
      "\u001B[92m\u001B[1m[2024-12-04 11:21:03.280] | Success | \u001B[0mComputational sequence read from file C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu\\CMU-MOSI\\acoustic\\CMU_MOSI_COVAREP.csd ...\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:03.298] | Status  | \u001B[0mChecking the integrity of the <COVAREP> computational sequence ...\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:03.298] | Status  | \u001B[0mChecking the format of the data in <COVAREP> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-04 11:21:03.358] | Success | \u001B[0m<COVAREP> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:03.358] | Status  | \u001B[0mChecking the format of the metadata in <COVAREP> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2024-12-04 11:21:03.358] | Warning | \u001B[0m<COVAREP> computational sequence does not have all the required metadata ... continuing \n",
      "\u001B[92m\u001B[1m[2024-12-04 11:21:03.359] | Success | \u001B[0mComputational sequence read from file C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu\\CMU-MOSI\\acoustic\\CMU_MOSI_OpenSmile_EB10.csd ...\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:03.381] | Status  | \u001B[0mChecking the integrity of the <OpenSmile_emobase2010> computational sequence ...\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:03.381] | Status  | \u001B[0mChecking the format of the data in <OpenSmile_emobase2010> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-04 11:21:03.439] | Success | \u001B[0m<OpenSmile_emobase2010> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:03.439] | Status  | \u001B[0mChecking the format of the metadata in <OpenSmile_emobase2010> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2024-12-04 11:21:03.439] | Warning | \u001B[0m<OpenSmile_emobase2010> computational sequence does not have all the required metadata ... continuing \n",
      "\u001B[92m\u001B[1m[2024-12-04 11:21:03.442] | Success | \u001B[0mComputational sequence read from file C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu\\CMU-MOSI\\acoustic\\CMU_MOSI_openSMILE_IS09.csd ...\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:03.462] | Status  | \u001B[0mChecking the integrity of the <b'OpenSMILE'> computational sequence ...\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:03.462] | Status  | \u001B[0mChecking the format of the data in <b'OpenSMILE'> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-04 11:21:03.505] | Success | \u001B[0m<b'OpenSMILE'> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2024-12-04 11:21:03.506] | Status  | \u001B[0mChecking the format of the metadata in <b'OpenSMILE'> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2024-12-04 11:21:03.506] | Warning | \u001B[0m<b'OpenSMILE'> computational sequence does not have all the required metadata ... continuing \n",
      "\u001B[92m\u001B[1m[2024-12-04 11:21:03.506] | Success | \u001B[0mDataset initialized successfully ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "# text_field = 'CMU_MOSI_ModifiedTimestampedWords'\n",
    "\n",
    "\n",
    "# List of features\n",
    "features = [\n",
    "    text_field_Words,\n",
    "    text_field_Phones,\n",
    "    text_field_WordVectors,\n",
    "    visual_field_Facet41, \n",
    "    visual_field_Facet42,\n",
    "    visual_field_OpenFace1,\n",
    "    # visual_field_OpenFace2,\n",
    "    acoustic_field_COVAREP,\n",
    "    acoustic_field_OpenSmile_IS09,\n",
    "    acoustic_field_OpenSmile_EB10\n",
    "]\n",
    "\n",
    "\n",
    "# Recipe with correct subdirectory paths for each modality\n",
    "recipe = {\n",
    "    text_field_Words: os.path.join(DATA_PATH, \"http__immortal.multicomp.cs.cmu.edu\", \"CMU-MOSI\", \"language\", text_field_Words) + '.csd',\n",
    "    \n",
    "    # not helpful\n",
    "    text_field_Phones: os.path.join(DATA_PATH, \"http__immortal.multicomp.cs.cmu.edu\",\"CMU-MOSI\", \"language\", text_field_Phones) + '.csd',\n",
    "\n",
    "    text_field_WordVectors: os.path.join(DATA_PATH, \"http__immortal.multicomp.cs.cmu.edu\", \"CMU-MOSI\", \"language\", text_field_WordVectors) + '.csd',\n",
    "    \n",
    "    visual_field_Facet41: os.path.join(DATA_PATH, \"http__immortal.multicomp.cs.cmu.edu\", \"CMU-MOSI\", \"visual\", visual_field_Facet41) + '.csd',\n",
    "    \n",
    "    visual_field_Facet42: os.path.join(DATA_PATH, \"http__immortal.multicomp.cs.cmu.edu\", \"CMU-MOSI\", \"visual\", visual_field_Facet42) + '.csd',\n",
    "    \n",
    "    visual_field_OpenFace1: os.path.join(DATA_PATH, \"http__immortal.multicomp.cs.cmu.edu\", \"CMU-MOSI\", \"visual\", visual_field_OpenFace1) + '.csd',\n",
    "    \n",
    "    \n",
    "    #not taken into account cause not runnable - \n",
    "    # visual_field_OpenFace2: os.path.join(DATA_PATH, \"http__immortal.multicomp.cs.cmu.edu\", \"CMU-MOSI\", \"visual\", visual_field_OpenFace2) + '.csd',\n",
    "    \n",
    "    acoustic_field_COVAREP: os.path.join(DATA_PATH, \"http__immortal.multicomp.cs.cmu.edu\", \"CMU-MOSI\", \"acoustic\", acoustic_field_COVAREP) + '.csd',\n",
    "    \n",
    "    acoustic_field_OpenSmile_EB10: os.path.join(DATA_PATH, \"http__immortal.multicomp.cs.cmu.edu\", \"CMU-MOSI\", \"acoustic\", acoustic_field_OpenSmile_EB10) + '.csd',\n",
    "    \n",
    "    # has same and less features as EB10\n",
    "    acoustic_field_OpenSmile_IS09: os.path.join(DATA_PATH, \"http__immortal.multicomp.cs.cmu.edu\", \"CMU-MOSI\", \"acoustic\", acoustic_field_OpenSmile_IS09) + '.csd'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "print (recipe)\n",
    "dataset = md.mmdataset(recipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## A peek into the dataset\n",
    "\n",
    "The multimodal dataset, after loaded, has the following hierarchy:\n",
    "\n",
    "\n",
    "```\n",
    "            computational_sequence_1 ---...\n",
    "           /                                   ...\n",
    "          /                                    /\n",
    "         /                          first_video     features -- T X N array\n",
    "        /                          /               /\n",
    "dataset ---computational_sequence_2 -- second_video\n",
    "        \\                          \\               \\\n",
    "         \\                          third_video     intervals -- T X 2 array\n",
    "          \\                                    \\...\n",
    "           \\\n",
    "            computational_sequence_3 ---...\n",
    "```\n",
    "\n",
    "It looks like a nested dictionary and can be indexed as if it is a nested dictionary. A dataset contains multiple computational sequences whose key is the `text_field`, `visual_field`, `acoustic_field` as defined above. Each computational sequence, however, has multiple video IDs in it, and different computational sequences are supposed to have the same set of video IDs. Within each video, there are two arrays: `features` and `intervals`, denoting the feature values at each time step and the start and end timestamp for each step. We can take a look at its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T19:10:00.031701300Z",
     "start_time": "2024-12-02T19:09:58.887115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CMU_MOSI_TimestampedWords', 'CMU_MOSI_TimestampedWordVectors', 'CMU_MOSI_Visual_Facet_41', 'CMU_MOSI_COVAREP']\n",
      "================================================================================\n",
      "['03bSnISJMiM', '0h-zjBukYpk', '1DmNV9C1hbY', '1iG0909rllw', '2WGyTLYerpo', '2iD-tVS8NPw', '5W7Z1C_fDaE', '6Egk_28TtTM', '6_0THN4chvY', '73jzhE8R1TQ', '7JsX8y1ysxY', '8OtFthrtaJM', '8d-gEyoeBzc', '8qrpnFRGt2A', '9J25DZhivz8', '9T9Hf74oK10', '9c67fiY0wGQ', '9qR7uwkblbs', 'Af8D0E4ZXaw', 'BI97DNYfe5I', 'BXuRRbG0Ugk', 'Bfr499ggo-0', 'BioHAh1qJAQ', 'BvYR0L6f2Ig', 'Ci-AH39fi3Y', 'Clx4VXItLTE', 'Dg_0XKD0Mf4', 'G-xst2euQUc', 'G6GlGvlkxAQ', 'GWuJjcEuzt8', 'HEsqda8_d0Q', 'I5y0__X72p0', 'Iu2PFX3z_1s', 'IumbAb8q2dM', 'Jkswaaud0hk', 'LSi-o-IrDMs', 'MLal-t_vJPM', 'Njd1F0vZSm4', 'Nzq88NnDkEk', 'OQvJTdtJ2H4', 'OtBXNcAL_lE', 'Oz06ZWiO20M', 'POKffnXeBds', 'PZ-lDQFboO8', 'QN9ZIUWUXsY', 'Qr1Ca94K55A', 'Sqr0AcuoNnk', 'TvyZBvOMOTc', 'VCslbP0mgZI', 'VbQk4H8hgr0', 'Vj1wYRQjB-o', 'W8NXH0Djyww', 'WKA5OygbEKI', 'X3j2zQgwYgE', 'ZAIRrfG22O0', 'ZUXBRvtny7o', '_dI--eQ6qVU', 'aiEXnCPZubE', 'atnd_PF-Lbs', 'bOL9jKpeJRs', 'bvLlb-M3UXU', 'c5xsKMxpXnc', 'c7UH_rxdZv4', 'cM3Yna7AavY', 'cW1FSBF59ik', 'cXypl4FnoZo', 'd3_k5Xpfmik', 'd6hH302o4v8', 'dq3Nf_lMPnE', 'etzxEpPuc6I', 'f9O3YtZ2VfI', 'f_pcplsH_V0', 'fvVhgmXxadc', 'iiK8YX8oH1E', 'jUzDDGyPkXU', 'k5Y_838nuGo', 'lXPQBPVc5Cw', 'nbWiPyCm4g0', 'nzpVDcQ0ywM', 'ob23OKe5a9Q', 'pLTX3ipuDJI', 'phBUpBr1hSo', 'rnaNMUZpvvg', 'tIrG4oNLFzE', 'tStelxIAHjw', 'tmZoasNr4rU', 'v0zCBqDeKcE', 'vvZ4IcEtiZc', 'vyB00TXsimI', 'wMbj6ajWbic', 'yDtzw_Y-7RU', 'yvsjCA6Y5Fc', 'zhpQhgha_KU']\n",
      "================================================================================\n",
      "['features', 'intervals']\n",
      "================================================================================\n",
      "[5404, 2]\n",
      "================================================================================\n",
      "[5404, 47]\n",
      "[645, 1]\n",
      "[18009, 74]\n",
      "Different modalities have different number of time steps!\n"
     ]
    }
   ],
   "source": [
    "print(list(dataset.keys()))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(list(dataset[visual_field_Facet41].keys()))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "some_id = list(dataset[visual_field_Facet41].keys())[15]\n",
    "print(list(dataset[visual_field_Facet41][some_id].keys()))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(list(dataset[visual_field_Facet41][some_id]['intervals'].shape))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(list(dataset[visual_field_Facet41][some_id]['features'].shape))\n",
    "print(list(dataset[text_field_Words][some_id]['features'].shape))\n",
    "print(list(dataset[acoustic_field_COVAREP][some_id]['features'].shape))\n",
    "print(\"Different modalities have different number of time steps!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Metadata FACE 41 Visual===\n",
      "\n",
      "Visual FACE 41 Metadata: {'alignment compatible': True, 'computational sequence description': 'FACET 4.1 Visual Features for CMU-MOSI Dataset', 'computational sequence version': 1.0, 'contact': 'abagherz@andrew.cmu.edu', 'creator': 'Amir Zadeh', 'dataset bib citation': '@article{zadeh2016multimodal,title={Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages},author={Zadeh, Amir and Zellers, Rowan and Pincus, Eli and Morency, Louis-Philippe},journal={IEEE Intelligent Systems},volume={31},number={6},pages={82--88},year={2016},publisher={IEEE}}', 'dataset name': 'CMU-MOSI', 'dataset version': 1.0, 'dimension names': ['Face X', 'Face Y', 'Face Width', 'Face Height', 'angerEvidence', 'contemptEvidence', 'disgustEvidence', 'joyEvidence', 'fearEvidence', 'negativeEvidence', 'neutralEvidence', 'positiveEvidence', 'sadnessEvidence', 'surpriseEvidence', 'confusionEvidence', 'frustrationEvidence', 'angerIntensity', 'contemptIntensity', 'disgustIntensity', 'joyIntensity', 'fearIntensity', 'negativeIntensity', 'neutralIntensity', 'positiveIntensity', 'sadnessIntensity', 'surpriseIntensity', 'confusionIntensity', 'frustrationIntensity', 'AU1Evidence', 'AU2Evidence', 'AU4Evidence', 'AU5Evidence', 'AU6Evidence', 'AU7Evidence', 'AU9Evidence', 'AU10Evidence', 'AU12Evidence', 'AU14Evidence', 'AU15Evidence', 'AU17Evidence', 'AU18Evidence', 'AU20Evidence', 'AU23Evidence', 'AU24Evidence', 'AU25Evidence', 'AU26Evidence', 'AU28Evidence'], 'featureset bib citation': '@online{emotient,author = {iMotions},title = {Facial Expression Analysis},year = {2017},url = {goo.gl/1rh1JN}}', 'md5': None, 'root name': 'FACET_4.1', 'uuid': '75b82d70-387f-4c1a-935e-99462b7e4388'}\n",
      "\n",
      "\n",
      "=== Metadata COVAREP Acoustic===\n",
      "\n",
      "Acoustic COVAREP Metadata: {'alignment compatible': True, 'computational sequence description': 'COVAREP Acoustic Features for CMU-MOSI Dataset', 'computational sequence version': 1.0, 'contact': 'abagherz@andrew.cmu.edu', 'creator': 'Amir Zadeh', 'dataset bib citation': '@article{zadeh2016multimodal,title={Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages},author={Zadeh, Amir and Zellers, Rowan and Pincus, Eli and Morency, Louis-Philippe},journal={IEEE Intelligent Systems},volume={31},number={6},pages={82--88},year={2016},publisher={IEEE}}', 'dataset name': 'CMU-MOSI', 'dataset version': 1.0, 'dimension names': ['F0', 'VUV', 'NAQ', 'QOQ', 'H1H2', 'PSP', 'MDQ', 'peakSlope', 'Rd', 'Rd_conf', 'creak', 'MCEP_0', 'MCEP_1', 'MCEP_2', 'MCEP_3', 'MCEP_4', 'MCEP_5', 'MCEP_6', 'MCEP_7', 'MCEP_8', 'MCEP_9', 'MCEP_10', 'MCEP_11', 'MCEP_12', 'MCEP_13', 'MCEP_14', 'MCEP_15', 'MCEP_16', 'MCEP_17', 'MCEP_18', 'MCEP_19', 'MCEP_20', 'MCEP_21', 'MCEP_22', 'MCEP_23', 'MCEP_24', 'HMPDM_0', 'HMPDM_1', 'HMPDM_2', 'HMPDM_3', 'HMPDM_4', 'HMPDM_5', 'HMPDM_6', 'HMPDM_7', 'HMPDM_8', 'HMPDM_9', 'HMPDM_10', 'HMPDM_11', 'HMPDM_12', 'HMPDM_13', 'HMPDM_14', 'HMPDM_15', 'HMPDM_16', 'HMPDM_17', 'HMPDM_18', 'HMPDM_19', 'HMPDM_20', 'HMPDM_21', 'HMPDM_22', 'HMPDM_23', 'HMPDM_24', 'HMPDD_0', 'HMPDD_1', 'HMPDD_2', 'HMPDD_3', 'HMPDD_4', 'HMPDD_5', 'HMPDD_6', 'HMPDD_7', 'HMPDD_8', 'HMPDD_9', 'HMPDD_10', 'HMPDD_11', 'HMPDD_12'], 'featureset bib citation': '@inproceedings{degottex2014covarep,title={COVAREP-A collaborative voice analysis repository for speech technologies},author={Degottex, Gilles and Kane, John and Drugman, Thomas and Raitio, Tuomo and Scherer, Stefan},booktitle={Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International Conference on},pages={960--964},year={2014},organization={IEEE}}', 'md5': None, 'root name': 'COVAREP', 'uuid': 'b3040d49-2a1b-45f8-b991-16fb1acc75c5'}\n",
      "\n",
      "\n",
      "=== Metadata Words===\n",
      "\n",
      "Words Metadata: {'alignment compatible': False, 'computational sequence description': 'Word sequences for CMU-MOSI Dataset', 'computational sequence version': 1.0, 'contact': 'abagherz@andrew.cmu.edu', 'creator': 'Amir Zadeh', 'dataset bib citation': '@article{zadeh2016multimodal,title={Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages},author={Zadeh, Amir and Zellers, Rowan and Pincus, Eli and Morency, Louis-Philippe},journal={IEEE Intelligent Systems},volume={31},number={6},pages={82--88},year={2016},publisher={IEEE}}', 'dataset name': 'CMU-MOSI', 'dataset version': 1.0, 'dimension names': ['word'], 'featureset bib citation': '@article{P2FA,title={Speaker identification on the SCOTUS corpus},author={Yuan, Jiahong and Liberman, Mark},journal={Journal of the Acoustical Society of America},volume={123},number={5},pages={3878},year={2008},publisher={[New York: Acoustical Society of America]}}', 'md5': None, 'root name': 'words', 'uuid': 'cf8e3281-bcec-49ff-be0e-6f98b55ad4d0'}\n",
      "\n",
      "\n",
      "=== Metadata WordVectors===\n",
      "\n",
      "WordVectors Metadata: {'alignment compatible': True, 'computational sequence description': 'Word vector sequences for CMU-MOSI Dataset', 'computational sequence version': 1.0, 'contact': 'abagherz@andrew.cmu.edu', 'creator': 'Amir Zadeh', 'dataset bib citation': '@article{zadeh2016multimodal,title={Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages},author={Zadeh, Amir and Zellers, Rowan and Pincus, Eli and Morency, Louis-Philippe},journal={IEEE Intelligent Systems},volume={31},number={6},pages={82--88},year={2016},publisher={IEEE}}', 'dataset name': 'CMU-MOSI', 'dataset version': 1.0, 'dimension names': ['glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector'], 'featureset bib citation': '@inproceedings{pennington2014glove,title={Glove: Global vectors for word representation},author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher},booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},pages={1532--1543},year={2014}}', 'md5': None, 'root name': 'glove_vectors', 'uuid': '156d7173-63fc-476b-8fc7-636283a7edb3'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=== Metadata FACE 41 Visual===\\n\")\n",
    "print(\"Visual FACE 41 Metadata:\", dataset[visual_field_Facet41].metadata)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"=== Metadata COVAREP Acoustic===\\n\")\n",
    "print(\"Acoustic COVAREP Metadata:\", dataset[acoustic_field_COVAREP].metadata)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"=== Metadata Words===\\n\")\n",
    "print(\"Words Metadata:\", dataset[text_field_Words].metadata)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"=== Metadata WordVectors===\\n\")\n",
    "print(\"WordVectors Metadata:\", dataset[text_field_WordVectors].metadata)\n",
    "print(\"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T19:10:00.767096200Z",
     "start_time": "2024-12-02T19:09:59.466660400Z"
    }
   },
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Metadata FACE 41 Visual===\n",
      "\n",
      "Visual FACE 41 Metadata: {'alignment compatible': True, 'computational sequence description': 'FACET 4.1 Visual Features for CMU-MOSI Dataset', 'computational sequence version': 1.0, 'contact': 'abagherz@andrew.cmu.edu', 'creator': 'Amir Zadeh', 'dataset bib citation': '@article{zadeh2016multimodal,title={Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages},author={Zadeh, Amir and Zellers, Rowan and Pincus, Eli and Morency, Louis-Philippe},journal={IEEE Intelligent Systems},volume={31},number={6},pages={82--88},year={2016},publisher={IEEE}}', 'dataset name': 'CMU-MOSI', 'dataset version': 1.0, 'dimension names': ['Face X', 'Face Y', 'Face Width', 'Face Height', 'angerEvidence', 'contemptEvidence', 'disgustEvidence', 'joyEvidence', 'fearEvidence', 'negativeEvidence', 'neutralEvidence', 'positiveEvidence', 'sadnessEvidence', 'surpriseEvidence', 'confusionEvidence', 'frustrationEvidence', 'angerIntensity', 'contemptIntensity', 'disgustIntensity', 'joyIntensity', 'fearIntensity', 'negativeIntensity', 'neutralIntensity', 'positiveIntensity', 'sadnessIntensity', 'surpriseIntensity', 'confusionIntensity', 'frustrationIntensity', 'AU1Evidence', 'AU2Evidence', 'AU4Evidence', 'AU5Evidence', 'AU6Evidence', 'AU7Evidence', 'AU9Evidence', 'AU10Evidence', 'AU12Evidence', 'AU14Evidence', 'AU15Evidence', 'AU17Evidence', 'AU18Evidence', 'AU20Evidence', 'AU23Evidence', 'AU24Evidence', 'AU25Evidence', 'AU26Evidence', 'AU28Evidence'], 'featureset bib citation': '@online{emotient,author = {iMotions},title = {Facial Expression Analysis},year = {2017},url = {goo.gl/1rh1JN}}', 'md5': None, 'root name': 'FACET_4.1', 'uuid': '75b82d70-387f-4c1a-935e-99462b7e4388'}\n",
      "\n",
      "\n",
      "=== Metadata FACE 42 Visual===\n",
      "\n",
      "Visual FACE 42 Metadata: {'alignment compatible': True, 'computational sequence description': 'FACET 4.2 Visual Features for CMU-MOSI Dataset', 'computational sequence version': 1.0, 'contact': 'abagherz@andrew.cmu.edu', 'creator': 'Amir Zadeh', 'dataset bib citation': '@article{zadeh2016multimodal,title={Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages},author={Zadeh, Amir and Zellers, Rowan and Pincus, Eli and Morency, Louis-Philippe},journal={IEEE Intelligent Systems},volume={31},number={6},pages={82--88},year={2016},publisher={IEEE}}', 'dataset name': 'CMU-MOSI', 'dataset version': 1.0, 'dimension names': ['Anger', 'Contempt', 'Disgust', 'Joy', 'Fear', 'Baseline', 'Sadness', 'Surprise', 'Confusion', 'Frustration', 'AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU18', 'AU20', 'AU23', 'AU24', 'AU25', 'AU26', 'AU28', 'AU43', 'Has_Glasses', 'Is_Male', 'Pitch', 'Yaw', 'Roll'], 'featureset bib citation': '@online{emotient,author = {iMotions},title = {Facial Expression Analysis},year = {2017},url = {goo.gl/1rh1JN}}', 'md5': None, 'root name': 'FACET_4.2', 'uuid': '9d512b65-f94f-4972-bf81-9845173620fa'}\n",
      "\n",
      "\n",
      "=== Metadata OpenFace Visual===\n",
      "\n",
      "Visual OpenFace Metadata: {'alignment compatible': True, 'computational sequence description': 'OpenFace V1 Visual Features for CMU-MOSI Dataset', 'computational sequence version': 1.0, 'contact': 'abagherz@andrew.cmu.edu', 'creator': 'Amir Zadeh', 'dataset bib citation': '@article{zadeh2016multimodal,title={Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages},author={Zadeh, Amir and Zellers, Rowan and Pincus, Eli and Morency, Louis-Philippe},journal={IEEE Intelligent Systems},volume={31},number={6},pages={82--88},year={2016},publisher={IEEE}}', 'dataset name': 'CMU-MOSI', 'dataset version': 1.0, 'dimension names': ['timestamp', 'confidence', 'success', 'gaze_0_x', 'gaze_0_y', 'gaze_0_z', 'gaze_1_x', 'gaze_1_y', 'gaze_1_z', 'pose_Tx', 'pose_Ty', 'pose_Tz', 'pose_Rx', 'pose_Ry', 'pose_Rz', 'x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9', 'x_10', 'x_11', 'x_12', 'x_13', 'x_14', 'x_15', 'x_16', 'x_17', 'x_18', 'x_19', 'x_20', 'x_21', 'x_22', 'x_23', 'x_24', 'x_25', 'x_26', 'x_27', 'x_28', 'x_29', 'x_30', 'x_31', 'x_32', 'x_33', 'x_34', 'x_35', 'x_36', 'x_37', 'x_38', 'x_39', 'x_40', 'x_41', 'x_42', 'x_43', 'x_44', 'x_45', 'x_46', 'x_47', 'x_48', 'x_49', 'x_50', 'x_51', 'x_52', 'x_53', 'x_54', 'x_55', 'x_56', 'x_57', 'x_58', 'x_59', 'x_60', 'x_61', 'x_62', 'x_63', 'x_64', 'x_65', 'x_66', 'x_67', 'y_0', 'y_1', 'y_2', 'y_3', 'y_4', 'y_5', 'y_6', 'y_7', 'y_8', 'y_9', 'y_10', 'y_11', 'y_12', 'y_13', 'y_14', 'y_15', 'y_16', 'y_17', 'y_18', 'y_19', 'y_20', 'y_21', 'y_22', 'y_23', 'y_24', 'y_25', 'y_26', 'y_27', 'y_28', 'y_29', 'y_30', 'y_31', 'y_32', 'y_33', 'y_34', 'y_35', 'y_36', 'y_37', 'y_38', 'y_39', 'y_40', 'y_41', 'y_42', 'y_43', 'y_44', 'y_45', 'y_46', 'y_47', 'y_48', 'y_49', 'y_50', 'y_51', 'y_52', 'y_53', 'y_54', 'y_55', 'y_56', 'y_57', 'y_58', 'y_59', 'y_60', 'y_61', 'y_62', 'y_63', 'y_64', 'y_65', 'y_66', 'y_67', 'X_0', 'X_1', 'X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7', 'X_8', 'X_9', 'X_10', 'X_11', 'X_12', 'X_13', 'X_14', 'X_15', 'X_16', 'X_17', 'X_18', 'X_19', 'X_20', 'X_21', 'X_22', 'X_23', 'X_24', 'X_25', 'X_26', 'X_27', 'X_28', 'X_29', 'X_30', 'X_31', 'X_32', 'X_33', 'X_34', 'X_35', 'X_36', 'X_37', 'X_38', 'X_39', 'X_40', 'X_41', 'X_42', 'X_43', 'X_44', 'X_45', 'X_46', 'X_47', 'X_48', 'X_49', 'X_50', 'X_51', 'X_52', 'X_53', 'X_54', 'X_55', 'X_56', 'X_57', 'X_58', 'X_59', 'X_60', 'X_61', 'X_62', 'X_63', 'X_64', 'X_65', 'X_66', 'X_67', 'Y_0', 'Y_1', 'Y_2', 'Y_3', 'Y_4', 'Y_5', 'Y_6', 'Y_7', 'Y_8', 'Y_9', 'Y_10', 'Y_11', 'Y_12', 'Y_13', 'Y_14', 'Y_15', 'Y_16', 'Y_17', 'Y_18', 'Y_19', 'Y_20', 'Y_21', 'Y_22', 'Y_23', 'Y_24', 'Y_25', 'Y_26', 'Y_27', 'Y_28', 'Y_29', 'Y_30', 'Y_31', 'Y_32', 'Y_33', 'Y_34', 'Y_35', 'Y_36', 'Y_37', 'Y_38', 'Y_39', 'Y_40', 'Y_41', 'Y_42', 'Y_43', 'Y_44', 'Y_45', 'Y_46', 'Y_47', 'Y_48', 'Y_49', 'Y_50', 'Y_51', 'Y_52', 'Y_53', 'Y_54', 'Y_55', 'Y_56', 'Y_57', 'Y_58', 'Y_59', 'Y_60', 'Y_61', 'Y_62', 'Y_63', 'Y_64', 'Y_65', 'Y_66', 'Y_67', 'Z_0', 'Z_1', 'Z_2', 'Z_3', 'Z_4', 'Z_5', 'Z_6', 'Z_7', 'Z_8', 'Z_9', 'Z_10', 'Z_11', 'Z_12', 'Z_13', 'Z_14', 'Z_15', 'Z_16', 'Z_17', 'Z_18', 'Z_19', 'Z_20', 'Z_21', 'Z_22', 'Z_23', 'Z_24', 'Z_25', 'Z_26', 'Z_27', 'Z_28', 'Z_29', 'Z_30', 'Z_31', 'Z_32', 'Z_33', 'Z_34', 'Z_35', 'Z_36', 'Z_37', 'Z_38', 'Z_39', 'Z_40', 'Z_41', 'Z_42', 'Z_43', 'Z_44', 'Z_45', 'Z_46', 'Z_47', 'Z_48', 'Z_49', 'Z_50', 'Z_51', 'Z_52', 'Z_53', 'Z_54', 'Z_55', 'Z_56', 'Z_57', 'Z_58', 'Z_59', 'Z_60', 'Z_61', 'Z_62', 'Z_63', 'Z_64', 'Z_65', 'Z_66', 'Z_67', 'p_scale', 'p_rx', 'p_ry', 'p_rz', 'p_tx', 'p_ty', 'p_0', 'p_1', 'p_2', 'p_3', 'p_4', 'p_5', 'p_6', 'p_7', 'p_8', 'p_9', 'p_10', 'p_11', 'p_12', 'p_13', 'p_14', 'p_15', 'p_16', 'p_17', 'p_18', 'p_19', 'p_20', 'p_21', 'p_22', 'p_23', 'p_24', 'p_25', 'p_26', 'p_27', 'p_28', 'p_29', 'p_30', 'p_31', 'p_32', 'p_33', 'AU01_r', 'AU02_r', 'AU04_r', 'AU05_r', 'AU06_r', 'AU07_r', 'AU09_r', 'AU10_r', 'AU12_r', 'AU14_r', 'AU15_r', 'AU17_r', 'AU20_r', 'AU23_r', 'AU25_r', 'AU26_r', 'AU45_r', 'AU01_c', 'AU02_c', 'AU04_c', 'AU05_c', 'AU06_c', 'AU07_c', 'AU09_c', 'AU10_c', 'AU12_c', 'AU14_c', 'AU15_c', 'AU17_c', 'AU20_c', 'AU23_c', 'AU25_c', 'AU26_c', 'AU28_c', 'AU45_c'], 'featureset bib citation': '@inproceedings{baltrusaitis2018openface,title={OpenFace 2.0: Facial Behavior Analysis Toolkit},author={Baltrusaitis, Tadas and Zadeh, Amir and Lim, Yao Chong and Morency, Louis-Philippe},booktitle={Automatic Face \\\\& Gesture Recognition (FG 2018), 2018 13th IEEE International Conference on},pages={59--66},year={2018},organization={IEEE}}', 'md5': None, 'root name': 'OpenFace_1', 'uuid': '42fee302-b4f3-4b64-b39f-d196dcf6e1fb'}\n",
      "\n",
      "\n",
      "=== Metadata COVAREP Acoustic===\n",
      "\n",
      "Acoustic COVAREP Metadata: {'alignment compatible': True, 'computational sequence description': 'COVAREP Acoustic Features for CMU-MOSI Dataset', 'computational sequence version': 1.0, 'contact': 'abagherz@andrew.cmu.edu', 'creator': 'Amir Zadeh', 'dataset bib citation': '@article{zadeh2016multimodal,title={Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages},author={Zadeh, Amir and Zellers, Rowan and Pincus, Eli and Morency, Louis-Philippe},journal={IEEE Intelligent Systems},volume={31},number={6},pages={82--88},year={2016},publisher={IEEE}}', 'dataset name': 'CMU-MOSI', 'dataset version': 1.0, 'dimension names': ['F0', 'VUV', 'NAQ', 'QOQ', 'H1H2', 'PSP', 'MDQ', 'peakSlope', 'Rd', 'Rd_conf', 'creak', 'MCEP_0', 'MCEP_1', 'MCEP_2', 'MCEP_3', 'MCEP_4', 'MCEP_5', 'MCEP_6', 'MCEP_7', 'MCEP_8', 'MCEP_9', 'MCEP_10', 'MCEP_11', 'MCEP_12', 'MCEP_13', 'MCEP_14', 'MCEP_15', 'MCEP_16', 'MCEP_17', 'MCEP_18', 'MCEP_19', 'MCEP_20', 'MCEP_21', 'MCEP_22', 'MCEP_23', 'MCEP_24', 'HMPDM_0', 'HMPDM_1', 'HMPDM_2', 'HMPDM_3', 'HMPDM_4', 'HMPDM_5', 'HMPDM_6', 'HMPDM_7', 'HMPDM_8', 'HMPDM_9', 'HMPDM_10', 'HMPDM_11', 'HMPDM_12', 'HMPDM_13', 'HMPDM_14', 'HMPDM_15', 'HMPDM_16', 'HMPDM_17', 'HMPDM_18', 'HMPDM_19', 'HMPDM_20', 'HMPDM_21', 'HMPDM_22', 'HMPDM_23', 'HMPDM_24', 'HMPDD_0', 'HMPDD_1', 'HMPDD_2', 'HMPDD_3', 'HMPDD_4', 'HMPDD_5', 'HMPDD_6', 'HMPDD_7', 'HMPDD_8', 'HMPDD_9', 'HMPDD_10', 'HMPDD_11', 'HMPDD_12'], 'featureset bib citation': '@inproceedings{degottex2014covarep,title={COVAREP-A collaborative voice analysis repository for speech technologies},author={Degottex, Gilles and Kane, John and Drugman, Thomas and Raitio, Tuomo and Scherer, Stefan},booktitle={Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International Conference on},pages={960--964},year={2014},organization={IEEE}}', 'md5': None, 'root name': 'COVAREP', 'uuid': 'b3040d49-2a1b-45f8-b991-16fb1acc75c5'}\n",
      "\n",
      "\n",
      "=== Metadata OpenSmile EB10 Acoustic===\n",
      "\n",
      "Acoustic OpenSmile EB10 Metadata: {'alignment compatible': True, 'computational sequence description': 'OpenSmile emobase2010 Acoustic Features for CMU-MOSI Dataset', 'computational sequence version': 1.0, 'contact': 'abagherz@andrew.cmu.edu', 'creator': 'Amir Zadeh', 'dataset bib citation': '@article{zadeh2016multimodal,title={Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages},author={Zadeh, Amir and Zellers, Rowan and Pincus, Eli and Morency, Louis-Philippe},journal={IEEE Intelligent Systems},volume={31},number={6},pages={82--88},year={2016},publisher={IEEE}}', 'dataset name': 'CMU-MOSI', 'dataset version': 1.0, 'dimension names': ['frameIndex', 'frameTime', 'pcm_loudness_sma_maxPos', 'pcm_loudness_sma_minPos', 'pcm_loudness_sma_amean', 'pcm_loudness_sma_linregc1', 'pcm_loudness_sma_linregc2', 'pcm_loudness_sma_linregerrA', 'pcm_loudness_sma_linregerrQ', 'pcm_loudness_sma_stddev', 'pcm_loudness_sma_skewness', 'pcm_loudness_sma_kurtosis', 'pcm_loudness_sma_quartile1', 'pcm_loudness_sma_quartile2', 'pcm_loudness_sma_quartile3', 'pcm_loudness_sma_iqr1-2', 'pcm_loudness_sma_iqr2-3', 'pcm_loudness_sma_iqr1-3', 'pcm_loudness_sma_percentile1.0', 'pcm_loudness_sma_percentile99.0', 'pcm_loudness_sma_pctlrange0-1', 'pcm_loudness_sma_upleveltime75', 'pcm_loudness_sma_upleveltime90', 'pcm_fftMag_mfcc_sma[0]_maxPos', 'pcm_fftMag_mfcc_sma[0]_minPos', 'pcm_fftMag_mfcc_sma[0]_amean', 'pcm_fftMag_mfcc_sma[0]_linregc1', 'pcm_fftMag_mfcc_sma[0]_linregc2', 'pcm_fftMag_mfcc_sma[0]_linregerrA', 'pcm_fftMag_mfcc_sma[0]_linregerrQ', 'pcm_fftMag_mfcc_sma[0]_stddev', 'pcm_fftMag_mfcc_sma[0]_skewness', 'pcm_fftMag_mfcc_sma[0]_kurtosis', 'pcm_fftMag_mfcc_sma[0]_quartile1', 'pcm_fftMag_mfcc_sma[0]_quartile2', 'pcm_fftMag_mfcc_sma[0]_quartile3', 'pcm_fftMag_mfcc_sma[0]_iqr1-2', 'pcm_fftMag_mfcc_sma[0]_iqr2-3', 'pcm_fftMag_mfcc_sma[0]_iqr1-3', 'pcm_fftMag_mfcc_sma[0]_percentile1.0', 'pcm_fftMag_mfcc_sma[0]_percentile99.0', 'pcm_fftMag_mfcc_sma[0]_pctlrange0-1', 'pcm_fftMag_mfcc_sma[0]_upleveltime75', 'pcm_fftMag_mfcc_sma[0]_upleveltime90', 'pcm_fftMag_mfcc_sma[1]_maxPos', 'pcm_fftMag_mfcc_sma[1]_minPos', 'pcm_fftMag_mfcc_sma[1]_amean', 'pcm_fftMag_mfcc_sma[1]_linregc1', 'pcm_fftMag_mfcc_sma[1]_linregc2', 'pcm_fftMag_mfcc_sma[1]_linregerrA', 'pcm_fftMag_mfcc_sma[1]_linregerrQ', 'pcm_fftMag_mfcc_sma[1]_stddev', 'pcm_fftMag_mfcc_sma[1]_skewness', 'pcm_fftMag_mfcc_sma[1]_kurtosis', 'pcm_fftMag_mfcc_sma[1]_quartile1', 'pcm_fftMag_mfcc_sma[1]_quartile2', 'pcm_fftMag_mfcc_sma[1]_quartile3', 'pcm_fftMag_mfcc_sma[1]_iqr1-2', 'pcm_fftMag_mfcc_sma[1]_iqr2-3', 'pcm_fftMag_mfcc_sma[1]_iqr1-3', 'pcm_fftMag_mfcc_sma[1]_percentile1.0', 'pcm_fftMag_mfcc_sma[1]_percentile99.0', 'pcm_fftMag_mfcc_sma[1]_pctlrange0-1', 'pcm_fftMag_mfcc_sma[1]_upleveltime75', 'pcm_fftMag_mfcc_sma[1]_upleveltime90', 'pcm_fftMag_mfcc_sma[2]_maxPos', 'pcm_fftMag_mfcc_sma[2]_minPos', 'pcm_fftMag_mfcc_sma[2]_amean', 'pcm_fftMag_mfcc_sma[2]_linregc1', 'pcm_fftMag_mfcc_sma[2]_linregc2', 'pcm_fftMag_mfcc_sma[2]_linregerrA', 'pcm_fftMag_mfcc_sma[2]_linregerrQ', 'pcm_fftMag_mfcc_sma[2]_stddev', 'pcm_fftMag_mfcc_sma[2]_skewness', 'pcm_fftMag_mfcc_sma[2]_kurtosis', 'pcm_fftMag_mfcc_sma[2]_quartile1', 'pcm_fftMag_mfcc_sma[2]_quartile2', 'pcm_fftMag_mfcc_sma[2]_quartile3', 'pcm_fftMag_mfcc_sma[2]_iqr1-2', 'pcm_fftMag_mfcc_sma[2]_iqr2-3', 'pcm_fftMag_mfcc_sma[2]_iqr1-3', 'pcm_fftMag_mfcc_sma[2]_percentile1.0', 'pcm_fftMag_mfcc_sma[2]_percentile99.0', 'pcm_fftMag_mfcc_sma[2]_pctlrange0-1', 'pcm_fftMag_mfcc_sma[2]_upleveltime75', 'pcm_fftMag_mfcc_sma[2]_upleveltime90', 'pcm_fftMag_mfcc_sma[3]_maxPos', 'pcm_fftMag_mfcc_sma[3]_minPos', 'pcm_fftMag_mfcc_sma[3]_amean', 'pcm_fftMag_mfcc_sma[3]_linregc1', 'pcm_fftMag_mfcc_sma[3]_linregc2', 'pcm_fftMag_mfcc_sma[3]_linregerrA', 'pcm_fftMag_mfcc_sma[3]_linregerrQ', 'pcm_fftMag_mfcc_sma[3]_stddev', 'pcm_fftMag_mfcc_sma[3]_skewness', 'pcm_fftMag_mfcc_sma[3]_kurtosis', 'pcm_fftMag_mfcc_sma[3]_quartile1', 'pcm_fftMag_mfcc_sma[3]_quartile2', 'pcm_fftMag_mfcc_sma[3]_quartile3', 'pcm_fftMag_mfcc_sma[3]_iqr1-2', 'pcm_fftMag_mfcc_sma[3]_iqr2-3', 'pcm_fftMag_mfcc_sma[3]_iqr1-3', 'pcm_fftMag_mfcc_sma[3]_percentile1.0', 'pcm_fftMag_mfcc_sma[3]_percentile99.0', 'pcm_fftMag_mfcc_sma[3]_pctlrange0-1', 'pcm_fftMag_mfcc_sma[3]_upleveltime75', 'pcm_fftMag_mfcc_sma[3]_upleveltime90', 'pcm_fftMag_mfcc_sma[4]_maxPos', 'pcm_fftMag_mfcc_sma[4]_minPos', 'pcm_fftMag_mfcc_sma[4]_amean', 'pcm_fftMag_mfcc_sma[4]_linregc1', 'pcm_fftMag_mfcc_sma[4]_linregc2', 'pcm_fftMag_mfcc_sma[4]_linregerrA', 'pcm_fftMag_mfcc_sma[4]_linregerrQ', 'pcm_fftMag_mfcc_sma[4]_stddev', 'pcm_fftMag_mfcc_sma[4]_skewness', 'pcm_fftMag_mfcc_sma[4]_kurtosis', 'pcm_fftMag_mfcc_sma[4]_quartile1', 'pcm_fftMag_mfcc_sma[4]_quartile2', 'pcm_fftMag_mfcc_sma[4]_quartile3', 'pcm_fftMag_mfcc_sma[4]_iqr1-2', 'pcm_fftMag_mfcc_sma[4]_iqr2-3', 'pcm_fftMag_mfcc_sma[4]_iqr1-3', 'pcm_fftMag_mfcc_sma[4]_percentile1.0', 'pcm_fftMag_mfcc_sma[4]_percentile99.0', 'pcm_fftMag_mfcc_sma[4]_pctlrange0-1', 'pcm_fftMag_mfcc_sma[4]_upleveltime75', 'pcm_fftMag_mfcc_sma[4]_upleveltime90', 'pcm_fftMag_mfcc_sma[5]_maxPos', 'pcm_fftMag_mfcc_sma[5]_minPos', 'pcm_fftMag_mfcc_sma[5]_amean', 'pcm_fftMag_mfcc_sma[5]_linregc1', 'pcm_fftMag_mfcc_sma[5]_linregc2', 'pcm_fftMag_mfcc_sma[5]_linregerrA', 'pcm_fftMag_mfcc_sma[5]_linregerrQ', 'pcm_fftMag_mfcc_sma[5]_stddev', 'pcm_fftMag_mfcc_sma[5]_skewness', 'pcm_fftMag_mfcc_sma[5]_kurtosis', 'pcm_fftMag_mfcc_sma[5]_quartile1', 'pcm_fftMag_mfcc_sma[5]_quartile2', 'pcm_fftMag_mfcc_sma[5]_quartile3', 'pcm_fftMag_mfcc_sma[5]_iqr1-2', 'pcm_fftMag_mfcc_sma[5]_iqr2-3', 'pcm_fftMag_mfcc_sma[5]_iqr1-3', 'pcm_fftMag_mfcc_sma[5]_percentile1.0', 'pcm_fftMag_mfcc_sma[5]_percentile99.0', 'pcm_fftMag_mfcc_sma[5]_pctlrange0-1', 'pcm_fftMag_mfcc_sma[5]_upleveltime75', 'pcm_fftMag_mfcc_sma[5]_upleveltime90', 'pcm_fftMag_mfcc_sma[6]_maxPos', 'pcm_fftMag_mfcc_sma[6]_minPos', 'pcm_fftMag_mfcc_sma[6]_amean', 'pcm_fftMag_mfcc_sma[6]_linregc1', 'pcm_fftMag_mfcc_sma[6]_linregc2', 'pcm_fftMag_mfcc_sma[6]_linregerrA', 'pcm_fftMag_mfcc_sma[6]_linregerrQ', 'pcm_fftMag_mfcc_sma[6]_stddev', 'pcm_fftMag_mfcc_sma[6]_skewness', 'pcm_fftMag_mfcc_sma[6]_kurtosis', 'pcm_fftMag_mfcc_sma[6]_quartile1', 'pcm_fftMag_mfcc_sma[6]_quartile2', 'pcm_fftMag_mfcc_sma[6]_quartile3', 'pcm_fftMag_mfcc_sma[6]_iqr1-2', 'pcm_fftMag_mfcc_sma[6]_iqr2-3', 'pcm_fftMag_mfcc_sma[6]_iqr1-3', 'pcm_fftMag_mfcc_sma[6]_percentile1.0', 'pcm_fftMag_mfcc_sma[6]_percentile99.0', 'pcm_fftMag_mfcc_sma[6]_pctlrange0-1', 'pcm_fftMag_mfcc_sma[6]_upleveltime75', 'pcm_fftMag_mfcc_sma[6]_upleveltime90', 'pcm_fftMag_mfcc_sma[7]_maxPos', 'pcm_fftMag_mfcc_sma[7]_minPos', 'pcm_fftMag_mfcc_sma[7]_amean', 'pcm_fftMag_mfcc_sma[7]_linregc1', 'pcm_fftMag_mfcc_sma[7]_linregc2', 'pcm_fftMag_mfcc_sma[7]_linregerrA', 'pcm_fftMag_mfcc_sma[7]_linregerrQ', 'pcm_fftMag_mfcc_sma[7]_stddev', 'pcm_fftMag_mfcc_sma[7]_skewness', 'pcm_fftMag_mfcc_sma[7]_kurtosis', 'pcm_fftMag_mfcc_sma[7]_quartile1', 'pcm_fftMag_mfcc_sma[7]_quartile2', 'pcm_fftMag_mfcc_sma[7]_quartile3', 'pcm_fftMag_mfcc_sma[7]_iqr1-2', 'pcm_fftMag_mfcc_sma[7]_iqr2-3', 'pcm_fftMag_mfcc_sma[7]_iqr1-3', 'pcm_fftMag_mfcc_sma[7]_percentile1.0', 'pcm_fftMag_mfcc_sma[7]_percentile99.0', 'pcm_fftMag_mfcc_sma[7]_pctlrange0-1', 'pcm_fftMag_mfcc_sma[7]_upleveltime75', 'pcm_fftMag_mfcc_sma[7]_upleveltime90', 'pcm_fftMag_mfcc_sma[8]_maxPos', 'pcm_fftMag_mfcc_sma[8]_minPos', 'pcm_fftMag_mfcc_sma[8]_amean', 'pcm_fftMag_mfcc_sma[8]_linregc1', 'pcm_fftMag_mfcc_sma[8]_linregc2', 'pcm_fftMag_mfcc_sma[8]_linregerrA', 'pcm_fftMag_mfcc_sma[8]_linregerrQ', 'pcm_fftMag_mfcc_sma[8]_stddev', 'pcm_fftMag_mfcc_sma[8]_skewness', 'pcm_fftMag_mfcc_sma[8]_kurtosis', 'pcm_fftMag_mfcc_sma[8]_quartile1', 'pcm_fftMag_mfcc_sma[8]_quartile2', 'pcm_fftMag_mfcc_sma[8]_quartile3', 'pcm_fftMag_mfcc_sma[8]_iqr1-2', 'pcm_fftMag_mfcc_sma[8]_iqr2-3', 'pcm_fftMag_mfcc_sma[8]_iqr1-3', 'pcm_fftMag_mfcc_sma[8]_percentile1.0', 'pcm_fftMag_mfcc_sma[8]_percentile99.0', 'pcm_fftMag_mfcc_sma[8]_pctlrange0-1', 'pcm_fftMag_mfcc_sma[8]_upleveltime75', 'pcm_fftMag_mfcc_sma[8]_upleveltime90', 'pcm_fftMag_mfcc_sma[9]_maxPos', 'pcm_fftMag_mfcc_sma[9]_minPos', 'pcm_fftMag_mfcc_sma[9]_amean', 'pcm_fftMag_mfcc_sma[9]_linregc1', 'pcm_fftMag_mfcc_sma[9]_linregc2', 'pcm_fftMag_mfcc_sma[9]_linregerrA', 'pcm_fftMag_mfcc_sma[9]_linregerrQ', 'pcm_fftMag_mfcc_sma[9]_stddev', 'pcm_fftMag_mfcc_sma[9]_skewness', 'pcm_fftMag_mfcc_sma[9]_kurtosis', 'pcm_fftMag_mfcc_sma[9]_quartile1', 'pcm_fftMag_mfcc_sma[9]_quartile2', 'pcm_fftMag_mfcc_sma[9]_quartile3', 'pcm_fftMag_mfcc_sma[9]_iqr1-2', 'pcm_fftMag_mfcc_sma[9]_iqr2-3', 'pcm_fftMag_mfcc_sma[9]_iqr1-3', 'pcm_fftMag_mfcc_sma[9]_percentile1.0', 'pcm_fftMag_mfcc_sma[9]_percentile99.0', 'pcm_fftMag_mfcc_sma[9]_pctlrange0-1', 'pcm_fftMag_mfcc_sma[9]_upleveltime75', 'pcm_fftMag_mfcc_sma[9]_upleveltime90', 'pcm_fftMag_mfcc_sma[10]_maxPos', 'pcm_fftMag_mfcc_sma[10]_minPos', 'pcm_fftMag_mfcc_sma[10]_amean', 'pcm_fftMag_mfcc_sma[10]_linregc1', 'pcm_fftMag_mfcc_sma[10]_linregc2', 'pcm_fftMag_mfcc_sma[10]_linregerrA', 'pcm_fftMag_mfcc_sma[10]_linregerrQ', 'pcm_fftMag_mfcc_sma[10]_stddev', 'pcm_fftMag_mfcc_sma[10]_skewness', 'pcm_fftMag_mfcc_sma[10]_kurtosis', 'pcm_fftMag_mfcc_sma[10]_quartile1', 'pcm_fftMag_mfcc_sma[10]_quartile2', 'pcm_fftMag_mfcc_sma[10]_quartile3', 'pcm_fftMag_mfcc_sma[10]_iqr1-2', 'pcm_fftMag_mfcc_sma[10]_iqr2-3', 'pcm_fftMag_mfcc_sma[10]_iqr1-3', 'pcm_fftMag_mfcc_sma[10]_percentile1.0', 'pcm_fftMag_mfcc_sma[10]_percentile99.0', 'pcm_fftMag_mfcc_sma[10]_pctlrange0-1', 'pcm_fftMag_mfcc_sma[10]_upleveltime75', 'pcm_fftMag_mfcc_sma[10]_upleveltime90', 'pcm_fftMag_mfcc_sma[11]_maxPos', 'pcm_fftMag_mfcc_sma[11]_minPos', 'pcm_fftMag_mfcc_sma[11]_amean', 'pcm_fftMag_mfcc_sma[11]_linregc1', 'pcm_fftMag_mfcc_sma[11]_linregc2', 'pcm_fftMag_mfcc_sma[11]_linregerrA', 'pcm_fftMag_mfcc_sma[11]_linregerrQ', 'pcm_fftMag_mfcc_sma[11]_stddev', 'pcm_fftMag_mfcc_sma[11]_skewness', 'pcm_fftMag_mfcc_sma[11]_kurtosis', 'pcm_fftMag_mfcc_sma[11]_quartile1', 'pcm_fftMag_mfcc_sma[11]_quartile2', 'pcm_fftMag_mfcc_sma[11]_quartile3', 'pcm_fftMag_mfcc_sma[11]_iqr1-2', 'pcm_fftMag_mfcc_sma[11]_iqr2-3', 'pcm_fftMag_mfcc_sma[11]_iqr1-3', 'pcm_fftMag_mfcc_sma[11]_percentile1.0', 'pcm_fftMag_mfcc_sma[11]_percentile99.0', 'pcm_fftMag_mfcc_sma[11]_pctlrange0-1', 'pcm_fftMag_mfcc_sma[11]_upleveltime75', 'pcm_fftMag_mfcc_sma[11]_upleveltime90', 'pcm_fftMag_mfcc_sma[12]_maxPos', 'pcm_fftMag_mfcc_sma[12]_minPos', 'pcm_fftMag_mfcc_sma[12]_amean', 'pcm_fftMag_mfcc_sma[12]_linregc1', 'pcm_fftMag_mfcc_sma[12]_linregc2', 'pcm_fftMag_mfcc_sma[12]_linregerrA', 'pcm_fftMag_mfcc_sma[12]_linregerrQ', 'pcm_fftMag_mfcc_sma[12]_stddev', 'pcm_fftMag_mfcc_sma[12]_skewness', 'pcm_fftMag_mfcc_sma[12]_kurtosis', 'pcm_fftMag_mfcc_sma[12]_quartile1', 'pcm_fftMag_mfcc_sma[12]_quartile2', 'pcm_fftMag_mfcc_sma[12]_quartile3', 'pcm_fftMag_mfcc_sma[12]_iqr1-2', 'pcm_fftMag_mfcc_sma[12]_iqr2-3', 'pcm_fftMag_mfcc_sma[12]_iqr1-3', 'pcm_fftMag_mfcc_sma[12]_percentile1.0', 'pcm_fftMag_mfcc_sma[12]_percentile99.0', 'pcm_fftMag_mfcc_sma[12]_pctlrange0-1', 'pcm_fftMag_mfcc_sma[12]_upleveltime75', 'pcm_fftMag_mfcc_sma[12]_upleveltime90', 'pcm_fftMag_mfcc_sma[13]_maxPos', 'pcm_fftMag_mfcc_sma[13]_minPos', 'pcm_fftMag_mfcc_sma[13]_amean', 'pcm_fftMag_mfcc_sma[13]_linregc1', 'pcm_fftMag_mfcc_sma[13]_linregc2', 'pcm_fftMag_mfcc_sma[13]_linregerrA', 'pcm_fftMag_mfcc_sma[13]_linregerrQ', 'pcm_fftMag_mfcc_sma[13]_stddev', 'pcm_fftMag_mfcc_sma[13]_skewness', 'pcm_fftMag_mfcc_sma[13]_kurtosis', 'pcm_fftMag_mfcc_sma[13]_quartile1', 'pcm_fftMag_mfcc_sma[13]_quartile2', 'pcm_fftMag_mfcc_sma[13]_quartile3', 'pcm_fftMag_mfcc_sma[13]_iqr1-2', 'pcm_fftMag_mfcc_sma[13]_iqr2-3', 'pcm_fftMag_mfcc_sma[13]_iqr1-3', 'pcm_fftMag_mfcc_sma[13]_percentile1.0', 'pcm_fftMag_mfcc_sma[13]_percentile99.0', 'pcm_fftMag_mfcc_sma[13]_pctlrange0-1', 'pcm_fftMag_mfcc_sma[13]_upleveltime75', 'pcm_fftMag_mfcc_sma[13]_upleveltime90', 'pcm_fftMag_mfcc_sma[14]_maxPos', 'pcm_fftMag_mfcc_sma[14]_minPos', 'pcm_fftMag_mfcc_sma[14]_amean', 'pcm_fftMag_mfcc_sma[14]_linregc1', 'pcm_fftMag_mfcc_sma[14]_linregc2', 'pcm_fftMag_mfcc_sma[14]_linregerrA', 'pcm_fftMag_mfcc_sma[14]_linregerrQ', 'pcm_fftMag_mfcc_sma[14]_stddev', 'pcm_fftMag_mfcc_sma[14]_skewness', 'pcm_fftMag_mfcc_sma[14]_kurtosis', 'pcm_fftMag_mfcc_sma[14]_quartile1', 'pcm_fftMag_mfcc_sma[14]_quartile2', 'pcm_fftMag_mfcc_sma[14]_quartile3', 'pcm_fftMag_mfcc_sma[14]_iqr1-2', 'pcm_fftMag_mfcc_sma[14]_iqr2-3', 'pcm_fftMag_mfcc_sma[14]_iqr1-3', 'pcm_fftMag_mfcc_sma[14]_percentile1.0', 'pcm_fftMag_mfcc_sma[14]_percentile99.0', 'pcm_fftMag_mfcc_sma[14]_pctlrange0-1', 'pcm_fftMag_mfcc_sma[14]_upleveltime75', 'pcm_fftMag_mfcc_sma[14]_upleveltime90', 'logMelFreqBand_sma[0]_maxPos', 'logMelFreqBand_sma[0]_minPos', 'logMelFreqBand_sma[0]_amean', 'logMelFreqBand_sma[0]_linregc1', 'logMelFreqBand_sma[0]_linregc2', 'logMelFreqBand_sma[0]_linregerrA', 'logMelFreqBand_sma[0]_linregerrQ', 'logMelFreqBand_sma[0]_stddev', 'logMelFreqBand_sma[0]_skewness', 'logMelFreqBand_sma[0]_kurtosis', 'logMelFreqBand_sma[0]_quartile1', 'logMelFreqBand_sma[0]_quartile2', 'logMelFreqBand_sma[0]_quartile3', 'logMelFreqBand_sma[0]_iqr1-2', 'logMelFreqBand_sma[0]_iqr2-3', 'logMelFreqBand_sma[0]_iqr1-3', 'logMelFreqBand_sma[0]_percentile1.0', 'logMelFreqBand_sma[0]_percentile99.0', 'logMelFreqBand_sma[0]_pctlrange0-1', 'logMelFreqBand_sma[0]_upleveltime75', 'logMelFreqBand_sma[0]_upleveltime90', 'logMelFreqBand_sma[1]_maxPos', 'logMelFreqBand_sma[1]_minPos', 'logMelFreqBand_sma[1]_amean', 'logMelFreqBand_sma[1]_linregc1', 'logMelFreqBand_sma[1]_linregc2', 'logMelFreqBand_sma[1]_linregerrA', 'logMelFreqBand_sma[1]_linregerrQ', 'logMelFreqBand_sma[1]_stddev', 'logMelFreqBand_sma[1]_skewness', 'logMelFreqBand_sma[1]_kurtosis', 'logMelFreqBand_sma[1]_quartile1', 'logMelFreqBand_sma[1]_quartile2', 'logMelFreqBand_sma[1]_quartile3', 'logMelFreqBand_sma[1]_iqr1-2', 'logMelFreqBand_sma[1]_iqr2-3', 'logMelFreqBand_sma[1]_iqr1-3', 'logMelFreqBand_sma[1]_percentile1.0', 'logMelFreqBand_sma[1]_percentile99.0', 'logMelFreqBand_sma[1]_pctlrange0-1', 'logMelFreqBand_sma[1]_upleveltime75', 'logMelFreqBand_sma[1]_upleveltime90', 'logMelFreqBand_sma[2]_maxPos', 'logMelFreqBand_sma[2]_minPos', 'logMelFreqBand_sma[2]_amean', 'logMelFreqBand_sma[2]_linregc1', 'logMelFreqBand_sma[2]_linregc2', 'logMelFreqBand_sma[2]_linregerrA', 'logMelFreqBand_sma[2]_linregerrQ', 'logMelFreqBand_sma[2]_stddev', 'logMelFreqBand_sma[2]_skewness', 'logMelFreqBand_sma[2]_kurtosis', 'logMelFreqBand_sma[2]_quartile1', 'logMelFreqBand_sma[2]_quartile2', 'logMelFreqBand_sma[2]_quartile3', 'logMelFreqBand_sma[2]_iqr1-2', 'logMelFreqBand_sma[2]_iqr2-3', 'logMelFreqBand_sma[2]_iqr1-3', 'logMelFreqBand_sma[2]_percentile1.0', 'logMelFreqBand_sma[2]_percentile99.0', 'logMelFreqBand_sma[2]_pctlrange0-1', 'logMelFreqBand_sma[2]_upleveltime75', 'logMelFreqBand_sma[2]_upleveltime90', 'logMelFreqBand_sma[3]_maxPos', 'logMelFreqBand_sma[3]_minPos', 'logMelFreqBand_sma[3]_amean', 'logMelFreqBand_sma[3]_linregc1', 'logMelFreqBand_sma[3]_linregc2', 'logMelFreqBand_sma[3]_linregerrA', 'logMelFreqBand_sma[3]_linregerrQ', 'logMelFreqBand_sma[3]_stddev', 'logMelFreqBand_sma[3]_skewness', 'logMelFreqBand_sma[3]_kurtosis', 'logMelFreqBand_sma[3]_quartile1', 'logMelFreqBand_sma[3]_quartile2', 'logMelFreqBand_sma[3]_quartile3', 'logMelFreqBand_sma[3]_iqr1-2', 'logMelFreqBand_sma[3]_iqr2-3', 'logMelFreqBand_sma[3]_iqr1-3', 'logMelFreqBand_sma[3]_percentile1.0', 'logMelFreqBand_sma[3]_percentile99.0', 'logMelFreqBand_sma[3]_pctlrange0-1', 'logMelFreqBand_sma[3]_upleveltime75', 'logMelFreqBand_sma[3]_upleveltime90', 'logMelFreqBand_sma[4]_maxPos', 'logMelFreqBand_sma[4]_minPos', 'logMelFreqBand_sma[4]_amean', 'logMelFreqBand_sma[4]_linregc1', 'logMelFreqBand_sma[4]_linregc2', 'logMelFreqBand_sma[4]_linregerrA', 'logMelFreqBand_sma[4]_linregerrQ', 'logMelFreqBand_sma[4]_stddev', 'logMelFreqBand_sma[4]_skewness', 'logMelFreqBand_sma[4]_kurtosis', 'logMelFreqBand_sma[4]_quartile1', 'logMelFreqBand_sma[4]_quartile2', 'logMelFreqBand_sma[4]_quartile3', 'logMelFreqBand_sma[4]_iqr1-2', 'logMelFreqBand_sma[4]_iqr2-3', 'logMelFreqBand_sma[4]_iqr1-3', 'logMelFreqBand_sma[4]_percentile1.0', 'logMelFreqBand_sma[4]_percentile99.0', 'logMelFreqBand_sma[4]_pctlrange0-1', 'logMelFreqBand_sma[4]_upleveltime75', 'logMelFreqBand_sma[4]_upleveltime90', 'logMelFreqBand_sma[5]_maxPos', 'logMelFreqBand_sma[5]_minPos', 'logMelFreqBand_sma[5]_amean', 'logMelFreqBand_sma[5]_linregc1', 'logMelFreqBand_sma[5]_linregc2', 'logMelFreqBand_sma[5]_linregerrA', 'logMelFreqBand_sma[5]_linregerrQ', 'logMelFreqBand_sma[5]_stddev', 'logMelFreqBand_sma[5]_skewness', 'logMelFreqBand_sma[5]_kurtosis', 'logMelFreqBand_sma[5]_quartile1', 'logMelFreqBand_sma[5]_quartile2', 'logMelFreqBand_sma[5]_quartile3', 'logMelFreqBand_sma[5]_iqr1-2', 'logMelFreqBand_sma[5]_iqr2-3', 'logMelFreqBand_sma[5]_iqr1-3', 'logMelFreqBand_sma[5]_percentile1.0', 'logMelFreqBand_sma[5]_percentile99.0', 'logMelFreqBand_sma[5]_pctlrange0-1', 'logMelFreqBand_sma[5]_upleveltime75', 'logMelFreqBand_sma[5]_upleveltime90', 'logMelFreqBand_sma[6]_maxPos', 'logMelFreqBand_sma[6]_minPos', 'logMelFreqBand_sma[6]_amean', 'logMelFreqBand_sma[6]_linregc1', 'logMelFreqBand_sma[6]_linregc2', 'logMelFreqBand_sma[6]_linregerrA', 'logMelFreqBand_sma[6]_linregerrQ', 'logMelFreqBand_sma[6]_stddev', 'logMelFreqBand_sma[6]_skewness', 'logMelFreqBand_sma[6]_kurtosis', 'logMelFreqBand_sma[6]_quartile1', 'logMelFreqBand_sma[6]_quartile2', 'logMelFreqBand_sma[6]_quartile3', 'logMelFreqBand_sma[6]_iqr1-2', 'logMelFreqBand_sma[6]_iqr2-3', 'logMelFreqBand_sma[6]_iqr1-3', 'logMelFreqBand_sma[6]_percentile1.0', 'logMelFreqBand_sma[6]_percentile99.0', 'logMelFreqBand_sma[6]_pctlrange0-1', 'logMelFreqBand_sma[6]_upleveltime75', 'logMelFreqBand_sma[6]_upleveltime90', 'logMelFreqBand_sma[7]_maxPos', 'logMelFreqBand_sma[7]_minPos', 'logMelFreqBand_sma[7]_amean', 'logMelFreqBand_sma[7]_linregc1', 'logMelFreqBand_sma[7]_linregc2', 'logMelFreqBand_sma[7]_linregerrA', 'logMelFreqBand_sma[7]_linregerrQ', 'logMelFreqBand_sma[7]_stddev', 'logMelFreqBand_sma[7]_skewness', 'logMelFreqBand_sma[7]_kurtosis', 'logMelFreqBand_sma[7]_quartile1', 'logMelFreqBand_sma[7]_quartile2', 'logMelFreqBand_sma[7]_quartile3', 'logMelFreqBand_sma[7]_iqr1-2', 'logMelFreqBand_sma[7]_iqr2-3', 'logMelFreqBand_sma[7]_iqr1-3', 'logMelFreqBand_sma[7]_percentile1.0', 'logMelFreqBand_sma[7]_percentile99.0', 'logMelFreqBand_sma[7]_pctlrange0-1', 'logMelFreqBand_sma[7]_upleveltime75', 'logMelFreqBand_sma[7]_upleveltime90', 'lspFreq_sma[0]_maxPos', 'lspFreq_sma[0]_minPos', 'lspFreq_sma[0]_amean', 'lspFreq_sma[0]_linregc1', 'lspFreq_sma[0]_linregc2', 'lspFreq_sma[0]_linregerrA', 'lspFreq_sma[0]_linregerrQ', 'lspFreq_sma[0]_stddev', 'lspFreq_sma[0]_skewness', 'lspFreq_sma[0]_kurtosis', 'lspFreq_sma[0]_quartile1', 'lspFreq_sma[0]_quartile2', 'lspFreq_sma[0]_quartile3', 'lspFreq_sma[0]_iqr1-2', 'lspFreq_sma[0]_iqr2-3', 'lspFreq_sma[0]_iqr1-3', 'lspFreq_sma[0]_percentile1.0', 'lspFreq_sma[0]_percentile99.0', 'lspFreq_sma[0]_pctlrange0-1', 'lspFreq_sma[0]_upleveltime75', 'lspFreq_sma[0]_upleveltime90', 'lspFreq_sma[1]_maxPos', 'lspFreq_sma[1]_minPos', 'lspFreq_sma[1]_amean', 'lspFreq_sma[1]_linregc1', 'lspFreq_sma[1]_linregc2', 'lspFreq_sma[1]_linregerrA', 'lspFreq_sma[1]_linregerrQ', 'lspFreq_sma[1]_stddev', 'lspFreq_sma[1]_skewness', 'lspFreq_sma[1]_kurtosis', 'lspFreq_sma[1]_quartile1', 'lspFreq_sma[1]_quartile2', 'lspFreq_sma[1]_quartile3', 'lspFreq_sma[1]_iqr1-2', 'lspFreq_sma[1]_iqr2-3', 'lspFreq_sma[1]_iqr1-3', 'lspFreq_sma[1]_percentile1.0', 'lspFreq_sma[1]_percentile99.0', 'lspFreq_sma[1]_pctlrange0-1', 'lspFreq_sma[1]_upleveltime75', 'lspFreq_sma[1]_upleveltime90', 'lspFreq_sma[2]_maxPos', 'lspFreq_sma[2]_minPos', 'lspFreq_sma[2]_amean', 'lspFreq_sma[2]_linregc1', 'lspFreq_sma[2]_linregc2', 'lspFreq_sma[2]_linregerrA', 'lspFreq_sma[2]_linregerrQ', 'lspFreq_sma[2]_stddev', 'lspFreq_sma[2]_skewness', 'lspFreq_sma[2]_kurtosis', 'lspFreq_sma[2]_quartile1', 'lspFreq_sma[2]_quartile2', 'lspFreq_sma[2]_quartile3', 'lspFreq_sma[2]_iqr1-2', 'lspFreq_sma[2]_iqr2-3', 'lspFreq_sma[2]_iqr1-3', 'lspFreq_sma[2]_percentile1.0', 'lspFreq_sma[2]_percentile99.0', 'lspFreq_sma[2]_pctlrange0-1', 'lspFreq_sma[2]_upleveltime75', 'lspFreq_sma[2]_upleveltime90', 'lspFreq_sma[3]_maxPos', 'lspFreq_sma[3]_minPos', 'lspFreq_sma[3]_amean', 'lspFreq_sma[3]_linregc1', 'lspFreq_sma[3]_linregc2', 'lspFreq_sma[3]_linregerrA', 'lspFreq_sma[3]_linregerrQ', 'lspFreq_sma[3]_stddev', 'lspFreq_sma[3]_skewness', 'lspFreq_sma[3]_kurtosis', 'lspFreq_sma[3]_quartile1', 'lspFreq_sma[3]_quartile2', 'lspFreq_sma[3]_quartile3', 'lspFreq_sma[3]_iqr1-2', 'lspFreq_sma[3]_iqr2-3', 'lspFreq_sma[3]_iqr1-3', 'lspFreq_sma[3]_percentile1.0', 'lspFreq_sma[3]_percentile99.0', 'lspFreq_sma[3]_pctlrange0-1', 'lspFreq_sma[3]_upleveltime75', 'lspFreq_sma[3]_upleveltime90', 'lspFreq_sma[4]_maxPos', 'lspFreq_sma[4]_minPos', 'lspFreq_sma[4]_amean', 'lspFreq_sma[4]_linregc1', 'lspFreq_sma[4]_linregc2', 'lspFreq_sma[4]_linregerrA', 'lspFreq_sma[4]_linregerrQ', 'lspFreq_sma[4]_stddev', 'lspFreq_sma[4]_skewness', 'lspFreq_sma[4]_kurtosis', 'lspFreq_sma[4]_quartile1', 'lspFreq_sma[4]_quartile2', 'lspFreq_sma[4]_quartile3', 'lspFreq_sma[4]_iqr1-2', 'lspFreq_sma[4]_iqr2-3', 'lspFreq_sma[4]_iqr1-3', 'lspFreq_sma[4]_percentile1.0', 'lspFreq_sma[4]_percentile99.0', 'lspFreq_sma[4]_pctlrange0-1', 'lspFreq_sma[4]_upleveltime75', 'lspFreq_sma[4]_upleveltime90', 'lspFreq_sma[5]_maxPos', 'lspFreq_sma[5]_minPos', 'lspFreq_sma[5]_amean', 'lspFreq_sma[5]_linregc1', 'lspFreq_sma[5]_linregc2', 'lspFreq_sma[5]_linregerrA', 'lspFreq_sma[5]_linregerrQ', 'lspFreq_sma[5]_stddev', 'lspFreq_sma[5]_skewness', 'lspFreq_sma[5]_kurtosis', 'lspFreq_sma[5]_quartile1', 'lspFreq_sma[5]_quartile2', 'lspFreq_sma[5]_quartile3', 'lspFreq_sma[5]_iqr1-2', 'lspFreq_sma[5]_iqr2-3', 'lspFreq_sma[5]_iqr1-3', 'lspFreq_sma[5]_percentile1.0', 'lspFreq_sma[5]_percentile99.0', 'lspFreq_sma[5]_pctlrange0-1', 'lspFreq_sma[5]_upleveltime75', 'lspFreq_sma[5]_upleveltime90', 'lspFreq_sma[6]_maxPos', 'lspFreq_sma[6]_minPos', 'lspFreq_sma[6]_amean', 'lspFreq_sma[6]_linregc1', 'lspFreq_sma[6]_linregc2', 'lspFreq_sma[6]_linregerrA', 'lspFreq_sma[6]_linregerrQ', 'lspFreq_sma[6]_stddev', 'lspFreq_sma[6]_skewness', 'lspFreq_sma[6]_kurtosis', 'lspFreq_sma[6]_quartile1', 'lspFreq_sma[6]_quartile2', 'lspFreq_sma[6]_quartile3', 'lspFreq_sma[6]_iqr1-2', 'lspFreq_sma[6]_iqr2-3', 'lspFreq_sma[6]_iqr1-3', 'lspFreq_sma[6]_percentile1.0', 'lspFreq_sma[6]_percentile99.0', 'lspFreq_sma[6]_pctlrange0-1', 'lspFreq_sma[6]_upleveltime75', 'lspFreq_sma[6]_upleveltime90', 'lspFreq_sma[7]_maxPos', 'lspFreq_sma[7]_minPos', 'lspFreq_sma[7]_amean', 'lspFreq_sma[7]_linregc1', 'lspFreq_sma[7]_linregc2', 'lspFreq_sma[7]_linregerrA', 'lspFreq_sma[7]_linregerrQ', 'lspFreq_sma[7]_stddev', 'lspFreq_sma[7]_skewness', 'lspFreq_sma[7]_kurtosis', 'lspFreq_sma[7]_quartile1', 'lspFreq_sma[7]_quartile2', 'lspFreq_sma[7]_quartile3', 'lspFreq_sma[7]_iqr1-2', 'lspFreq_sma[7]_iqr2-3', 'lspFreq_sma[7]_iqr1-3', 'lspFreq_sma[7]_percentile1.0', 'lspFreq_sma[7]_percentile99.0', 'lspFreq_sma[7]_pctlrange0-1', 'lspFreq_sma[7]_upleveltime75', 'lspFreq_sma[7]_upleveltime90', 'F0finEnv_sma_maxPos', 'F0finEnv_sma_minPos', 'F0finEnv_sma_amean', 'F0finEnv_sma_linregc1', 'F0finEnv_sma_linregc2', 'F0finEnv_sma_linregerrA', 'F0finEnv_sma_linregerrQ', 'F0finEnv_sma_stddev', 'F0finEnv_sma_skewness', 'F0finEnv_sma_kurtosis', 'F0finEnv_sma_quartile1', 'F0finEnv_sma_quartile2', 'F0finEnv_sma_quartile3', 'F0finEnv_sma_iqr1-2', 'F0finEnv_sma_iqr2-3', 'F0finEnv_sma_iqr1-3', 'F0finEnv_sma_percentile1.0', 'F0finEnv_sma_percentile99.0', 'F0finEnv_sma_pctlrange0-1', 'F0finEnv_sma_upleveltime75', 'F0finEnv_sma_upleveltime90', 'voicingFinalUnclipped_sma_maxPos', 'voicingFinalUnclipped_sma_minPos', 'voicingFinalUnclipped_sma_amean', 'voicingFinalUnclipped_sma_linregc1', 'voicingFinalUnclipped_sma_linregc2', 'voicingFinalUnclipped_sma_linregerrA', 'voicingFinalUnclipped_sma_linregerrQ', 'voicingFinalUnclipped_sma_stddev', 'voicingFinalUnclipped_sma_skewness', 'voicingFinalUnclipped_sma_kurtosis', 'voicingFinalUnclipped_sma_quartile1', 'voicingFinalUnclipped_sma_quartile2', 'voicingFinalUnclipped_sma_quartile3', 'voicingFinalUnclipped_sma_iqr1-2', 'voicingFinalUnclipped_sma_iqr2-3', 'voicingFinalUnclipped_sma_iqr1-3', 'voicingFinalUnclipped_sma_percentile1.0', 'voicingFinalUnclipped_sma_percentile99.0', 'voicingFinalUnclipped_sma_pctlrange0-1', 'voicingFinalUnclipped_sma_upleveltime75', 'voicingFinalUnclipped_sma_upleveltime90', 'pcm_loudness_sma_de_maxPos', 'pcm_loudness_sma_de_minPos', 'pcm_loudness_sma_de_amean', 'pcm_loudness_sma_de_linregc1', 'pcm_loudness_sma_de_linregc2', 'pcm_loudness_sma_de_linregerrA', 'pcm_loudness_sma_de_linregerrQ', 'pcm_loudness_sma_de_stddev', 'pcm_loudness_sma_de_skewness', 'pcm_loudness_sma_de_kurtosis', 'pcm_loudness_sma_de_quartile1', 'pcm_loudness_sma_de_quartile2', 'pcm_loudness_sma_de_quartile3', 'pcm_loudness_sma_de_iqr1-2', 'pcm_loudness_sma_de_iqr2-3', 'pcm_loudness_sma_de_iqr1-3', 'pcm_loudness_sma_de_percentile1.0', 'pcm_loudness_sma_de_percentile99.0', 'pcm_loudness_sma_de_pctlrange0-1', 'pcm_loudness_sma_de_upleveltime75', 'pcm_loudness_sma_de_upleveltime90', 'pcm_fftMag_mfcc_sma_de[0]_maxPos', 'pcm_fftMag_mfcc_sma_de[0]_minPos', 'pcm_fftMag_mfcc_sma_de[0]_amean', 'pcm_fftMag_mfcc_sma_de[0]_linregc1', 'pcm_fftMag_mfcc_sma_de[0]_linregc2', 'pcm_fftMag_mfcc_sma_de[0]_linregerrA', 'pcm_fftMag_mfcc_sma_de[0]_linregerrQ', 'pcm_fftMag_mfcc_sma_de[0]_stddev', 'pcm_fftMag_mfcc_sma_de[0]_skewness', 'pcm_fftMag_mfcc_sma_de[0]_kurtosis', 'pcm_fftMag_mfcc_sma_de[0]_quartile1', 'pcm_fftMag_mfcc_sma_de[0]_quartile2', 'pcm_fftMag_mfcc_sma_de[0]_quartile3', 'pcm_fftMag_mfcc_sma_de[0]_iqr1-2', 'pcm_fftMag_mfcc_sma_de[0]_iqr2-3', 'pcm_fftMag_mfcc_sma_de[0]_iqr1-3', 'pcm_fftMag_mfcc_sma_de[0]_percentile1.0', 'pcm_fftMag_mfcc_sma_de[0]_percentile99.0', 'pcm_fftMag_mfcc_sma_de[0]_pctlrange0-1', 'pcm_fftMag_mfcc_sma_de[0]_upleveltime75', 'pcm_fftMag_mfcc_sma_de[0]_upleveltime90', 'pcm_fftMag_mfcc_sma_de[1]_maxPos', 'pcm_fftMag_mfcc_sma_de[1]_minPos', 'pcm_fftMag_mfcc_sma_de[1]_amean', 'pcm_fftMag_mfcc_sma_de[1]_linregc1', 'pcm_fftMag_mfcc_sma_de[1]_linregc2', 'pcm_fftMag_mfcc_sma_de[1]_linregerrA', 'pcm_fftMag_mfcc_sma_de[1]_linregerrQ', 'pcm_fftMag_mfcc_sma_de[1]_stddev', 'pcm_fftMag_mfcc_sma_de[1]_skewness', 'pcm_fftMag_mfcc_sma_de[1]_kurtosis', 'pcm_fftMag_mfcc_sma_de[1]_quartile1', 'pcm_fftMag_mfcc_sma_de[1]_quartile2', 'pcm_fftMag_mfcc_sma_de[1]_quartile3', 'pcm_fftMag_mfcc_sma_de[1]_iqr1-2', 'pcm_fftMag_mfcc_sma_de[1]_iqr2-3', 'pcm_fftMag_mfcc_sma_de[1]_iqr1-3', 'pcm_fftMag_mfcc_sma_de[1]_percentile1.0', 'pcm_fftMag_mfcc_sma_de[1]_percentile99.0', 'pcm_fftMag_mfcc_sma_de[1]_pctlrange0-1', 'pcm_fftMag_mfcc_sma_de[1]_upleveltime75', 'pcm_fftMag_mfcc_sma_de[1]_upleveltime90', 'pcm_fftMag_mfcc_sma_de[2]_maxPos', 'pcm_fftMag_mfcc_sma_de[2]_minPos', 'pcm_fftMag_mfcc_sma_de[2]_amean', 'pcm_fftMag_mfcc_sma_de[2]_linregc1', 'pcm_fftMag_mfcc_sma_de[2]_linregc2', 'pcm_fftMag_mfcc_sma_de[2]_linregerrA', 'pcm_fftMag_mfcc_sma_de[2]_linregerrQ', 'pcm_fftMag_mfcc_sma_de[2]_stddev', 'pcm_fftMag_mfcc_sma_de[2]_skewness', 'pcm_fftMag_mfcc_sma_de[2]_kurtosis', 'pcm_fftMag_mfcc_sma_de[2]_quartile1', 'pcm_fftMag_mfcc_sma_de[2]_quartile2', 'pcm_fftMag_mfcc_sma_de[2]_quartile3', 'pcm_fftMag_mfcc_sma_de[2]_iqr1-2', 'pcm_fftMag_mfcc_sma_de[2]_iqr2-3', 'pcm_fftMag_mfcc_sma_de[2]_iqr1-3', 'pcm_fftMag_mfcc_sma_de[2]_percentile1.0', 'pcm_fftMag_mfcc_sma_de[2]_percentile99.0', 'pcm_fftMag_mfcc_sma_de[2]_pctlrange0-1', 'pcm_fftMag_mfcc_sma_de[2]_upleveltime75', 'pcm_fftMag_mfcc_sma_de[2]_upleveltime90', 'pcm_fftMag_mfcc_sma_de[3]_maxPos', 'pcm_fftMag_mfcc_sma_de[3]_minPos', 'pcm_fftMag_mfcc_sma_de[3]_amean', 'pcm_fftMag_mfcc_sma_de[3]_linregc1', 'pcm_fftMag_mfcc_sma_de[3]_linregc2', 'pcm_fftMag_mfcc_sma_de[3]_linregerrA', 'pcm_fftMag_mfcc_sma_de[3]_linregerrQ', 'pcm_fftMag_mfcc_sma_de[3]_stddev', 'pcm_fftMag_mfcc_sma_de[3]_skewness', 'pcm_fftMag_mfcc_sma_de[3]_kurtosis', 'pcm_fftMag_mfcc_sma_de[3]_quartile1', 'pcm_fftMag_mfcc_sma_de[3]_quartile2', 'pcm_fftMag_mfcc_sma_de[3]_quartile3', 'pcm_fftMag_mfcc_sma_de[3]_iqr1-2', 'pcm_fftMag_mfcc_sma_de[3]_iqr2-3', 'pcm_fftMag_mfcc_sma_de[3]_iqr1-3', 'pcm_fftMag_mfcc_sma_de[3]_percentile1.0', 'pcm_fftMag_mfcc_sma_de[3]_percentile99.0', 'pcm_fftMag_mfcc_sma_de[3]_pctlrange0-1', 'pcm_fftMag_mfcc_sma_de[3]_upleveltime75', 'pcm_fftMag_mfcc_sma_de[3]_upleveltime90', 'pcm_fftMag_mfcc_sma_de[4]_maxPos', 'pcm_fftMag_mfcc_sma_de[4]_minPos', 'pcm_fftMag_mfcc_sma_de[4]_amean', 'pcm_fftMag_mfcc_sma_de[4]_linregc1', 'pcm_fftMag_mfcc_sma_de[4]_linregc2', 'pcm_fftMag_mfcc_sma_de[4]_linregerrA', 'pcm_fftMag_mfcc_sma_de[4]_linregerrQ', 'pcm_fftMag_mfcc_sma_de[4]_stddev', 'pcm_fftMag_mfcc_sma_de[4]_skewness', 'pcm_fftMag_mfcc_sma_de[4]_kurtosis', 'pcm_fftMag_mfcc_sma_de[4]_quartile1', 'pcm_fftMag_mfcc_sma_de[4]_quartile2', 'pcm_fftMag_mfcc_sma_de[4]_quartile3', 'pcm_fftMag_mfcc_sma_de[4]_iqr1-2', 'pcm_fftMag_mfcc_sma_de[4]_iqr2-3', 'pcm_fftMag_mfcc_sma_de[4]_iqr1-3', 'pcm_fftMag_mfcc_sma_de[4]_percentile1.0', 'pcm_fftMag_mfcc_sma_de[4]_percentile99.0', 'pcm_fftMag_mfcc_sma_de[4]_pctlrange0-1', 'pcm_fftMag_mfcc_sma_de[4]_upleveltime75', 'pcm_fftMag_mfcc_sma_de[4]_upleveltime90', 'pcm_fftMag_mfcc_sma_de[5]_maxPos', 'pcm_fftMag_mfcc_sma_de[5]_minPos', 'pcm_fftMag_mfcc_sma_de[5]_amean', 'pcm_fftMag_mfcc_sma_de[5]_linregc1', 'pcm_fftMag_mfcc_sma_de[5]_linregc2', 'pcm_fftMag_mfcc_sma_de[5]_linregerrA', 'pcm_fftMag_mfcc_sma_de[5]_linregerrQ', 'pcm_fftMag_mfcc_sma_de[5]_stddev', 'pcm_fftMag_mfcc_sma_de[5]_skewness', 'pcm_fftMag_mfcc_sma_de[5]_kurtosis', 'pcm_fftMag_mfcc_sma_de[5]_quartile1', 'pcm_fftMag_mfcc_sma_de[5]_quartile2', 'pcm_fftMag_mfcc_sma_de[5]_quartile3', 'pcm_fftMag_mfcc_sma_de[5]_iqr1-2', 'pcm_fftMag_mfcc_sma_de[5]_iqr2-3', 'pcm_fftMag_mfcc_sma_de[5]_iqr1-3', 'pcm_fftMag_mfcc_sma_de[5]_percentile1.0', 'pcm_fftMag_mfcc_sma_de[5]_percentile99.0', 'pcm_fftMag_mfcc_sma_de[5]_pctlrange0-1', 'pcm_fftMag_mfcc_sma_de[5]_upleveltime75', 'pcm_fftMag_mfcc_sma_de[5]_upleveltime90', 'pcm_fftMag_mfcc_sma_de[6]_maxPos', 'pcm_fftMag_mfcc_sma_de[6]_minPos', 'pcm_fftMag_mfcc_sma_de[6]_amean', 'pcm_fftMag_mfcc_sma_de[6]_linregc1', 'pcm_fftMag_mfcc_sma_de[6]_linregc2', 'pcm_fftMag_mfcc_sma_de[6]_linregerrA', 'pcm_fftMag_mfcc_sma_de[6]_linregerrQ', 'pcm_fftMag_mfcc_sma_de[6]_stddev', 'pcm_fftMag_mfcc_sma_de[6]_skewness', 'pcm_fftMag_mfcc_sma_de[6]_kurtosis', 'pcm_fftMag_mfcc_sma_de[6]_quartile1', 'pcm_fftMag_mfcc_sma_de[6]_quartile2', 'pcm_fftMag_mfcc_sma_de[6]_quartile3', 'pcm_fftMag_mfcc_sma_de[6]_iqr1-2', 'pcm_fftMag_mfcc_sma_de[6]_iqr2-3', 'pcm_fftMag_mfcc_sma_de[6]_iqr1-3', 'pcm_fftMag_mfcc_sma_de[6]_percentile1.0', 'pcm_fftMag_mfcc_sma_de[6]_percentile99.0', 'pcm_fftMag_mfcc_sma_de[6]_pctlrange0-1', 'pcm_fftMag_mfcc_sma_de[6]_upleveltime75', 'pcm_fftMag_mfcc_sma_de[6]_upleveltime90', 'pcm_fftMag_mfcc_sma_de[7]_maxPos', 'pcm_fftMag_mfcc_sma_de[7]_minPos', 'pcm_fftMag_mfcc_sma_de[7]_amean', 'pcm_fftMag_mfcc_sma_de[7]_linregc1', 'pcm_fftMag_mfcc_sma_de[7]_linregc2', 'pcm_fftMag_mfcc_sma_de[7]_linregerrA', 'pcm_fftMag_mfcc_sma_de[7]_linregerrQ', 'pcm_fftMag_mfcc_sma_de[7]_stddev', 'pcm_fftMag_mfcc_sma_de[7]_skewness', 'pcm_fftMag_mfcc_sma_de[7]_kurtosis', 'pcm_fftMag_mfcc_sma_de[7]_quartile1', 'pcm_fftMag_mfcc_sma_de[7]_quartile2', 'pcm_fftMag_mfcc_sma_de[7]_quartile3', 'pcm_fftMag_mfcc_sma_de[7]_iqr1-2', 'pcm_fftMag_mfcc_sma_de[7]_iqr2-3', 'pcm_fftMag_mfcc_sma_de[7]_iqr1-3', 'pcm_fftMag_mfcc_sma_de[7]_percentile1.0', 'pcm_fftMag_mfcc_sma_de[7]_percentile99.0', 'pcm_fftMag_mfcc_sma_de[7]_pctlrange0-1', 'pcm_fftMag_mfcc_sma_de[7]_upleveltime75', 'pcm_fftMag_mfcc_sma_de[7]_upleveltime90', 'pcm_fftMag_mfcc_sma_de[8]_maxPos', 'pcm_fftMag_mfcc_sma_de[8]_minPos', 'pcm_fftMag_mfcc_sma_de[8]_amean', 'pcm_fftMag_mfcc_sma_de[8]_linregc1', 'pcm_fftMag_mfcc_sma_de[8]_linregc2', 'pcm_fftMag_mfcc_sma_de[8]_linregerrA', 'pcm_fftMag_mfcc_sma_de[8]_linregerrQ', 'pcm_fftMag_mfcc_sma_de[8]_stddev', 'pcm_fftMag_mfcc_sma_de[8]_skewness', 'pcm_fftMag_mfcc_sma_de[8]_kurtosis', 'pcm_fftMag_mfcc_sma_de[8]_quartile1', 'pcm_fftMag_mfcc_sma_de[8]_quartile2', 'pcm_fftMag_mfcc_sma_de[8]_quartile3', 'pcm_fftMag_mfcc_sma_de[8]_iqr1-2', 'pcm_fftMag_mfcc_sma_de[8]_iqr2-3', 'pcm_fftMag_mfcc_sma_de[8]_iqr1-3', 'pcm_fftMag_mfcc_sma_de[8]_percentile1.0', 'pcm_fftMag_mfcc_sma_de[8]_percentile99.0', 'pcm_fftMag_mfcc_sma_de[8]_pctlrange0-1', 'pcm_fftMag_mfcc_sma_de[8]_upleveltime75', 'pcm_fftMag_mfcc_sma_de[8]_upleveltime90', 'pcm_fftMag_mfcc_sma_de[9]_maxPos', 'pcm_fftMag_mfcc_sma_de[9]_minPos', 'pcm_fftMag_mfcc_sma_de[9]_amean', 'pcm_fftMag_mfcc_sma_de[9]_linregc1', 'pcm_fftMag_mfcc_sma_de[9]_linregc2', 'pcm_fftMag_mfcc_sma_de[9]_linregerrA', 'pcm_fftMag_mfcc_sma_de[9]_linregerrQ', 'pcm_fftMag_mfcc_sma_de[9]_stddev', 'pcm_fftMag_mfcc_sma_de[9]_skewness', 'pcm_fftMag_mfcc_sma_de[9]_kurtosis', 'pcm_fftMag_mfcc_sma_de[9]_quartile1', 'pcm_fftMag_mfcc_sma_de[9]_quartile2', 'pcm_fftMag_mfcc_sma_de[9]_quartile3', 'pcm_fftMag_mfcc_sma_de[9]_iqr1-2', 'pcm_fftMag_mfcc_sma_de[9]_iqr2-3', 'pcm_fftMag_mfcc_sma_de[9]_iqr1-3', 'pcm_fftMag_mfcc_sma_de[9]_percentile1.0', 'pcm_fftMag_mfcc_sma_de[9]_percentile99.0', 'pcm_fftMag_mfcc_sma_de[9]_pctlrange0-1', 'pcm_fftMag_mfcc_sma_de[9]_upleveltime75', 'pcm_fftMag_mfcc_sma_de[9]_upleveltime90', 'pcm_fftMag_mfcc_sma_de[10]_maxPos', 'pcm_fftMag_mfcc_sma_de[10]_minPos', 'pcm_fftMag_mfcc_sma_de[10]_amean', 'pcm_fftMag_mfcc_sma_de[10]_linregc1', 'pcm_fftMag_mfcc_sma_de[10]_linregc2', 'pcm_fftMag_mfcc_sma_de[10]_linregerrA', 'pcm_fftMag_mfcc_sma_de[10]_linregerrQ', 'pcm_fftMag_mfcc_sma_de[10]_stddev', 'pcm_fftMag_mfcc_sma_de[10]_skewness', 'pcm_fftMag_mfcc_sma_de[10]_kurtosis', 'pcm_fftMag_mfcc_sma_de[10]_quartile1', 'pcm_fftMag_mfcc_sma_de[10]_quartile2', 'pcm_fftMag_mfcc_sma_de[10]_quartile3', 'pcm_fftMag_mfcc_sma_de[10]_iqr1-2', 'pcm_fftMag_mfcc_sma_de[10]_iqr2-3', 'pcm_fftMag_mfcc_sma_de[10]_iqr1-3', 'pcm_fftMag_mfcc_sma_de[10]_percentile1.0', 'pcm_fftMag_mfcc_sma_de[10]_percentile99.0', 'pcm_fftMag_mfcc_sma_de[10]_pctlrange0-1', 'pcm_fftMag_mfcc_sma_de[10]_upleveltime75', 'pcm_fftMag_mfcc_sma_de[10]_upleveltime90', 'pcm_fftMag_mfcc_sma_de[11]_maxPos', 'pcm_fftMag_mfcc_sma_de[11]_minPos', 'pcm_fftMag_mfcc_sma_de[11]_amean', 'pcm_fftMag_mfcc_sma_de[11]_linregc1', 'pcm_fftMag_mfcc_sma_de[11]_linregc2', 'pcm_fftMag_mfcc_sma_de[11]_linregerrA', 'pcm_fftMag_mfcc_sma_de[11]_linregerrQ', 'pcm_fftMag_mfcc_sma_de[11]_stddev', 'pcm_fftMag_mfcc_sma_de[11]_skewness', 'pcm_fftMag_mfcc_sma_de[11]_kurtosis', 'pcm_fftMag_mfcc_sma_de[11]_quartile1', 'pcm_fftMag_mfcc_sma_de[11]_quartile2', 'pcm_fftMag_mfcc_sma_de[11]_quartile3', 'pcm_fftMag_mfcc_sma_de[11]_iqr1-2', 'pcm_fftMag_mfcc_sma_de[11]_iqr2-3', 'pcm_fftMag_mfcc_sma_de[11]_iqr1-3', 'pcm_fftMag_mfcc_sma_de[11]_percentile1.0', 'pcm_fftMag_mfcc_sma_de[11]_percentile99.0', 'pcm_fftMag_mfcc_sma_de[11]_pctlrange0-1', 'pcm_fftMag_mfcc_sma_de[11]_upleveltime75', 'pcm_fftMag_mfcc_sma_de[11]_upleveltime90', 'pcm_fftMag_mfcc_sma_de[12]_maxPos', 'pcm_fftMag_mfcc_sma_de[12]_minPos', 'pcm_fftMag_mfcc_sma_de[12]_amean', 'pcm_fftMag_mfcc_sma_de[12]_linregc1', 'pcm_fftMag_mfcc_sma_de[12]_linregc2', 'pcm_fftMag_mfcc_sma_de[12]_linregerrA', 'pcm_fftMag_mfcc_sma_de[12]_linregerrQ', 'pcm_fftMag_mfcc_sma_de[12]_stddev', 'pcm_fftMag_mfcc_sma_de[12]_skewness', 'pcm_fftMag_mfcc_sma_de[12]_kurtosis', 'pcm_fftMag_mfcc_sma_de[12]_quartile1', 'pcm_fftMag_mfcc_sma_de[12]_quartile2', 'pcm_fftMag_mfcc_sma_de[12]_quartile3', 'pcm_fftMag_mfcc_sma_de[12]_iqr1-2', 'pcm_fftMag_mfcc_sma_de[12]_iqr2-3', 'pcm_fftMag_mfcc_sma_de[12]_iqr1-3', 'pcm_fftMag_mfcc_sma_de[12]_percentile1.0', 'pcm_fftMag_mfcc_sma_de[12]_percentile99.0', 'pcm_fftMag_mfcc_sma_de[12]_pctlrange0-1', 'pcm_fftMag_mfcc_sma_de[12]_upleveltime75', 'pcm_fftMag_mfcc_sma_de[12]_upleveltime90', 'pcm_fftMag_mfcc_sma_de[13]_maxPos', 'pcm_fftMag_mfcc_sma_de[13]_minPos', 'pcm_fftMag_mfcc_sma_de[13]_amean', 'pcm_fftMag_mfcc_sma_de[13]_linregc1', 'pcm_fftMag_mfcc_sma_de[13]_linregc2', 'pcm_fftMag_mfcc_sma_de[13]_linregerrA', 'pcm_fftMag_mfcc_sma_de[13]_linregerrQ', 'pcm_fftMag_mfcc_sma_de[13]_stddev', 'pcm_fftMag_mfcc_sma_de[13]_skewness', 'pcm_fftMag_mfcc_sma_de[13]_kurtosis', 'pcm_fftMag_mfcc_sma_de[13]_quartile1', 'pcm_fftMag_mfcc_sma_de[13]_quartile2', 'pcm_fftMag_mfcc_sma_de[13]_quartile3', 'pcm_fftMag_mfcc_sma_de[13]_iqr1-2', 'pcm_fftMag_mfcc_sma_de[13]_iqr2-3', 'pcm_fftMag_mfcc_sma_de[13]_iqr1-3', 'pcm_fftMag_mfcc_sma_de[13]_percentile1.0', 'pcm_fftMag_mfcc_sma_de[13]_percentile99.0', 'pcm_fftMag_mfcc_sma_de[13]_pctlrange0-1', 'pcm_fftMag_mfcc_sma_de[13]_upleveltime75', 'pcm_fftMag_mfcc_sma_de[13]_upleveltime90', 'pcm_fftMag_mfcc_sma_de[14]_maxPos', 'pcm_fftMag_mfcc_sma_de[14]_minPos', 'pcm_fftMag_mfcc_sma_de[14]_amean', 'pcm_fftMag_mfcc_sma_de[14]_linregc1', 'pcm_fftMag_mfcc_sma_de[14]_linregc2', 'pcm_fftMag_mfcc_sma_de[14]_linregerrA', 'pcm_fftMag_mfcc_sma_de[14]_linregerrQ', 'pcm_fftMag_mfcc_sma_de[14]_stddev', 'pcm_fftMag_mfcc_sma_de[14]_skewness', 'pcm_fftMag_mfcc_sma_de[14]_kurtosis', 'pcm_fftMag_mfcc_sma_de[14]_quartile1', 'pcm_fftMag_mfcc_sma_de[14]_quartile2', 'pcm_fftMag_mfcc_sma_de[14]_quartile3', 'pcm_fftMag_mfcc_sma_de[14]_iqr1-2', 'pcm_fftMag_mfcc_sma_de[14]_iqr2-3', 'pcm_fftMag_mfcc_sma_de[14]_iqr1-3', 'pcm_fftMag_mfcc_sma_de[14]_percentile1.0', 'pcm_fftMag_mfcc_sma_de[14]_percentile99.0', 'pcm_fftMag_mfcc_sma_de[14]_pctlrange0-1', 'pcm_fftMag_mfcc_sma_de[14]_upleveltime75', 'pcm_fftMag_mfcc_sma_de[14]_upleveltime90', 'logMelFreqBand_sma_de[0]_maxPos', 'logMelFreqBand_sma_de[0]_minPos', 'logMelFreqBand_sma_de[0]_amean', 'logMelFreqBand_sma_de[0]_linregc1', 'logMelFreqBand_sma_de[0]_linregc2', 'logMelFreqBand_sma_de[0]_linregerrA', 'logMelFreqBand_sma_de[0]_linregerrQ', 'logMelFreqBand_sma_de[0]_stddev', 'logMelFreqBand_sma_de[0]_skewness', 'logMelFreqBand_sma_de[0]_kurtosis', 'logMelFreqBand_sma_de[0]_quartile1', 'logMelFreqBand_sma_de[0]_quartile2', 'logMelFreqBand_sma_de[0]_quartile3', 'logMelFreqBand_sma_de[0]_iqr1-2', 'logMelFreqBand_sma_de[0]_iqr2-3', 'logMelFreqBand_sma_de[0]_iqr1-3', 'logMelFreqBand_sma_de[0]_percentile1.0', 'logMelFreqBand_sma_de[0]_percentile99.0', 'logMelFreqBand_sma_de[0]_pctlrange0-1', 'logMelFreqBand_sma_de[0]_upleveltime75', 'logMelFreqBand_sma_de[0]_upleveltime90', 'logMelFreqBand_sma_de[1]_maxPos', 'logMelFreqBand_sma_de[1]_minPos', 'logMelFreqBand_sma_de[1]_amean', 'logMelFreqBand_sma_de[1]_linregc1', 'logMelFreqBand_sma_de[1]_linregc2', 'logMelFreqBand_sma_de[1]_linregerrA', 'logMelFreqBand_sma_de[1]_linregerrQ', 'logMelFreqBand_sma_de[1]_stddev', 'logMelFreqBand_sma_de[1]_skewness', 'logMelFreqBand_sma_de[1]_kurtosis', 'logMelFreqBand_sma_de[1]_quartile1', 'logMelFreqBand_sma_de[1]_quartile2', 'logMelFreqBand_sma_de[1]_quartile3', 'logMelFreqBand_sma_de[1]_iqr1-2', 'logMelFreqBand_sma_de[1]_iqr2-3', 'logMelFreqBand_sma_de[1]_iqr1-3', 'logMelFreqBand_sma_de[1]_percentile1.0', 'logMelFreqBand_sma_de[1]_percentile99.0', 'logMelFreqBand_sma_de[1]_pctlrange0-1', 'logMelFreqBand_sma_de[1]_upleveltime75', 'logMelFreqBand_sma_de[1]_upleveltime90', 'logMelFreqBand_sma_de[2]_maxPos', 'logMelFreqBand_sma_de[2]_minPos', 'logMelFreqBand_sma_de[2]_amean', 'logMelFreqBand_sma_de[2]_linregc1', 'logMelFreqBand_sma_de[2]_linregc2', 'logMelFreqBand_sma_de[2]_linregerrA', 'logMelFreqBand_sma_de[2]_linregerrQ', 'logMelFreqBand_sma_de[2]_stddev', 'logMelFreqBand_sma_de[2]_skewness', 'logMelFreqBand_sma_de[2]_kurtosis', 'logMelFreqBand_sma_de[2]_quartile1', 'logMelFreqBand_sma_de[2]_quartile2', 'logMelFreqBand_sma_de[2]_quartile3', 'logMelFreqBand_sma_de[2]_iqr1-2', 'logMelFreqBand_sma_de[2]_iqr2-3', 'logMelFreqBand_sma_de[2]_iqr1-3', 'logMelFreqBand_sma_de[2]_percentile1.0', 'logMelFreqBand_sma_de[2]_percentile99.0', 'logMelFreqBand_sma_de[2]_pctlrange0-1', 'logMelFreqBand_sma_de[2]_upleveltime75', 'logMelFreqBand_sma_de[2]_upleveltime90', 'logMelFreqBand_sma_de[3]_maxPos', 'logMelFreqBand_sma_de[3]_minPos', 'logMelFreqBand_sma_de[3]_amean', 'logMelFreqBand_sma_de[3]_linregc1', 'logMelFreqBand_sma_de[3]_linregc2', 'logMelFreqBand_sma_de[3]_linregerrA', 'logMelFreqBand_sma_de[3]_linregerrQ', 'logMelFreqBand_sma_de[3]_stddev', 'logMelFreqBand_sma_de[3]_skewness', 'logMelFreqBand_sma_de[3]_kurtosis', 'logMelFreqBand_sma_de[3]_quartile1', 'logMelFreqBand_sma_de[3]_quartile2', 'logMelFreqBand_sma_de[3]_quartile3', 'logMelFreqBand_sma_de[3]_iqr1-2', 'logMelFreqBand_sma_de[3]_iqr2-3', 'logMelFreqBand_sma_de[3]_iqr1-3', 'logMelFreqBand_sma_de[3]_percentile1.0', 'logMelFreqBand_sma_de[3]_percentile99.0', 'logMelFreqBand_sma_de[3]_pctlrange0-1', 'logMelFreqBand_sma_de[3]_upleveltime75', 'logMelFreqBand_sma_de[3]_upleveltime90', 'logMelFreqBand_sma_de[4]_maxPos', 'logMelFreqBand_sma_de[4]_minPos', 'logMelFreqBand_sma_de[4]_amean', 'logMelFreqBand_sma_de[4]_linregc1', 'logMelFreqBand_sma_de[4]_linregc2', 'logMelFreqBand_sma_de[4]_linregerrA', 'logMelFreqBand_sma_de[4]_linregerrQ', 'logMelFreqBand_sma_de[4]_stddev', 'logMelFreqBand_sma_de[4]_skewness', 'logMelFreqBand_sma_de[4]_kurtosis', 'logMelFreqBand_sma_de[4]_quartile1', 'logMelFreqBand_sma_de[4]_quartile2', 'logMelFreqBand_sma_de[4]_quartile3', 'logMelFreqBand_sma_de[4]_iqr1-2', 'logMelFreqBand_sma_de[4]_iqr2-3', 'logMelFreqBand_sma_de[4]_iqr1-3', 'logMelFreqBand_sma_de[4]_percentile1.0', 'logMelFreqBand_sma_de[4]_percentile99.0', 'logMelFreqBand_sma_de[4]_pctlrange0-1', 'logMelFreqBand_sma_de[4]_upleveltime75', 'logMelFreqBand_sma_de[4]_upleveltime90', 'logMelFreqBand_sma_de[5]_maxPos', 'logMelFreqBand_sma_de[5]_minPos', 'logMelFreqBand_sma_de[5]_amean', 'logMelFreqBand_sma_de[5]_linregc1', 'logMelFreqBand_sma_de[5]_linregc2', 'logMelFreqBand_sma_de[5]_linregerrA', 'logMelFreqBand_sma_de[5]_linregerrQ', 'logMelFreqBand_sma_de[5]_stddev', 'logMelFreqBand_sma_de[5]_skewness', 'logMelFreqBand_sma_de[5]_kurtosis', 'logMelFreqBand_sma_de[5]_quartile1', 'logMelFreqBand_sma_de[5]_quartile2', 'logMelFreqBand_sma_de[5]_quartile3', 'logMelFreqBand_sma_de[5]_iqr1-2', 'logMelFreqBand_sma_de[5]_iqr2-3', 'logMelFreqBand_sma_de[5]_iqr1-3', 'logMelFreqBand_sma_de[5]_percentile1.0', 'logMelFreqBand_sma_de[5]_percentile99.0', 'logMelFreqBand_sma_de[5]_pctlrange0-1', 'logMelFreqBand_sma_de[5]_upleveltime75', 'logMelFreqBand_sma_de[5]_upleveltime90', 'logMelFreqBand_sma_de[6]_maxPos', 'logMelFreqBand_sma_de[6]_minPos', 'logMelFreqBand_sma_de[6]_amean', 'logMelFreqBand_sma_de[6]_linregc1', 'logMelFreqBand_sma_de[6]_linregc2', 'logMelFreqBand_sma_de[6]_linregerrA', 'logMelFreqBand_sma_de[6]_linregerrQ', 'logMelFreqBand_sma_de[6]_stddev', 'logMelFreqBand_sma_de[6]_skewness', 'logMelFreqBand_sma_de[6]_kurtosis', 'logMelFreqBand_sma_de[6]_quartile1', 'logMelFreqBand_sma_de[6]_quartile2', 'logMelFreqBand_sma_de[6]_quartile3', 'logMelFreqBand_sma_de[6]_iqr1-2', 'logMelFreqBand_sma_de[6]_iqr2-3', 'logMelFreqBand_sma_de[6]_iqr1-3', 'logMelFreqBand_sma_de[6]_percentile1.0', 'logMelFreqBand_sma_de[6]_percentile99.0', 'logMelFreqBand_sma_de[6]_pctlrange0-1', 'logMelFreqBand_sma_de[6]_upleveltime75', 'logMelFreqBand_sma_de[6]_upleveltime90', 'logMelFreqBand_sma_de[7]_maxPos', 'logMelFreqBand_sma_de[7]_minPos', 'logMelFreqBand_sma_de[7]_amean', 'logMelFreqBand_sma_de[7]_linregc1', 'logMelFreqBand_sma_de[7]_linregc2', 'logMelFreqBand_sma_de[7]_linregerrA', 'logMelFreqBand_sma_de[7]_linregerrQ', 'logMelFreqBand_sma_de[7]_stddev', 'logMelFreqBand_sma_de[7]_skewness', 'logMelFreqBand_sma_de[7]_kurtosis', 'logMelFreqBand_sma_de[7]_quartile1', 'logMelFreqBand_sma_de[7]_quartile2', 'logMelFreqBand_sma_de[7]_quartile3', 'logMelFreqBand_sma_de[7]_iqr1-2', 'logMelFreqBand_sma_de[7]_iqr2-3', 'logMelFreqBand_sma_de[7]_iqr1-3', 'logMelFreqBand_sma_de[7]_percentile1.0', 'logMelFreqBand_sma_de[7]_percentile99.0', 'logMelFreqBand_sma_de[7]_pctlrange0-1', 'logMelFreqBand_sma_de[7]_upleveltime75', 'logMelFreqBand_sma_de[7]_upleveltime90', 'lspFreq_sma_de[0]_maxPos', 'lspFreq_sma_de[0]_minPos', 'lspFreq_sma_de[0]_amean', 'lspFreq_sma_de[0]_linregc1', 'lspFreq_sma_de[0]_linregc2', 'lspFreq_sma_de[0]_linregerrA', 'lspFreq_sma_de[0]_linregerrQ', 'lspFreq_sma_de[0]_stddev', 'lspFreq_sma_de[0]_skewness', 'lspFreq_sma_de[0]_kurtosis', 'lspFreq_sma_de[0]_quartile1', 'lspFreq_sma_de[0]_quartile2', 'lspFreq_sma_de[0]_quartile3', 'lspFreq_sma_de[0]_iqr1-2', 'lspFreq_sma_de[0]_iqr2-3', 'lspFreq_sma_de[0]_iqr1-3', 'lspFreq_sma_de[0]_percentile1.0', 'lspFreq_sma_de[0]_percentile99.0', 'lspFreq_sma_de[0]_pctlrange0-1', 'lspFreq_sma_de[0]_upleveltime75', 'lspFreq_sma_de[0]_upleveltime90', 'lspFreq_sma_de[1]_maxPos', 'lspFreq_sma_de[1]_minPos', 'lspFreq_sma_de[1]_amean', 'lspFreq_sma_de[1]_linregc1', 'lspFreq_sma_de[1]_linregc2', 'lspFreq_sma_de[1]_linregerrA', 'lspFreq_sma_de[1]_linregerrQ', 'lspFreq_sma_de[1]_stddev', 'lspFreq_sma_de[1]_skewness', 'lspFreq_sma_de[1]_kurtosis', 'lspFreq_sma_de[1]_quartile1', 'lspFreq_sma_de[1]_quartile2', 'lspFreq_sma_de[1]_quartile3', 'lspFreq_sma_de[1]_iqr1-2', 'lspFreq_sma_de[1]_iqr2-3', 'lspFreq_sma_de[1]_iqr1-3', 'lspFreq_sma_de[1]_percentile1.0', 'lspFreq_sma_de[1]_percentile99.0', 'lspFreq_sma_de[1]_pctlrange0-1', 'lspFreq_sma_de[1]_upleveltime75', 'lspFreq_sma_de[1]_upleveltime90', 'lspFreq_sma_de[2]_maxPos', 'lspFreq_sma_de[2]_minPos', 'lspFreq_sma_de[2]_amean', 'lspFreq_sma_de[2]_linregc1', 'lspFreq_sma_de[2]_linregc2', 'lspFreq_sma_de[2]_linregerrA', 'lspFreq_sma_de[2]_linregerrQ', 'lspFreq_sma_de[2]_stddev', 'lspFreq_sma_de[2]_skewness', 'lspFreq_sma_de[2]_kurtosis', 'lspFreq_sma_de[2]_quartile1', 'lspFreq_sma_de[2]_quartile2', 'lspFreq_sma_de[2]_quartile3', 'lspFreq_sma_de[2]_iqr1-2', 'lspFreq_sma_de[2]_iqr2-3', 'lspFreq_sma_de[2]_iqr1-3', 'lspFreq_sma_de[2]_percentile1.0', 'lspFreq_sma_de[2]_percentile99.0', 'lspFreq_sma_de[2]_pctlrange0-1', 'lspFreq_sma_de[2]_upleveltime75', 'lspFreq_sma_de[2]_upleveltime90', 'lspFreq_sma_de[3]_maxPos', 'lspFreq_sma_de[3]_minPos', 'lspFreq_sma_de[3]_amean', 'lspFreq_sma_de[3]_linregc1', 'lspFreq_sma_de[3]_linregc2', 'lspFreq_sma_de[3]_linregerrA', 'lspFreq_sma_de[3]_linregerrQ', 'lspFreq_sma_de[3]_stddev', 'lspFreq_sma_de[3]_skewness', 'lspFreq_sma_de[3]_kurtosis', 'lspFreq_sma_de[3]_quartile1', 'lspFreq_sma_de[3]_quartile2', 'lspFreq_sma_de[3]_quartile3', 'lspFreq_sma_de[3]_iqr1-2', 'lspFreq_sma_de[3]_iqr2-3', 'lspFreq_sma_de[3]_iqr1-3', 'lspFreq_sma_de[3]_percentile1.0', 'lspFreq_sma_de[3]_percentile99.0', 'lspFreq_sma_de[3]_pctlrange0-1', 'lspFreq_sma_de[3]_upleveltime75', 'lspFreq_sma_de[3]_upleveltime90', 'lspFreq_sma_de[4]_maxPos', 'lspFreq_sma_de[4]_minPos', 'lspFreq_sma_de[4]_amean', 'lspFreq_sma_de[4]_linregc1', 'lspFreq_sma_de[4]_linregc2', 'lspFreq_sma_de[4]_linregerrA', 'lspFreq_sma_de[4]_linregerrQ', 'lspFreq_sma_de[4]_stddev', 'lspFreq_sma_de[4]_skewness', 'lspFreq_sma_de[4]_kurtosis', 'lspFreq_sma_de[4]_quartile1', 'lspFreq_sma_de[4]_quartile2', 'lspFreq_sma_de[4]_quartile3', 'lspFreq_sma_de[4]_iqr1-2', 'lspFreq_sma_de[4]_iqr2-3', 'lspFreq_sma_de[4]_iqr1-3', 'lspFreq_sma_de[4]_percentile1.0', 'lspFreq_sma_de[4]_percentile99.0', 'lspFreq_sma_de[4]_pctlrange0-1', 'lspFreq_sma_de[4]_upleveltime75', 'lspFreq_sma_de[4]_upleveltime90', 'lspFreq_sma_de[5]_maxPos', 'lspFreq_sma_de[5]_minPos', 'lspFreq_sma_de[5]_amean', 'lspFreq_sma_de[5]_linregc1', 'lspFreq_sma_de[5]_linregc2', 'lspFreq_sma_de[5]_linregerrA', 'lspFreq_sma_de[5]_linregerrQ', 'lspFreq_sma_de[5]_stddev', 'lspFreq_sma_de[5]_skewness', 'lspFreq_sma_de[5]_kurtosis', 'lspFreq_sma_de[5]_quartile1', 'lspFreq_sma_de[5]_quartile2', 'lspFreq_sma_de[5]_quartile3', 'lspFreq_sma_de[5]_iqr1-2', 'lspFreq_sma_de[5]_iqr2-3', 'lspFreq_sma_de[5]_iqr1-3', 'lspFreq_sma_de[5]_percentile1.0', 'lspFreq_sma_de[5]_percentile99.0', 'lspFreq_sma_de[5]_pctlrange0-1', 'lspFreq_sma_de[5]_upleveltime75', 'lspFreq_sma_de[5]_upleveltime90', 'lspFreq_sma_de[6]_maxPos', 'lspFreq_sma_de[6]_minPos', 'lspFreq_sma_de[6]_amean', 'lspFreq_sma_de[6]_linregc1', 'lspFreq_sma_de[6]_linregc2', 'lspFreq_sma_de[6]_linregerrA', 'lspFreq_sma_de[6]_linregerrQ', 'lspFreq_sma_de[6]_stddev', 'lspFreq_sma_de[6]_skewness', 'lspFreq_sma_de[6]_kurtosis', 'lspFreq_sma_de[6]_quartile1', 'lspFreq_sma_de[6]_quartile2', 'lspFreq_sma_de[6]_quartile3', 'lspFreq_sma_de[6]_iqr1-2', 'lspFreq_sma_de[6]_iqr2-3', 'lspFreq_sma_de[6]_iqr1-3', 'lspFreq_sma_de[6]_percentile1.0', 'lspFreq_sma_de[6]_percentile99.0', 'lspFreq_sma_de[6]_pctlrange0-1', 'lspFreq_sma_de[6]_upleveltime75', 'lspFreq_sma_de[6]_upleveltime90', 'lspFreq_sma_de[7]_maxPos', 'lspFreq_sma_de[7]_minPos', 'lspFreq_sma_de[7]_amean', 'lspFreq_sma_de[7]_linregc1', 'lspFreq_sma_de[7]_linregc2', 'lspFreq_sma_de[7]_linregerrA', 'lspFreq_sma_de[7]_linregerrQ', 'lspFreq_sma_de[7]_stddev', 'lspFreq_sma_de[7]_skewness', 'lspFreq_sma_de[7]_kurtosis', 'lspFreq_sma_de[7]_quartile1', 'lspFreq_sma_de[7]_quartile2', 'lspFreq_sma_de[7]_quartile3', 'lspFreq_sma_de[7]_iqr1-2', 'lspFreq_sma_de[7]_iqr2-3', 'lspFreq_sma_de[7]_iqr1-3', 'lspFreq_sma_de[7]_percentile1.0', 'lspFreq_sma_de[7]_percentile99.0', 'lspFreq_sma_de[7]_pctlrange0-1', 'lspFreq_sma_de[7]_upleveltime75', 'lspFreq_sma_de[7]_upleveltime90', 'F0finEnv_sma_de_maxPos', 'F0finEnv_sma_de_minPos', 'F0finEnv_sma_de_amean', 'F0finEnv_sma_de_linregc1', 'F0finEnv_sma_de_linregc2', 'F0finEnv_sma_de_linregerrA', 'F0finEnv_sma_de_linregerrQ', 'F0finEnv_sma_de_stddev', 'F0finEnv_sma_de_skewness', 'F0finEnv_sma_de_kurtosis', 'F0finEnv_sma_de_quartile1', 'F0finEnv_sma_de_quartile2', 'F0finEnv_sma_de_quartile3', 'F0finEnv_sma_de_iqr1-2', 'F0finEnv_sma_de_iqr2-3', 'F0finEnv_sma_de_iqr1-3', 'F0finEnv_sma_de_percentile1.0', 'F0finEnv_sma_de_percentile99.0', 'F0finEnv_sma_de_pctlrange0-1', 'F0finEnv_sma_de_upleveltime75', 'F0finEnv_sma_de_upleveltime90', 'voicingFinalUnclipped_sma_de_maxPos', 'voicingFinalUnclipped_sma_de_minPos', 'voicingFinalUnclipped_sma_de_amean', 'voicingFinalUnclipped_sma_de_linregc1', 'voicingFinalUnclipped_sma_de_linregc2', 'voicingFinalUnclipped_sma_de_linregerrA', 'voicingFinalUnclipped_sma_de_linregerrQ', 'voicingFinalUnclipped_sma_de_stddev', 'voicingFinalUnclipped_sma_de_skewness', 'voicingFinalUnclipped_sma_de_kurtosis', 'voicingFinalUnclipped_sma_de_quartile1', 'voicingFinalUnclipped_sma_de_quartile2', 'voicingFinalUnclipped_sma_de_quartile3', 'voicingFinalUnclipped_sma_de_iqr1-2', 'voicingFinalUnclipped_sma_de_iqr2-3', 'voicingFinalUnclipped_sma_de_iqr1-3', 'voicingFinalUnclipped_sma_de_percentile1.0', 'voicingFinalUnclipped_sma_de_percentile99.0', 'voicingFinalUnclipped_sma_de_pctlrange0-1', 'voicingFinalUnclipped_sma_de_upleveltime75', 'voicingFinalUnclipped_sma_de_upleveltime90', 'F0final_sma_maxPos', 'F0final_sma_minPos', 'F0final_sma_amean', 'F0final_sma_linregc1', 'F0final_sma_linregc2', 'F0final_sma_linregerrA', 'F0final_sma_linregerrQ', 'F0final_sma_stddev', 'F0final_sma_skewness', 'F0final_sma_kurtosis', 'F0final_sma_quartile1', 'F0final_sma_quartile2', 'F0final_sma_quartile3', 'F0final_sma_iqr1-2', 'F0final_sma_iqr2-3', 'F0final_sma_iqr1-3', 'F0final_sma_percentile99.0', 'F0final_sma_upleveltime75', 'F0final_sma_upleveltime90', 'jitterLocal_sma_maxPos', 'jitterLocal_sma_minPos', 'jitterLocal_sma_amean', 'jitterLocal_sma_linregc1', 'jitterLocal_sma_linregc2', 'jitterLocal_sma_linregerrA', 'jitterLocal_sma_linregerrQ', 'jitterLocal_sma_stddev', 'jitterLocal_sma_skewness', 'jitterLocal_sma_kurtosis', 'jitterLocal_sma_quartile1', 'jitterLocal_sma_quartile2', 'jitterLocal_sma_quartile3', 'jitterLocal_sma_iqr1-2', 'jitterLocal_sma_iqr2-3', 'jitterLocal_sma_iqr1-3', 'jitterLocal_sma_percentile99.0', 'jitterLocal_sma_upleveltime75', 'jitterLocal_sma_upleveltime90', 'jitterDDP_sma_maxPos', 'jitterDDP_sma_minPos', 'jitterDDP_sma_amean', 'jitterDDP_sma_linregc1', 'jitterDDP_sma_linregc2', 'jitterDDP_sma_linregerrA', 'jitterDDP_sma_linregerrQ', 'jitterDDP_sma_stddev', 'jitterDDP_sma_skewness', 'jitterDDP_sma_kurtosis', 'jitterDDP_sma_quartile1', 'jitterDDP_sma_quartile2', 'jitterDDP_sma_quartile3', 'jitterDDP_sma_iqr1-2', 'jitterDDP_sma_iqr2-3', 'jitterDDP_sma_iqr1-3', 'jitterDDP_sma_percentile99.0', 'jitterDDP_sma_upleveltime75', 'jitterDDP_sma_upleveltime90', 'shimmerLocal_sma_maxPos', 'shimmerLocal_sma_minPos', 'shimmerLocal_sma_amean', 'shimmerLocal_sma_linregc1', 'shimmerLocal_sma_linregc2', 'shimmerLocal_sma_linregerrA', 'shimmerLocal_sma_linregerrQ', 'shimmerLocal_sma_stddev', 'shimmerLocal_sma_skewness', 'shimmerLocal_sma_kurtosis', 'shimmerLocal_sma_quartile1', 'shimmerLocal_sma_quartile2', 'shimmerLocal_sma_quartile3', 'shimmerLocal_sma_iqr1-2', 'shimmerLocal_sma_iqr2-3', 'shimmerLocal_sma_iqr1-3', 'shimmerLocal_sma_percentile99.0', 'shimmerLocal_sma_upleveltime75', 'shimmerLocal_sma_upleveltime90', 'F0final_sma_de_maxPos', 'F0final_sma_de_minPos', 'F0final_sma_de_amean', 'F0final_sma_de_linregc1', 'F0final_sma_de_linregc2', 'F0final_sma_de_linregerrA', 'F0final_sma_de_linregerrQ', 'F0final_sma_de_stddev', 'F0final_sma_de_skewness', 'F0final_sma_de_kurtosis', 'F0final_sma_de_quartile1', 'F0final_sma_de_quartile2', 'F0final_sma_de_quartile3', 'F0final_sma_de_iqr1-2', 'F0final_sma_de_iqr2-3', 'F0final_sma_de_iqr1-3', 'F0final_sma_de_percentile99.0', 'F0final_sma_de_upleveltime75', 'F0final_sma_de_upleveltime90', 'jitterLocal_sma_de_maxPos', 'jitterLocal_sma_de_minPos', 'jitterLocal_sma_de_amean', 'jitterLocal_sma_de_linregc1', 'jitterLocal_sma_de_linregc2', 'jitterLocal_sma_de_linregerrA', 'jitterLocal_sma_de_linregerrQ', 'jitterLocal_sma_de_stddev', 'jitterLocal_sma_de_skewness', 'jitterLocal_sma_de_kurtosis', 'jitterLocal_sma_de_quartile1', 'jitterLocal_sma_de_quartile2', 'jitterLocal_sma_de_quartile3', 'jitterLocal_sma_de_iqr1-2', 'jitterLocal_sma_de_iqr2-3', 'jitterLocal_sma_de_iqr1-3', 'jitterLocal_sma_de_percentile99.0', 'jitterLocal_sma_de_upleveltime75', 'jitterLocal_sma_de_upleveltime90', 'jitterDDP_sma_de_maxPos', 'jitterDDP_sma_de_minPos', 'jitterDDP_sma_de_amean', 'jitterDDP_sma_de_linregc1', 'jitterDDP_sma_de_linregc2', 'jitterDDP_sma_de_linregerrA', 'jitterDDP_sma_de_linregerrQ', 'jitterDDP_sma_de_stddev', 'jitterDDP_sma_de_skewness', 'jitterDDP_sma_de_kurtosis', 'jitterDDP_sma_de_quartile1', 'jitterDDP_sma_de_quartile2', 'jitterDDP_sma_de_quartile3', 'jitterDDP_sma_de_iqr1-2', 'jitterDDP_sma_de_iqr2-3', 'jitterDDP_sma_de_iqr1-3', 'jitterDDP_sma_de_percentile99.0', 'jitterDDP_sma_de_upleveltime75', 'jitterDDP_sma_de_upleveltime90', 'shimmerLocal_sma_de_maxPos', 'shimmerLocal_sma_de_minPos', 'shimmerLocal_sma_de_amean', 'shimmerLocal_sma_de_linregc1', 'shimmerLocal_sma_de_linregc2', 'shimmerLocal_sma_de_linregerrA', 'shimmerLocal_sma_de_linregerrQ', 'shimmerLocal_sma_de_stddev', 'shimmerLocal_sma_de_skewness', 'shimmerLocal_sma_de_kurtosis', 'shimmerLocal_sma_de_quartile1', 'shimmerLocal_sma_de_quartile2', 'shimmerLocal_sma_de_quartile3', 'shimmerLocal_sma_de_iqr1-2', 'shimmerLocal_sma_de_iqr2-3', 'shimmerLocal_sma_de_iqr1-3', 'shimmerLocal_sma_de_percentile99.0', 'shimmerLocal_sma_de_upleveltime75', 'shimmerLocal_sma_de_upleveltime90', 'F0final__Turn_numOnsets', 'F0final__Turn_duration', 'class'], 'featureset bib citation': '@inproceedings{eyben2010opensmile,title={Opensmile: the munich versatile and fast open-source audio feature extractor},author={Eyben, Florian and W{\"o}llmer, Martin and Schuller, Bj{\"o}rn},booktitle={Proceedings of the 18th ACM international conference on Multimedia},pages={1459--1462},year={2010},organization={ACM}}', 'md5': None, 'root name': 'OpenSmile_emobase2010', 'uuid': 'd1a761a6-fd87-41e3-9812-64fd24996491'}\n",
      "\n",
      "\n",
      "=== Metadata OpenSmile IS09 Acoustic===\n",
      "\n",
      "Acoustic OpenSmile IS09 Metadata: {'alignment compatible': \"b'True'\", 'computational sequence description': \"b'MOSI openSMILE'\", 'computational sequence version': 1.0, 'contact': \"b'abagherz@andrew.cmu.edu;zhunl@cs.cmu.edu'\", 'creator': \"b'Zhun Liu'\", 'dataset bib citation': \"b'@article{zadeh2016mosi,title={MOSI: multimodal corpus of sentiment intensity and subjectivity analysis in online opinion videos},author={Zadeh, Amir and Zellers, Rowan and Pincus, Eli and Morency, Louis-Philippe},journal={arXiv preprint arXiv:1606.06259},year={2016}}'\", 'dataset name': \"b'MOSI'\", 'dataset version': 1.0, 'dimension names': 'b\"[\\'pcm_RMSenergy_sma_max\\', \\'pcm_RMSenergy_sma_min\\', \\'pcm_RMSenergy_sma_range\\', \\'pcm_RMSenergy_sma_maxPos\\', \\'pcm_RMSenergy_sma_minPos\\', \\'pcm_RMSenergy_sma_amean\\', \\'pcm_RMSenergy_sma_linregc1\\', \\'pcm_RMSenergy_sma_linregc2\\', \\'pcm_RMSenergy_sma_linregerrQ\\', \\'pcm_RMSenergy_sma_stddev\\', \\'pcm_RMSenergy_sma_skewness\\', \\'pcm_RMSenergy_sma_kurtosis\\', \\'pcm_fftMag_mfcc_sma[1]_max\\', \\'pcm_fftMag_mfcc_sma[1]_min\\', \\'pcm_fftMag_mfcc_sma[1]_range\\', \\'pcm_fftMag_mfcc_sma[1]_maxPos\\', \\'pcm_fftMag_mfcc_sma[1]_minPos\\', \\'pcm_fftMag_mfcc_sma[1]_amean\\', \\'pcm_fftMag_mfcc_sma[1]_linregc1\\', \\'pcm_fftMag_mfcc_sma[1]_linregc2\\', \\'pcm_fftMag_mfcc_sma[1]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma[1]_stddev\\', \\'pcm_fftMag_mfcc_sma[1]_skewness\\', \\'pcm_fftMag_mfcc_sma[1]_kurtosis\\', \\'pcm_fftMag_mfcc_sma[2]_max\\', \\'pcm_fftMag_mfcc_sma[2]_min\\', \\'pcm_fftMag_mfcc_sma[2]_range\\', \\'pcm_fftMag_mfcc_sma[2]_maxPos\\', \\'pcm_fftMag_mfcc_sma[2]_minPos\\', \\'pcm_fftMag_mfcc_sma[2]_amean\\', \\'pcm_fftMag_mfcc_sma[2]_linregc1\\', \\'pcm_fftMag_mfcc_sma[2]_linregc2\\', \\'pcm_fftMag_mfcc_sma[2]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma[2]_stddev\\', \\'pcm_fftMag_mfcc_sma[2]_skewness\\', \\'pcm_fftMag_mfcc_sma[2]_kurtosis\\', \\'pcm_fftMag_mfcc_sma[3]_max\\', \\'pcm_fftMag_mfcc_sma[3]_min\\', \\'pcm_fftMag_mfcc_sma[3]_range\\', \\'pcm_fftMag_mfcc_sma[3]_maxPos\\', \\'pcm_fftMag_mfcc_sma[3]_minPos\\', \\'pcm_fftMag_mfcc_sma[3]_amean\\', \\'pcm_fftMag_mfcc_sma[3]_linregc1\\', \\'pcm_fftMag_mfcc_sma[3]_linregc2\\', \\'pcm_fftMag_mfcc_sma[3]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma[3]_stddev\\', \\'pcm_fftMag_mfcc_sma[3]_skewness\\', \\'pcm_fftMag_mfcc_sma[3]_kurtosis\\', \\'pcm_fftMag_mfcc_sma[4]_max\\', \\'pcm_fftMag_mfcc_sma[4]_min\\', \\'pcm_fftMag_mfcc_sma[4]_range\\', \\'pcm_fftMag_mfcc_sma[4]_maxPos\\', \\'pcm_fftMag_mfcc_sma[4]_minPos\\', \\'pcm_fftMag_mfcc_sma[4]_amean\\', \\'pcm_fftMag_mfcc_sma[4]_linregc1\\', \\'pcm_fftMag_mfcc_sma[4]_linregc2\\', \\'pcm_fftMag_mfcc_sma[4]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma[4]_stddev\\', \\'pcm_fftMag_mfcc_sma[4]_skewness\\', \\'pcm_fftMag_mfcc_sma[4]_kurtosis\\', \\'pcm_fftMag_mfcc_sma[5]_max\\', \\'pcm_fftMag_mfcc_sma[5]_min\\', \\'pcm_fftMag_mfcc_sma[5]_range\\', \\'pcm_fftMag_mfcc_sma[5]_maxPos\\', \\'pcm_fftMag_mfcc_sma[5]_minPos\\', \\'pcm_fftMag_mfcc_sma[5]_amean\\', \\'pcm_fftMag_mfcc_sma[5]_linregc1\\', \\'pcm_fftMag_mfcc_sma[5]_linregc2\\', \\'pcm_fftMag_mfcc_sma[5]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma[5]_stddev\\', \\'pcm_fftMag_mfcc_sma[5]_skewness\\', \\'pcm_fftMag_mfcc_sma[5]_kurtosis\\', \\'pcm_fftMag_mfcc_sma[6]_max\\', \\'pcm_fftMag_mfcc_sma[6]_min\\', \\'pcm_fftMag_mfcc_sma[6]_range\\', \\'pcm_fftMag_mfcc_sma[6]_maxPos\\', \\'pcm_fftMag_mfcc_sma[6]_minPos\\', \\'pcm_fftMag_mfcc_sma[6]_amean\\', \\'pcm_fftMag_mfcc_sma[6]_linregc1\\', \\'pcm_fftMag_mfcc_sma[6]_linregc2\\', \\'pcm_fftMag_mfcc_sma[6]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma[6]_stddev\\', \\'pcm_fftMag_mfcc_sma[6]_skewness\\', \\'pcm_fftMag_mfcc_sma[6]_kurtosis\\', \\'pcm_fftMag_mfcc_sma[7]_max\\', \\'pcm_fftMag_mfcc_sma[7]_min\\', \\'pcm_fftMag_mfcc_sma[7]_range\\', \\'pcm_fftMag_mfcc_sma[7]_maxPos\\', \\'pcm_fftMag_mfcc_sma[7]_minPos\\', \\'pcm_fftMag_mfcc_sma[7]_amean\\', \\'pcm_fftMag_mfcc_sma[7]_linregc1\\', \\'pcm_fftMag_mfcc_sma[7]_linregc2\\', \\'pcm_fftMag_mfcc_sma[7]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma[7]_stddev\\', \\'pcm_fftMag_mfcc_sma[7]_skewness\\', \\'pcm_fftMag_mfcc_sma[7]_kurtosis\\', \\'pcm_fftMag_mfcc_sma[8]_max\\', \\'pcm_fftMag_mfcc_sma[8]_min\\', \\'pcm_fftMag_mfcc_sma[8]_range\\', \\'pcm_fftMag_mfcc_sma[8]_maxPos\\', \\'pcm_fftMag_mfcc_sma[8]_minPos\\', \\'pcm_fftMag_mfcc_sma[8]_amean\\', \\'pcm_fftMag_mfcc_sma[8]_linregc1\\', \\'pcm_fftMag_mfcc_sma[8]_linregc2\\', \\'pcm_fftMag_mfcc_sma[8]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma[8]_stddev\\', \\'pcm_fftMag_mfcc_sma[8]_skewness\\', \\'pcm_fftMag_mfcc_sma[8]_kurtosis\\', \\'pcm_fftMag_mfcc_sma[9]_max\\', \\'pcm_fftMag_mfcc_sma[9]_min\\', \\'pcm_fftMag_mfcc_sma[9]_range\\', \\'pcm_fftMag_mfcc_sma[9]_maxPos\\', \\'pcm_fftMag_mfcc_sma[9]_minPos\\', \\'pcm_fftMag_mfcc_sma[9]_amean\\', \\'pcm_fftMag_mfcc_sma[9]_linregc1\\', \\'pcm_fftMag_mfcc_sma[9]_linregc2\\', \\'pcm_fftMag_mfcc_sma[9]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma[9]_stddev\\', \\'pcm_fftMag_mfcc_sma[9]_skewness\\', \\'pcm_fftMag_mfcc_sma[9]_kurtosis\\', \\'pcm_fftMag_mfcc_sma[10]_max\\', \\'pcm_fftMag_mfcc_sma[10]_min\\', \\'pcm_fftMag_mfcc_sma[10]_range\\', \\'pcm_fftMag_mfcc_sma[10]_maxPos\\', \\'pcm_fftMag_mfcc_sma[10]_minPos\\', \\'pcm_fftMag_mfcc_sma[10]_amean\\', \\'pcm_fftMag_mfcc_sma[10]_linregc1\\', \\'pcm_fftMag_mfcc_sma[10]_linregc2\\', \\'pcm_fftMag_mfcc_sma[10]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma[10]_stddev\\', \\'pcm_fftMag_mfcc_sma[10]_skewness\\', \\'pcm_fftMag_mfcc_sma[10]_kurtosis\\', \\'pcm_fftMag_mfcc_sma[11]_max\\', \\'pcm_fftMag_mfcc_sma[11]_min\\', \\'pcm_fftMag_mfcc_sma[11]_range\\', \\'pcm_fftMag_mfcc_sma[11]_maxPos\\', \\'pcm_fftMag_mfcc_sma[11]_minPos\\', \\'pcm_fftMag_mfcc_sma[11]_amean\\', \\'pcm_fftMag_mfcc_sma[11]_linregc1\\', \\'pcm_fftMag_mfcc_sma[11]_linregc2\\', \\'pcm_fftMag_mfcc_sma[11]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma[11]_stddev\\', \\'pcm_fftMag_mfcc_sma[11]_skewness\\', \\'pcm_fftMag_mfcc_sma[11]_kurtosis\\', \\'pcm_fftMag_mfcc_sma[12]_max\\', \\'pcm_fftMag_mfcc_sma[12]_min\\', \\'pcm_fftMag_mfcc_sma[12]_range\\', \\'pcm_fftMag_mfcc_sma[12]_maxPos\\', \\'pcm_fftMag_mfcc_sma[12]_minPos\\', \\'pcm_fftMag_mfcc_sma[12]_amean\\', \\'pcm_fftMag_mfcc_sma[12]_linregc1\\', \\'pcm_fftMag_mfcc_sma[12]_linregc2\\', \\'pcm_fftMag_mfcc_sma[12]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma[12]_stddev\\', \\'pcm_fftMag_mfcc_sma[12]_skewness\\', \\'pcm_fftMag_mfcc_sma[12]_kurtosis\\', \\'pcm_zcr_sma_max\\', \\'pcm_zcr_sma_min\\', \\'pcm_zcr_sma_range\\', \\'pcm_zcr_sma_maxPos\\', \\'pcm_zcr_sma_minPos\\', \\'pcm_zcr_sma_amean\\', \\'pcm_zcr_sma_linregc1\\', \\'pcm_zcr_sma_linregc2\\', \\'pcm_zcr_sma_linregerrQ\\', \\'pcm_zcr_sma_stddev\\', \\'pcm_zcr_sma_skewness\\', \\'pcm_zcr_sma_kurtosis\\', \\'voiceProb_sma_max\\', \\'voiceProb_sma_min\\', \\'voiceProb_sma_range\\', \\'voiceProb_sma_maxPos\\', \\'voiceProb_sma_minPos\\', \\'voiceProb_sma_amean\\', \\'voiceProb_sma_linregc1\\', \\'voiceProb_sma_linregc2\\', \\'voiceProb_sma_linregerrQ\\', \\'voiceProb_sma_stddev\\', \\'voiceProb_sma_skewness\\', \\'voiceProb_sma_kurtosis\\', \\'F0_sma_max\\', \\'F0_sma_min\\', \\'F0_sma_range\\', \\'F0_sma_maxPos\\', \\'F0_sma_minPos\\', \\'F0_sma_amean\\', \\'F0_sma_linregc1\\', \\'F0_sma_linregc2\\', \\'F0_sma_linregerrQ\\', \\'F0_sma_stddev\\', \\'F0_sma_skewness\\', \\'F0_sma_kurtosis\\', \\'pcm_RMSenergy_sma_de_max\\', \\'pcm_RMSenergy_sma_de_min\\', \\'pcm_RMSenergy_sma_de_range\\', \\'pcm_RMSenergy_sma_de_maxPos\\', \\'pcm_RMSenergy_sma_de_minPos\\', \\'pcm_RMSenergy_sma_de_amean\\', \\'pcm_RMSenergy_sma_de_linregc1\\', \\'pcm_RMSenergy_sma_de_linregc2\\', \\'pcm_RMSenergy_sma_de_linregerrQ\\', \\'pcm_RMSenergy_sma_de_stddev\\', \\'pcm_RMSenergy_sma_de_skewness\\', \\'pcm_RMSenergy_sma_de_kurtosis\\', \\'pcm_fftMag_mfcc_sma_de[1]_max\\', \\'pcm_fftMag_mfcc_sma_de[1]_min\\', \\'pcm_fftMag_mfcc_sma_de[1]_range\\', \\'pcm_fftMag_mfcc_sma_de[1]_maxPos\\', \\'pcm_fftMag_mfcc_sma_de[1]_minPos\\', \\'pcm_fftMag_mfcc_sma_de[1]_amean\\', \\'pcm_fftMag_mfcc_sma_de[1]_linregc1\\', \\'pcm_fftMag_mfcc_sma_de[1]_linregc2\\', \\'pcm_fftMag_mfcc_sma_de[1]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma_de[1]_stddev\\', \\'pcm_fftMag_mfcc_sma_de[1]_skewness\\', \\'pcm_fftMag_mfcc_sma_de[1]_kurtosis\\', \\'pcm_fftMag_mfcc_sma_de[2]_max\\', \\'pcm_fftMag_mfcc_sma_de[2]_min\\', \\'pcm_fftMag_mfcc_sma_de[2]_range\\', \\'pcm_fftMag_mfcc_sma_de[2]_maxPos\\', \\'pcm_fftMag_mfcc_sma_de[2]_minPos\\', \\'pcm_fftMag_mfcc_sma_de[2]_amean\\', \\'pcm_fftMag_mfcc_sma_de[2]_linregc1\\', \\'pcm_fftMag_mfcc_sma_de[2]_linregc2\\', \\'pcm_fftMag_mfcc_sma_de[2]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma_de[2]_stddev\\', \\'pcm_fftMag_mfcc_sma_de[2]_skewness\\', \\'pcm_fftMag_mfcc_sma_de[2]_kurtosis\\', \\'pcm_fftMag_mfcc_sma_de[3]_max\\', \\'pcm_fftMag_mfcc_sma_de[3]_min\\', \\'pcm_fftMag_mfcc_sma_de[3]_range\\', \\'pcm_fftMag_mfcc_sma_de[3]_maxPos\\', \\'pcm_fftMag_mfcc_sma_de[3]_minPos\\', \\'pcm_fftMag_mfcc_sma_de[3]_amean\\', \\'pcm_fftMag_mfcc_sma_de[3]_linregc1\\', \\'pcm_fftMag_mfcc_sma_de[3]_linregc2\\', \\'pcm_fftMag_mfcc_sma_de[3]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma_de[3]_stddev\\', \\'pcm_fftMag_mfcc_sma_de[3]_skewness\\', \\'pcm_fftMag_mfcc_sma_de[3]_kurtosis\\', \\'pcm_fftMag_mfcc_sma_de[4]_max\\', \\'pcm_fftMag_mfcc_sma_de[4]_min\\', \\'pcm_fftMag_mfcc_sma_de[4]_range\\', \\'pcm_fftMag_mfcc_sma_de[4]_maxPos\\', \\'pcm_fftMag_mfcc_sma_de[4]_minPos\\', \\'pcm_fftMag_mfcc_sma_de[4]_amean\\', \\'pcm_fftMag_mfcc_sma_de[4]_linregc1\\', \\'pcm_fftMag_mfcc_sma_de[4]_linregc2\\', \\'pcm_fftMag_mfcc_sma_de[4]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma_de[4]_stddev\\', \\'pcm_fftMag_mfcc_sma_de[4]_skewness\\', \\'pcm_fftMag_mfcc_sma_de[4]_kurtosis\\', \\'pcm_fftMag_mfcc_sma_de[5]_max\\', \\'pcm_fftMag_mfcc_sma_de[5]_min\\', \\'pcm_fftMag_mfcc_sma_de[5]_range\\', \\'pcm_fftMag_mfcc_sma_de[5]_maxPos\\', \\'pcm_fftMag_mfcc_sma_de[5]_minPos\\', \\'pcm_fftMag_mfcc_sma_de[5]_amean\\', \\'pcm_fftMag_mfcc_sma_de[5]_linregc1\\', \\'pcm_fftMag_mfcc_sma_de[5]_linregc2\\', \\'pcm_fftMag_mfcc_sma_de[5]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma_de[5]_stddev\\', \\'pcm_fftMag_mfcc_sma_de[5]_skewness\\', \\'pcm_fftMag_mfcc_sma_de[5]_kurtosis\\', \\'pcm_fftMag_mfcc_sma_de[6]_max\\', \\'pcm_fftMag_mfcc_sma_de[6]_min\\', \\'pcm_fftMag_mfcc_sma_de[6]_range\\', \\'pcm_fftMag_mfcc_sma_de[6]_maxPos\\', \\'pcm_fftMag_mfcc_sma_de[6]_minPos\\', \\'pcm_fftMag_mfcc_sma_de[6]_amean\\', \\'pcm_fftMag_mfcc_sma_de[6]_linregc1\\', \\'pcm_fftMag_mfcc_sma_de[6]_linregc2\\', \\'pcm_fftMag_mfcc_sma_de[6]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma_de[6]_stddev\\', \\'pcm_fftMag_mfcc_sma_de[6]_skewness\\', \\'pcm_fftMag_mfcc_sma_de[6]_kurtosis\\', \\'pcm_fftMag_mfcc_sma_de[7]_max\\', \\'pcm_fftMag_mfcc_sma_de[7]_min\\', \\'pcm_fftMag_mfcc_sma_de[7]_range\\', \\'pcm_fftMag_mfcc_sma_de[7]_maxPos\\', \\'pcm_fftMag_mfcc_sma_de[7]_minPos\\', \\'pcm_fftMag_mfcc_sma_de[7]_amean\\', \\'pcm_fftMag_mfcc_sma_de[7]_linregc1\\', \\'pcm_fftMag_mfcc_sma_de[7]_linregc2\\', \\'pcm_fftMag_mfcc_sma_de[7]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma_de[7]_stddev\\', \\'pcm_fftMag_mfcc_sma_de[7]_skewness\\', \\'pcm_fftMag_mfcc_sma_de[7]_kurtosis\\', \\'pcm_fftMag_mfcc_sma_de[8]_max\\', \\'pcm_fftMag_mfcc_sma_de[8]_min\\', \\'pcm_fftMag_mfcc_sma_de[8]_range\\', \\'pcm_fftMag_mfcc_sma_de[8]_maxPos\\', \\'pcm_fftMag_mfcc_sma_de[8]_minPos\\', \\'pcm_fftMag_mfcc_sma_de[8]_amean\\', \\'pcm_fftMag_mfcc_sma_de[8]_linregc1\\', \\'pcm_fftMag_mfcc_sma_de[8]_linregc2\\', \\'pcm_fftMag_mfcc_sma_de[8]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma_de[8]_stddev\\', \\'pcm_fftMag_mfcc_sma_de[8]_skewness\\', \\'pcm_fftMag_mfcc_sma_de[8]_kurtosis\\', \\'pcm_fftMag_mfcc_sma_de[9]_max\\', \\'pcm_fftMag_mfcc_sma_de[9]_min\\', \\'pcm_fftMag_mfcc_sma_de[9]_range\\', \\'pcm_fftMag_mfcc_sma_de[9]_maxPos\\', \\'pcm_fftMag_mfcc_sma_de[9]_minPos\\', \\'pcm_fftMag_mfcc_sma_de[9]_amean\\', \\'pcm_fftMag_mfcc_sma_de[9]_linregc1\\', \\'pcm_fftMag_mfcc_sma_de[9]_linregc2\\', \\'pcm_fftMag_mfcc_sma_de[9]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma_de[9]_stddev\\', \\'pcm_fftMag_mfcc_sma_de[9]_skewness\\', \\'pcm_fftMag_mfcc_sma_de[9]_kurtosis\\', \\'pcm_fftMag_mfcc_sma_de[10]_max\\', \\'pcm_fftMag_mfcc_sma_de[10]_min\\', \\'pcm_fftMag_mfcc_sma_de[10]_range\\', \\'pcm_fftMag_mfcc_sma_de[10]_maxPos\\', \\'pcm_fftMag_mfcc_sma_de[10]_minPos\\', \\'pcm_fftMag_mfcc_sma_de[10]_amean\\', \\'pcm_fftMag_mfcc_sma_de[10]_linregc1\\', \\'pcm_fftMag_mfcc_sma_de[10]_linregc2\\', \\'pcm_fftMag_mfcc_sma_de[10]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma_de[10]_stddev\\', \\'pcm_fftMag_mfcc_sma_de[10]_skewness\\', \\'pcm_fftMag_mfcc_sma_de[10]_kurtosis\\', \\'pcm_fftMag_mfcc_sma_de[11]_max\\', \\'pcm_fftMag_mfcc_sma_de[11]_min\\', \\'pcm_fftMag_mfcc_sma_de[11]_range\\', \\'pcm_fftMag_mfcc_sma_de[11]_maxPos\\', \\'pcm_fftMag_mfcc_sma_de[11]_minPos\\', \\'pcm_fftMag_mfcc_sma_de[11]_amean\\', \\'pcm_fftMag_mfcc_sma_de[11]_linregc1\\', \\'pcm_fftMag_mfcc_sma_de[11]_linregc2\\', \\'pcm_fftMag_mfcc_sma_de[11]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma_de[11]_stddev\\', \\'pcm_fftMag_mfcc_sma_de[11]_skewness\\', \\'pcm_fftMag_mfcc_sma_de[11]_kurtosis\\', \\'pcm_fftMag_mfcc_sma_de[12]_max\\', \\'pcm_fftMag_mfcc_sma_de[12]_min\\', \\'pcm_fftMag_mfcc_sma_de[12]_range\\', \\'pcm_fftMag_mfcc_sma_de[12]_maxPos\\', \\'pcm_fftMag_mfcc_sma_de[12]_minPos\\', \\'pcm_fftMag_mfcc_sma_de[12]_amean\\', \\'pcm_fftMag_mfcc_sma_de[12]_linregc1\\', \\'pcm_fftMag_mfcc_sma_de[12]_linregc2\\', \\'pcm_fftMag_mfcc_sma_de[12]_linregerrQ\\', \\'pcm_fftMag_mfcc_sma_de[12]_stddev\\', \\'pcm_fftMag_mfcc_sma_de[12]_skewness\\', \\'pcm_fftMag_mfcc_sma_de[12]_kurtosis\\', \\'pcm_zcr_sma_de_max\\', \\'pcm_zcr_sma_de_min\\', \\'pcm_zcr_sma_de_range\\', \\'pcm_zcr_sma_de_maxPos\\', \\'pcm_zcr_sma_de_minPos\\', \\'pcm_zcr_sma_de_amean\\', \\'pcm_zcr_sma_de_linregc1\\', \\'pcm_zcr_sma_de_linregc2\\', \\'pcm_zcr_sma_de_linregerrQ\\', \\'pcm_zcr_sma_de_stddev\\', \\'pcm_zcr_sma_de_skewness\\', \\'pcm_zcr_sma_de_kurtosis\\', \\'voiceProb_sma_de_max\\', \\'voiceProb_sma_de_min\\', \\'voiceProb_sma_de_range\\', \\'voiceProb_sma_de_maxPos\\', \\'voiceProb_sma_de_minPos\\', \\'voiceProb_sma_de_amean\\', \\'voiceProb_sma_de_linregc1\\', \\'voiceProb_sma_de_linregc2\\', \\'voiceProb_sma_de_linregerrQ\\', \\'voiceProb_sma_de_stddev\\', \\'voiceProb_sma_de_skewness\\', \\'voiceProb_sma_de_kurtosis\\', \\'F0_sma_de_max\\', \\'F0_sma_de_min\\', \\'F0_sma_de_range\\', \\'F0_sma_de_maxPos\\', \\'F0_sma_de_minPos\\', \\'F0_sma_de_amean\\', \\'F0_sma_de_linregc1\\', \\'F0_sma_de_linregc2\\', \\'F0_sma_de_linregerrQ\\', \\'F0_sma_de_stddev\\', \\'F0_sma_de_skewness\\', \\'F0_sma_de_kurtosis\\']\"', 'featureset bib citation': 'b\\'@inproceedings{eyben2010opensmile,title={Opensmile: the munich versatile and fast open-source audio feature extractor},author={Eyben, Florian and W{\"o}llmer, Martin and Schuller, Bj{\"o}rn},booktitle={Proceedings of the 18th ACM international conference on Multimedia},pages={1459--1462},year={2010},organization={ACM}}\\'', 'md5': \"b'None'\", 'root name': \"b'OpenSMILE'\", 'uuid': \"b'c42c8e82-0272-4b48-8b79-0a3122295d0a'\"}\n",
      "\n",
      "\n",
      "=== Metadata Words===\n",
      "\n",
      "Words Metadata: {'alignment compatible': False, 'computational sequence description': 'Word sequences for CMU-MOSI Dataset', 'computational sequence version': 1.0, 'contact': 'abagherz@andrew.cmu.edu', 'creator': 'Amir Zadeh', 'dataset bib citation': '@article{zadeh2016multimodal,title={Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages},author={Zadeh, Amir and Zellers, Rowan and Pincus, Eli and Morency, Louis-Philippe},journal={IEEE Intelligent Systems},volume={31},number={6},pages={82--88},year={2016},publisher={IEEE}}', 'dataset name': 'CMU-MOSI', 'dataset version': 1.0, 'dimension names': ['word'], 'featureset bib citation': '@article{P2FA,title={Speaker identification on the SCOTUS corpus},author={Yuan, Jiahong and Liberman, Mark},journal={Journal of the Acoustical Society of America},volume={123},number={5},pages={3878},year={2008},publisher={[New York: Acoustical Society of America]}}', 'md5': None, 'root name': 'words', 'uuid': 'cf8e3281-bcec-49ff-be0e-6f98b55ad4d0'}\n",
      "\n",
      "\n",
      "=== Metadata Phones===\n",
      "\n",
      "Phones Metadata: {'alignment compatible': False, 'computational sequence description': 'Phoneme sequences for CMU-MOSI Dataset', 'computational sequence version': 1.0, 'contact': 'abagherz@andrew.cmu.edu', 'creator': 'Amir Zadeh', 'dataset bib citation': '@article{zadeh2016multimodal,title={Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages},author={Zadeh, Amir and Zellers, Rowan and Pincus, Eli and Morency, Louis-Philippe},journal={IEEE Intelligent Systems},volume={31},number={6},pages={82--88},year={2016},publisher={IEEE}}', 'dataset name': 'CMU-MOSI', 'dataset version': 1.0, 'dimension names': ['phoneme'], 'featureset bib citation': '@article{P2FA,title={Speaker identification on the SCOTUS corpus},author={Yuan, Jiahong and Liberman, Mark},journal={Journal of the Acoustical Society of America},volume={123},number={5},pages={3878},year={2008},publisher={[New York: Acoustical Society of America]}}', 'md5': None, 'root name': 'phoneme', 'uuid': '16f60546-1517-4621-9ac9-fb1b92439337'}\n",
      "\n",
      "\n",
      "=== Metadata WordVectors===\n",
      "\n",
      "WordVectors Metadata: {'alignment compatible': True, 'computational sequence description': 'Word vector sequences for CMU-MOSI Dataset', 'computational sequence version': 1.0, 'contact': 'abagherz@andrew.cmu.edu', 'creator': 'Amir Zadeh', 'dataset bib citation': '@article{zadeh2016multimodal,title={Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages},author={Zadeh, Amir and Zellers, Rowan and Pincus, Eli and Morency, Louis-Philippe},journal={IEEE Intelligent Systems},volume={31},number={6},pages={82--88},year={2016},publisher={IEEE}}', 'dataset name': 'CMU-MOSI', 'dataset version': 1.0, 'dimension names': ['glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector', 'glove_vector'], 'featureset bib citation': '@inproceedings{pennington2014glove,title={Glove: Global vectors for word representation},author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher},booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},pages={1532--1543},year={2014}}', 'md5': None, 'root name': 'glove_vectors', 'uuid': '156d7173-63fc-476b-8fc7-636283a7edb3'}\n"
     ]
    }
   ],
   "source": [
    "# List all keys in the visual and acoustic fields\n",
    "# print(\"Keys in visual FACE41 field:\", dataset[visual_field_Facet41].keys())\n",
    "# print(\"Keys in visual FACE42 field:\", dataset[visual_field_Facet41].keys())\n",
    "# print(\"Keys in visual OpenFace field:\", dataset[visual_field_OpenFace1].keys())\n",
    "# \n",
    "# print(\"Keys in acousticC field:\", dataset[acoustic_field_COVAREP].keys())\n",
    "# print(\"Keys in acousticOEB field:\", dataset[acoustic_field_OpenSmile_EB10].keys())\n",
    "# print(\"Keys in acousticOIS field:\", dataset[acoustic_field_OpenSmile_IS09].keys())\n",
    "\n",
    "print(\"=== Metadata FACE 41 Visual===\\n\")\n",
    "print(\"Visual FACE 41 Metadata:\", dataset[visual_field_Facet41].metadata)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"=== Metadata FACE 42 Visual===\\n\")\n",
    "print(\"Visual FACE 42 Metadata:\", dataset[visual_field_Facet42].metadata)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"=== Metadata OpenFace Visual===\\n\")\n",
    "print(\"Visual OpenFace Metadata:\", dataset[visual_field_OpenFace1].metadata)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"=== Metadata COVAREP Acoustic===\\n\")\n",
    "print(\"Acoustic COVAREP Metadata:\", dataset[acoustic_field_COVAREP].metadata)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"=== Metadata OpenSmile EB10 Acoustic===\\n\")\n",
    "print(\"Acoustic OpenSmile EB10 Metadata:\", dataset[acoustic_field_OpenSmile_EB10].metadata)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"=== Metadata OpenSmile IS09 Acoustic===\\n\")\n",
    "print(\"Acoustic OpenSmile IS09 Metadata:\", dataset[acoustic_field_OpenSmile_IS09].metadata)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"=== Metadata Words===\\n\")\n",
    "print(\"Words Metadata:\", dataset[text_field_Words].metadata)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"=== Metadata Phones===\\n\")\n",
    "print(\"Phones Metadata:\", dataset[text_field_Phones].metadata)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"=== Metadata WordVectors===\\n\")\n",
    "print(\"WordVectors Metadata:\", dataset[text_field_WordVectors].metadata)\n",
    "print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T11:21:22.050847600Z",
     "start_time": "2024-12-04T11:21:21.944174500Z"
    }
   },
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T11:21:41.415748300Z",
     "start_time": "2024-12-04T11:21:40.857567500Z"
    }
   },
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Field alignment compatible  \\\n",
      "0           Visual FACE 41                 True   \n",
      "1           Visual FACE 42                 True   \n",
      "2          Visual OpenFace                 True   \n",
      "3         Acoustic COVAREP                 True   \n",
      "4  Acoustic OpenSmile EB10                 True   \n",
      "5  Acoustic OpenSmile IS09              b'True'   \n",
      "6                    Words                False   \n",
      "7                   Phones                False   \n",
      "8              WordVectors                 True   \n",
      "\n",
      "                  computational sequence description  \\\n",
      "0     FACET 4.1 Visual Features for CMU-MOSI Dataset   \n",
      "1     FACET 4.2 Visual Features for CMU-MOSI Dataset   \n",
      "2   OpenFace V1 Visual Features for CMU-MOSI Dataset   \n",
      "3     COVAREP Acoustic Features for CMU-MOSI Dataset   \n",
      "4  OpenSmile emobase2010 Acoustic Features for CM...   \n",
      "5                                  b'MOSI openSMILE'   \n",
      "6                Word sequences for CMU-MOSI Dataset   \n",
      "7             Phoneme sequences for CMU-MOSI Dataset   \n",
      "8         Word vector sequences for CMU-MOSI Dataset   \n",
      "\n",
      "   computational sequence version  \\\n",
      "0                             1.0   \n",
      "1                             1.0   \n",
      "2                             1.0   \n",
      "3                             1.0   \n",
      "4                             1.0   \n",
      "5                             1.0   \n",
      "6                             1.0   \n",
      "7                             1.0   \n",
      "8                             1.0   \n",
      "\n",
      "                                       contact      creator  \\\n",
      "0                      abagherz@andrew.cmu.edu   Amir Zadeh   \n",
      "1                      abagherz@andrew.cmu.edu   Amir Zadeh   \n",
      "2                      abagherz@andrew.cmu.edu   Amir Zadeh   \n",
      "3                      abagherz@andrew.cmu.edu   Amir Zadeh   \n",
      "4                      abagherz@andrew.cmu.edu   Amir Zadeh   \n",
      "5  b'abagherz@andrew.cmu.edu;zhunl@cs.cmu.edu'  b'Zhun Liu'   \n",
      "6                      abagherz@andrew.cmu.edu   Amir Zadeh   \n",
      "7                      abagherz@andrew.cmu.edu   Amir Zadeh   \n",
      "8                      abagherz@andrew.cmu.edu   Amir Zadeh   \n",
      "\n",
      "                                dataset bib citation dataset name  \\\n",
      "0  @article{zadeh2016multimodal,title={Multimodal...     CMU-MOSI   \n",
      "1  @article{zadeh2016multimodal,title={Multimodal...     CMU-MOSI   \n",
      "2  @article{zadeh2016multimodal,title={Multimodal...     CMU-MOSI   \n",
      "3  @article{zadeh2016multimodal,title={Multimodal...     CMU-MOSI   \n",
      "4  @article{zadeh2016multimodal,title={Multimodal...     CMU-MOSI   \n",
      "5  b'@article{zadeh2016mosi,title={MOSI: multimod...      b'MOSI'   \n",
      "6  @article{zadeh2016multimodal,title={Multimodal...     CMU-MOSI   \n",
      "7  @article{zadeh2016multimodal,title={Multimodal...     CMU-MOSI   \n",
      "8  @article{zadeh2016multimodal,title={Multimodal...     CMU-MOSI   \n",
      "\n",
      "   dataset version                                    dimension names  \\\n",
      "0              1.0  [Face X, Face Y, Face Width, Face Height, ange...   \n",
      "1              1.0  [Anger, Contempt, Disgust, Joy, Fear, Baseline...   \n",
      "2              1.0  [timestamp, confidence, success, gaze_0_x, gaz...   \n",
      "3              1.0  [F0, VUV, NAQ, QOQ, H1H2, PSP, MDQ, peakSlope,...   \n",
      "4              1.0  [frameIndex, frameTime, pcm_loudness_sma_maxPo...   \n",
      "5              1.0  b\"['pcm_RMSenergy_sma_max', 'pcm_RMSenergy_sma...   \n",
      "6              1.0                                             [word]   \n",
      "7              1.0                                          [phoneme]   \n",
      "8              1.0  [glove_vector, glove_vector, glove_vector, glo...   \n",
      "\n",
      "                             featureset bib citation      md5  \\\n",
      "0  @online{emotient,author = {iMotions},title = {...     None   \n",
      "1  @online{emotient,author = {iMotions},title = {...     None   \n",
      "2  @inproceedings{baltrusaitis2018openface,title=...     None   \n",
      "3  @inproceedings{degottex2014covarep,title={COVA...     None   \n",
      "4  @inproceedings{eyben2010opensmile,title={Opens...     None   \n",
      "5  b'@inproceedings{eyben2010opensmile,title={Ope...  b'None'   \n",
      "6  @article{P2FA,title={Speaker identification on...     None   \n",
      "7  @article{P2FA,title={Speaker identification on...     None   \n",
      "8  @inproceedings{pennington2014glove,title={Glov...     None   \n",
      "\n",
      "               root name                                     uuid  \n",
      "0              FACET_4.1     75b82d70-387f-4c1a-935e-99462b7e4388  \n",
      "1              FACET_4.2     9d512b65-f94f-4972-bf81-9845173620fa  \n",
      "2             OpenFace_1     42fee302-b4f3-4b64-b39f-d196dcf6e1fb  \n",
      "3                COVAREP     b3040d49-2a1b-45f8-b991-16fb1acc75c5  \n",
      "4  OpenSmile_emobase2010     d1a761a6-fd87-41e3-9812-64fd24996491  \n",
      "5           b'OpenSMILE'  b'c42c8e82-0272-4b48-8b79-0a3122295d0a'  \n",
      "6                  words     cf8e3281-bcec-49ff-be0e-6f98b55ad4d0  \n",
      "7                phoneme     16f60546-1517-4621-9ac9-fb1b92439337  \n",
      "8          glove_vectors     156d7173-63fc-476b-8fc7-636283a7edb3  \n",
      "Metadata successfully saved to metadata_summary.csv\n"
     ]
    }
   ],
   "source": [
    "fields_metadata = [\n",
    "    {\"Field\": \"Visual FACE 41\", \"Metadata\": dataset[visual_field_Facet41].metadata},\n",
    "    {\"Field\": \"Visual FACE 42\", \"Metadata\": dataset[visual_field_Facet42].metadata},\n",
    "    {\"Field\": \"Visual OpenFace\", \"Metadata\": dataset[visual_field_OpenFace1].metadata},\n",
    "    {\"Field\": \"Acoustic COVAREP\", \"Metadata\": dataset[acoustic_field_COVAREP].metadata},\n",
    "    {\"Field\": \"Acoustic OpenSmile EB10\", \"Metadata\": dataset[acoustic_field_OpenSmile_EB10].metadata},\n",
    "    {\"Field\": \"Acoustic OpenSmile IS09\", \"Metadata\": dataset[acoustic_field_OpenSmile_IS09].metadata},\n",
    "    {\"Field\": \"Words\", \"Metadata\": dataset[text_field_Words].metadata},\n",
    "    {\"Field\": \"Phones\", \"Metadata\": dataset[text_field_Phones].metadata},\n",
    "    {\"Field\": \"WordVectors\", \"Metadata\": dataset[text_field_WordVectors].metadata},\n",
    "]\n",
    "\n",
    "# Normalize (flatten) the metadata dictionaries\n",
    "normalized_data = []\n",
    "for entry in fields_metadata:\n",
    "    metadata_flat = pd.json_normalize(entry[\"Metadata\"], sep=\"_\")\n",
    "    metadata_flat[\"Field\"] = entry[\"Field\"]\n",
    "    normalized_data.append(metadata_flat)\n",
    "\n",
    "# print(f\"normalized metadata: {normalized_data}\")\n",
    "\n",
    "df_metadata = pd.concat(normalized_data, ignore_index=True)\n",
    "df_metadata = df_metadata[[\"Field\"] + [col for col in df_metadata.columns if col != \"Field\"]]\n",
    "\n",
    "print(df_metadata)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_filename = \"metadata_summary.csv\"\n",
    "df_metadata.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"Metadata successfully saved to {csv_filename}\")\n",
    "\n",
    "# \n",
    "# \n",
    "#remove \\ for Acoustic OpenSmile EB10\n",
    "#remove b\" and \" for Acoustic OpenSmile IS09"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T11:22:36.461996600Z",
     "start_time": "2024-12-04T11:22:36.357853400Z"
    }
   },
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from functools import reduce"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T19:10:02.313116800Z",
     "start_time": "2024-12-02T19:10:01.867468900Z"
    }
   },
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Field                                    dimension names\n",
      "0    Visual FACE 41  [Face X, Face Y, Face Width, Face Height, ange...\n",
      "1  Acoustic COVAREP  [F0, VUV, NAQ, QOQ, H1H2, PSP, MDQ, peakSlope,...\n",
      "2             Words                                             [word]\n",
      "3       WordVectors  [glove_vector, glove_vector, glove_vector, glo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Viki\\AppData\\Local\\Temp\\ipykernel_20740\\4218429857.py:23: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_components = df_components.applymap(replace_strings)\n"
     ]
    }
   ],
   "source": [
    "df_components = df_metadata[[\"Field\", \"dimension names\"]]\n",
    "\n",
    "# Define the replacements in a dictionary\n",
    "replacements = {\n",
    "    'b\"': '',\n",
    "    '\"': '',\n",
    "    '\\'' : '',\n",
    "    '[': '',\n",
    "    ']': ''\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def replace_strings(x):\n",
    "    if isinstance(x, str):\n",
    "        for old, new in replacements.items():\n",
    "            x = x.replace(old, new)\n",
    "    return x\n",
    "\n",
    "\n",
    "# Apply the replacements using map\n",
    "df_components = df_components.applymap(replace_strings)\n",
    "\n",
    "print(df_components)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_filename = \"componentsWithoutIS.csv\"\n",
    "df_components.to_csv(csv_filename, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T19:10:02.726669800Z",
     "start_time": "2024-12-02T19:10:02.293366Z"
    }
   },
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Viki\\AppData\\Local\\Temp\\ipykernel_20740\\2718881803.py:36: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(replace_strings)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Define the replacements in a dictionary\n",
    "replacements = {\n",
    "    'b\"': '',\n",
    "    '\\\"': '',\n",
    "    '\\'': '',\n",
    "    '[': '',\n",
    "    ']': ''\n",
    "}\n",
    "\n",
    "# Function to apply replacements\n",
    "def replace_strings(x):\n",
    "    if isinstance(x, str):\n",
    "        for old, new in replacements.items():\n",
    "            x = x.replace(old, new)\n",
    "    return x\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "with open('componentsWithoutIS.csv', 'r', newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    rows = []\n",
    "    for row in reader:\n",
    "        new_row = []\n",
    "        for element in row:\n",
    "            # Split elements by comma and strip spaces\n",
    "            split_elements = [e.strip() for e in element.split(',')]\n",
    "            new_row.extend(split_elements)\n",
    "        rows.append(new_row)\n",
    "\n",
    "# Create DataFrame from the processed rows\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Apply the replacements using applymap to the entire DataFrame\n",
    "df = df.applymap(replace_strings)\n",
    "\n",
    "# Save the modified DataFrame back to a CSV file\n",
    "df.to_csv('componentsModifiedWithoutIS.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T19:10:02.880726300Z",
     "start_time": "2024-12-02T19:10:02.534054500Z"
    }
   },
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate analysis complete. Results saved to 'outputWithoutIS.txt'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from a CSV file\n",
    "# Replace 'your_file.csv' with the path to your actual file\n",
    "df = pd.read_csv('componentsModifiedWithoutIS.csv', header=None)\n",
    "\n",
    "# Flatten the DataFrame into a single list, keeping track of field positions\n",
    "data = []\n",
    "for col in df.columns:\n",
    "    for row in df.index:\n",
    "        value = df.iloc[row, col]\n",
    "        if pd.notna(value):  # Exclude empty elements\n",
    "            data.append((value.strip(), f\"Row {row+1}, Column {col+1}\"))\n",
    "\n",
    "# Create a dictionary to count occurrences and track positions\n",
    "duplicate_tracker = {}\n",
    "for value, position in data:\n",
    "    if value in duplicate_tracker:\n",
    "        duplicate_tracker[value]['count'] += 1\n",
    "        duplicate_tracker[value]['positions'].append(position)\n",
    "    else:\n",
    "        duplicate_tracker[value] = {'count': 1, 'positions': [position]}\n",
    "\n",
    "# Write results to a text file\n",
    "with open('outputDuplicatesWithoutIS.txt', 'w') as output_file:\n",
    "    output_file.write(\"Duplicates Found:\\n\")\n",
    "    for value, info in duplicate_tracker.items():\n",
    "        if info['count'] > 1:\n",
    "            output_file.write(\n",
    "                f\"{value}: {info['count']}; Positions: {', '.join(info['positions'])}\\n\"\n",
    "            )\n",
    "\n",
    "print(\"Duplicate analysis complete. Results saved to 'outputWithoutIS.txt'.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T19:10:03.205302500Z",
     "start_time": "2024-12-02T19:10:02.769084400Z"
    }
   },
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment of multimodal time series\n",
    "\n",
    "To work with multimodal time series that contains multiple views of data with different frequencies, we have to first align them to a ***pivot*** modality. The convention is to align to ***words***. Alignment groups feature vectors from other modalities into bins denoted by the timestamps of the pivot modality, and apply a certain processing function to each bin. We call this function ***collapse function***, because usually it is a pooling function that collapses multiple feature vectors from another modality into one single vector. This will give you sequences of same lengths in each modality (as the length of the pivot modality) for all videos.\n",
    "\n",
    "Here we define our collapse funtion as simple averaging. We feed the function to the SDK when we invoke `align` method. Note that the SDK always expect collapse functions with two arguments: `intervals` and `features`. Even if you don't use intervals (as is in the case below) you still need to define your function in the following way.\n",
    "\n",
    "***Note: Currently the SDK applies the collapse function to all modalities including the pivot, and obviously text modality cannot be \"averaged\", causing some errors. My solution is to define the avg function such that it averages the features when it can, and return the content as is when it cannot average.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-12-02T19:13:02.547638300Z",
     "start_time": "2024-12-02T19:10:03.186579500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94m\u001B[1m[2024-12-02 19:10:03.187] | Status  | \u001B[0mUnify was called ...\n",
      "\u001B[92m\u001B[1m[2024-12-02 19:10:03.188] | Success | \u001B[0mUnify completed ...\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:10:03.188] | Status  | \u001B[0mPre-alignment based on <CMU_MOSI_TimestampedWords> computational sequence started ...\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:10:13.346] | Status  | \u001B[0mPre-alignment done for <CMU_MOSI_COVAREP> ...\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:10:15.113] | Status  | \u001B[0mPre-alignment done for <CMU_MOSI_TimestampedWordVectors> ...\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:10:17.409] | Status  | \u001B[0mPre-alignment done for <CMU_MOSI_Visual_Facet_41> ...\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:10:17.629] | Status  | \u001B[0mAlignment starting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:   0%|          | 0/93 [00:00<?, ? Computational Sequence Entries/s]\n",
      "  0%|          | 0/464 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 03bSnISJMiM:   0%|          | 0/464 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 03bSnISJMiM:   5%|▌         | 25/464 [00:00<00:01, 238.23 Segments/s]\u001B[A\n",
      "Aligning 03bSnISJMiM:  11%|█         | 49/464 [00:00<00:01, 231.14 Segments/s]\u001B[A\n",
      "Aligning 03bSnISJMiM:  16%|█▌        | 73/464 [00:00<00:01, 228.16 Segments/s]\u001B[A\n",
      "Aligning 03bSnISJMiM:  21%|██        | 96/464 [00:00<00:01, 216.93 Segments/s]\u001B[A\n",
      "Aligning 03bSnISJMiM:  25%|██▌       | 118/464 [00:00<00:01, 213.21 Segments/s]\u001B[A\n",
      "Aligning 03bSnISJMiM:  30%|███       | 141/464 [00:00<00:01, 217.19 Segments/s]\u001B[A\n",
      "Aligning 03bSnISJMiM:  35%|███▌      | 163/464 [00:00<00:01, 210.27 Segments/s]\u001B[A\n",
      "Aligning 03bSnISJMiM:  41%|████      | 191/464 [00:00<00:01, 229.72 Segments/s]\u001B[A\n",
      "Aligning 03bSnISJMiM:  48%|████▊     | 223/464 [00:00<00:00, 254.26 Segments/s]\u001B[A\n",
      "Aligning 03bSnISJMiM:  55%|█████▌    | 257/464 [00:01<00:00, 277.69 Segments/s]\u001B[A\n",
      "Aligning 03bSnISJMiM:  62%|██████▏   | 289/464 [00:01<00:00, 289.12 Segments/s]\u001B[A\n",
      "Aligning 03bSnISJMiM:  69%|██████▉   | 319/464 [00:01<00:00, 288.05 Segments/s]\u001B[A\n",
      "Aligning 03bSnISJMiM:  76%|███████▋  | 354/464 [00:01<00:00, 306.30 Segments/s]\u001B[A\n",
      "Aligning 03bSnISJMiM:  83%|████████▎ | 387/464 [00:01<00:00, 312.17 Segments/s]\u001B[A\n",
      "Aligning 03bSnISJMiM:  90%|█████████ | 419/464 [00:01<00:00, 290.53 Segments/s]\u001B[A\n",
      "Aligning 03bSnISJMiM:  97%|█████████▋| 449/464 [00:01<00:00, 282.11 Segments/s]\u001B[A\n",
      "Overall Progress:   1%|          | 1/93 [00:01<02:42,  1.76s/ Computational Sequence Entries]\n",
      "  0%|          | 0/485 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 0h-zjBukYpk:   0%|          | 0/485 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 0h-zjBukYpk:   4%|▍         | 21/485 [00:00<00:02, 209.07 Segments/s]\u001B[A\n",
      "Aligning 0h-zjBukYpk:  11%|█         | 51/485 [00:00<00:01, 259.63 Segments/s]\u001B[A\n",
      "Aligning 0h-zjBukYpk:  16%|█▋        | 80/485 [00:00<00:01, 272.37 Segments/s]\u001B[A\n",
      "Aligning 0h-zjBukYpk:  22%|██▏       | 109/485 [00:00<00:01, 278.29 Segments/s]\u001B[A\n",
      "Aligning 0h-zjBukYpk:  28%|██▊       | 137/485 [00:00<00:01, 276.54 Segments/s]\u001B[A\n",
      "Aligning 0h-zjBukYpk:  35%|███▍      | 168/485 [00:00<00:01, 286.58 Segments/s]\u001B[A\n",
      "Aligning 0h-zjBukYpk:  41%|████      | 197/485 [00:00<00:01, 287.59 Segments/s]\u001B[A\n",
      "Aligning 0h-zjBukYpk:  47%|████▋     | 227/485 [00:00<00:00, 290.70 Segments/s]\u001B[A\n",
      "Aligning 0h-zjBukYpk:  54%|█████▎    | 260/485 [00:00<00:00, 300.34 Segments/s]\u001B[A\n",
      "Aligning 0h-zjBukYpk:  61%|██████    | 295/485 [00:01<00:00, 313.37 Segments/s]\u001B[A\n",
      "Aligning 0h-zjBukYpk:  67%|██████▋   | 327/485 [00:01<00:00, 306.90 Segments/s]\u001B[A\n",
      "Aligning 0h-zjBukYpk:  74%|███████▍  | 358/485 [00:01<00:00, 287.29 Segments/s]\u001B[A\n",
      "Aligning 0h-zjBukYpk:  80%|███████▉  | 387/485 [00:01<00:00, 285.95 Segments/s]\u001B[A\n",
      "Aligning 0h-zjBukYpk:  86%|████████▌ | 416/485 [00:01<00:00, 286.71 Segments/s]\u001B[A\n",
      "Aligning 0h-zjBukYpk:  92%|█████████▏| 445/485 [00:01<00:00, 286.21 Segments/s]\u001B[A\n",
      "Aligning 0h-zjBukYpk:  98%|█████████▊| 474/485 [00:01<00:00, 284.71 Segments/s]\u001B[A\n",
      "Overall Progress:   2%|▏         | 2/93 [00:03<02:37,  1.73s/ Computational Sequence Entries]\n",
      "  0%|          | 0/237 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 1DmNV9C1hbY:   0%|          | 0/237 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 1DmNV9C1hbY:  15%|█▌        | 36/237 [00:00<00:00, 358.43 Segments/s]\u001B[A\n",
      "Aligning 1DmNV9C1hbY:  30%|███       | 72/237 [00:00<00:00, 348.22 Segments/s]\u001B[A\n",
      "Aligning 1DmNV9C1hbY:  45%|████▌     | 107/237 [00:00<00:00, 335.76 Segments/s]\u001B[A\n",
      "Aligning 1DmNV9C1hbY:  59%|█████▉    | 141/237 [00:00<00:00, 327.76 Segments/s]\u001B[A\n",
      "Aligning 1DmNV9C1hbY:  73%|███████▎  | 174/237 [00:00<00:00, 326.42 Segments/s]\u001B[A\n",
      "Aligning 1DmNV9C1hbY:  87%|████████▋ | 207/237 [00:00<00:00, 317.35 Segments/s]\u001B[A\n",
      "Overall Progress:   3%|▎         | 3/93 [00:04<01:54,  1.27s/ Computational Sequence Entries]\n",
      "  0%|          | 0/562 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 1iG0909rllw:   0%|          | 0/562 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 1iG0909rllw:   2%|▏         | 14/562 [00:00<00:03, 138.58 Segments/s]\u001B[A\n",
      "Aligning 1iG0909rllw:   8%|▊         | 45/562 [00:00<00:02, 236.46 Segments/s]\u001B[A\n",
      "Aligning 1iG0909rllw:  14%|█▎        | 77/562 [00:00<00:01, 271.69 Segments/s]\u001B[A\n",
      "Aligning 1iG0909rllw:  19%|█▊        | 105/562 [00:00<00:01, 271.93 Segments/s]\u001B[A\n",
      "Aligning 1iG0909rllw:  25%|██▌       | 143/562 [00:00<00:01, 308.37 Segments/s]\u001B[A\n",
      "Aligning 1iG0909rllw:  32%|███▏      | 180/562 [00:00<00:01, 326.22 Segments/s]\u001B[A\n",
      "Aligning 1iG0909rllw:  39%|███▊      | 217/562 [00:00<00:01, 338.57 Segments/s]\u001B[A\n",
      "Aligning 1iG0909rllw:  45%|████▍     | 251/562 [00:00<00:00, 331.62 Segments/s]\u001B[A\n",
      "Aligning 1iG0909rllw:  51%|█████     | 287/562 [00:00<00:00, 338.62 Segments/s]\u001B[A\n",
      "Aligning 1iG0909rllw:  57%|█████▋    | 321/562 [00:01<00:00, 331.52 Segments/s]\u001B[A\n",
      "Aligning 1iG0909rllw:  63%|██████▎   | 355/562 [00:01<00:00, 288.46 Segments/s]\u001B[A\n",
      "Aligning 1iG0909rllw:  69%|██████▉   | 389/562 [00:01<00:00, 299.40 Segments/s]\u001B[A\n",
      "Aligning 1iG0909rllw:  75%|███████▍  | 420/562 [00:01<00:00, 290.02 Segments/s]\u001B[A\n",
      "Aligning 1iG0909rllw:  81%|████████  | 453/562 [00:01<00:00, 299.85 Segments/s]\u001B[A\n",
      "Aligning 1iG0909rllw:  86%|████████▌ | 484/562 [00:01<00:00, 301.96 Segments/s]\u001B[A\n",
      "Aligning 1iG0909rllw:  92%|█████████▏| 517/562 [00:01<00:00, 308.77 Segments/s]\u001B[A\n",
      "Aligning 1iG0909rllw:  98%|█████████▊| 549/562 [00:01<00:00, 300.70 Segments/s]\u001B[A\n",
      "Overall Progress:   4%|▍         | 4/93 [00:06<02:14,  1.51s/ Computational Sequence Entries]\n",
      "  0%|          | 0/651 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:   0%|          | 0/651 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:   3%|▎         | 20/651 [00:00<00:03, 197.56 Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:   7%|▋         | 48/651 [00:00<00:02, 245.72 Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:  12%|█▏        | 78/651 [00:00<00:02, 268.81 Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:  17%|█▋        | 110/651 [00:00<00:01, 287.16 Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:  21%|██▏       | 139/651 [00:00<00:01, 279.15 Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:  26%|██▌       | 167/651 [00:00<00:01, 270.29 Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:  31%|███       | 202/651 [00:00<00:01, 293.66 Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:  36%|███▋      | 236/651 [00:00<00:01, 307.92 Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:  41%|████      | 268/651 [00:00<00:01, 309.59 Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:  46%|████▌     | 300/651 [00:01<00:01, 306.25 Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:  51%|█████     | 331/651 [00:01<00:01, 298.84 Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:  56%|█████▌    | 365/651 [00:01<00:00, 307.84 Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:  61%|██████    | 396/651 [00:01<00:00, 302.21 Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:  66%|██████▌   | 427/651 [00:01<00:00, 300.36 Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:  70%|███████   | 458/651 [00:01<00:00, 298.08 Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:  75%|███████▍  | 488/651 [00:01<00:00, 295.75 Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:  80%|███████▉  | 519/651 [00:01<00:00, 296.82 Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:  84%|████████▍ | 549/651 [00:01<00:00, 295.82 Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:  89%|████████▉ | 580/651 [00:01<00:00, 297.69 Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:  94%|█████████▍| 613/651 [00:02<00:00, 304.62 Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:  99%|█████████▉| 644/651 [00:02<00:00, 298.91 Segments/s]\u001B[A\n",
      "Overall Progress:   5%|▌         | 5/93 [00:08<02:35,  1.77s/ Computational Sequence Entries]\n",
      "  0%|          | 0/700 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:   0%|          | 0/700 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:   2%|▏         | 17/700 [00:00<00:04, 168.96 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:   7%|▋         | 47/700 [00:00<00:02, 243.14 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:  11%|█         | 78/700 [00:00<00:02, 272.85 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:  16%|█▌        | 110/700 [00:00<00:02, 287.04 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:  20%|█▉        | 139/700 [00:00<00:01, 281.02 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:  24%|██▍       | 170/700 [00:00<00:01, 288.21 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:  28%|██▊       | 199/700 [00:00<00:01, 285.66 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:  33%|███▎      | 230/700 [00:00<00:01, 290.48 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:  37%|███▋      | 260/700 [00:00<00:01, 291.66 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:  41%|████▏     | 290/700 [00:01<00:01, 293.28 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:  46%|████▌     | 320/700 [00:01<00:01, 293.61 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:  50%|█████     | 350/700 [00:01<00:01, 289.18 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:  54%|█████▍    | 379/700 [00:01<00:01, 288.54 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:  58%|█████▊    | 409/700 [00:01<00:01, 290.35 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:  63%|██████▎   | 439/700 [00:01<00:00, 293.12 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:  67%|██████▋   | 469/700 [00:01<00:00, 293.16 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:  72%|███████▏  | 503/700 [00:01<00:00, 304.86 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:  76%|███████▋  | 535/700 [00:01<00:00, 308.01 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:  81%|████████  | 566/700 [00:01<00:00, 286.84 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:  85%|████████▌ | 595/700 [00:02<00:00, 273.59 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:  90%|█████████ | 631/700 [00:02<00:00, 296.20 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:  95%|█████████▍| 663/700 [00:02<00:00, 301.69 Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:  99%|█████████▉| 695/700 [00:02<00:00, 304.42 Segments/s]\u001B[A\n",
      "Overall Progress:   6%|▋         | 6/93 [00:10<02:53,  1.99s/ Computational Sequence Entries]\n",
      "  0%|          | 0/262 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 5W7Z1C_fDaE:   0%|          | 0/262 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 5W7Z1C_fDaE:  14%|█▎        | 36/262 [00:00<00:00, 349.84 Segments/s]\u001B[A\n",
      "Aligning 5W7Z1C_fDaE:  28%|██▊       | 74/262 [00:00<00:00, 366.18 Segments/s]\u001B[A\n",
      "Aligning 5W7Z1C_fDaE:  44%|████▍     | 116/262 [00:00<00:00, 390.09 Segments/s]\u001B[A\n",
      "Aligning 5W7Z1C_fDaE:  61%|██████    | 159/262 [00:00<00:00, 402.83 Segments/s]\u001B[A\n",
      "Aligning 5W7Z1C_fDaE:  76%|███████▋  | 200/262 [00:00<00:00, 403.75 Segments/s]\u001B[A\n",
      "Aligning 5W7Z1C_fDaE:  94%|█████████▎| 245/262 [00:00<00:00, 417.01 Segments/s]\u001B[A\n",
      "Overall Progress:   8%|▊         | 7/93 [00:11<02:13,  1.56s/ Computational Sequence Entries]\n",
      "  0%|          | 0/411 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 6Egk_28TtTM:   0%|          | 0/411 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 6Egk_28TtTM:   8%|▊         | 34/411 [00:00<00:01, 336.42 Segments/s]\u001B[A\n",
      "Aligning 6Egk_28TtTM:  17%|█▋        | 70/411 [00:00<00:00, 349.42 Segments/s]\u001B[A\n",
      "Aligning 6Egk_28TtTM:  26%|██▌       | 105/411 [00:00<00:00, 342.02 Segments/s]\u001B[A\n",
      "Aligning 6Egk_28TtTM:  34%|███▍      | 140/411 [00:00<00:00, 337.92 Segments/s]\u001B[A\n",
      "Aligning 6Egk_28TtTM:  42%|████▏     | 174/411 [00:00<00:00, 321.24 Segments/s]\u001B[A\n",
      "Aligning 6Egk_28TtTM:  50%|█████     | 207/411 [00:00<00:00, 292.87 Segments/s]\u001B[A\n",
      "Aligning 6Egk_28TtTM:  58%|█████▊    | 237/411 [00:00<00:00, 286.65 Segments/s]\u001B[A\n",
      "Aligning 6Egk_28TtTM:  66%|██████▌   | 272/411 [00:00<00:00, 302.78 Segments/s]\u001B[A\n",
      "Aligning 6Egk_28TtTM:  74%|███████▎  | 303/411 [00:00<00:00, 298.79 Segments/s]\u001B[A\n",
      "Aligning 6Egk_28TtTM:  81%|████████▏ | 334/411 [00:01<00:00, 301.46 Segments/s]\u001B[A\n",
      "Aligning 6Egk_28TtTM:  89%|████████▉ | 365/411 [00:01<00:00, 297.43 Segments/s]\u001B[A\n",
      "Aligning 6Egk_28TtTM:  96%|█████████▋| 396/411 [00:01<00:00, 299.07 Segments/s]\u001B[A\n",
      "Overall Progress:   9%|▊         | 8/93 [00:12<02:06,  1.49s/ Computational Sequence Entries]\n",
      "  0%|          | 0/374 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 6_0THN4chvY:   0%|          | 0/374 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 6_0THN4chvY:   8%|▊         | 29/374 [00:00<00:01, 289.75 Segments/s]\u001B[A\n",
      "Aligning 6_0THN4chvY:  18%|█▊        | 66/374 [00:00<00:00, 335.69 Segments/s]\u001B[A\n",
      "Aligning 6_0THN4chvY:  28%|██▊       | 106/374 [00:00<00:00, 362.62 Segments/s]\u001B[A\n",
      "Aligning 6_0THN4chvY:  40%|███▉      | 148/374 [00:00<00:00, 384.76 Segments/s]\u001B[A\n",
      "Aligning 6_0THN4chvY:  51%|█████     | 190/374 [00:00<00:00, 396.35 Segments/s]\u001B[A\n",
      "Aligning 6_0THN4chvY:  61%|██████▏   | 230/374 [00:00<00:00, 388.19 Segments/s]\u001B[A\n",
      "Aligning 6_0THN4chvY:  72%|███████▏  | 270/374 [00:00<00:00, 390.27 Segments/s]\u001B[A\n",
      "Aligning 6_0THN4chvY:  83%|████████▎ | 310/374 [00:00<00:00, 373.40 Segments/s]\u001B[A\n",
      "Aligning 6_0THN4chvY:  93%|█████████▎| 348/374 [00:00<00:00, 350.72 Segments/s]\u001B[A\n",
      "Overall Progress:  10%|▉         | 9/93 [00:13<01:53,  1.35s/ Computational Sequence Entries]\n",
      "  0%|          | 0/591 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 73jzhE8R1TQ:   0%|          | 0/591 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 73jzhE8R1TQ:   5%|▌         | 30/591 [00:00<00:01, 293.80 Segments/s]\u001B[A\n",
      "Aligning 73jzhE8R1TQ:  10%|█         | 60/591 [00:00<00:01, 287.37 Segments/s]\u001B[A\n",
      "Aligning 73jzhE8R1TQ:  16%|█▌        | 94/591 [00:00<00:01, 308.28 Segments/s]\u001B[A\n",
      "Aligning 73jzhE8R1TQ:  21%|██▏       | 127/591 [00:00<00:01, 313.41 Segments/s]\u001B[A\n",
      "Aligning 73jzhE8R1TQ:  27%|██▋       | 161/591 [00:00<00:01, 317.82 Segments/s]\u001B[A\n",
      "Aligning 73jzhE8R1TQ:  33%|███▎      | 193/591 [00:00<00:01, 295.81 Segments/s]\u001B[A\n",
      "Aligning 73jzhE8R1TQ:  38%|███▊      | 223/591 [00:00<00:01, 289.04 Segments/s]\u001B[A\n",
      "Aligning 73jzhE8R1TQ:  43%|████▎     | 253/591 [00:00<00:01, 291.37 Segments/s]\u001B[A\n",
      "Aligning 73jzhE8R1TQ:  48%|████▊     | 286/591 [00:00<00:01, 300.45 Segments/s]\u001B[A\n",
      "Aligning 73jzhE8R1TQ:  55%|█████▍    | 323/591 [00:01<00:00, 320.44 Segments/s]\u001B[A\n",
      "Aligning 73jzhE8R1TQ:  61%|██████    | 359/591 [00:01<00:00, 329.12 Segments/s]\u001B[A\n",
      "Aligning 73jzhE8R1TQ:  66%|██████▋   | 393/591 [00:01<00:00, 318.06 Segments/s]\u001B[A\n",
      "Aligning 73jzhE8R1TQ:  72%|███████▏  | 425/591 [00:01<00:00, 308.49 Segments/s]\u001B[A\n",
      "Aligning 73jzhE8R1TQ:  77%|███████▋  | 456/591 [00:01<00:00, 308.74 Segments/s]\u001B[A\n",
      "Aligning 73jzhE8R1TQ:  82%|████████▏ | 487/591 [00:01<00:00, 303.23 Segments/s]\u001B[A\n",
      "Aligning 73jzhE8R1TQ:  88%|████████▊ | 518/591 [00:01<00:00, 303.54 Segments/s]\u001B[A\n",
      "Aligning 73jzhE8R1TQ:  93%|█████████▎| 550/591 [00:01<00:00, 305.75 Segments/s]\u001B[A\n",
      "Aligning 73jzhE8R1TQ:  98%|█████████▊| 581/591 [00:01<00:00, 287.90 Segments/s]\u001B[A\n",
      "Overall Progress:  11%|█         | 10/93 [00:15<02:08,  1.54s/ Computational Sequence Entries]\n",
      "  0%|          | 0/636 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:   0%|          | 0/636 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:   4%|▍         | 27/636 [00:00<00:02, 259.10 Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:   9%|▊         | 55/636 [00:00<00:02, 268.68 Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:  13%|█▎        | 85/636 [00:00<00:01, 282.18 Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:  19%|█▊        | 118/636 [00:00<00:01, 299.36 Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:  23%|██▎       | 148/636 [00:00<00:01, 298.47 Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:  29%|██▊       | 182/636 [00:00<00:01, 309.02 Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:  34%|███▍      | 217/636 [00:00<00:01, 321.38 Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:  39%|███▉      | 250/636 [00:00<00:01, 314.05 Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:  44%|████▍     | 282/636 [00:00<00:01, 302.33 Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:  49%|████▉     | 313/636 [00:01<00:01, 293.35 Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:  54%|█████▍    | 344/636 [00:01<00:00, 296.85 Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:  59%|█████▉    | 376/636 [00:01<00:00, 302.00 Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:  64%|██████▍   | 408/636 [00:01<00:00, 305.68 Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:  69%|██████▉   | 439/636 [00:01<00:00, 297.09 Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:  74%|███████▍  | 472/636 [00:01<00:00, 306.35 Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:  79%|███████▉  | 505/636 [00:01<00:00, 312.75 Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:  84%|████████▍ | 537/636 [00:01<00:00, 313.46 Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:  89%|████████▉ | 569/636 [00:01<00:00, 309.99 Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:  94%|█████████▍| 601/636 [00:01<00:00, 298.70 Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY: 100%|█████████▉| 634/636 [00:02<00:00, 306.75 Segments/s]\u001B[A\n",
      "Overall Progress:  12%|█▏        | 11/93 [00:17<02:20,  1.72s/ Computational Sequence Entries]\n",
      "  0%|          | 0/654 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:   0%|          | 0/654 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:   5%|▌         | 33/654 [00:00<00:01, 326.42 Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:  10%|█         | 68/654 [00:00<00:01, 337.60 Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:  16%|█▌        | 102/654 [00:00<00:01, 321.49 Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:  21%|██        | 135/654 [00:00<00:01, 323.32 Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:  26%|██▌       | 168/654 [00:00<00:01, 315.66 Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:  31%|███       | 203/654 [00:00<00:01, 324.10 Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:  36%|███▌      | 236/654 [00:00<00:01, 308.02 Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:  41%|████      | 268/654 [00:00<00:01, 310.67 Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:  46%|████▌     | 301/654 [00:00<00:01, 314.15 Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:  51%|█████     | 333/654 [00:01<00:01, 308.66 Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:  56%|█████▌    | 364/654 [00:01<00:00, 295.62 Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:  60%|██████    | 394/654 [00:01<00:00, 296.27 Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:  65%|██████▍   | 424/654 [00:01<00:00, 295.14 Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:  69%|██████▉   | 454/654 [00:01<00:00, 293.34 Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:  75%|███████▍  | 490/654 [00:01<00:00, 311.39 Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:  80%|████████  | 525/654 [00:01<00:00, 320.73 Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:  85%|████████▌ | 558/654 [00:01<00:00, 310.45 Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:  90%|█████████ | 590/654 [00:01<00:00, 297.76 Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:  95%|█████████▍| 620/654 [00:02<00:00, 290.32 Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM: 100%|█████████▉| 652/654 [00:02<00:00, 296.80 Segments/s]\u001B[A\n",
      "Overall Progress:  13%|█▎        | 12/93 [00:20<02:29,  1.85s/ Computational Sequence Entries]\n",
      "  0%|          | 0/584 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 8d-gEyoeBzc:   0%|          | 0/584 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 8d-gEyoeBzc:   6%|▌         | 35/584 [00:00<00:01, 349.02 Segments/s]\u001B[A\n",
      "Aligning 8d-gEyoeBzc:  12%|█▏        | 70/584 [00:00<00:01, 334.03 Segments/s]\u001B[A\n",
      "Aligning 8d-gEyoeBzc:  18%|█▊        | 104/584 [00:00<00:01, 312.90 Segments/s]\u001B[A\n",
      "Aligning 8d-gEyoeBzc:  23%|██▎       | 136/584 [00:00<00:01, 314.00 Segments/s]\u001B[A\n",
      "Aligning 8d-gEyoeBzc:  29%|██▉       | 168/584 [00:00<00:01, 303.15 Segments/s]\u001B[A\n",
      "Aligning 8d-gEyoeBzc:  34%|███▍      | 199/584 [00:00<00:01, 298.67 Segments/s]\u001B[A\n",
      "Aligning 8d-gEyoeBzc:  39%|███▉      | 229/584 [00:00<00:01, 297.07 Segments/s]\u001B[A\n",
      "Aligning 8d-gEyoeBzc:  45%|████▍     | 260/584 [00:00<00:01, 300.03 Segments/s]\u001B[A\n",
      "Aligning 8d-gEyoeBzc:  50%|████▉     | 291/584 [00:00<00:01, 288.48 Segments/s]\u001B[A\n",
      "Aligning 8d-gEyoeBzc:  55%|█████▍    | 321/584 [00:01<00:00, 291.28 Segments/s]\u001B[A\n",
      "Aligning 8d-gEyoeBzc:  60%|██████    | 351/584 [00:01<00:00, 286.61 Segments/s]\u001B[A\n",
      "Aligning 8d-gEyoeBzc:  65%|██████▌   | 381/584 [00:01<00:00, 290.09 Segments/s]\u001B[A\n",
      "Aligning 8d-gEyoeBzc:  70%|███████   | 411/584 [00:01<00:00, 290.65 Segments/s]\u001B[A\n",
      "Aligning 8d-gEyoeBzc:  76%|███████▌  | 441/584 [00:01<00:00, 286.60 Segments/s]\u001B[A\n",
      "Aligning 8d-gEyoeBzc:  81%|████████  | 472/584 [00:01<00:00, 293.16 Segments/s]\u001B[A\n",
      "Aligning 8d-gEyoeBzc:  86%|████████▌ | 502/584 [00:01<00:00, 290.82 Segments/s]\u001B[A\n",
      "Aligning 8d-gEyoeBzc:  91%|█████████ | 532/584 [00:01<00:00, 287.94 Segments/s]\u001B[A\n",
      "Aligning 8d-gEyoeBzc:  96%|█████████▋| 563/584 [00:01<00:00, 292.68 Segments/s]\u001B[A\n",
      "Overall Progress:  14%|█▍        | 13/93 [00:21<02:30,  1.89s/ Computational Sequence Entries]\n",
      "  0%|          | 0/523 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 8qrpnFRGt2A:   0%|          | 0/523 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 8qrpnFRGt2A:   6%|▌         | 32/523 [00:00<00:01, 318.11 Segments/s]\u001B[A\n",
      "Aligning 8qrpnFRGt2A:  12%|█▏        | 64/523 [00:00<00:01, 299.30 Segments/s]\u001B[A\n",
      "Aligning 8qrpnFRGt2A:  18%|█▊        | 95/523 [00:00<00:01, 286.66 Segments/s]\u001B[A\n",
      "Aligning 8qrpnFRGt2A:  24%|██▎       | 124/523 [00:00<00:01, 283.64 Segments/s]\u001B[A\n",
      "Aligning 8qrpnFRGt2A:  29%|██▉       | 153/523 [00:00<00:01, 277.49 Segments/s]\u001B[A\n",
      "Aligning 8qrpnFRGt2A:  35%|███▍      | 183/523 [00:00<00:01, 283.25 Segments/s]\u001B[A\n",
      "Aligning 8qrpnFRGt2A:  42%|████▏     | 218/523 [00:00<00:01, 302.83 Segments/s]\u001B[A\n",
      "Aligning 8qrpnFRGt2A:  48%|████▊     | 249/523 [00:00<00:00, 297.61 Segments/s]\u001B[A\n",
      "Aligning 8qrpnFRGt2A:  54%|█████▍    | 282/523 [00:00<00:00, 306.72 Segments/s]\u001B[A\n",
      "Aligning 8qrpnFRGt2A:  60%|█████▉    | 313/523 [00:01<00:00, 302.19 Segments/s]\u001B[A\n",
      "Aligning 8qrpnFRGt2A:  66%|██████▌   | 344/523 [00:01<00:00, 288.83 Segments/s]\u001B[A\n",
      "Aligning 8qrpnFRGt2A:  72%|███████▏  | 374/523 [00:01<00:00, 289.76 Segments/s]\u001B[A\n",
      "Aligning 8qrpnFRGt2A:  77%|███████▋  | 405/523 [00:01<00:00, 294.50 Segments/s]\u001B[A\n",
      "Aligning 8qrpnFRGt2A:  83%|████████▎ | 436/523 [00:01<00:00, 298.53 Segments/s]\u001B[A\n",
      "Aligning 8qrpnFRGt2A:  89%|████████▉ | 468/523 [00:01<00:00, 303.44 Segments/s]\u001B[A\n",
      "Aligning 8qrpnFRGt2A:  95%|█████████▌| 499/523 [00:01<00:00, 303.61 Segments/s]\u001B[A\n",
      "Overall Progress:  15%|█▌        | 14/93 [00:23<02:26,  1.86s/ Computational Sequence Entries]\n",
      "  0%|          | 0/554 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 9J25DZhivz8:   0%|          | 0/554 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 9J25DZhivz8:   6%|▌         | 31/554 [00:00<00:01, 307.21 Segments/s]\u001B[A\n",
      "Aligning 9J25DZhivz8:  11%|█▏        | 63/554 [00:00<00:01, 309.26 Segments/s]\u001B[A\n",
      "Aligning 9J25DZhivz8:  17%|█▋        | 94/554 [00:00<00:01, 305.53 Segments/s]\u001B[A\n",
      "Aligning 9J25DZhivz8:  23%|██▎       | 125/554 [00:00<00:01, 287.78 Segments/s]\u001B[A\n",
      "Aligning 9J25DZhivz8:  29%|██▊       | 158/554 [00:00<00:01, 300.01 Segments/s]\u001B[A\n",
      "Aligning 9J25DZhivz8:  34%|███▍      | 189/554 [00:00<00:01, 301.87 Segments/s]\u001B[A\n",
      "Aligning 9J25DZhivz8:  40%|███▉      | 220/554 [00:00<00:01, 300.72 Segments/s]\u001B[A\n",
      "Aligning 9J25DZhivz8:  45%|████▌     | 251/554 [00:00<00:01, 300.24 Segments/s]\u001B[A\n",
      "Aligning 9J25DZhivz8:  51%|█████     | 282/554 [00:00<00:00, 289.42 Segments/s]\u001B[A\n",
      "Aligning 9J25DZhivz8:  56%|█████▋    | 312/554 [00:01<00:00, 290.94 Segments/s]\u001B[A\n",
      "Aligning 9J25DZhivz8:  62%|██████▏   | 346/554 [00:01<00:00, 303.38 Segments/s]\u001B[A\n",
      "Aligning 9J25DZhivz8:  68%|██████▊   | 378/554 [00:01<00:00, 307.16 Segments/s]\u001B[A\n",
      "Aligning 9J25DZhivz8:  74%|███████▍  | 411/554 [00:01<00:00, 311.02 Segments/s]\u001B[A\n",
      "Aligning 9J25DZhivz8:  80%|███████▉  | 443/554 [00:01<00:00, 297.75 Segments/s]\u001B[A\n",
      "Aligning 9J25DZhivz8:  86%|████████▌ | 474/554 [00:01<00:00, 300.46 Segments/s]\u001B[A\n",
      "Aligning 9J25DZhivz8:  91%|█████████▏| 506/554 [00:01<00:00, 303.16 Segments/s]\u001B[A\n",
      "Aligning 9J25DZhivz8:  97%|█████████▋| 538/554 [00:01<00:00, 307.10 Segments/s]\u001B[A\n",
      "Overall Progress:  16%|█▌        | 15/93 [00:25<02:24,  1.85s/ Computational Sequence Entries]\n",
      "  0%|          | 0/645 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:   0%|          | 0/645 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:   4%|▍         | 27/645 [00:00<00:02, 262.28 Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:   9%|▊         | 56/645 [00:00<00:02, 277.02 Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:  13%|█▎        | 87/645 [00:00<00:01, 284.26 Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:  18%|█▊        | 116/645 [00:00<00:01, 283.31 Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:  23%|██▎       | 149/645 [00:00<00:01, 295.87 Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:  28%|██▊       | 179/645 [00:00<00:01, 292.64 Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:  32%|███▏      | 209/645 [00:00<00:01, 269.65 Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:  37%|███▋      | 237/645 [00:00<00:01, 272.54 Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:  41%|████▏     | 267/645 [00:00<00:01, 278.79 Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:  46%|████▌     | 296/645 [00:01<00:01, 271.32 Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:  50%|█████     | 324/645 [00:01<00:01, 264.79 Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:  55%|█████▍    | 354/645 [00:01<00:01, 272.59 Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:  59%|█████▉    | 382/645 [00:01<00:00, 271.04 Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:  64%|██████▎   | 410/645 [00:01<00:00, 271.62 Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:  68%|██████▊   | 438/645 [00:01<00:00, 267.99 Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:  73%|███████▎  | 469/645 [00:01<00:00, 278.94 Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:  77%|███████▋  | 497/645 [00:01<00:00, 269.76 Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:  82%|████████▏ | 529/645 [00:01<00:00, 283.43 Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:  87%|████████▋ | 558/645 [00:02<00:00, 284.61 Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:  92%|█████████▏| 592/645 [00:02<00:00, 299.44 Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:  97%|█████████▋| 623/645 [00:02<00:00, 292.09 Segments/s]\u001B[A\n",
      "Overall Progress:  17%|█▋        | 16/93 [00:27<02:33,  1.99s/ Computational Sequence Entries]\n",
      "  0%|          | 0/300 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 9c67fiY0wGQ:   0%|          | 0/300 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 9c67fiY0wGQ:  13%|█▎        | 40/300 [00:00<00:00, 395.55 Segments/s]\u001B[A\n",
      "Aligning 9c67fiY0wGQ:  27%|██▋       | 81/300 [00:00<00:00, 403.47 Segments/s]\u001B[A\n",
      "Aligning 9c67fiY0wGQ:  41%|████      | 123/300 [00:00<00:00, 407.17 Segments/s]\u001B[A\n",
      "Aligning 9c67fiY0wGQ:  55%|█████▍    | 164/300 [00:00<00:00, 395.31 Segments/s]\u001B[A\n",
      "Aligning 9c67fiY0wGQ:  68%|██████▊   | 204/300 [00:00<00:00, 373.39 Segments/s]\u001B[A\n",
      "Aligning 9c67fiY0wGQ:  81%|████████  | 242/300 [00:00<00:00, 355.29 Segments/s]\u001B[A\n",
      "Aligning 9c67fiY0wGQ:  93%|█████████▎| 280/300 [00:00<00:00, 360.18 Segments/s]\u001B[A\n",
      "Overall Progress:  18%|█▊        | 17/93 [00:28<02:04,  1.64s/ Computational Sequence Entries]\n",
      "  0%|          | 0/735 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:   0%|          | 0/735 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:   4%|▎         | 27/735 [00:00<00:02, 269.47 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:   7%|▋         | 54/735 [00:00<00:02, 264.83 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:  11%|█         | 82/735 [00:00<00:02, 268.83 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:  16%|█▌        | 114/735 [00:00<00:02, 288.57 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:  20%|█▉        | 144/735 [00:00<00:02, 291.50 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:  24%|██▎       | 174/735 [00:00<00:01, 287.41 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:  28%|██▊       | 203/735 [00:00<00:01, 284.75 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:  32%|███▏      | 237/735 [00:00<00:01, 301.03 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:  37%|███▋      | 270/735 [00:00<00:01, 307.22 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:  41%|████      | 301/735 [00:01<00:01, 296.45 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:  45%|████▌     | 332/735 [00:01<00:01, 298.98 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:  49%|████▉     | 363/735 [00:01<00:01, 300.38 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:  54%|█████▎    | 394/735 [00:01<00:01, 297.94 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:  58%|█████▊    | 427/735 [00:01<00:01, 306.59 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:  62%|██████▏   | 458/735 [00:01<00:00, 306.11 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:  67%|██████▋   | 489/735 [00:01<00:00, 305.19 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:  71%|███████   | 520/735 [00:01<00:00, 300.20 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:  75%|███████▍  | 551/735 [00:01<00:00, 295.20 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:  79%|███████▉  | 584/735 [00:01<00:00, 304.54 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:  84%|████████▍ | 616/735 [00:02<00:00, 308.45 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:  88%|████████▊ | 647/735 [00:02<00:00, 304.48 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:  92%|█████████▏| 678/735 [00:02<00:00, 300.19 Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:  96%|█████████▋| 709/735 [00:02<00:00, 297.94 Segments/s]\u001B[A\n",
      "Overall Progress:  19%|█▉        | 18/93 [00:31<02:21,  1.89s/ Computational Sequence Entries]\n",
      "  0%|          | 0/659 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:   0%|          | 0/659 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:   3%|▎         | 21/659 [00:00<00:03, 206.49 Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:   8%|▊         | 53/659 [00:00<00:02, 269.91 Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:  13%|█▎        | 83/659 [00:00<00:02, 280.77 Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:  18%|█▊        | 116/659 [00:00<00:01, 297.06 Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:  22%|██▏       | 146/659 [00:00<00:01, 295.75 Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:  27%|██▋       | 178/659 [00:00<00:01, 301.72 Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:  32%|███▏      | 209/659 [00:00<00:01, 296.89 Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:  36%|███▋      | 239/659 [00:00<00:01, 288.81 Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:  41%|████      | 270/659 [00:00<00:01, 293.09 Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:  46%|████▌     | 300/659 [00:01<00:01, 287.58 Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:  50%|█████     | 331/659 [00:01<00:01, 293.37 Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:  55%|█████▍    | 362/659 [00:01<00:01, 295.24 Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:  59%|█████▉    | 392/659 [00:01<00:00, 289.31 Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:  65%|██████▍   | 426/659 [00:01<00:00, 303.66 Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:  70%|██████▉   | 460/659 [00:01<00:00, 311.61 Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:  75%|███████▍  | 494/659 [00:01<00:00, 317.94 Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:  80%|███████▉  | 526/659 [00:01<00:00, 303.32 Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:  85%|████████▌ | 561/659 [00:01<00:00, 313.29 Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:  90%|█████████ | 596/659 [00:01<00:00, 320.51 Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:  95%|█████████▌| 629/659 [00:02<00:00, 316.82 Segments/s]\u001B[A\n",
      "Overall Progress:  20%|██        | 19/93 [00:33<02:26,  1.99s/ Computational Sequence Entries]\n",
      "  0%|          | 0/406 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning BI97DNYfe5I:   0%|          | 0/406 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning BI97DNYfe5I:   8%|▊         | 33/406 [00:00<00:01, 303.50 Segments/s]\u001B[A\n",
      "Aligning BI97DNYfe5I:  18%|█▊        | 75/406 [00:00<00:00, 368.30 Segments/s]\u001B[A\n",
      "Aligning BI97DNYfe5I:  29%|██▊       | 116/406 [00:00<00:00, 384.97 Segments/s]\u001B[A\n",
      "Aligning BI97DNYfe5I:  39%|███▊      | 157/406 [00:00<00:00, 392.59 Segments/s]\u001B[A\n",
      "Aligning BI97DNYfe5I:  49%|████▊     | 197/406 [00:00<00:00, 382.19 Segments/s]\u001B[A\n",
      "Aligning BI97DNYfe5I:  58%|█████▊    | 236/406 [00:00<00:00, 384.01 Segments/s]\u001B[A\n",
      "Aligning BI97DNYfe5I:  68%|██████▊   | 275/406 [00:00<00:00, 384.87 Segments/s]\u001B[A\n",
      "Aligning BI97DNYfe5I:  77%|███████▋  | 314/406 [00:00<00:00, 356.54 Segments/s]\u001B[A\n",
      "Aligning BI97DNYfe5I:  86%|████████▋ | 351/406 [00:00<00:00, 338.96 Segments/s]\u001B[A\n",
      "Aligning BI97DNYfe5I:  96%|█████████▌| 389/406 [00:01<00:00, 349.78 Segments/s]\u001B[A\n",
      "Overall Progress:  22%|██▏       | 20/93 [00:34<02:06,  1.73s/ Computational Sequence Entries]\n",
      "  0%|          | 0/566 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning BXuRRbG0Ugk:   0%|          | 0/566 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning BXuRRbG0Ugk:   5%|▍         | 26/566 [00:00<00:02, 255.62 Segments/s]\u001B[A\n",
      "Aligning BXuRRbG0Ugk:  10%|▉         | 54/566 [00:00<00:01, 266.15 Segments/s]\u001B[A\n",
      "Aligning BXuRRbG0Ugk:  15%|█▍        | 84/566 [00:00<00:01, 280.14 Segments/s]\u001B[A\n",
      "Aligning BXuRRbG0Ugk:  21%|██        | 117/566 [00:00<00:01, 299.56 Segments/s]\u001B[A\n",
      "Aligning BXuRRbG0Ugk:  26%|██▌       | 148/566 [00:00<00:01, 302.71 Segments/s]\u001B[A\n",
      "Aligning BXuRRbG0Ugk:  32%|███▏      | 181/566 [00:00<00:01, 309.78 Segments/s]\u001B[A\n",
      "Aligning BXuRRbG0Ugk:  38%|███▊      | 213/566 [00:00<00:01, 311.13 Segments/s]\u001B[A\n",
      "Aligning BXuRRbG0Ugk:  43%|████▎     | 245/566 [00:00<00:01, 304.92 Segments/s]\u001B[A\n",
      "Aligning BXuRRbG0Ugk:  49%|████▉     | 276/566 [00:00<00:00, 299.97 Segments/s]\u001B[A\n",
      "Aligning BXuRRbG0Ugk:  54%|█████▍    | 307/566 [00:01<00:00, 299.24 Segments/s]\u001B[A\n",
      "Aligning BXuRRbG0Ugk:  60%|█████▉    | 339/566 [00:01<00:00, 303.38 Segments/s]\u001B[A\n",
      "Aligning BXuRRbG0Ugk:  66%|██████▌   | 371/566 [00:01<00:00, 307.12 Segments/s]\u001B[A\n",
      "Aligning BXuRRbG0Ugk:  71%|███████▏  | 404/566 [00:01<00:00, 313.72 Segments/s]\u001B[A\n",
      "Aligning BXuRRbG0Ugk:  77%|███████▋  | 436/566 [00:01<00:00, 311.08 Segments/s]\u001B[A\n",
      "Aligning BXuRRbG0Ugk:  83%|████████▎ | 469/566 [00:01<00:00, 314.99 Segments/s]\u001B[A\n",
      "Aligning BXuRRbG0Ugk:  89%|████████▉ | 503/566 [00:01<00:00, 319.35 Segments/s]\u001B[A\n",
      "Aligning BXuRRbG0Ugk:  95%|█████████▌| 538/566 [00:01<00:00, 327.09 Segments/s]\u001B[A\n",
      "Overall Progress:  23%|██▎       | 21/93 [00:36<02:07,  1.76s/ Computational Sequence Entries]\n",
      "  0%|          | 0/282 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Bfr499ggo-0:   0%|          | 0/282 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Bfr499ggo-0:  13%|█▎        | 36/282 [00:00<00:00, 354.70 Segments/s]\u001B[A\n",
      "Aligning Bfr499ggo-0:  28%|██▊       | 79/282 [00:00<00:00, 396.67 Segments/s]\u001B[A\n",
      "Aligning Bfr499ggo-0:  42%|████▏     | 119/282 [00:00<00:00, 394.66 Segments/s]\u001B[A\n",
      "Aligning Bfr499ggo-0:  56%|█████▋    | 159/282 [00:00<00:00, 392.28 Segments/s]\u001B[A\n",
      "Aligning Bfr499ggo-0:  71%|███████   | 199/282 [00:00<00:00, 388.14 Segments/s]\u001B[A\n",
      "Aligning Bfr499ggo-0:  84%|████████▍ | 238/282 [00:00<00:00, 363.12 Segments/s]\u001B[A\n",
      "Aligning Bfr499ggo-0:  98%|█████████▊| 276/282 [00:00<00:00, 367.86 Segments/s]\u001B[A\n",
      "Overall Progress:  24%|██▎       | 22/93 [00:37<01:43,  1.46s/ Computational Sequence Entries]\n",
      "  0%|          | 0/659 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:   0%|          | 0/659 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:   5%|▍         | 30/659 [00:00<00:02, 297.09 Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:   9%|▉         | 62/659 [00:00<00:01, 309.93 Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:  14%|█▍        | 93/659 [00:00<00:01, 304.54 Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:  19%|█▉        | 126/659 [00:00<00:01, 310.65 Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:  24%|██▍       | 158/659 [00:00<00:01, 312.63 Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:  29%|██▉       | 193/659 [00:00<00:01, 322.71 Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:  34%|███▍      | 226/659 [00:00<00:01, 303.83 Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:  39%|███▉      | 257/659 [00:00<00:01, 302.96 Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:  44%|████▎     | 288/659 [00:00<00:01, 304.88 Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:  49%|████▉     | 322/659 [00:01<00:01, 312.73 Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:  54%|█████▎    | 354/659 [00:01<00:00, 310.44 Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:  59%|█████▊    | 386/659 [00:01<00:00, 312.22 Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:  64%|██████▍   | 422/659 [00:01<00:00, 323.95 Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:  69%|██████▉   | 455/659 [00:01<00:00, 316.80 Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:  74%|███████▍  | 487/659 [00:01<00:00, 314.13 Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:  79%|███████▉  | 519/659 [00:01<00:00, 297.31 Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:  84%|████████▍ | 554/659 [00:01<00:00, 312.07 Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:  89%|████████▉ | 588/659 [00:01<00:00, 319.79 Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:  94%|█████████▍| 621/659 [00:01<00:00, 317.07 Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ: 100%|█████████▉| 656/659 [00:02<00:00, 324.11 Segments/s]\u001B[A\n",
      "Overall Progress:  25%|██▍       | 23/93 [00:39<01:56,  1.66s/ Computational Sequence Entries]\n",
      "  0%|          | 0/695 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:   0%|          | 0/695 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:   4%|▍         | 30/695 [00:00<00:02, 299.33 Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:   9%|▉         | 64/695 [00:00<00:01, 322.24 Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:  14%|█▍        | 97/695 [00:00<00:01, 321.66 Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:  19%|█▊        | 130/695 [00:00<00:01, 317.79 Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:  23%|██▎       | 162/695 [00:00<00:01, 312.67 Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:  28%|██▊       | 195/695 [00:00<00:01, 316.24 Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:  33%|███▎      | 230/695 [00:00<00:01, 324.68 Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:  38%|███▊      | 266/695 [00:00<00:01, 332.61 Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:  43%|████▎     | 300/695 [00:00<00:01, 313.47 Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:  48%|████▊     | 332/695 [00:01<00:01, 303.57 Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:  53%|█████▎    | 365/695 [00:01<00:01, 310.08 Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:  58%|█████▊    | 402/695 [00:01<00:00, 325.45 Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:  63%|██████▎   | 435/695 [00:01<00:00, 322.21 Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:  67%|██████▋   | 468/695 [00:01<00:00, 321.50 Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:  72%|███████▏  | 502/695 [00:01<00:00, 325.47 Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:  77%|███████▋  | 535/695 [00:01<00:00, 325.91 Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:  82%|████████▏ | 568/695 [00:01<00:00, 315.30 Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:  87%|████████▋ | 603/695 [00:01<00:00, 320.07 Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:  92%|█████████▏| 638/695 [00:01<00:00, 326.75 Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:  97%|█████████▋| 674/695 [00:02<00:00, 334.87 Segments/s]\u001B[A\n",
      "Overall Progress:  26%|██▌       | 24/93 [00:41<02:05,  1.81s/ Computational Sequence Entries]\n",
      "  0%|          | 0/777 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:   0%|          | 0/777 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:   3%|▎         | 21/777 [00:00<00:03, 207.03 Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:   7%|▋         | 58/777 [00:00<00:02, 299.75 Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:  12%|█▏        | 93/777 [00:00<00:02, 322.45 Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:  16%|█▋        | 128/777 [00:00<00:01, 331.77 Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:  21%|██        | 162/777 [00:00<00:01, 320.86 Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:  25%|██▌       | 195/777 [00:00<00:01, 319.20 Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:  29%|██▉       | 229/777 [00:00<00:01, 325.39 Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:  34%|███▍      | 263/777 [00:00<00:01, 328.39 Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:  38%|███▊      | 296/777 [00:00<00:01, 317.65 Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:  42%|████▏     | 330/777 [00:01<00:01, 322.95 Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:  47%|████▋     | 366/777 [00:01<00:01, 331.63 Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:  51%|█████▏    | 400/777 [00:01<00:01, 331.71 Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:  56%|█████▌    | 434/777 [00:01<00:01, 308.46 Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:  60%|█████▉    | 466/777 [00:01<00:00, 311.33 Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:  65%|██████▍   | 502/777 [00:01<00:00, 322.91 Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:  69%|██████▉   | 537/777 [00:01<00:00, 328.22 Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:  73%|███████▎  | 570/777 [00:01<00:00, 328.51 Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:  78%|███████▊  | 604/777 [00:01<00:00, 329.94 Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:  82%|████████▏ | 640/777 [00:01<00:00, 338.73 Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:  87%|████████▋ | 676/777 [00:02<00:00, 342.62 Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:  92%|█████████▏| 711/777 [00:02<00:00, 328.39 Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:  96%|█████████▌| 746/777 [00:02<00:00, 333.75 Segments/s]\u001B[A\n",
      "Overall Progress:  27%|██▋       | 25/93 [00:43<02:15,  1.99s/ Computational Sequence Entries]\n",
      "  0%|          | 0/590 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Clx4VXItLTE:   0%|          | 0/590 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Clx4VXItLTE:   6%|▌         | 36/590 [00:00<00:01, 357.34 Segments/s]\u001B[A\n",
      "Aligning Clx4VXItLTE:  12%|█▏        | 72/590 [00:00<00:01, 333.23 Segments/s]\u001B[A\n",
      "Aligning Clx4VXItLTE:  18%|█▊        | 106/590 [00:00<00:01, 314.23 Segments/s]\u001B[A\n",
      "Aligning Clx4VXItLTE:  23%|██▎       | 138/590 [00:00<00:01, 316.00 Segments/s]\u001B[A\n",
      "Aligning Clx4VXItLTE:  29%|██▉       | 172/590 [00:00<00:01, 320.18 Segments/s]\u001B[A\n",
      "Aligning Clx4VXItLTE:  35%|███▌      | 207/590 [00:00<00:01, 327.81 Segments/s]\u001B[A\n",
      "Aligning Clx4VXItLTE:  41%|████      | 240/590 [00:00<00:01, 324.40 Segments/s]\u001B[A\n",
      "Aligning Clx4VXItLTE:  46%|████▋     | 273/590 [00:00<00:01, 316.19 Segments/s]\u001B[A\n",
      "Aligning Clx4VXItLTE:  52%|█████▏    | 305/590 [00:00<00:00, 307.23 Segments/s]\u001B[A\n",
      "Aligning Clx4VXItLTE:  57%|█████▋    | 336/590 [00:01<00:00, 298.22 Segments/s]\u001B[A\n",
      "Aligning Clx4VXItLTE:  62%|██████▏   | 366/590 [00:01<00:00, 295.60 Segments/s]\u001B[A\n",
      "Aligning Clx4VXItLTE:  67%|██████▋   | 396/590 [00:01<00:00, 286.75 Segments/s]\u001B[A\n",
      "Aligning Clx4VXItLTE:  73%|███████▎  | 429/590 [00:01<00:00, 297.00 Segments/s]\u001B[A\n",
      "Aligning Clx4VXItLTE:  78%|███████▊  | 461/590 [00:01<00:00, 303.38 Segments/s]\u001B[A\n",
      "Aligning Clx4VXItLTE:  83%|████████▎ | 492/590 [00:01<00:00, 298.92 Segments/s]\u001B[A\n",
      "Aligning Clx4VXItLTE:  89%|████████▉ | 524/590 [00:01<00:00, 303.49 Segments/s]\u001B[A\n",
      "Aligning Clx4VXItLTE:  95%|█████████▍| 559/590 [00:01<00:00, 314.59 Segments/s]\u001B[A\n",
      "Overall Progress:  28%|██▊       | 26/93 [00:45<02:11,  1.96s/ Computational Sequence Entries]\n",
      "  0%|          | 0/411 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Dg_0XKD0Mf4:   0%|          | 0/411 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Dg_0XKD0Mf4:   9%|▉         | 38/411 [00:00<00:01, 370.10 Segments/s]\u001B[A\n",
      "Aligning Dg_0XKD0Mf4:  18%|█▊        | 76/411 [00:00<00:00, 359.46 Segments/s]\u001B[A\n",
      "Aligning Dg_0XKD0Mf4:  28%|██▊       | 115/411 [00:00<00:00, 370.21 Segments/s]\u001B[A\n",
      "Aligning Dg_0XKD0Mf4:  38%|███▊      | 155/411 [00:00<00:00, 379.89 Segments/s]\u001B[A\n",
      "Aligning Dg_0XKD0Mf4:  47%|████▋     | 194/411 [00:00<00:00, 378.73 Segments/s]\u001B[A\n",
      "Aligning Dg_0XKD0Mf4:  56%|█████▋    | 232/411 [00:00<00:00, 379.01 Segments/s]\u001B[A\n",
      "Aligning Dg_0XKD0Mf4:  66%|██████▌   | 270/411 [00:00<00:00, 349.55 Segments/s]\u001B[A\n",
      "Aligning Dg_0XKD0Mf4:  75%|███████▍  | 307/411 [00:00<00:00, 355.54 Segments/s]\u001B[A\n",
      "Aligning Dg_0XKD0Mf4:  83%|████████▎ | 343/411 [00:00<00:00, 355.35 Segments/s]\u001B[A\n",
      "Aligning Dg_0XKD0Mf4:  93%|█████████▎| 382/411 [00:01<00:00, 362.60 Segments/s]\u001B[A\n",
      "Overall Progress:  29%|██▉       | 27/93 [00:46<01:53,  1.72s/ Computational Sequence Entries]\n",
      "  0%|          | 0/559 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning G-xst2euQUc:   0%|          | 0/559 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning G-xst2euQUc:   4%|▍         | 21/559 [00:00<00:02, 205.27 Segments/s]\u001B[A\n",
      "Aligning G-xst2euQUc:  10%|█         | 56/559 [00:00<00:01, 288.60 Segments/s]\u001B[A\n",
      "Aligning G-xst2euQUc:  17%|█▋        | 94/559 [00:00<00:01, 327.89 Segments/s]\u001B[A\n",
      "Aligning G-xst2euQUc:  23%|██▎       | 127/559 [00:00<00:01, 324.25 Segments/s]\u001B[A\n",
      "Aligning G-xst2euQUc:  29%|██▊       | 160/559 [00:00<00:01, 325.88 Segments/s]\u001B[A\n",
      "Aligning G-xst2euQUc:  35%|███▌      | 197/559 [00:00<00:01, 338.88 Segments/s]\u001B[A\n",
      "Aligning G-xst2euQUc:  42%|████▏     | 232/559 [00:00<00:00, 341.34 Segments/s]\u001B[A\n",
      "Aligning G-xst2euQUc:  48%|████▊     | 267/559 [00:00<00:00, 308.55 Segments/s]\u001B[A\n",
      "Aligning G-xst2euQUc:  53%|█████▎    | 299/559 [00:00<00:00, 303.46 Segments/s]\u001B[A\n",
      "Aligning G-xst2euQUc:  59%|█████▉    | 332/559 [00:01<00:00, 309.08 Segments/s]\u001B[A\n",
      "Aligning G-xst2euQUc:  65%|██████▌   | 366/559 [00:01<00:00, 317.25 Segments/s]\u001B[A\n",
      "Aligning G-xst2euQUc:  71%|███████   | 398/559 [00:01<00:00, 308.12 Segments/s]\u001B[A\n",
      "Aligning G-xst2euQUc:  77%|███████▋  | 430/559 [00:01<00:00, 311.50 Segments/s]\u001B[A\n",
      "Aligning G-xst2euQUc:  83%|████████▎ | 462/559 [00:01<00:00, 296.88 Segments/s]\u001B[A\n",
      "Aligning G-xst2euQUc:  88%|████████▊ | 492/559 [00:01<00:00, 292.07 Segments/s]\u001B[A\n",
      "Aligning G-xst2euQUc:  94%|█████████▍| 526/559 [00:01<00:00, 305.65 Segments/s]\u001B[A\n",
      "Aligning G-xst2euQUc: 100%|█████████▉| 558/559 [00:01<00:00, 306.53 Segments/s]\u001B[A\n",
      "Overall Progress:  30%|███       | 28/93 [00:48<01:53,  1.75s/ Computational Sequence Entries]\n",
      "  0%|          | 0/763 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:   0%|          | 0/763 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:   4%|▍         | 31/763 [00:00<00:02, 307.49 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:   9%|▉         | 67/763 [00:00<00:02, 338.16 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:  13%|█▎        | 101/763 [00:00<00:01, 335.56 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:  18%|█▊        | 135/763 [00:00<00:02, 312.58 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:  22%|██▏       | 167/763 [00:00<00:01, 305.08 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:  26%|██▋       | 201/763 [00:00<00:01, 315.21 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:  31%|███       | 233/763 [00:00<00:01, 306.02 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:  35%|███▍      | 265/763 [00:00<00:01, 309.84 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:  39%|███▉      | 298/763 [00:00<00:01, 314.90 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:  44%|████▎     | 332/763 [00:01<00:01, 321.87 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:  48%|████▊     | 365/763 [00:01<00:01, 317.90 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:  52%|█████▏    | 397/763 [00:01<00:01, 306.43 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:  57%|█████▋    | 432/763 [00:01<00:01, 316.51 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:  61%|██████    | 465/763 [00:01<00:00, 318.91 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:  65%|██████▌   | 497/763 [00:01<00:00, 314.19 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:  70%|██████▉   | 532/763 [00:01<00:00, 323.20 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:  74%|███████▍  | 565/763 [00:01<00:00, 321.91 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:  78%|███████▊  | 598/763 [00:01<00:00, 317.93 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:  83%|████████▎ | 630/763 [00:01<00:00, 316.12 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:  87%|████████▋ | 663/763 [00:02<00:00, 318.67 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:  91%|█████████ | 695/763 [00:02<00:00, 316.23 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:  95%|█████████▌| 727/763 [00:02<00:00, 303.97 Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:  99%|█████████▉| 759/763 [00:02<00:00, 306.94 Segments/s]\u001B[A\n",
      "Overall Progress:  31%|███       | 29/93 [00:51<02:05,  1.96s/ Computational Sequence Entries]\n",
      "  0%|          | 0/417 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning GWuJjcEuzt8:   0%|          | 0/417 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning GWuJjcEuzt8:   5%|▍         | 20/417 [00:00<00:02, 198.34 Segments/s]\u001B[A\n",
      "Aligning GWuJjcEuzt8:  13%|█▎        | 56/417 [00:00<00:01, 290.84 Segments/s]\u001B[A\n",
      "Aligning GWuJjcEuzt8:  22%|██▏       | 92/417 [00:00<00:01, 318.82 Segments/s]\u001B[A\n",
      "Aligning GWuJjcEuzt8:  30%|███       | 127/417 [00:00<00:00, 328.07 Segments/s]\u001B[A\n",
      "Aligning GWuJjcEuzt8:  39%|███▉      | 163/417 [00:00<00:00, 339.11 Segments/s]\u001B[A\n",
      "Aligning GWuJjcEuzt8:  48%|████▊     | 199/417 [00:00<00:00, 345.17 Segments/s]\u001B[A\n",
      "Aligning GWuJjcEuzt8:  57%|█████▋    | 237/417 [00:00<00:00, 355.70 Segments/s]\u001B[A\n",
      "Aligning GWuJjcEuzt8:  65%|██████▌   | 273/417 [00:00<00:00, 354.91 Segments/s]\u001B[A\n",
      "Aligning GWuJjcEuzt8:  74%|███████▍  | 309/417 [00:00<00:00, 329.12 Segments/s]\u001B[A\n",
      "Aligning GWuJjcEuzt8:  83%|████████▎ | 348/417 [00:01<00:00, 345.07 Segments/s]\u001B[A\n",
      "Aligning GWuJjcEuzt8:  92%|█████████▏| 383/417 [00:01<00:00, 338.34 Segments/s]\u001B[A\n",
      "Overall Progress:  32%|███▏      | 30/93 [00:52<01:49,  1.74s/ Computational Sequence Entries]\n",
      "  0%|          | 0/622 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning HEsqda8_d0Q:   0%|          | 0/622 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning HEsqda8_d0Q:   5%|▌         | 34/622 [00:00<00:01, 331.76 Segments/s]\u001B[A\n",
      "Aligning HEsqda8_d0Q:  11%|█         | 68/622 [00:00<00:01, 331.55 Segments/s]\u001B[A\n",
      "Aligning HEsqda8_d0Q:  16%|█▋        | 102/622 [00:00<00:01, 328.36 Segments/s]\u001B[A\n",
      "Aligning HEsqda8_d0Q:  22%|██▏       | 138/622 [00:00<00:01, 336.81 Segments/s]\u001B[A\n",
      "Aligning HEsqda8_d0Q:  28%|██▊       | 174/622 [00:00<00:01, 344.88 Segments/s]\u001B[A\n",
      "Aligning HEsqda8_d0Q:  34%|███▎      | 209/622 [00:00<00:01, 334.61 Segments/s]\u001B[A\n",
      "Aligning HEsqda8_d0Q:  39%|███▉      | 243/622 [00:00<00:01, 327.79 Segments/s]\u001B[A\n",
      "Aligning HEsqda8_d0Q:  44%|████▍     | 276/622 [00:00<00:01, 328.41 Segments/s]\u001B[A\n",
      "Aligning HEsqda8_d0Q:  50%|█████     | 311/622 [00:00<00:00, 333.70 Segments/s]\u001B[A\n",
      "Aligning HEsqda8_d0Q:  55%|█████▌    | 345/622 [00:01<00:00, 335.28 Segments/s]\u001B[A\n",
      "Aligning HEsqda8_d0Q:  61%|██████    | 379/622 [00:01<00:00, 334.92 Segments/s]\u001B[A\n",
      "Aligning HEsqda8_d0Q:  66%|██████▋   | 413/622 [00:01<00:00, 332.81 Segments/s]\u001B[A\n",
      "Aligning HEsqda8_d0Q:  72%|███████▏  | 449/622 [00:01<00:00, 338.75 Segments/s]\u001B[A\n",
      "Aligning HEsqda8_d0Q:  78%|███████▊  | 484/622 [00:01<00:00, 341.20 Segments/s]\u001B[A\n",
      "Aligning HEsqda8_d0Q:  83%|████████▎ | 519/622 [00:01<00:00, 332.16 Segments/s]\u001B[A\n",
      "Aligning HEsqda8_d0Q:  89%|████████▉ | 556/622 [00:01<00:00, 341.86 Segments/s]\u001B[A\n",
      "Aligning HEsqda8_d0Q:  95%|█████████▌| 591/622 [00:01<00:00, 336.19 Segments/s]\u001B[A\n",
      "Overall Progress:  33%|███▎      | 31/93 [00:54<01:50,  1.78s/ Computational Sequence Entries]\n",
      "  0%|          | 0/640 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning I5y0__X72p0:   0%|          | 0/640 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning I5y0__X72p0:   5%|▌         | 34/640 [00:00<00:01, 336.64 Segments/s]\u001B[A\n",
      "Aligning I5y0__X72p0:  11%|█         | 68/640 [00:00<00:01, 302.20 Segments/s]\u001B[A\n",
      "Aligning I5y0__X72p0:  16%|█▋        | 104/640 [00:00<00:01, 322.82 Segments/s]\u001B[A\n",
      "Aligning I5y0__X72p0:  22%|██▏       | 138/640 [00:00<00:01, 327.64 Segments/s]\u001B[A\n",
      "Aligning I5y0__X72p0:  27%|██▋       | 174/640 [00:00<00:01, 336.82 Segments/s]\u001B[A\n",
      "Aligning I5y0__X72p0:  32%|███▎      | 208/640 [00:00<00:01, 310.80 Segments/s]\u001B[A\n",
      "Aligning I5y0__X72p0:  38%|███▊      | 241/640 [00:00<00:01, 314.42 Segments/s]\u001B[A\n",
      "Aligning I5y0__X72p0:  43%|████▎     | 274/640 [00:00<00:01, 314.43 Segments/s]\u001B[A\n",
      "Aligning I5y0__X72p0:  48%|████▊     | 306/640 [00:00<00:01, 294.50 Segments/s]\u001B[A\n",
      "Aligning I5y0__X72p0:  53%|█████▎    | 341/640 [00:01<00:00, 309.26 Segments/s]\u001B[A\n",
      "Aligning I5y0__X72p0:  59%|█████▉    | 376/640 [00:01<00:00, 320.62 Segments/s]\u001B[A\n",
      "Aligning I5y0__X72p0:  64%|██████▍   | 409/640 [00:01<00:00, 321.58 Segments/s]\u001B[A\n",
      "Aligning I5y0__X72p0:  69%|██████▉   | 442/640 [00:01<00:00, 316.35 Segments/s]\u001B[A\n",
      "Aligning I5y0__X72p0:  74%|███████▍  | 474/640 [00:01<00:00, 314.20 Segments/s]\u001B[A\n",
      "Aligning I5y0__X72p0:  80%|███████▉  | 509/640 [00:01<00:00, 323.37 Segments/s]\u001B[A\n",
      "Aligning I5y0__X72p0:  85%|████████▍ | 542/640 [00:01<00:00, 325.05 Segments/s]\u001B[A\n",
      "Aligning I5y0__X72p0:  90%|████████▉ | 575/640 [00:01<00:00, 325.25 Segments/s]\u001B[A\n",
      "Aligning I5y0__X72p0:  95%|█████████▌| 608/640 [00:01<00:00, 326.09 Segments/s]\u001B[A\n",
      "Overall Progress:  34%|███▍      | 32/93 [00:56<01:52,  1.85s/ Computational Sequence Entries]\n",
      "  0%|          | 0/316 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Iu2PFX3z_1s:   0%|          | 0/316 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Iu2PFX3z_1s:  12%|█▏        | 39/316 [00:00<00:00, 386.83 Segments/s]\u001B[A\n",
      "Aligning Iu2PFX3z_1s:  25%|██▍       | 78/316 [00:00<00:00, 383.72 Segments/s]\u001B[A\n",
      "Aligning Iu2PFX3z_1s:  37%|███▋      | 117/316 [00:00<00:00, 375.12 Segments/s]\u001B[A\n",
      "Aligning Iu2PFX3z_1s:  49%|████▉     | 155/316 [00:00<00:00, 360.25 Segments/s]\u001B[A\n",
      "Aligning Iu2PFX3z_1s:  63%|██████▎   | 198/316 [00:00<00:00, 382.78 Segments/s]\u001B[A\n",
      "Aligning Iu2PFX3z_1s:  77%|███████▋  | 243/316 [00:00<00:00, 402.74 Segments/s]\u001B[A\n",
      "Aligning Iu2PFX3z_1s:  91%|█████████ | 287/316 [00:00<00:00, 412.66 Segments/s]\u001B[A\n",
      "Overall Progress:  35%|███▌      | 33/93 [00:57<01:32,  1.54s/ Computational Sequence Entries]\n",
      "  0%|          | 0/450 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning IumbAb8q2dM:   0%|          | 0/450 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning IumbAb8q2dM:   8%|▊         | 38/450 [00:00<00:01, 371.77 Segments/s]\u001B[A\n",
      "Aligning IumbAb8q2dM:  17%|█▋        | 76/450 [00:00<00:01, 347.36 Segments/s]\u001B[A\n",
      "Aligning IumbAb8q2dM:  25%|██▍       | 111/450 [00:00<00:00, 343.46 Segments/s]\u001B[A\n",
      "Aligning IumbAb8q2dM:  33%|███▎      | 150/450 [00:00<00:00, 360.52 Segments/s]\u001B[A\n",
      "Aligning IumbAb8q2dM:  42%|████▏     | 187/450 [00:00<00:00, 339.32 Segments/s]\u001B[A\n",
      "Aligning IumbAb8q2dM:  50%|████▉     | 223/450 [00:00<00:00, 344.96 Segments/s]\u001B[A\n",
      "Aligning IumbAb8q2dM:  57%|█████▋    | 258/450 [00:00<00:00, 341.32 Segments/s]\u001B[A\n",
      "Aligning IumbAb8q2dM:  66%|██████▌   | 295/450 [00:00<00:00, 349.20 Segments/s]\u001B[A\n",
      "Aligning IumbAb8q2dM:  74%|███████▎  | 331/450 [00:00<00:00, 342.01 Segments/s]\u001B[A\n",
      "Aligning IumbAb8q2dM:  82%|████████▏ | 367/450 [00:01<00:00, 346.23 Segments/s]\u001B[A\n",
      "Aligning IumbAb8q2dM:  90%|████████▉ | 404/450 [00:01<00:00, 349.80 Segments/s]\u001B[A\n",
      "Aligning IumbAb8q2dM:  98%|█████████▊| 440/450 [00:01<00:00, 344.61 Segments/s]\u001B[A\n",
      "Overall Progress:  37%|███▋      | 34/93 [00:58<01:27,  1.48s/ Computational Sequence Entries]\n",
      "  0%|          | 0/219 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Jkswaaud0hk:   0%|          | 0/219 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Jkswaaud0hk:  16%|█▋        | 36/219 [00:00<00:00, 359.04 Segments/s]\u001B[A\n",
      "Aligning Jkswaaud0hk:  36%|███▌      | 78/219 [00:00<00:00, 393.76 Segments/s]\u001B[A\n",
      "Aligning Jkswaaud0hk:  54%|█████▍    | 118/219 [00:00<00:00, 387.10 Segments/s]\u001B[A\n",
      "Aligning Jkswaaud0hk:  74%|███████▎  | 161/219 [00:00<00:00, 402.01 Segments/s]\u001B[A\n",
      "Aligning Jkswaaud0hk:  94%|█████████▎| 205/219 [00:00<00:00, 414.42 Segments/s]\u001B[A\n",
      "Overall Progress:  38%|███▊      | 35/93 [00:59<01:09,  1.20s/ Computational Sequence Entries]\n",
      "  0%|          | 0/735 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:   0%|          | 0/735 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:   4%|▍         | 31/735 [00:00<00:02, 307.22 Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:   8%|▊         | 62/735 [00:00<00:02, 295.46 Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:  13%|█▎        | 96/735 [00:00<00:02, 313.72 Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:  18%|█▊        | 129/735 [00:00<00:01, 316.24 Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:  22%|██▏       | 161/735 [00:00<00:01, 316.45 Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:  26%|██▋       | 193/735 [00:00<00:01, 301.50 Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:  30%|███       | 224/735 [00:00<00:01, 303.29 Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:  35%|███▍      | 256/735 [00:00<00:01, 307.76 Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:  39%|███▉      | 288/735 [00:00<00:01, 310.81 Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:  44%|████▍     | 322/735 [00:01<00:01, 317.39 Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:  49%|████▊     | 357/735 [00:01<00:01, 325.77 Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:  53%|█████▎    | 390/735 [00:01<00:01, 324.48 Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:  58%|█████▊    | 423/735 [00:01<00:00, 319.62 Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:  62%|██████▏   | 455/735 [00:01<00:00, 317.92 Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:  67%|██████▋   | 491/735 [00:01<00:00, 327.17 Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:  71%|███████▏  | 525/735 [00:01<00:00, 329.38 Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:  76%|███████▌  | 558/735 [00:01<00:00, 329.36 Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:  80%|████████  | 591/735 [00:01<00:00, 324.14 Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:  85%|████████▍ | 624/735 [00:01<00:00, 320.91 Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:  89%|████████▉ | 657/735 [00:02<00:00, 295.48 Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:  94%|█████████▎| 689/735 [00:02<00:00, 302.03 Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:  98%|█████████▊| 720/735 [00:02<00:00, 299.15 Segments/s]\u001B[A\n",
      "Overall Progress:  39%|███▊      | 36/93 [01:01<01:28,  1.55s/ Computational Sequence Entries]\n",
      "  0%|          | 0/385 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning MLal-t_vJPM:   0%|          | 0/385 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning MLal-t_vJPM:  10%|▉         | 37/385 [00:00<00:00, 364.64 Segments/s]\u001B[A\n",
      "Aligning MLal-t_vJPM:  19%|█▉        | 75/385 [00:00<00:00, 370.73 Segments/s]\u001B[A\n",
      "Aligning MLal-t_vJPM:  30%|██▉       | 114/385 [00:00<00:00, 379.40 Segments/s]\u001B[A\n",
      "Aligning MLal-t_vJPM:  40%|███▉      | 153/385 [00:00<00:00, 381.93 Segments/s]\u001B[A\n",
      "Aligning MLal-t_vJPM:  50%|█████     | 194/385 [00:00<00:00, 389.96 Segments/s]\u001B[A\n",
      "Aligning MLal-t_vJPM:  61%|██████    | 233/385 [00:00<00:00, 389.84 Segments/s]\u001B[A\n",
      "Aligning MLal-t_vJPM:  71%|███████   | 272/385 [00:00<00:00, 384.34 Segments/s]\u001B[A\n",
      "Aligning MLal-t_vJPM:  81%|████████  | 312/385 [00:00<00:00, 385.71 Segments/s]\u001B[A\n",
      "Aligning MLal-t_vJPM:  92%|█████████▏| 355/385 [00:00<00:00, 398.18 Segments/s]\u001B[A\n",
      "Overall Progress:  40%|███▉      | 37/93 [01:02<01:17,  1.39s/ Computational Sequence Entries]\n",
      "  0%|          | 0/266 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Njd1F0vZSm4:   0%|          | 0/266 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Njd1F0vZSm4:  14%|█▍        | 38/266 [00:00<00:00, 372.95 Segments/s]\u001B[A\n",
      "Aligning Njd1F0vZSm4:  30%|███       | 80/266 [00:00<00:00, 398.76 Segments/s]\u001B[A\n",
      "Aligning Njd1F0vZSm4:  45%|████▌     | 120/266 [00:00<00:00, 391.71 Segments/s]\u001B[A\n",
      "Aligning Njd1F0vZSm4:  60%|██████    | 160/266 [00:00<00:00, 390.42 Segments/s]\u001B[A\n",
      "Aligning Njd1F0vZSm4:  75%|███████▌  | 200/266 [00:00<00:00, 391.33 Segments/s]\u001B[A\n",
      "Aligning Njd1F0vZSm4:  90%|█████████ | 240/266 [00:00<00:00, 388.29 Segments/s]\u001B[A\n",
      "Overall Progress:  41%|████      | 38/93 [01:03<01:05,  1.18s/ Computational Sequence Entries]\n",
      "  0%|          | 0/621 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Nzq88NnDkEk:   0%|          | 0/621 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Nzq88NnDkEk:   5%|▌         | 34/621 [00:00<00:01, 331.60 Segments/s]\u001B[A\n",
      "Aligning Nzq88NnDkEk:  12%|█▏        | 72/621 [00:00<00:01, 354.99 Segments/s]\u001B[A\n",
      "Aligning Nzq88NnDkEk:  17%|█▋        | 108/621 [00:00<00:01, 309.72 Segments/s]\u001B[A\n",
      "Aligning Nzq88NnDkEk:  23%|██▎       | 140/621 [00:00<00:01, 276.26 Segments/s]\u001B[A\n",
      "Aligning Nzq88NnDkEk:  28%|██▊       | 174/621 [00:00<00:01, 294.08 Segments/s]\u001B[A\n",
      "Aligning Nzq88NnDkEk:  34%|███▍      | 210/621 [00:00<00:01, 314.21 Segments/s]\u001B[A\n",
      "Aligning Nzq88NnDkEk:  40%|███▉      | 246/621 [00:00<00:01, 326.80 Segments/s]\u001B[A\n",
      "Aligning Nzq88NnDkEk:  45%|████▌     | 280/621 [00:00<00:01, 320.71 Segments/s]\u001B[A\n",
      "Aligning Nzq88NnDkEk:  50%|█████     | 313/621 [00:00<00:00, 322.63 Segments/s]\u001B[A\n",
      "Aligning Nzq88NnDkEk:  56%|█████▌    | 346/621 [00:01<00:00, 323.78 Segments/s]\u001B[A\n",
      "Aligning Nzq88NnDkEk:  61%|██████▏   | 381/621 [00:01<00:00, 331.49 Segments/s]\u001B[A\n",
      "Aligning Nzq88NnDkEk:  67%|██████▋   | 416/621 [00:01<00:00, 336.75 Segments/s]\u001B[A\n",
      "Aligning Nzq88NnDkEk:  72%|███████▏  | 450/621 [00:01<00:00, 318.30 Segments/s]\u001B[A\n",
      "Aligning Nzq88NnDkEk:  78%|███████▊  | 484/621 [00:01<00:00, 322.63 Segments/s]\u001B[A\n",
      "Aligning Nzq88NnDkEk:  83%|████████▎ | 517/621 [00:01<00:00, 322.20 Segments/s]\u001B[A\n",
      "Aligning Nzq88NnDkEk:  89%|████████▉ | 552/621 [00:01<00:00, 329.04 Segments/s]\u001B[A\n",
      "Aligning Nzq88NnDkEk:  95%|█████████▍| 588/621 [00:01<00:00, 337.24 Segments/s]\u001B[A\n",
      "Overall Progress:  42%|████▏     | 39/93 [01:05<01:16,  1.41s/ Computational Sequence Entries]\n",
      "  0%|          | 0/311 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning OQvJTdtJ2H4:   0%|          | 0/311 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning OQvJTdtJ2H4:   7%|▋         | 21/311 [00:00<00:01, 208.42 Segments/s]\u001B[A\n",
      "Aligning OQvJTdtJ2H4:  17%|█▋        | 52/311 [00:00<00:00, 267.39 Segments/s]\u001B[A\n",
      "Aligning OQvJTdtJ2H4:  29%|██▊       | 89/311 [00:00<00:00, 311.19 Segments/s]\u001B[A\n",
      "Aligning OQvJTdtJ2H4:  42%|████▏     | 130/311 [00:00<00:00, 349.57 Segments/s]\u001B[A\n",
      "Aligning OQvJTdtJ2H4:  55%|█████▌    | 172/311 [00:00<00:00, 374.09 Segments/s]\u001B[A\n",
      "Aligning OQvJTdtJ2H4:  68%|██████▊   | 213/311 [00:00<00:00, 384.01 Segments/s]\u001B[A\n",
      "Aligning OQvJTdtJ2H4:  81%|████████  | 252/311 [00:00<00:00, 371.78 Segments/s]\u001B[A\n",
      "Aligning OQvJTdtJ2H4:  95%|█████████▍| 294/311 [00:00<00:00, 384.09 Segments/s]\u001B[A\n",
      "Overall Progress:  43%|████▎     | 40/93 [01:05<01:06,  1.25s/ Computational Sequence Entries]\n",
      "  0%|          | 0/597 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning OtBXNcAL_lE:   0%|          | 0/597 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning OtBXNcAL_lE:   6%|▌         | 35/597 [00:00<00:01, 346.14 Segments/s]\u001B[A\n",
      "Aligning OtBXNcAL_lE:  12%|█▏        | 70/597 [00:00<00:01, 322.47 Segments/s]\u001B[A\n",
      "Aligning OtBXNcAL_lE:  18%|█▊        | 106/597 [00:00<00:01, 337.50 Segments/s]\u001B[A\n",
      "Aligning OtBXNcAL_lE:  23%|██▎       | 140/597 [00:00<00:01, 336.95 Segments/s]\u001B[A\n",
      "Aligning OtBXNcAL_lE:  29%|██▉       | 174/597 [00:00<00:01, 324.82 Segments/s]\u001B[A\n",
      "Aligning OtBXNcAL_lE:  35%|███▍      | 207/597 [00:00<00:01, 325.19 Segments/s]\u001B[A\n",
      "Aligning OtBXNcAL_lE:  40%|████      | 240/597 [00:00<00:01, 318.81 Segments/s]\u001B[A\n",
      "Aligning OtBXNcAL_lE:  46%|████▌     | 274/597 [00:00<00:00, 323.46 Segments/s]\u001B[A\n",
      "Aligning OtBXNcAL_lE:  51%|█████▏    | 307/597 [00:00<00:00, 304.99 Segments/s]\u001B[A\n",
      "Aligning OtBXNcAL_lE:  57%|█████▋    | 341/597 [00:01<00:00, 314.37 Segments/s]\u001B[A\n",
      "Aligning OtBXNcAL_lE:  63%|██████▎   | 375/597 [00:01<00:00, 321.04 Segments/s]\u001B[A\n",
      "Aligning OtBXNcAL_lE:  68%|██████▊   | 408/597 [00:01<00:00, 320.89 Segments/s]\u001B[A\n",
      "Aligning OtBXNcAL_lE:  74%|███████▍  | 441/597 [00:01<00:00, 317.65 Segments/s]\u001B[A\n",
      "Aligning OtBXNcAL_lE:  79%|███████▉  | 474/597 [00:01<00:00, 318.98 Segments/s]\u001B[A\n",
      "Aligning OtBXNcAL_lE:  85%|████████▍ | 506/597 [00:01<00:00, 314.00 Segments/s]\u001B[A\n",
      "Aligning OtBXNcAL_lE:  90%|█████████ | 538/597 [00:01<00:00, 306.16 Segments/s]\u001B[A\n",
      "Aligning OtBXNcAL_lE:  96%|█████████▋| 575/597 [00:01<00:00, 322.32 Segments/s]\u001B[A\n",
      "Overall Progress:  44%|████▍     | 41/93 [01:07<01:14,  1.43s/ Computational Sequence Entries]\n",
      "  0%|          | 0/740 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:   0%|          | 0/740 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:   3%|▎         | 22/740 [00:00<00:03, 218.88 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:   7%|▋         | 55/740 [00:00<00:02, 282.49 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:  12%|█▏        | 86/740 [00:00<00:02, 293.07 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:  16%|█▌        | 117/740 [00:00<00:02, 298.99 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:  20%|██        | 151/740 [00:00<00:01, 313.58 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:  25%|██▍       | 183/740 [00:00<00:01, 305.80 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:  29%|██▉       | 214/740 [00:00<00:01, 300.96 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:  33%|███▎      | 245/740 [00:00<00:01, 302.08 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:  37%|███▋      | 276/740 [00:00<00:01, 288.56 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:  42%|████▏     | 310/740 [00:01<00:01, 303.23 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:  46%|████▋     | 344/740 [00:01<00:01, 313.35 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:  51%|█████     | 376/740 [00:01<00:01, 311.58 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:  55%|█████▌    | 409/740 [00:01<00:01, 315.47 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:  60%|█████▉    | 443/740 [00:01<00:00, 320.24 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:  64%|██████▍   | 476/740 [00:01<00:00, 322.34 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:  69%|██████▉   | 509/740 [00:01<00:00, 312.51 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:  73%|███████▎  | 541/740 [00:01<00:00, 312.21 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:  77%|███████▋  | 573/740 [00:01<00:00, 308.65 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:  82%|████████▏ | 606/740 [00:01<00:00, 313.53 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:  86%|████████▌ | 638/740 [00:02<00:00, 304.24 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:  91%|█████████ | 670/740 [00:02<00:00, 308.32 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:  95%|█████████▌| 703/740 [00:02<00:00, 313.33 Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M: 100%|█████████▉| 737/740 [00:02<00:00, 320.12 Segments/s]\u001B[A\n",
      "Overall Progress:  45%|████▌     | 42/93 [01:10<01:28,  1.73s/ Computational Sequence Entries]\n",
      "  0%|          | 0/395 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning POKffnXeBds:   0%|          | 0/395 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning POKffnXeBds:   7%|▋         | 29/395 [00:00<00:01, 284.02 Segments/s]\u001B[A\n",
      "Aligning POKffnXeBds:  16%|█▌        | 64/395 [00:00<00:01, 319.56 Segments/s]\u001B[A\n",
      "Aligning POKffnXeBds:  27%|██▋       | 105/395 [00:00<00:00, 356.61 Segments/s]\u001B[A\n",
      "Aligning POKffnXeBds:  37%|███▋      | 148/395 [00:00<00:00, 382.44 Segments/s]\u001B[A\n",
      "Aligning POKffnXeBds:  47%|████▋     | 187/395 [00:00<00:00, 376.03 Segments/s]\u001B[A\n",
      "Aligning POKffnXeBds:  58%|█████▊    | 228/395 [00:00<00:00, 384.44 Segments/s]\u001B[A\n",
      "Aligning POKffnXeBds:  68%|██████▊   | 267/395 [00:00<00:00, 374.74 Segments/s]\u001B[A\n",
      "Aligning POKffnXeBds:  78%|███████▊  | 309/395 [00:00<00:00, 386.56 Segments/s]\u001B[A\n",
      "Aligning POKffnXeBds:  88%|████████▊ | 348/395 [00:00<00:00, 372.23 Segments/s]\u001B[A\n",
      "Aligning POKffnXeBds:  98%|█████████▊| 386/395 [00:01<00:00, 343.69 Segments/s]\u001B[A\n",
      "Overall Progress:  46%|████▌     | 43/93 [01:11<01:17,  1.54s/ Computational Sequence Entries]\n",
      "  0%|          | 0/385 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning PZ-lDQFboO8:   0%|          | 0/385 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning PZ-lDQFboO8:  11%|█         | 42/385 [00:00<00:00, 417.40 Segments/s]\u001B[A\n",
      "Aligning PZ-lDQFboO8:  22%|██▏       | 85/385 [00:00<00:00, 423.24 Segments/s]\u001B[A\n",
      "Aligning PZ-lDQFboO8:  33%|███▎      | 128/385 [00:00<00:00, 422.55 Segments/s]\u001B[A\n",
      "Aligning PZ-lDQFboO8:  44%|████▍     | 171/385 [00:00<00:00, 415.98 Segments/s]\u001B[A\n",
      "Aligning PZ-lDQFboO8:  55%|█████▌    | 213/385 [00:00<00:00, 411.89 Segments/s]\u001B[A\n",
      "Aligning PZ-lDQFboO8:  66%|██████▌   | 255/385 [00:00<00:00, 397.59 Segments/s]\u001B[A\n",
      "Aligning PZ-lDQFboO8:  77%|███████▋  | 295/385 [00:00<00:00, 391.68 Segments/s]\u001B[A\n",
      "Aligning PZ-lDQFboO8:  87%|████████▋ | 335/385 [00:00<00:00, 384.98 Segments/s]\u001B[A\n",
      "Aligning PZ-lDQFboO8:  98%|█████████▊| 376/385 [00:00<00:00, 390.69 Segments/s]\u001B[A\n",
      "Overall Progress:  47%|████▋     | 44/93 [01:12<01:07,  1.37s/ Computational Sequence Entries]\n",
      "  0%|          | 0/663 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:   0%|          | 0/663 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:   5%|▌         | 36/663 [00:00<00:01, 354.51 Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:  11%|█         | 72/663 [00:00<00:01, 347.25 Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:  16%|█▌        | 107/663 [00:00<00:01, 313.13 Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:  21%|██        | 139/663 [00:00<00:01, 308.93 Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:  26%|██▌       | 171/663 [00:00<00:01, 282.77 Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:  31%|███       | 205/663 [00:00<00:01, 298.61 Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:  36%|███▌      | 240/663 [00:00<00:01, 313.36 Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:  41%|████      | 272/663 [00:00<00:01, 312.31 Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:  46%|████▌     | 304/663 [00:00<00:01, 311.90 Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:  51%|█████     | 336/663 [00:01<00:01, 306.89 Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:  56%|█████▌    | 368/663 [00:01<00:00, 310.08 Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:  60%|██████    | 400/663 [00:01<00:00, 301.04 Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:  65%|██████▌   | 431/663 [00:01<00:00, 293.69 Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:  70%|██████▉   | 461/663 [00:01<00:00, 276.56 Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:  74%|███████▍  | 493/663 [00:01<00:00, 288.53 Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:  79%|███████▉  | 523/663 [00:01<00:00, 291.63 Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:  83%|████████▎ | 553/663 [00:01<00:00, 281.97 Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:  88%|████████▊ | 582/663 [00:01<00:00, 272.09 Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:  92%|█████████▏| 613/663 [00:02<00:00, 281.91 Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:  97%|█████████▋| 642/663 [00:02<00:00, 267.03 Segments/s]\u001B[A\n",
      "Overall Progress:  48%|████▊     | 45/93 [01:14<01:19,  1.65s/ Computational Sequence Entries]\n",
      "  0%|          | 0/484 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Qr1Ca94K55A:   0%|          | 0/484 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Qr1Ca94K55A:   6%|▌         | 30/484 [00:00<00:01, 295.84 Segments/s]\u001B[A\n",
      "Aligning Qr1Ca94K55A:  13%|█▎        | 62/484 [00:00<00:01, 306.69 Segments/s]\u001B[A\n",
      "Aligning Qr1Ca94K55A:  19%|█▉        | 94/484 [00:00<00:01, 308.22 Segments/s]\u001B[A\n",
      "Aligning Qr1Ca94K55A:  26%|██▋       | 128/484 [00:00<00:01, 318.65 Segments/s]\u001B[A\n",
      "Aligning Qr1Ca94K55A:  33%|███▎      | 161/484 [00:00<00:01, 318.72 Segments/s]\u001B[A\n",
      "Aligning Qr1Ca94K55A:  40%|███▉      | 193/484 [00:00<00:00, 318.89 Segments/s]\u001B[A\n",
      "Aligning Qr1Ca94K55A:  47%|████▋     | 229/484 [00:00<00:00, 331.00 Segments/s]\u001B[A\n",
      "Aligning Qr1Ca94K55A:  54%|█████▍    | 263/484 [00:00<00:00, 328.09 Segments/s]\u001B[A\n",
      "Aligning Qr1Ca94K55A:  61%|██████▏   | 297/484 [00:00<00:00, 331.03 Segments/s]\u001B[A\n",
      "Aligning Qr1Ca94K55A:  69%|██████▉   | 333/484 [00:01<00:00, 338.23 Segments/s]\u001B[A\n",
      "Aligning Qr1Ca94K55A:  76%|███████▋  | 370/484 [00:01<00:00, 347.79 Segments/s]\u001B[A\n",
      "Aligning Qr1Ca94K55A:  84%|████████▎ | 405/484 [00:01<00:00, 322.92 Segments/s]\u001B[A\n",
      "Aligning Qr1Ca94K55A:  90%|█████████ | 438/484 [00:01<00:00, 318.38 Segments/s]\u001B[A\n",
      "Aligning Qr1Ca94K55A:  98%|█████████▊| 474/484 [00:01<00:00, 326.82 Segments/s]\u001B[A\n",
      "Overall Progress:  49%|████▉     | 46/93 [01:16<01:15,  1.60s/ Computational Sequence Entries]\n",
      "  0%|          | 0/706 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:   0%|          | 0/706 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:   4%|▍         | 27/706 [00:00<00:02, 269.64 Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:   8%|▊         | 58/706 [00:00<00:02, 292.18 Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:  12%|█▏        | 88/706 [00:00<00:02, 288.35 Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:  17%|█▋        | 117/706 [00:00<00:02, 281.23 Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:  21%|██        | 146/706 [00:00<00:01, 281.68 Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:  25%|██▍       | 176/706 [00:00<00:01, 285.24 Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:  29%|██▉       | 206/706 [00:00<00:01, 288.92 Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:  33%|███▎      | 236/706 [00:00<00:01, 291.05 Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:  38%|███▊      | 268/706 [00:00<00:01, 297.11 Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:  43%|████▎     | 301/706 [00:01<00:01, 306.75 Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:  47%|████▋     | 332/706 [00:01<00:01, 305.11 Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:  52%|█████▏    | 364/706 [00:01<00:01, 308.41 Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:  56%|█████▋    | 398/706 [00:01<00:00, 315.69 Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:  61%|██████    | 430/706 [00:01<00:00, 316.20 Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:  65%|██████▌   | 462/706 [00:01<00:00, 306.70 Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:  70%|██████▉   | 493/706 [00:01<00:00, 304.08 Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:  75%|███████▍  | 527/706 [00:01<00:00, 312.76 Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:  79%|███████▉  | 559/706 [00:01<00:00, 308.52 Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:  84%|████████▎ | 590/706 [00:01<00:00, 307.63 Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:  89%|████████▊ | 626/706 [00:02<00:00, 321.24 Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:  94%|█████████▎| 661/706 [00:02<00:00, 329.21 Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:  98%|█████████▊| 694/706 [00:02<00:00, 321.32 Segments/s]\u001B[A\n",
      "Overall Progress:  51%|█████     | 47/93 [01:18<01:23,  1.82s/ Computational Sequence Entries]\n",
      "  0%|          | 0/317 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning TvyZBvOMOTc:   0%|          | 0/317 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning TvyZBvOMOTc:  12%|█▏        | 38/317 [00:00<00:00, 379.18 Segments/s]\u001B[A\n",
      "Aligning TvyZBvOMOTc:  26%|██▌       | 82/317 [00:00<00:00, 408.27 Segments/s]\u001B[A\n",
      "Aligning TvyZBvOMOTc:  39%|███▉      | 123/317 [00:00<00:00, 390.37 Segments/s]\u001B[A\n",
      "Aligning TvyZBvOMOTc:  52%|█████▏    | 164/317 [00:00<00:00, 396.87 Segments/s]\u001B[A\n",
      "Aligning TvyZBvOMOTc:  66%|██████▌   | 208/317 [00:00<00:00, 410.22 Segments/s]\u001B[A\n",
      "Aligning TvyZBvOMOTc:  79%|███████▉  | 250/317 [00:00<00:00, 380.69 Segments/s]\u001B[A\n",
      "Aligning TvyZBvOMOTc:  91%|█████████ | 289/317 [00:00<00:00, 381.88 Segments/s]\u001B[A\n",
      "Overall Progress:  52%|█████▏    | 48/93 [01:19<01:08,  1.52s/ Computational Sequence Entries]\n",
      "  0%|          | 0/611 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:   0%|          | 0/611 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:   5%|▌         | 32/611 [00:00<00:01, 313.87 Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:  10%|█         | 64/611 [00:00<00:01, 303.41 Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:  16%|█▌        | 95/611 [00:00<00:01, 303.64 Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:  21%|██        | 127/611 [00:00<00:01, 308.79 Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:  26%|██▌       | 158/611 [00:00<00:01, 300.52 Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:  31%|███▏      | 191/611 [00:00<00:01, 307.19 Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:  36%|███▋      | 222/611 [00:00<00:01, 299.32 Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:  41%|████▏     | 253/611 [00:00<00:01, 301.53 Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:  47%|████▋     | 285/611 [00:00<00:01, 305.36 Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:  52%|█████▏    | 317/611 [00:01<00:00, 309.56 Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:  57%|█████▋    | 348/611 [00:01<00:00, 304.62 Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:  62%|██████▏   | 379/611 [00:01<00:00, 305.42 Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:  67%|██████▋   | 410/611 [00:01<00:00, 299.98 Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:  72%|███████▏  | 442/611 [00:01<00:00, 305.05 Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:  77%|███████▋  | 473/611 [00:01<00:00, 298.99 Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:  83%|████████▎ | 506/611 [00:01<00:00, 305.90 Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:  88%|████████▊ | 537/611 [00:01<00:00, 302.53 Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:  93%|█████████▎| 568/611 [00:01<00:00, 297.06 Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:  98%|█████████▊| 598/611 [00:01<00:00, 290.64 Segments/s]\u001B[A\n",
      "Overall Progress:  53%|█████▎    | 49/93 [01:21<01:13,  1.68s/ Computational Sequence Entries]\n",
      "  0%|          | 0/751 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:   0%|          | 0/751 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:   4%|▍         | 31/751 [00:00<00:02, 302.97 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:   8%|▊         | 62/751 [00:00<00:02, 305.55 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:  12%|█▏        | 93/751 [00:00<00:02, 301.15 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:  17%|█▋        | 124/751 [00:00<00:02, 290.55 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:  21%|██        | 155/751 [00:00<00:02, 295.07 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:  25%|██▍       | 186/751 [00:00<00:01, 299.53 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:  29%|██▉       | 217/751 [00:00<00:01, 289.97 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:  33%|███▎      | 247/751 [00:00<00:01, 274.80 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:  37%|███▋      | 277/751 [00:00<00:01, 281.33 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:  41%|████      | 307/751 [00:01<00:01, 286.51 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:  45%|████▌     | 340/751 [00:01<00:01, 296.11 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:  50%|████▉     | 374/751 [00:01<00:01, 308.47 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:  54%|█████▍    | 407/751 [00:01<00:01, 313.45 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:  58%|█████▊    | 439/751 [00:01<00:01, 301.60 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:  63%|██████▎   | 473/751 [00:01<00:00, 310.64 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:  67%|██████▋   | 505/751 [00:01<00:00, 307.84 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:  72%|███████▏  | 537/751 [00:01<00:00, 308.92 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:  76%|███████▌  | 568/751 [00:01<00:00, 303.05 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:  80%|████████  | 601/751 [00:02<00:00, 310.43 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:  84%|████████▍ | 634/751 [00:02<00:00, 314.27 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:  89%|████████▉ | 668/751 [00:02<00:00, 321.20 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:  93%|█████████▎| 701/751 [00:02<00:00, 318.52 Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:  98%|█████████▊| 734/751 [00:02<00:00, 321.62 Segments/s]\u001B[A\n",
      "Overall Progress:  54%|█████▍    | 50/93 [01:23<01:22,  1.92s/ Computational Sequence Entries]\n",
      "  0%|          | 0/622 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Vj1wYRQjB-o:   0%|          | 0/622 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Vj1wYRQjB-o:   4%|▍         | 27/622 [00:00<00:02, 267.49 Segments/s]\u001B[A\n",
      "Aligning Vj1wYRQjB-o:  10%|▉         | 61/622 [00:00<00:01, 306.94 Segments/s]\u001B[A\n",
      "Aligning Vj1wYRQjB-o:  16%|█▌        | 97/622 [00:00<00:01, 329.69 Segments/s]\u001B[A\n",
      "Aligning Vj1wYRQjB-o:  21%|██        | 132/622 [00:00<00:01, 337.06 Segments/s]\u001B[A\n",
      "Aligning Vj1wYRQjB-o:  27%|██▋       | 166/622 [00:00<00:01, 337.47 Segments/s]\u001B[A\n",
      "Aligning Vj1wYRQjB-o:  32%|███▏      | 201/622 [00:00<00:01, 337.98 Segments/s]\u001B[A\n",
      "Aligning Vj1wYRQjB-o:  38%|███▊      | 236/622 [00:00<00:01, 339.74 Segments/s]\u001B[A\n",
      "Aligning Vj1wYRQjB-o:  43%|████▎     | 270/622 [00:00<00:01, 338.00 Segments/s]\u001B[A\n",
      "Aligning Vj1wYRQjB-o:  49%|████▉     | 304/622 [00:00<00:00, 332.46 Segments/s]\u001B[A\n",
      "Aligning Vj1wYRQjB-o:  54%|█████▍    | 338/622 [00:01<00:00, 321.95 Segments/s]\u001B[A\n",
      "Aligning Vj1wYRQjB-o:  60%|█████▉    | 372/622 [00:01<00:00, 326.49 Segments/s]\u001B[A\n",
      "Aligning Vj1wYRQjB-o:  65%|██████▌   | 407/622 [00:01<00:00, 331.76 Segments/s]\u001B[A\n",
      "Aligning Vj1wYRQjB-o:  71%|███████   | 442/622 [00:01<00:00, 335.31 Segments/s]\u001B[A\n",
      "Aligning Vj1wYRQjB-o:  77%|███████▋  | 477/622 [00:01<00:00, 339.11 Segments/s]\u001B[A\n",
      "Aligning Vj1wYRQjB-o:  82%|████████▏ | 511/622 [00:01<00:00, 336.27 Segments/s]\u001B[A\n",
      "Aligning Vj1wYRQjB-o:  88%|████████▊ | 545/622 [00:01<00:00, 327.77 Segments/s]\u001B[A\n",
      "Aligning Vj1wYRQjB-o:  93%|█████████▎| 578/622 [00:01<00:00, 313.52 Segments/s]\u001B[A\n",
      "Aligning Vj1wYRQjB-o:  98%|█████████▊| 610/622 [00:01<00:00, 314.59 Segments/s]\u001B[A\n",
      "Overall Progress:  55%|█████▍    | 51/93 [01:25<01:20,  1.92s/ Computational Sequence Entries]\n",
      "  0%|          | 0/612 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning W8NXH0Djyww:   0%|          | 0/612 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning W8NXH0Djyww:   6%|▌         | 36/612 [00:00<00:01, 356.70 Segments/s]\u001B[A\n",
      "Aligning W8NXH0Djyww:  12%|█▏        | 72/612 [00:00<00:01, 310.13 Segments/s]\u001B[A\n",
      "Aligning W8NXH0Djyww:  18%|█▊        | 108/612 [00:00<00:01, 328.72 Segments/s]\u001B[A\n",
      "Aligning W8NXH0Djyww:  24%|██▎       | 144/612 [00:00<00:01, 338.40 Segments/s]\u001B[A\n",
      "Aligning W8NXH0Djyww:  29%|██▉       | 179/612 [00:00<00:01, 312.85 Segments/s]\u001B[A\n",
      "Aligning W8NXH0Djyww:  34%|███▍      | 211/612 [00:00<00:01, 285.37 Segments/s]\u001B[A\n",
      "Aligning W8NXH0Djyww:  39%|███▉      | 241/612 [00:00<00:01, 280.21 Segments/s]\u001B[A\n",
      "Aligning W8NXH0Djyww:  44%|████▍     | 270/612 [00:00<00:01, 282.60 Segments/s]\u001B[A\n",
      "Aligning W8NXH0Djyww:  49%|████▉     | 299/612 [00:01<00:01, 279.12 Segments/s]\u001B[A\n",
      "Aligning W8NXH0Djyww:  54%|█████▍    | 333/612 [00:01<00:00, 293.55 Segments/s]\u001B[A\n",
      "Aligning W8NXH0Djyww:  60%|█████▉    | 367/612 [00:01<00:00, 304.63 Segments/s]\u001B[A\n",
      "Aligning W8NXH0Djyww:  66%|██████▌   | 401/612 [00:01<00:00, 312.63 Segments/s]\u001B[A\n",
      "Aligning W8NXH0Djyww:  71%|███████   | 433/612 [00:01<00:00, 307.94 Segments/s]\u001B[A\n",
      "Aligning W8NXH0Djyww:  76%|███████▌  | 464/612 [00:01<00:00, 302.46 Segments/s]\u001B[A\n",
      "Aligning W8NXH0Djyww:  81%|████████  | 495/612 [00:01<00:00, 302.11 Segments/s]\u001B[A\n",
      "Aligning W8NXH0Djyww:  86%|████████▌ | 526/612 [00:01<00:00, 295.29 Segments/s]\u001B[A\n",
      "Aligning W8NXH0Djyww:  91%|█████████ | 557/612 [00:01<00:00, 297.84 Segments/s]\u001B[A\n",
      "Aligning W8NXH0Djyww:  96%|█████████▌| 588/612 [00:01<00:00, 298.97 Segments/s]\u001B[A\n",
      "Overall Progress:  56%|█████▌    | 52/93 [01:27<01:20,  1.96s/ Computational Sequence Entries]\n",
      "  0%|          | 0/621 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning WKA5OygbEKI:   0%|          | 0/621 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning WKA5OygbEKI:   6%|▌         | 37/621 [00:00<00:01, 357.69 Segments/s]\u001B[A\n",
      "Aligning WKA5OygbEKI:  12%|█▏        | 73/621 [00:00<00:01, 355.08 Segments/s]\u001B[A\n",
      "Aligning WKA5OygbEKI:  18%|█▊        | 109/621 [00:00<00:01, 349.77 Segments/s]\u001B[A\n",
      "Aligning WKA5OygbEKI:  23%|██▎       | 144/621 [00:00<00:01, 317.82 Segments/s]\u001B[A\n",
      "Aligning WKA5OygbEKI:  29%|██▊       | 177/621 [00:00<00:01, 315.48 Segments/s]\u001B[A\n",
      "Aligning WKA5OygbEKI:  34%|███▍      | 213/621 [00:00<00:01, 327.55 Segments/s]\u001B[A\n",
      "Aligning WKA5OygbEKI:  40%|███▉      | 246/621 [00:00<00:01, 320.43 Segments/s]\u001B[A\n",
      "Aligning WKA5OygbEKI:  45%|████▍     | 279/621 [00:00<00:01, 315.28 Segments/s]\u001B[A\n",
      "Aligning WKA5OygbEKI:  50%|█████     | 311/621 [00:00<00:00, 312.80 Segments/s]\u001B[A\n",
      "Aligning WKA5OygbEKI:  56%|█████▌    | 346/621 [00:01<00:00, 322.54 Segments/s]\u001B[A\n",
      "Aligning WKA5OygbEKI:  61%|██████    | 380/621 [00:01<00:00, 325.96 Segments/s]\u001B[A\n",
      "Aligning WKA5OygbEKI:  67%|██████▋   | 418/621 [00:01<00:00, 340.02 Segments/s]\u001B[A\n",
      "Aligning WKA5OygbEKI:  73%|███████▎  | 453/621 [00:01<00:00, 339.43 Segments/s]\u001B[A\n",
      "Aligning WKA5OygbEKI:  79%|███████▊  | 489/621 [00:01<00:00, 344.34 Segments/s]\u001B[A\n",
      "Aligning WKA5OygbEKI:  84%|████████▍ | 524/621 [00:01<00:00, 338.82 Segments/s]\u001B[A\n",
      "Aligning WKA5OygbEKI:  90%|████████▉ | 558/621 [00:01<00:00, 321.06 Segments/s]\u001B[A\n",
      "Aligning WKA5OygbEKI:  95%|█████████▌| 591/621 [00:01<00:00, 315.53 Segments/s]\u001B[A\n",
      "Overall Progress:  57%|█████▋    | 53/93 [01:29<01:17,  1.95s/ Computational Sequence Entries]\n",
      "  0%|          | 0/249 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning X3j2zQgwYgE:   0%|          | 0/249 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning X3j2zQgwYgE:  16%|█▌        | 40/249 [00:00<00:00, 389.42 Segments/s]\u001B[A\n",
      "Aligning X3j2zQgwYgE:  33%|███▎      | 83/249 [00:00<00:00, 411.58 Segments/s]\u001B[A\n",
      "Aligning X3j2zQgwYgE:  50%|█████     | 125/249 [00:00<00:00, 404.63 Segments/s]\u001B[A\n",
      "Aligning X3j2zQgwYgE:  67%|██████▋   | 166/249 [00:00<00:00, 382.70 Segments/s]\u001B[A\n",
      "Aligning X3j2zQgwYgE:  82%|████████▏ | 205/249 [00:00<00:00, 383.93 Segments/s]\u001B[A\n",
      "Overall Progress:  58%|█████▊    | 54/93 [01:30<01:00,  1.55s/ Computational Sequence Entries]\n",
      "  0%|          | 0/220 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning ZAIRrfG22O0:   0%|          | 0/220 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning ZAIRrfG22O0:  20%|██        | 44/220 [00:00<00:00, 439.14 Segments/s]\u001B[A\n",
      "Aligning ZAIRrfG22O0:  40%|████      | 88/220 [00:00<00:00, 433.04 Segments/s]\u001B[A\n",
      "Aligning ZAIRrfG22O0:  60%|██████    | 132/220 [00:00<00:00, 422.39 Segments/s]\u001B[A\n",
      "Aligning ZAIRrfG22O0:  81%|████████  | 178/220 [00:00<00:00, 436.57 Segments/s]\u001B[A\n",
      "Overall Progress:  59%|█████▉    | 55/93 [01:30<00:47,  1.24s/ Computational Sequence Entries]\n",
      "  0%|          | 0/537 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning ZUXBRvtny7o:   0%|          | 0/537 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning ZUXBRvtny7o:   6%|▌         | 30/537 [00:00<00:01, 294.10 Segments/s]\u001B[A\n",
      "Aligning ZUXBRvtny7o:  12%|█▏        | 62/537 [00:00<00:01, 306.45 Segments/s]\u001B[A\n",
      "Aligning ZUXBRvtny7o:  18%|█▊        | 95/537 [00:00<00:01, 313.13 Segments/s]\u001B[A\n",
      "Aligning ZUXBRvtny7o:  24%|██▎       | 127/537 [00:00<00:01, 295.43 Segments/s]\u001B[A\n",
      "Aligning ZUXBRvtny7o:  29%|██▉       | 157/537 [00:00<00:01, 274.31 Segments/s]\u001B[A\n",
      "Aligning ZUXBRvtny7o:  34%|███▍      | 185/537 [00:00<00:01, 271.70 Segments/s]\u001B[A\n",
      "Aligning ZUXBRvtny7o:  41%|████      | 218/537 [00:00<00:01, 286.63 Segments/s]\u001B[A\n",
      "Aligning ZUXBRvtny7o:  46%|████▌     | 247/537 [00:00<00:01, 281.49 Segments/s]\u001B[A\n",
      "Aligning ZUXBRvtny7o:  52%|█████▏    | 280/537 [00:00<00:00, 293.99 Segments/s]\u001B[A\n",
      "Aligning ZUXBRvtny7o:  58%|█████▊    | 310/537 [00:01<00:00, 295.37 Segments/s]\u001B[A\n",
      "Aligning ZUXBRvtny7o:  63%|██████▎   | 340/537 [00:01<00:00, 296.59 Segments/s]\u001B[A\n",
      "Aligning ZUXBRvtny7o:  69%|██████▉   | 370/537 [00:01<00:00, 290.99 Segments/s]\u001B[A\n",
      "Aligning ZUXBRvtny7o:  74%|███████▍  | 400/537 [00:01<00:00, 292.58 Segments/s]\u001B[A\n",
      "Aligning ZUXBRvtny7o:  80%|████████  | 430/537 [00:01<00:00, 282.65 Segments/s]\u001B[A\n",
      "Aligning ZUXBRvtny7o:  85%|████████▌ | 459/537 [00:01<00:00, 283.95 Segments/s]\u001B[A\n",
      "Aligning ZUXBRvtny7o:  92%|█████████▏| 493/537 [00:01<00:00, 299.93 Segments/s]\u001B[A\n",
      "Aligning ZUXBRvtny7o:  98%|█████████▊| 528/537 [00:01<00:00, 314.05 Segments/s]\u001B[A\n",
      "Overall Progress:  60%|██████    | 56/93 [01:32<00:52,  1.42s/ Computational Sequence Entries]\n",
      "  0%|          | 0/675 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:   0%|          | 0/675 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:   4%|▍         | 29/675 [00:00<00:02, 284.98 Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:   9%|▉         | 62/675 [00:00<00:01, 310.17 Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:  14%|█▍        | 94/675 [00:00<00:01, 311.92 Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:  19%|█▊        | 126/675 [00:00<00:01, 312.12 Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:  24%|██▎       | 159/675 [00:00<00:01, 316.39 Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:  28%|██▊       | 191/675 [00:00<00:01, 312.94 Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:  33%|███▎      | 223/675 [00:00<00:01, 307.29 Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:  38%|███▊      | 254/675 [00:00<00:01, 294.34 Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:  42%|████▏     | 284/675 [00:00<00:01, 289.27 Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:  46%|████▋     | 313/675 [00:01<00:01, 285.83 Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:  51%|█████     | 343/675 [00:01<00:01, 289.67 Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:  55%|█████▌    | 373/675 [00:01<00:01, 290.05 Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:  60%|█████▉    | 403/675 [00:01<00:00, 281.78 Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:  64%|██████▍   | 432/675 [00:01<00:00, 276.38 Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:  68%|██████▊   | 461/675 [00:01<00:00, 278.10 Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:  73%|███████▎  | 490/675 [00:01<00:00, 280.69 Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:  77%|███████▋  | 519/675 [00:01<00:00, 276.05 Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:  82%|████████▏ | 553/675 [00:01<00:00, 292.77 Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:  87%|████████▋ | 587/675 [00:01<00:00, 305.60 Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:  92%|█████████▏| 618/675 [00:02<00:00, 306.37 Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:  96%|█████████▌| 649/675 [00:02<00:00, 288.42 Segments/s]\u001B[A\n",
      "Overall Progress:  61%|██████▏   | 57/93 [01:34<01:00,  1.69s/ Computational Sequence Entries]\n",
      "  0%|          | 0/591 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning aiEXnCPZubE:   0%|          | 0/591 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning aiEXnCPZubE:   6%|▌         | 33/591 [00:00<00:01, 320.13 Segments/s]\u001B[A\n",
      "Aligning aiEXnCPZubE:  11%|█         | 66/591 [00:00<00:01, 318.59 Segments/s]\u001B[A\n",
      "Aligning aiEXnCPZubE:  17%|█▋        | 101/591 [00:00<00:01, 329.87 Segments/s]\u001B[A\n",
      "Aligning aiEXnCPZubE:  23%|██▎       | 134/591 [00:00<00:01, 318.14 Segments/s]\u001B[A\n",
      "Aligning aiEXnCPZubE:  28%|██▊       | 166/591 [00:00<00:01, 292.85 Segments/s]\u001B[A\n",
      "Aligning aiEXnCPZubE:  34%|███▎      | 198/591 [00:00<00:01, 300.57 Segments/s]\u001B[A\n",
      "Aligning aiEXnCPZubE:  39%|███▉      | 230/591 [00:00<00:01, 304.98 Segments/s]\u001B[A\n",
      "Aligning aiEXnCPZubE:  45%|████▍     | 263/591 [00:00<00:01, 310.99 Segments/s]\u001B[A\n",
      "Aligning aiEXnCPZubE:  50%|████▉     | 295/591 [00:00<00:01, 290.90 Segments/s]\u001B[A\n",
      "Aligning aiEXnCPZubE:  55%|█████▍    | 325/591 [00:01<00:00, 283.58 Segments/s]\u001B[A\n",
      "Aligning aiEXnCPZubE:  60%|██████    | 356/591 [00:01<00:00, 289.85 Segments/s]\u001B[A\n",
      "Aligning aiEXnCPZubE:  65%|██████▌   | 386/591 [00:01<00:00, 292.06 Segments/s]\u001B[A\n",
      "Aligning aiEXnCPZubE:  71%|███████   | 420/591 [00:01<00:00, 303.34 Segments/s]\u001B[A\n",
      "Aligning aiEXnCPZubE:  76%|███████▋  | 451/591 [00:01<00:00, 298.56 Segments/s]\u001B[A\n",
      "Aligning aiEXnCPZubE:  81%|████████▏ | 481/591 [00:01<00:00, 285.60 Segments/s]\u001B[A\n",
      "Aligning aiEXnCPZubE:  87%|████████▋ | 515/591 [00:01<00:00, 300.69 Segments/s]\u001B[A\n",
      "Aligning aiEXnCPZubE:  92%|█████████▏| 546/591 [00:01<00:00, 299.12 Segments/s]\u001B[A\n",
      "Aligning aiEXnCPZubE:  98%|█████████▊| 579/591 [00:01<00:00, 305.43 Segments/s]\u001B[A\n",
      "Overall Progress:  62%|██████▏   | 58/93 [01:36<01:02,  1.78s/ Computational Sequence Entries]\n",
      "  0%|          | 0/557 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning atnd_PF-Lbs:   0%|          | 0/557 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning atnd_PF-Lbs:   6%|▌         | 32/557 [00:00<00:01, 314.37 Segments/s]\u001B[A\n",
      "Aligning atnd_PF-Lbs:  11%|█▏        | 64/557 [00:00<00:01, 313.97 Segments/s]\u001B[A\n",
      "Aligning atnd_PF-Lbs:  17%|█▋        | 96/557 [00:00<00:01, 293.22 Segments/s]\u001B[A\n",
      "Aligning atnd_PF-Lbs:  23%|██▎       | 126/557 [00:00<00:01, 295.26 Segments/s]\u001B[A\n",
      "Aligning atnd_PF-Lbs:  28%|██▊       | 156/557 [00:00<00:01, 285.92 Segments/s]\u001B[A\n",
      "Aligning atnd_PF-Lbs:  33%|███▎      | 185/557 [00:00<00:01, 278.08 Segments/s]\u001B[A\n",
      "Aligning atnd_PF-Lbs:  39%|███▉      | 216/557 [00:00<00:01, 287.86 Segments/s]\u001B[A\n",
      "Aligning atnd_PF-Lbs:  44%|████▍     | 245/557 [00:00<00:01, 279.82 Segments/s]\u001B[A\n",
      "Aligning atnd_PF-Lbs:  49%|████▉     | 274/557 [00:00<00:01, 282.41 Segments/s]\u001B[A\n",
      "Aligning atnd_PF-Lbs:  55%|█████▍    | 304/557 [00:01<00:00, 286.55 Segments/s]\u001B[A\n",
      "Aligning atnd_PF-Lbs:  60%|█████▉    | 333/557 [00:01<00:01, 210.34 Segments/s]\u001B[A\n",
      "Aligning atnd_PF-Lbs:  64%|██████▍   | 357/557 [00:01<00:00, 214.63 Segments/s]\u001B[A\n",
      "Aligning atnd_PF-Lbs:  70%|██████▉   | 389/557 [00:01<00:00, 241.06 Segments/s]\u001B[A\n",
      "Aligning atnd_PF-Lbs:  76%|███████▌  | 423/557 [00:01<00:00, 265.67 Segments/s]\u001B[A\n",
      "Aligning atnd_PF-Lbs:  82%|████████▏ | 455/557 [00:01<00:00, 280.31 Segments/s]\u001B[A\n",
      "Aligning atnd_PF-Lbs:  87%|████████▋ | 485/557 [00:01<00:00, 274.45 Segments/s]\u001B[A\n",
      "Aligning atnd_PF-Lbs:  92%|█████████▏| 514/557 [00:01<00:00, 262.80 Segments/s]\u001B[A\n",
      "Aligning atnd_PF-Lbs:  97%|█████████▋| 542/557 [00:02<00:00, 265.11 Segments/s]\u001B[A\n",
      "Overall Progress:  63%|██████▎   | 59/93 [01:39<01:03,  1.87s/ Computational Sequence Entries]\n",
      "  0%|          | 0/443 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning bOL9jKpeJRs:   0%|          | 0/443 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning bOL9jKpeJRs:   7%|▋         | 32/443 [00:00<00:01, 317.54 Segments/s]\u001B[A\n",
      "Aligning bOL9jKpeJRs:  15%|█▌        | 68/443 [00:00<00:01, 339.33 Segments/s]\u001B[A\n",
      "Aligning bOL9jKpeJRs:  23%|██▎       | 102/443 [00:00<00:01, 329.04 Segments/s]\u001B[A\n",
      "Aligning bOL9jKpeJRs:  32%|███▏      | 140/443 [00:00<00:00, 347.88 Segments/s]\u001B[A\n",
      "Aligning bOL9jKpeJRs:  41%|████      | 180/443 [00:00<00:00, 362.66 Segments/s]\u001B[A\n",
      "Aligning bOL9jKpeJRs:  49%|████▉     | 217/443 [00:00<00:00, 329.83 Segments/s]\u001B[A\n",
      "Aligning bOL9jKpeJRs:  58%|█████▊    | 256/443 [00:00<00:00, 346.42 Segments/s]\u001B[A\n",
      "Aligning bOL9jKpeJRs:  66%|██████▋   | 294/443 [00:00<00:00, 355.50 Segments/s]\u001B[A\n",
      "Aligning bOL9jKpeJRs:  74%|███████▍  | 330/443 [00:00<00:00, 356.63 Segments/s]\u001B[A\n",
      "Aligning bOL9jKpeJRs:  83%|████████▎ | 366/443 [00:01<00:00, 332.33 Segments/s]\u001B[A\n",
      "Aligning bOL9jKpeJRs:  91%|█████████ | 401/443 [00:01<00:00, 334.84 Segments/s]\u001B[A\n",
      "Aligning bOL9jKpeJRs:  99%|█████████▉| 438/443 [00:01<00:00, 342.41 Segments/s]\u001B[A\n",
      "Overall Progress:  65%|██████▍   | 60/93 [01:40<00:56,  1.70s/ Computational Sequence Entries]\n",
      "  0%|          | 0/595 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:   0%|          | 0/595 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:   5%|▌         | 30/595 [00:00<00:01, 293.66 Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:  11%|█▏        | 67/595 [00:00<00:01, 334.01 Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:  17%|█▋        | 101/595 [00:00<00:01, 328.34 Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:  23%|██▎       | 134/595 [00:00<00:01, 310.24 Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:  28%|██▊       | 166/595 [00:00<00:01, 297.17 Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:  33%|███▎      | 196/595 [00:00<00:01, 296.34 Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:  38%|███▊      | 226/595 [00:00<00:01, 289.80 Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:  43%|████▎     | 256/595 [00:00<00:01, 277.08 Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:  48%|████▊     | 284/595 [00:00<00:01, 275.46 Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:  52%|█████▏    | 312/595 [00:01<00:01, 274.49 Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:  57%|█████▋    | 340/595 [00:01<00:00, 273.74 Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:  62%|██████▏   | 369/595 [00:01<00:00, 277.30 Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:  67%|██████▋   | 397/595 [00:01<00:00, 274.37 Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:  71%|███████▏  | 425/595 [00:01<00:00, 264.98 Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:  76%|███████▌  | 452/595 [00:01<00:00, 265.88 Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:  81%|████████  | 482/595 [00:01<00:00, 274.50 Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:  86%|████████▋ | 514/595 [00:01<00:00, 287.31 Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:  91%|█████████▏| 544/595 [00:01<00:00, 290.64 Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:  97%|█████████▋| 576/595 [00:02<00:00, 298.93 Segments/s]\u001B[A\n",
      "Overall Progress:  66%|██████▌   | 61/93 [01:42<00:58,  1.82s/ Computational Sequence Entries]\n",
      "  0%|          | 0/694 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:   0%|          | 0/694 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:   5%|▍         | 34/694 [00:00<00:02, 328.31 Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:  10%|▉         | 67/694 [00:00<00:02, 298.52 Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:  14%|█▍        | 98/694 [00:00<00:01, 302.09 Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:  19%|█▊        | 129/694 [00:00<00:02, 270.82 Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:  23%|██▎       | 157/694 [00:00<00:02, 251.06 Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:  28%|██▊       | 193/694 [00:00<00:01, 281.66 Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:  33%|███▎      | 228/694 [00:00<00:01, 301.15 Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:  37%|███▋      | 259/694 [00:00<00:01, 291.29 Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:  42%|████▏     | 289/694 [00:01<00:01, 285.41 Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:  46%|████▌     | 318/694 [00:01<00:01, 279.77 Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:  50%|█████     | 347/694 [00:01<00:01, 280.62 Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:  54%|█████▍    | 376/694 [00:01<00:01, 276.68 Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:  59%|█████▊    | 406/694 [00:01<00:01, 281.17 Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:  63%|██████▎   | 435/694 [00:01<00:00, 271.83 Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:  67%|██████▋   | 463/694 [00:01<00:00, 271.87 Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:  71%|███████   | 491/694 [00:01<00:00, 273.41 Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:  75%|███████▌  | 521/694 [00:01<00:00, 280.04 Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:  79%|███████▉  | 550/694 [00:01<00:00, 273.11 Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:  84%|████████▎ | 581/694 [00:02<00:00, 281.89 Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:  88%|████████▊ | 610/694 [00:02<00:00, 283.33 Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:  92%|█████████▏| 641/694 [00:02<00:00, 289.13 Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:  97%|█████████▋| 670/694 [00:02<00:00, 281.30 Segments/s]\u001B[A\n",
      "Overall Progress:  67%|██████▋   | 62/93 [01:44<01:02,  2.02s/ Computational Sequence Entries]\n",
      "  0%|          | 0/448 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning c7UH_rxdZv4:   0%|          | 0/448 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning c7UH_rxdZv4:   6%|▌         | 26/448 [00:00<00:01, 259.54 Segments/s]\u001B[A\n",
      "Aligning c7UH_rxdZv4:  13%|█▎        | 57/448 [00:00<00:01, 287.69 Segments/s]\u001B[A\n",
      "Aligning c7UH_rxdZv4:  19%|█▉        | 86/448 [00:00<00:01, 270.91 Segments/s]\u001B[A\n",
      "Aligning c7UH_rxdZv4:  25%|██▌       | 114/448 [00:00<00:01, 268.43 Segments/s]\u001B[A\n",
      "Aligning c7UH_rxdZv4:  31%|███▏      | 141/448 [00:00<00:01, 267.01 Segments/s]\u001B[A\n",
      "Aligning c7UH_rxdZv4:  38%|███▊      | 168/448 [00:00<00:01, 260.34 Segments/s]\u001B[A\n",
      "Aligning c7UH_rxdZv4:  45%|████▌     | 203/448 [00:00<00:00, 286.68 Segments/s]\u001B[A\n",
      "Aligning c7UH_rxdZv4:  53%|█████▎    | 236/448 [00:00<00:00, 297.75 Segments/s]\u001B[A\n",
      "Aligning c7UH_rxdZv4:  59%|█████▉    | 266/448 [00:00<00:00, 293.91 Segments/s]\u001B[A\n",
      "Aligning c7UH_rxdZv4:  66%|██████▌   | 296/448 [00:01<00:00, 289.57 Segments/s]\u001B[A\n",
      "Aligning c7UH_rxdZv4:  73%|███████▎  | 326/448 [00:01<00:00, 284.95 Segments/s]\u001B[A\n",
      "Aligning c7UH_rxdZv4:  79%|███████▉  | 355/448 [00:01<00:00, 285.00 Segments/s]\u001B[A\n",
      "Aligning c7UH_rxdZv4:  86%|████████▌ | 384/448 [00:01<00:00, 285.43 Segments/s]\u001B[A\n",
      "Aligning c7UH_rxdZv4:  93%|█████████▎| 417/448 [00:01<00:00, 297.35 Segments/s]\u001B[A\n",
      "Aligning c7UH_rxdZv4: 100%|█████████▉| 447/448 [00:01<00:00, 293.14 Segments/s]\u001B[A\n",
      "Overall Progress:  68%|██████▊   | 63/93 [01:46<00:56,  1.89s/ Computational Sequence Entries]\n",
      "  0%|          | 0/548 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:   0%|          | 0/548 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:   5%|▌         | 29/548 [00:00<00:01, 282.05 Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:  11%|█         | 58/548 [00:00<00:01, 263.73 Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:  16%|█▌        | 85/548 [00:00<00:01, 245.77 Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:  21%|██        | 115/548 [00:00<00:01, 263.94 Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:  26%|██▌       | 142/548 [00:00<00:01, 263.12 Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:  31%|███       | 169/548 [00:00<00:01, 262.35 Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:  36%|███▋      | 199/548 [00:00<00:01, 272.39 Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:  41%|████▏     | 227/548 [00:00<00:01, 263.86 Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:  46%|████▋     | 254/548 [00:00<00:01, 261.18 Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:  51%|█████▏    | 281/548 [00:01<00:01, 252.84 Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:  56%|█████▌    | 307/548 [00:01<00:00, 249.83 Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:  61%|██████    | 333/548 [00:01<00:00, 248.23 Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:  66%|██████▌   | 361/548 [00:01<00:00, 256.41 Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:  72%|███████▏  | 392/548 [00:01<00:00, 271.81 Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:  77%|███████▋  | 421/548 [00:01<00:00, 275.15 Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:  82%|████████▏ | 450/548 [00:01<00:00, 276.91 Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:  88%|████████▊ | 482/548 [00:01<00:00, 288.74 Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:  94%|█████████▍| 514/548 [00:01<00:00, 297.62 Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:  99%|█████████▉| 544/548 [00:02<00:00, 295.99 Segments/s]\u001B[A\n",
      "Overall Progress:  69%|██████▉   | 64/93 [01:48<00:56,  1.93s/ Computational Sequence Entries]\n",
      "  0%|          | 0/497 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning cW1FSBF59ik:   0%|          | 0/497 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning cW1FSBF59ik:   5%|▌         | 27/497 [00:00<00:01, 268.38 Segments/s]\u001B[A\n",
      "Aligning cW1FSBF59ik:  12%|█▏        | 59/497 [00:00<00:01, 293.96 Segments/s]\u001B[A\n",
      "Aligning cW1FSBF59ik:  19%|█▊        | 92/497 [00:00<00:01, 307.43 Segments/s]\u001B[A\n",
      "Aligning cW1FSBF59ik:  26%|██▌       | 127/497 [00:00<00:01, 321.86 Segments/s]\u001B[A\n",
      "Aligning cW1FSBF59ik:  32%|███▏      | 160/497 [00:00<00:01, 321.85 Segments/s]\u001B[A\n",
      "Aligning cW1FSBF59ik:  39%|███▉      | 193/497 [00:00<00:01, 293.37 Segments/s]\u001B[A\n",
      "Aligning cW1FSBF59ik:  45%|████▌     | 225/497 [00:00<00:00, 299.51 Segments/s]\u001B[A\n",
      "Aligning cW1FSBF59ik:  52%|█████▏    | 258/497 [00:00<00:00, 308.06 Segments/s]\u001B[A\n",
      "Aligning cW1FSBF59ik:  59%|█████▉    | 292/497 [00:00<00:00, 317.26 Segments/s]\u001B[A\n",
      "Aligning cW1FSBF59ik:  65%|██████▌   | 324/497 [00:01<00:00, 303.18 Segments/s]\u001B[A\n",
      "Aligning cW1FSBF59ik:  71%|███████▏  | 355/497 [00:01<00:00, 300.03 Segments/s]\u001B[A\n",
      "Aligning cW1FSBF59ik:  78%|███████▊  | 386/497 [00:01<00:00, 279.61 Segments/s]\u001B[A\n",
      "Aligning cW1FSBF59ik:  84%|████████▎ | 415/497 [00:01<00:00, 264.71 Segments/s]\u001B[A\n",
      "Aligning cW1FSBF59ik:  89%|████████▉ | 442/497 [00:01<00:00, 250.44 Segments/s]\u001B[A\n",
      "Aligning cW1FSBF59ik:  94%|█████████▍| 468/497 [00:01<00:00, 240.14 Segments/s]\u001B[A\n",
      "Aligning cW1FSBF59ik:  99%|█████████▉| 493/497 [00:01<00:00, 234.41 Segments/s]\u001B[A\n",
      "Overall Progress:  70%|██████▉   | 65/93 [01:50<00:53,  1.90s/ Computational Sequence Entries]\n",
      "  0%|          | 0/717 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:   0%|          | 0/717 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:   3%|▎         | 24/717 [00:00<00:03, 230.29 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:   7%|▋         | 48/717 [00:00<00:02, 230.15 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  10%|█         | 72/717 [00:00<00:02, 223.06 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  14%|█▍        | 101/717 [00:00<00:02, 245.34 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  18%|█▊        | 132/717 [00:00<00:02, 266.26 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  22%|██▏       | 161/717 [00:00<00:02, 273.59 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  26%|██▋       | 190/717 [00:00<00:01, 278.15 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  30%|███       | 218/717 [00:00<00:01, 271.49 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  35%|███▍      | 248/717 [00:00<00:01, 278.42 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  39%|███▊      | 277/717 [00:01<00:01, 279.89 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  43%|████▎     | 306/717 [00:01<00:01, 277.22 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  47%|████▋     | 334/717 [00:01<00:01, 276.22 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  50%|█████     | 362/717 [00:01<00:01, 271.53 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  54%|█████▍    | 390/717 [00:01<00:01, 261.45 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  59%|█████▉    | 422/717 [00:01<00:01, 278.10 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  63%|██████▎   | 452/717 [00:01<00:00, 283.29 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  67%|██████▋   | 481/717 [00:01<00:00, 285.23 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  71%|███████▏  | 511/717 [00:01<00:00, 286.65 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  75%|███████▌  | 540/717 [00:01<00:00, 284.95 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  80%|███████▉  | 573/717 [00:02<00:00, 294.52 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  84%|████████▍ | 605/717 [00:02<00:00, 300.54 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  89%|████████▊ | 636/717 [00:02<00:00, 297.09 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  93%|█████████▎| 666/717 [00:02<00:00, 286.45 Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:  97%|█████████▋| 695/717 [00:02<00:00, 273.74 Segments/s]\u001B[A\n",
      "Overall Progress:  71%|███████   | 66/93 [01:52<00:57,  2.12s/ Computational Sequence Entries]\n",
      "  0%|          | 0/572 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:   0%|          | 0/572 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:   4%|▍         | 25/572 [00:00<00:02, 249.27 Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:   9%|▊         | 50/572 [00:00<00:02, 247.78 Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:  14%|█▎        | 78/572 [00:00<00:01, 260.23 Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:  19%|█▉        | 110/572 [00:00<00:01, 279.13 Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:  25%|██▍       | 141/572 [00:00<00:01, 288.07 Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:  30%|██▉       | 170/572 [00:00<00:01, 284.75 Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:  35%|███▍      | 199/572 [00:00<00:01, 276.96 Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:  40%|███▉      | 227/572 [00:00<00:01, 270.85 Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:  45%|████▌     | 259/572 [00:00<00:01, 283.55 Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:  51%|█████     | 292/572 [00:01<00:00, 296.08 Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:  56%|█████▋    | 323/572 [00:01<00:00, 298.07 Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:  62%|██████▏   | 353/572 [00:01<00:00, 292.80 Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:  67%|██████▋   | 383/572 [00:01<00:00, 270.37 Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:  72%|███████▏  | 413/572 [00:01<00:00, 277.10 Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:  77%|███████▋  | 443/572 [00:01<00:00, 283.47 Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:  83%|████████▎ | 472/572 [00:01<00:00, 276.63 Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:  88%|████████▊ | 501/572 [00:01<00:00, 278.56 Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:  92%|█████████▏| 529/572 [00:01<00:00, 278.59 Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:  98%|█████████▊| 560/572 [00:01<00:00, 286.68 Segments/s]\u001B[A\n",
      "Overall Progress:  72%|███████▏  | 67/93 [01:54<00:54,  2.09s/ Computational Sequence Entries]\n",
      "  0%|          | 0/481 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning d6hH302o4v8:   0%|          | 0/481 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning d6hH302o4v8:   8%|▊         | 37/481 [00:00<00:01, 369.23 Segments/s]\u001B[A\n",
      "Aligning d6hH302o4v8:  15%|█▌        | 74/481 [00:00<00:01, 342.24 Segments/s]\u001B[A\n",
      "Aligning d6hH302o4v8:  23%|██▎       | 109/481 [00:00<00:01, 338.06 Segments/s]\u001B[A\n",
      "Aligning d6hH302o4v8:  31%|███       | 147/481 [00:00<00:00, 351.31 Segments/s]\u001B[A\n",
      "Aligning d6hH302o4v8:  38%|███▊      | 183/481 [00:00<00:00, 352.71 Segments/s]\u001B[A\n",
      "Aligning d6hH302o4v8:  46%|████▌     | 219/481 [00:00<00:00, 293.47 Segments/s]\u001B[A\n",
      "Aligning d6hH302o4v8:  53%|█████▎    | 254/481 [00:00<00:00, 307.59 Segments/s]\u001B[A\n",
      "Aligning d6hH302o4v8:  60%|██████    | 289/481 [00:00<00:00, 317.84 Segments/s]\u001B[A\n",
      "Aligning d6hH302o4v8:  67%|██████▋   | 322/481 [00:01<00:00, 310.92 Segments/s]\u001B[A\n",
      "Aligning d6hH302o4v8:  74%|███████▎  | 354/481 [00:01<00:00, 304.78 Segments/s]\u001B[A\n",
      "Aligning d6hH302o4v8:  80%|████████  | 386/481 [00:01<00:00, 307.43 Segments/s]\u001B[A\n",
      "Aligning d6hH302o4v8:  87%|████████▋ | 419/481 [00:01<00:00, 311.50 Segments/s]\u001B[A\n",
      "Aligning d6hH302o4v8:  95%|█████████▍| 455/481 [00:01<00:00, 324.13 Segments/s]\u001B[A\n",
      "Overall Progress:  73%|███████▎  | 68/93 [01:56<00:47,  1.92s/ Computational Sequence Entries]\n",
      "  0%|          | 0/287 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning dq3Nf_lMPnE:   0%|          | 0/287 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning dq3Nf_lMPnE:  14%|█▍        | 41/287 [00:00<00:00, 405.78 Segments/s]\u001B[A\n",
      "Aligning dq3Nf_lMPnE:  29%|██▊       | 82/287 [00:00<00:00, 390.88 Segments/s]\u001B[A\n",
      "Aligning dq3Nf_lMPnE:  43%|████▎     | 122/287 [00:00<00:00, 374.21 Segments/s]\u001B[A\n",
      "Aligning dq3Nf_lMPnE:  56%|█████▌    | 160/287 [00:00<00:00, 372.20 Segments/s]\u001B[A\n",
      "Aligning dq3Nf_lMPnE:  69%|██████▉   | 198/287 [00:00<00:00, 347.01 Segments/s]\u001B[A\n",
      "Aligning dq3Nf_lMPnE:  82%|████████▏ | 236/287 [00:00<00:00, 356.86 Segments/s]\u001B[A\n",
      "Aligning dq3Nf_lMPnE:  96%|█████████▌| 276/287 [00:00<00:00, 367.91 Segments/s]\u001B[A\n",
      "Overall Progress:  74%|███████▍  | 69/93 [01:57<00:38,  1.58s/ Computational Sequence Entries]\n",
      "  0%|          | 0/687 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:   0%|          | 0/687 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:   4%|▍         | 28/687 [00:00<00:02, 279.88 Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:   8%|▊         | 58/687 [00:00<00:02, 286.85 Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:  13%|█▎        | 87/687 [00:00<00:02, 284.00 Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:  17%|█▋        | 118/687 [00:00<00:01, 290.53 Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:  22%|██▏       | 148/687 [00:00<00:01, 286.19 Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:  26%|██▌       | 180/687 [00:00<00:01, 294.58 Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:  31%|███       | 210/687 [00:00<00:01, 282.71 Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:  35%|███▍      | 240/687 [00:00<00:01, 286.81 Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:  40%|███▉      | 273/687 [00:00<00:01, 297.09 Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:  44%|████▍     | 303/687 [00:01<00:01, 287.12 Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:  48%|████▊     | 333/687 [00:01<00:01, 288.31 Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:  53%|█████▎    | 362/687 [00:01<00:01, 282.46 Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:  57%|█████▋    | 391/687 [00:01<00:01, 276.50 Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:  61%|██████    | 419/687 [00:01<00:00, 272.19 Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:  65%|██████▌   | 447/687 [00:01<00:00, 263.56 Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:  70%|██████▉   | 480/687 [00:01<00:00, 280.78 Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:  74%|███████▍  | 509/687 [00:01<00:00, 276.92 Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:  78%|███████▊  | 539/687 [00:01<00:00, 281.01 Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:  83%|████████▎ | 570/687 [00:02<00:00, 287.18 Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:  87%|████████▋ | 601/687 [00:02<00:00, 292.02 Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:  92%|█████████▏| 632/687 [00:02<00:00, 294.99 Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:  97%|█████████▋| 663/687 [00:02<00:00, 295.17 Segments/s]\u001B[A\n",
      "Overall Progress:  75%|███████▌  | 70/93 [01:59<00:42,  1.83s/ Computational Sequence Entries]\n",
      "  0%|          | 0/500 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning f9O3YtZ2VfI:   0%|          | 0/500 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning f9O3YtZ2VfI:   6%|▌         | 31/500 [00:00<00:01, 307.26 Segments/s]\u001B[A\n",
      "Aligning f9O3YtZ2VfI:  12%|█▏        | 62/500 [00:00<00:01, 296.51 Segments/s]\u001B[A\n",
      "Aligning f9O3YtZ2VfI:  18%|█▊        | 92/500 [00:00<00:01, 287.30 Segments/s]\u001B[A\n",
      "Aligning f9O3YtZ2VfI:  25%|██▍       | 124/500 [00:00<00:01, 295.76 Segments/s]\u001B[A\n",
      "Aligning f9O3YtZ2VfI:  31%|███▏      | 157/500 [00:00<00:01, 305.32 Segments/s]\u001B[A\n",
      "Aligning f9O3YtZ2VfI:  38%|███▊      | 191/500 [00:00<00:00, 314.44 Segments/s]\u001B[A\n",
      "Aligning f9O3YtZ2VfI:  45%|████▍     | 223/500 [00:00<00:00, 311.77 Segments/s]\u001B[A\n",
      "Aligning f9O3YtZ2VfI:  51%|█████     | 255/500 [00:00<00:00, 305.43 Segments/s]\u001B[A\n",
      "Aligning f9O3YtZ2VfI:  58%|█████▊    | 290/500 [00:00<00:00, 316.27 Segments/s]\u001B[A\n",
      "Aligning f9O3YtZ2VfI:  64%|██████▍   | 322/500 [00:01<00:00, 297.60 Segments/s]\u001B[A\n",
      "Aligning f9O3YtZ2VfI:  70%|███████   | 352/500 [00:01<00:00, 291.98 Segments/s]\u001B[A\n",
      "Aligning f9O3YtZ2VfI:  77%|███████▋  | 383/500 [00:01<00:00, 293.33 Segments/s]\u001B[A\n",
      "Aligning f9O3YtZ2VfI:  83%|████████▎ | 416/500 [00:01<00:00, 303.64 Segments/s]\u001B[A\n",
      "Aligning f9O3YtZ2VfI:  89%|████████▉ | 447/500 [00:01<00:00, 297.21 Segments/s]\u001B[A\n",
      "Aligning f9O3YtZ2VfI:  95%|█████████▌| 477/500 [00:01<00:00, 289.46 Segments/s]\u001B[A\n",
      "Overall Progress:  76%|███████▋  | 71/93 [02:01<00:39,  1.79s/ Computational Sequence Entries]\n",
      "  0%|          | 0/456 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning f_pcplsH_V0:   0%|          | 0/456 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning f_pcplsH_V0:   7%|▋         | 31/456 [00:00<00:01, 307.39 Segments/s]\u001B[A\n",
      "Aligning f_pcplsH_V0:  14%|█▍        | 66/456 [00:00<00:01, 331.71 Segments/s]\u001B[A\n",
      "Aligning f_pcplsH_V0:  22%|██▏       | 100/456 [00:00<00:01, 327.11 Segments/s]\u001B[A\n",
      "Aligning f_pcplsH_V0:  29%|██▉       | 134/456 [00:00<00:00, 329.66 Segments/s]\u001B[A\n",
      "Aligning f_pcplsH_V0:  37%|███▋      | 167/456 [00:00<00:00, 307.55 Segments/s]\u001B[A\n",
      "Aligning f_pcplsH_V0:  43%|████▎     | 198/456 [00:00<00:00, 302.16 Segments/s]\u001B[A\n",
      "Aligning f_pcplsH_V0:  50%|█████     | 229/456 [00:00<00:00, 297.47 Segments/s]\u001B[A\n",
      "Aligning f_pcplsH_V0:  57%|█████▋    | 259/456 [00:00<00:00, 296.37 Segments/s]\u001B[A\n",
      "Aligning f_pcplsH_V0:  64%|██████▍   | 292/456 [00:00<00:00, 305.76 Segments/s]\u001B[A\n",
      "Aligning f_pcplsH_V0:  71%|███████   | 323/456 [00:01<00:00, 284.92 Segments/s]\u001B[A\n",
      "Aligning f_pcplsH_V0:  77%|███████▋  | 352/456 [00:01<00:00, 275.85 Segments/s]\u001B[A\n",
      "Aligning f_pcplsH_V0:  83%|████████▎ | 380/456 [00:01<00:00, 266.42 Segments/s]\u001B[A\n",
      "Aligning f_pcplsH_V0:  90%|█████████ | 412/456 [00:01<00:00, 281.24 Segments/s]\u001B[A\n",
      "Aligning f_pcplsH_V0:  97%|█████████▋| 442/456 [00:01<00:00, 286.28 Segments/s]\u001B[A\n",
      "Overall Progress:  77%|███████▋  | 72/93 [02:02<00:36,  1.72s/ Computational Sequence Entries]\n",
      "  0%|          | 0/642 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:   0%|          | 0/642 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:   4%|▍         | 25/642 [00:00<00:02, 240.03 Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:   8%|▊         | 50/642 [00:00<00:02, 238.25 Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:  12%|█▏        | 74/642 [00:00<00:02, 231.49 Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:  15%|█▌        | 99/642 [00:00<00:02, 237.12 Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:  20%|█▉        | 126/642 [00:00<00:02, 246.74 Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:  24%|██▍       | 156/642 [00:00<00:01, 261.72 Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:  30%|██▉       | 190/642 [00:00<00:01, 285.30 Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:  34%|███▍      | 219/642 [00:00<00:01, 281.10 Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:  39%|███▊      | 248/642 [00:00<00:01, 263.43 Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:  43%|████▎     | 275/642 [00:01<00:01, 254.20 Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:  47%|████▋     | 303/642 [00:01<00:01, 259.14 Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:  51%|█████▏    | 330/642 [00:01<00:01, 260.45 Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:  56%|█████▌    | 357/642 [00:01<00:01, 260.50 Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:  60%|██████    | 388/642 [00:01<00:00, 274.36 Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:  66%|██████▌   | 423/642 [00:01<00:00, 293.46 Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:  71%|███████   | 456/642 [00:01<00:00, 303.71 Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:  76%|███████▌  | 487/642 [00:01<00:00, 300.12 Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:  81%|████████  | 518/642 [00:01<00:00, 298.70 Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:  85%|████████▌ | 548/642 [00:02<00:00, 298.15 Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:  90%|█████████ | 578/642 [00:02<00:00, 294.68 Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:  95%|█████████▌| 610/642 [00:02<00:00, 301.52 Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc: 100%|█████████▉| 641/642 [00:02<00:00, 297.03 Segments/s]\u001B[A\n",
      "Overall Progress:  78%|███████▊  | 73/93 [02:05<00:38,  1.90s/ Computational Sequence Entries]\n",
      "  0%|          | 0/306 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning iiK8YX8oH1E:   0%|          | 0/306 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning iiK8YX8oH1E:  13%|█▎        | 41/306 [00:00<00:00, 398.06 Segments/s]\u001B[A\n",
      "Aligning iiK8YX8oH1E:  26%|██▋       | 81/306 [00:00<00:00, 394.34 Segments/s]\u001B[A\n",
      "Aligning iiK8YX8oH1E:  40%|███▉      | 121/306 [00:00<00:00, 374.87 Segments/s]\u001B[A\n",
      "Aligning iiK8YX8oH1E:  52%|█████▏    | 159/306 [00:00<00:00, 361.10 Segments/s]\u001B[A\n",
      "Aligning iiK8YX8oH1E:  64%|██████▍   | 196/306 [00:00<00:00, 347.78 Segments/s]\u001B[A\n",
      "Aligning iiK8YX8oH1E:  78%|███████▊  | 240/306 [00:00<00:00, 373.20 Segments/s]\u001B[A\n",
      "Aligning iiK8YX8oH1E:  93%|█████████▎| 284/306 [00:00<00:00, 392.50 Segments/s]\u001B[A\n",
      "Overall Progress:  80%|███████▉  | 74/93 [02:06<00:29,  1.58s/ Computational Sequence Entries]\n",
      "  0%|          | 0/638 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:   0%|          | 0/638 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:   5%|▍         | 30/638 [00:00<00:02, 299.84 Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:   9%|▉         | 60/638 [00:00<00:01, 294.11 Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:  14%|█▍        | 90/638 [00:00<00:01, 293.74 Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:  19%|█▉        | 120/638 [00:00<00:01, 292.52 Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:  24%|██▎       | 151/638 [00:00<00:01, 296.07 Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:  28%|██▊       | 181/638 [00:00<00:01, 296.78 Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:  34%|███▎      | 214/638 [00:00<00:01, 304.88 Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:  38%|███▊      | 245/638 [00:00<00:01, 304.40 Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:  44%|████▎     | 278/638 [00:00<00:01, 310.50 Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:  49%|████▊     | 310/638 [00:01<00:01, 306.63 Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:  53%|█████▎    | 341/638 [00:01<00:01, 288.03 Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:  58%|█████▊    | 372/638 [00:01<00:00, 294.00 Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:  63%|██████▎   | 402/638 [00:01<00:00, 270.07 Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:  67%|██████▋   | 430/638 [00:01<00:00, 271.33 Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:  72%|███████▏  | 462/638 [00:01<00:00, 283.94 Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:  77%|███████▋  | 494/638 [00:01<00:00, 293.36 Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:  82%|████████▏ | 524/638 [00:01<00:00, 295.23 Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:  87%|████████▋ | 554/638 [00:01<00:00, 292.14 Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:  92%|█████████▏| 584/638 [00:01<00:00, 289.15 Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:  96%|█████████▋| 615/638 [00:02<00:00, 294.94 Segments/s]\u001B[A\n",
      "Overall Progress:  81%|████████  | 75/93 [02:08<00:31,  1.76s/ Computational Sequence Entries]\n",
      "  0%|          | 0/623 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:   0%|          | 0/623 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:   5%|▍         | 30/623 [00:00<00:01, 299.23 Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:  10%|▉         | 60/623 [00:00<00:01, 282.90 Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:  14%|█▍        | 90/623 [00:00<00:01, 287.53 Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:  20%|█▉        | 122/623 [00:00<00:01, 299.20 Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:  25%|██▍       | 155/623 [00:00<00:01, 309.08 Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:  30%|███       | 189/623 [00:00<00:01, 316.02 Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:  35%|███▌      | 221/623 [00:00<00:01, 306.28 Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:  40%|████      | 252/623 [00:00<00:01, 303.38 Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:  45%|████▌     | 283/623 [00:00<00:01, 303.00 Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:  50%|█████     | 314/623 [00:01<00:01, 294.16 Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:  55%|█████▌    | 344/623 [00:01<00:00, 292.03 Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:  60%|██████    | 374/623 [00:01<00:00, 288.07 Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:  66%|██████▌   | 409/623 [00:01<00:00, 303.37 Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:  71%|███████   | 440/623 [00:01<00:00, 281.08 Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:  76%|███████▌  | 471/623 [00:01<00:00, 288.96 Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:  81%|████████  | 506/623 [00:01<00:00, 305.27 Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:  86%|████████▌ | 537/623 [00:01<00:00, 305.65 Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:  91%|█████████ | 568/623 [00:01<00:00, 304.86 Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:  96%|█████████▌| 599/623 [00:02<00:00, 292.37 Segments/s]\u001B[A\n",
      "Overall Progress:  82%|████████▏ | 76/93 [02:10<00:31,  1.86s/ Computational Sequence Entries]\n",
      "  0%|          | 0/655 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:   0%|          | 0/655 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:   5%|▌         | 33/655 [00:00<00:01, 329.23 Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:  10%|█         | 67/655 [00:00<00:01, 333.71 Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:  15%|█▌        | 101/655 [00:00<00:01, 326.50 Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:  20%|██        | 134/655 [00:00<00:01, 305.43 Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:  26%|██▌       | 170/655 [00:00<00:01, 322.58 Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:  31%|███       | 204/655 [00:00<00:01, 327.80 Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:  36%|███▌      | 237/655 [00:00<00:01, 325.86 Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:  41%|████      | 270/655 [00:00<00:01, 313.10 Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:  46%|████▋     | 303/655 [00:00<00:01, 316.14 Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:  51%|█████     | 335/655 [00:01<00:01, 312.77 Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:  56%|█████▌    | 367/655 [00:01<00:00, 289.46 Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:  61%|██████    | 398/655 [00:01<00:00, 294.52 Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:  66%|██████▌   | 433/655 [00:01<00:00, 309.65 Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:  71%|███████▏  | 468/655 [00:01<00:00, 319.24 Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:  76%|███████▋  | 501/655 [00:01<00:00, 307.00 Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:  81%|████████▏ | 533/655 [00:01<00:00, 308.37 Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:  87%|████████▋ | 567/655 [00:01<00:00, 315.84 Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:  92%|█████████▏| 602/655 [00:01<00:00, 325.34 Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:  97%|█████████▋| 637/655 [00:02<00:00, 329.59 Segments/s]\u001B[A\n",
      "Overall Progress:  83%|████████▎ | 77/93 [02:12<00:30,  1.93s/ Computational Sequence Entries]\n",
      "  0%|          | 0/593 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0:   0%|          | 0/593 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0:   5%|▍         | 27/593 [00:00<00:02, 268.31 Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0:   9%|▉         | 54/593 [00:00<00:02, 252.31 Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0:  15%|█▍        | 86/593 [00:00<00:01, 281.50 Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0:  19%|█▉        | 115/593 [00:00<00:01, 267.03 Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0:  25%|██▌       | 150/593 [00:00<00:01, 292.48 Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0:  31%|███       | 184/593 [00:00<00:01, 304.57 Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0:  37%|███▋      | 217/593 [00:00<00:01, 312.52 Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0:  42%|████▏     | 251/593 [00:00<00:01, 318.66 Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0:  48%|████▊     | 284/593 [00:00<00:00, 319.74 Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0:  53%|█████▎    | 317/593 [00:01<00:00, 299.96 Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0:  59%|█████▊    | 348/593 [00:01<00:00, 288.48 Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0:  64%|██████▍   | 379/593 [00:01<00:00, 292.42 Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0:  69%|██████▉   | 409/593 [00:01<00:00, 293.58 Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0:  74%|███████▍  | 441/593 [00:01<00:00, 300.40 Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0:  80%|███████▉  | 474/593 [00:01<00:00, 307.07 Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0:  85%|████████▌ | 505/593 [00:01<00:00, 286.48 Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0:  90%|█████████ | 534/593 [00:01<00:00, 285.65 Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0:  95%|█████████▍| 563/593 [00:01<00:00, 277.98 Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0: 100%|█████████▉| 592/593 [00:02<00:00, 281.22 Segments/s]\u001B[A\n",
      "Overall Progress:  84%|████████▍ | 78/93 [02:14<00:29,  1.96s/ Computational Sequence Entries]\n",
      "  0%|          | 0/574 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning nzpVDcQ0ywM:   0%|          | 0/574 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning nzpVDcQ0ywM:   3%|▎         | 20/574 [00:00<00:02, 195.75 Segments/s]\u001B[A\n",
      "Aligning nzpVDcQ0ywM:   9%|▊         | 49/574 [00:00<00:02, 250.67 Segments/s]\u001B[A\n",
      "Aligning nzpVDcQ0ywM:  14%|█▍        | 79/574 [00:00<00:01, 271.58 Segments/s]\u001B[A\n",
      "Aligning nzpVDcQ0ywM:  19%|█▊        | 107/574 [00:00<00:01, 272.11 Segments/s]\u001B[A\n",
      "Aligning nzpVDcQ0ywM:  25%|██▌       | 144/574 [00:00<00:01, 305.99 Segments/s]\u001B[A\n",
      "Aligning nzpVDcQ0ywM:  31%|███       | 178/574 [00:00<00:01, 316.13 Segments/s]\u001B[A\n",
      "Aligning nzpVDcQ0ywM:  37%|███▋      | 210/574 [00:00<00:01, 317.12 Segments/s]\u001B[A\n",
      "Aligning nzpVDcQ0ywM:  42%|████▏     | 242/574 [00:00<00:01, 315.04 Segments/s]\u001B[A\n",
      "Aligning nzpVDcQ0ywM:  48%|████▊     | 274/574 [00:00<00:00, 302.91 Segments/s]\u001B[A\n",
      "Aligning nzpVDcQ0ywM:  53%|█████▎    | 305/574 [00:01<00:00, 297.88 Segments/s]\u001B[A\n",
      "Aligning nzpVDcQ0ywM:  58%|█████▊    | 335/574 [00:01<00:00, 281.15 Segments/s]\u001B[A\n",
      "Aligning nzpVDcQ0ywM:  63%|██████▎   | 364/574 [00:01<00:00, 281.75 Segments/s]\u001B[A\n",
      "Aligning nzpVDcQ0ywM:  68%|██████▊   | 393/574 [00:01<00:00, 284.07 Segments/s]\u001B[A\n",
      "Aligning nzpVDcQ0ywM:  74%|███████▎  | 422/574 [00:01<00:00, 283.99 Segments/s]\u001B[A\n",
      "Aligning nzpVDcQ0ywM:  79%|███████▉  | 455/574 [00:01<00:00, 295.47 Segments/s]\u001B[A\n",
      "Aligning nzpVDcQ0ywM:  84%|████████▍ | 485/574 [00:01<00:00, 291.66 Segments/s]\u001B[A\n",
      "Aligning nzpVDcQ0ywM:  91%|█████████ | 521/574 [00:01<00:00, 311.49 Segments/s]\u001B[A\n",
      "Aligning nzpVDcQ0ywM:  97%|█████████▋| 554/574 [00:01<00:00, 316.57 Segments/s]\u001B[A\n",
      "Overall Progress:  85%|████████▍ | 79/93 [02:16<00:27,  1.96s/ Computational Sequence Entries]\n",
      "  0%|          | 0/413 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning ob23OKe5a9Q:   0%|          | 0/413 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning ob23OKe5a9Q:   7%|▋         | 30/413 [00:00<00:01, 296.42 Segments/s]\u001B[A\n",
      "Aligning ob23OKe5a9Q:  15%|█▍        | 60/413 [00:00<00:01, 270.56 Segments/s]\u001B[A\n",
      "Aligning ob23OKe5a9Q:  22%|██▏       | 89/413 [00:00<00:01, 274.77 Segments/s]\u001B[A\n",
      "Aligning ob23OKe5a9Q:  29%|██▊       | 118/413 [00:00<00:01, 276.77 Segments/s]\u001B[A\n",
      "Aligning ob23OKe5a9Q:  36%|███▋      | 150/413 [00:00<00:00, 290.21 Segments/s]\u001B[A\n",
      "Aligning ob23OKe5a9Q:  44%|████▎     | 180/413 [00:00<00:00, 281.87 Segments/s]\u001B[A\n",
      "Aligning ob23OKe5a9Q:  51%|█████     | 209/413 [00:00<00:00, 277.70 Segments/s]\u001B[A\n",
      "Aligning ob23OKe5a9Q:  58%|█████▊    | 241/413 [00:00<00:00, 290.50 Segments/s]\u001B[A\n",
      "Aligning ob23OKe5a9Q:  66%|██████▌   | 271/413 [00:00<00:00, 292.38 Segments/s]\u001B[A\n",
      "Aligning ob23OKe5a9Q:  73%|███████▎  | 301/413 [00:01<00:00, 282.52 Segments/s]\u001B[A\n",
      "Aligning ob23OKe5a9Q:  81%|████████  | 334/413 [00:01<00:00, 295.21 Segments/s]\u001B[A\n",
      "Aligning ob23OKe5a9Q:  89%|████████▉ | 369/413 [00:01<00:00, 310.38 Segments/s]\u001B[A\n",
      "Aligning ob23OKe5a9Q:  97%|█████████▋| 401/413 [00:01<00:00, 311.64 Segments/s]\u001B[A\n",
      "Overall Progress:  86%|████████▌ | 80/93 [02:17<00:23,  1.80s/ Computational Sequence Entries]\n",
      "  0%|          | 0/489 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning pLTX3ipuDJI:   0%|          | 0/489 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning pLTX3ipuDJI:   7%|▋         | 35/489 [00:00<00:01, 344.43 Segments/s]\u001B[A\n",
      "Aligning pLTX3ipuDJI:  15%|█▍        | 72/489 [00:00<00:01, 354.42 Segments/s]\u001B[A\n",
      "Aligning pLTX3ipuDJI:  22%|██▏       | 110/489 [00:00<00:01, 359.42 Segments/s]\u001B[A\n",
      "Aligning pLTX3ipuDJI:  30%|██▉       | 146/489 [00:00<00:01, 338.66 Segments/s]\u001B[A\n",
      "Aligning pLTX3ipuDJI:  37%|███▋      | 181/489 [00:00<00:00, 330.65 Segments/s]\u001B[A\n",
      "Aligning pLTX3ipuDJI:  44%|████▍     | 215/489 [00:00<00:00, 325.95 Segments/s]\u001B[A\n",
      "Aligning pLTX3ipuDJI:  51%|█████     | 248/489 [00:00<00:00, 316.96 Segments/s]\u001B[A\n",
      "Aligning pLTX3ipuDJI:  57%|█████▋    | 280/489 [00:00<00:00, 305.97 Segments/s]\u001B[A\n",
      "Aligning pLTX3ipuDJI:  64%|██████▎   | 311/489 [00:00<00:00, 300.29 Segments/s]\u001B[A\n",
      "Aligning pLTX3ipuDJI:  70%|███████   | 344/489 [00:01<00:00, 308.21 Segments/s]\u001B[A\n",
      "Aligning pLTX3ipuDJI:  78%|███████▊  | 380/489 [00:01<00:00, 321.15 Segments/s]\u001B[A\n",
      "Aligning pLTX3ipuDJI:  84%|████████▍ | 413/489 [00:01<00:00, 319.28 Segments/s]\u001B[A\n",
      "Aligning pLTX3ipuDJI:  91%|█████████ | 445/489 [00:01<00:00, 316.72 Segments/s]\u001B[A\n",
      "Aligning pLTX3ipuDJI:  98%|█████████▊| 478/489 [00:01<00:00, 318.99 Segments/s]\u001B[A\n",
      "Overall Progress:  87%|████████▋ | 81/93 [02:19<00:20,  1.72s/ Computational Sequence Entries]\n",
      "  0%|          | 0/720 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:   0%|          | 0/720 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:   4%|▍         | 27/720 [00:00<00:02, 269.63 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:   8%|▊         | 54/720 [00:00<00:03, 207.44 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  12%|█▏        | 84/720 [00:00<00:02, 242.22 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  17%|█▋        | 119/720 [00:00<00:02, 280.68 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  21%|██        | 149/720 [00:00<00:02, 269.71 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  25%|██▍       | 177/720 [00:00<00:02, 259.65 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  28%|██▊       | 204/720 [00:00<00:02, 252.20 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  32%|███▏      | 232/720 [00:00<00:01, 260.02 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  36%|███▌      | 259/720 [00:01<00:01, 262.35 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  41%|████      | 292/720 [00:01<00:01, 280.96 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  45%|████▌     | 326/720 [00:01<00:01, 296.92 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  49%|████▉     | 356/720 [00:01<00:01, 296.74 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  54%|█████▎    | 386/720 [00:01<00:01, 284.39 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  58%|█████▊    | 415/720 [00:01<00:01, 283.91 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  62%|██████▏   | 444/720 [00:01<00:00, 277.55 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  66%|██████▌   | 472/720 [00:01<00:00, 278.13 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  69%|██████▉   | 500/720 [00:01<00:00, 278.21 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  73%|███████▎  | 528/720 [00:01<00:00, 265.69 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  77%|███████▋  | 555/720 [00:02<00:00, 256.99 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  81%|████████  | 581/720 [00:02<00:00, 250.97 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  84%|████████▍ | 607/720 [00:02<00:00, 253.07 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  88%|████████▊ | 637/720 [00:02<00:00, 264.10 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  93%|█████████▎| 668/720 [00:02<00:00, 274.84 Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:  97%|█████████▋| 697/720 [00:02<00:00, 277.03 Segments/s]\u001B[A\n",
      "Overall Progress:  88%|████████▊ | 82/93 [02:22<00:22,  2.01s/ Computational Sequence Entries]\n",
      "  0%|          | 0/701 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:   0%|          | 0/701 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:   4%|▎         | 26/701 [00:00<00:02, 259.73 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:   8%|▊         | 57/701 [00:00<00:02, 285.19 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:  12%|█▏        | 86/701 [00:00<00:02, 258.91 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:  16%|█▌        | 113/701 [00:00<00:02, 260.00 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:  21%|██        | 144/701 [00:00<00:02, 275.38 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:  25%|██▌       | 176/701 [00:00<00:01, 289.96 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:  29%|██▉       | 206/701 [00:00<00:01, 277.02 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:  34%|███▎      | 236/701 [00:00<00:01, 282.79 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:  38%|███▊      | 267/701 [00:00<00:01, 289.33 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:  42%|████▏     | 297/701 [00:01<00:01, 284.83 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:  47%|████▋     | 327/701 [00:01<00:01, 287.33 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:  51%|█████     | 356/701 [00:01<00:01, 286.21 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:  55%|█████▍    | 385/701 [00:01<00:01, 280.77 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:  60%|██████    | 421/701 [00:01<00:00, 300.74 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:  64%|██████▍   | 452/701 [00:01<00:00, 286.56 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:  69%|██████▊   | 481/701 [00:01<00:00, 273.38 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:  73%|███████▎  | 512/701 [00:01<00:00, 282.94 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:  77%|███████▋  | 541/701 [00:01<00:00, 272.90 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:  81%|████████  | 569/701 [00:02<00:00, 271.28 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:  85%|████████▌ | 597/701 [00:02<00:00, 273.11 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:  89%|████████▉ | 627/701 [00:02<00:00, 279.90 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:  94%|█████████▎| 657/701 [00:02<00:00, 283.57 Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:  98%|█████████▊| 688/701 [00:02<00:00, 291.28 Segments/s]\u001B[A\n",
      "Overall Progress:  89%|████████▉ | 83/93 [02:24<00:21,  2.16s/ Computational Sequence Entries]\n",
      "  0%|          | 0/589 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning tIrG4oNLFzE:   0%|          | 0/589 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning tIrG4oNLFzE:   5%|▌         | 30/589 [00:00<00:01, 296.59 Segments/s]\u001B[A\n",
      "Aligning tIrG4oNLFzE:  10%|█         | 60/589 [00:00<00:01, 298.36 Segments/s]\u001B[A\n",
      "Aligning tIrG4oNLFzE:  16%|█▌        | 92/589 [00:00<00:01, 302.35 Segments/s]\u001B[A\n",
      "Aligning tIrG4oNLFzE:  21%|██▏       | 126/589 [00:00<00:01, 316.30 Segments/s]\u001B[A\n",
      "Aligning tIrG4oNLFzE:  27%|██▋       | 158/589 [00:00<00:01, 309.46 Segments/s]\u001B[A\n",
      "Aligning tIrG4oNLFzE:  32%|███▏      | 189/589 [00:00<00:01, 308.70 Segments/s]\u001B[A\n",
      "Aligning tIrG4oNLFzE:  37%|███▋      | 220/589 [00:00<00:01, 299.04 Segments/s]\u001B[A\n",
      "Aligning tIrG4oNLFzE:  43%|████▎     | 252/589 [00:00<00:01, 301.92 Segments/s]\u001B[A\n",
      "Aligning tIrG4oNLFzE:  48%|████▊     | 283/589 [00:00<00:01, 274.34 Segments/s]\u001B[A\n",
      "Aligning tIrG4oNLFzE:  53%|█████▎    | 313/589 [00:01<00:00, 280.44 Segments/s]\u001B[A\n",
      "Aligning tIrG4oNLFzE:  59%|█████▊    | 346/589 [00:01<00:00, 292.57 Segments/s]\u001B[A\n",
      "Aligning tIrG4oNLFzE:  64%|██████▍   | 376/589 [00:01<00:00, 290.69 Segments/s]\u001B[A\n",
      "Aligning tIrG4oNLFzE:  69%|██████▉   | 406/589 [00:01<00:00, 287.95 Segments/s]\u001B[A\n",
      "Aligning tIrG4oNLFzE:  74%|███████▍  | 438/589 [00:01<00:00, 294.66 Segments/s]\u001B[A\n",
      "Aligning tIrG4oNLFzE:  79%|███████▉  | 468/589 [00:01<00:00, 283.96 Segments/s]\u001B[A\n",
      "Aligning tIrG4oNLFzE:  84%|████████▍ | 497/589 [00:01<00:00, 274.91 Segments/s]\u001B[A\n",
      "Aligning tIrG4oNLFzE:  90%|████████▉ | 529/589 [00:01<00:00, 286.90 Segments/s]\u001B[A\n",
      "Aligning tIrG4oNLFzE:  96%|█████████▌| 564/589 [00:01<00:00, 303.21 Segments/s]\u001B[A\n",
      "Overall Progress:  90%|█████████ | 84/93 [02:26<00:19,  2.11s/ Computational Sequence Entries]\n",
      "  0%|          | 0/429 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning tStelxIAHjw:   0%|          | 0/429 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning tStelxIAHjw:   8%|▊         | 35/429 [00:00<00:01, 349.25 Segments/s]\u001B[A\n",
      "Aligning tStelxIAHjw:  16%|█▋        | 70/429 [00:00<00:01, 325.35 Segments/s]\u001B[A\n",
      "Aligning tStelxIAHjw:  25%|██▍       | 106/429 [00:00<00:00, 338.54 Segments/s]\u001B[A\n",
      "Aligning tStelxIAHjw:  33%|███▎      | 141/429 [00:00<00:00, 342.46 Segments/s]\u001B[A\n",
      "Aligning tStelxIAHjw:  41%|████      | 176/429 [00:00<00:00, 319.55 Segments/s]\u001B[A\n",
      "Aligning tStelxIAHjw:  49%|████▊     | 209/429 [00:00<00:00, 316.17 Segments/s]\u001B[A\n",
      "Aligning tStelxIAHjw:  56%|█████▌    | 241/429 [00:00<00:00, 314.75 Segments/s]\u001B[A\n",
      "Aligning tStelxIAHjw:  64%|██████▎   | 273/429 [00:00<00:00, 302.61 Segments/s]\u001B[A\n",
      "Aligning tStelxIAHjw:  72%|███████▏  | 307/429 [00:00<00:00, 311.38 Segments/s]\u001B[A\n",
      "Aligning tStelxIAHjw:  81%|████████  | 346/429 [00:01<00:00, 334.15 Segments/s]\u001B[A\n",
      "Aligning tStelxIAHjw:  89%|████████▉ | 381/429 [00:01<00:00, 338.16 Segments/s]\u001B[A\n",
      "Aligning tStelxIAHjw:  97%|█████████▋| 416/429 [00:01<00:00, 340.01 Segments/s]\u001B[A\n",
      "Overall Progress:  91%|█████████▏| 85/93 [02:27<00:15,  1.88s/ Computational Sequence Entries]\n",
      "  0%|          | 0/376 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning tmZoasNr4rU:   0%|          | 0/376 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning tmZoasNr4rU:   8%|▊         | 31/376 [00:00<00:01, 302.25 Segments/s]\u001B[A\n",
      "Aligning tmZoasNr4rU:  16%|█▋        | 62/376 [00:00<00:01, 295.43 Segments/s]\u001B[A\n",
      "Aligning tmZoasNr4rU:  24%|██▍       | 92/376 [00:00<00:00, 290.72 Segments/s]\u001B[A\n",
      "Aligning tmZoasNr4rU:  32%|███▏      | 122/376 [00:00<00:00, 288.98 Segments/s]\u001B[A\n",
      "Aligning tmZoasNr4rU:  40%|████      | 151/376 [00:00<00:00, 257.07 Segments/s]\u001B[A\n",
      "Aligning tmZoasNr4rU:  48%|████▊     | 179/376 [00:00<00:00, 263.65 Segments/s]\u001B[A\n",
      "Aligning tmZoasNr4rU:  57%|█████▋    | 213/376 [00:00<00:00, 286.61 Segments/s]\u001B[A\n",
      "Aligning tmZoasNr4rU:  65%|██████▌   | 246/376 [00:00<00:00, 298.59 Segments/s]\u001B[A\n",
      "Aligning tmZoasNr4rU:  74%|███████▎  | 277/376 [00:00<00:00, 285.06 Segments/s]\u001B[A\n",
      "Aligning tmZoasNr4rU:  81%|████████▏ | 306/376 [00:01<00:00, 285.88 Segments/s]\u001B[A\n",
      "Aligning tmZoasNr4rU:  89%|████████▉ | 335/376 [00:01<00:00, 277.98 Segments/s]\u001B[A\n",
      "Aligning tmZoasNr4rU:  97%|█████████▋| 363/376 [00:01<00:00, 275.64 Segments/s]\u001B[A\n",
      "Overall Progress:  92%|█████████▏| 86/93 [02:29<00:12,  1.72s/ Computational Sequence Entries]\n",
      "  0%|          | 0/470 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning v0zCBqDeKcE:   0%|          | 0/470 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning v0zCBqDeKcE:   7%|▋         | 35/470 [00:00<00:01, 346.87 Segments/s]\u001B[A\n",
      "Aligning v0zCBqDeKcE:  15%|█▍        | 70/470 [00:00<00:01, 310.26 Segments/s]\u001B[A\n",
      "Aligning v0zCBqDeKcE:  22%|██▏       | 102/470 [00:00<00:01, 304.95 Segments/s]\u001B[A\n",
      "Aligning v0zCBqDeKcE:  28%|██▊       | 133/470 [00:00<00:01, 284.00 Segments/s]\u001B[A\n",
      "Aligning v0zCBqDeKcE:  36%|███▌      | 168/470 [00:00<00:00, 305.02 Segments/s]\u001B[A\n",
      "Aligning v0zCBqDeKcE:  42%|████▏     | 199/470 [00:00<00:00, 299.95 Segments/s]\u001B[A\n",
      "Aligning v0zCBqDeKcE:  49%|████▉     | 232/470 [00:00<00:00, 305.09 Segments/s]\u001B[A\n",
      "Aligning v0zCBqDeKcE:  56%|█████▌    | 263/470 [00:00<00:00, 306.07 Segments/s]\u001B[A\n",
      "Aligning v0zCBqDeKcE:  63%|██████▎   | 294/470 [00:00<00:00, 294.65 Segments/s]\u001B[A\n",
      "Aligning v0zCBqDeKcE:  69%|██████▉   | 324/470 [00:01<00:00, 294.22 Segments/s]\u001B[A\n",
      "Aligning v0zCBqDeKcE:  76%|███████▌  | 358/470 [00:01<00:00, 305.74 Segments/s]\u001B[A\n",
      "Aligning v0zCBqDeKcE:  83%|████████▎ | 391/470 [00:01<00:00, 310.93 Segments/s]\u001B[A\n",
      "Aligning v0zCBqDeKcE:  90%|█████████ | 423/470 [00:01<00:00, 310.61 Segments/s]\u001B[A\n",
      "Aligning v0zCBqDeKcE:  97%|█████████▋| 456/470 [00:01<00:00, 314.13 Segments/s]\u001B[A\n",
      "Overall Progress:  94%|█████████▎| 87/93 [02:30<00:09,  1.67s/ Computational Sequence Entries]\n",
      "  0%|          | 0/610 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:   0%|          | 0/610 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:   5%|▌         | 32/610 [00:00<00:01, 311.49 Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:  10%|█         | 64/610 [00:00<00:01, 289.55 Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:  15%|█▌        | 94/610 [00:00<00:01, 293.62 Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:  20%|██        | 125/610 [00:00<00:01, 299.15 Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:  25%|██▌       | 155/610 [00:00<00:01, 297.97 Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:  30%|███       | 185/610 [00:00<00:01, 288.54 Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:  35%|███▌      | 216/610 [00:00<00:01, 294.21 Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:  40%|████      | 247/610 [00:00<00:01, 299.06 Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:  46%|████▌     | 282/610 [00:00<00:01, 313.20 Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:  51%|█████▏    | 314/610 [00:01<00:00, 304.33 Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:  57%|█████▋    | 345/610 [00:01<00:00, 293.11 Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:  61%|██████▏   | 375/610 [00:01<00:00, 277.50 Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:  66%|██████▌   | 403/610 [00:01<00:00, 266.01 Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:  70%|███████   | 430/610 [00:01<00:00, 257.19 Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:  75%|███████▍  | 456/610 [00:01<00:00, 256.61 Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:  80%|███████▉  | 486/610 [00:01<00:00, 267.43 Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:  84%|████████▍ | 513/610 [00:01<00:00, 265.93 Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:  89%|████████▊ | 541/610 [00:01<00:00, 269.93 Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:  94%|█████████▍| 572/610 [00:02<00:00, 279.34 Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:  98%|█████████▊| 600/610 [00:02<00:00, 279.15 Segments/s]\u001B[A\n",
      "Overall Progress:  95%|█████████▍| 88/93 [02:33<00:09,  1.82s/ Computational Sequence Entries]\n",
      "  0%|          | 0/589 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:   0%|          | 0/589 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:   5%|▌         | 31/589 [00:00<00:01, 305.27 Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:  11%|█         | 63/589 [00:00<00:01, 313.76 Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:  16%|█▋        | 97/589 [00:00<00:01, 318.94 Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:  22%|██▏       | 129/589 [00:00<00:01, 292.94 Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:  27%|██▋       | 159/589 [00:00<00:01, 276.90 Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:  32%|███▏      | 190/589 [00:00<00:01, 285.22 Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:  38%|███▊      | 221/589 [00:00<00:01, 290.90 Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:  43%|████▎     | 254/589 [00:00<00:01, 301.05 Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:  48%|████▊     | 285/589 [00:00<00:01, 296.78 Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:  53%|█████▎    | 315/589 [00:01<00:00, 286.32 Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:  59%|█████▊    | 345/589 [00:01<00:00, 290.00 Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:  64%|██████▍   | 377/589 [00:01<00:00, 297.80 Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:  69%|██████▉   | 407/589 [00:01<00:00, 288.93 Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:  74%|███████▍  | 437/589 [00:01<00:00, 281.48 Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:  79%|███████▉  | 466/589 [00:01<00:00, 266.48 Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:  84%|████████▎ | 493/589 [00:01<00:00, 257.81 Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:  88%|████████▊ | 520/589 [00:01<00:00, 259.64 Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:  93%|█████████▎| 547/589 [00:01<00:00, 252.46 Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:  97%|█████████▋| 573/589 [00:02<00:00, 251.53 Segments/s]\u001B[A\n",
      "Overall Progress:  96%|█████████▌| 89/93 [02:35<00:07,  1.91s/ Computational Sequence Entries]\n",
      "  0%|          | 0/690 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:   0%|          | 0/690 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:   4%|▍         | 31/690 [00:00<00:02, 302.47 Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:   9%|▉         | 62/690 [00:00<00:02, 287.86 Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:  13%|█▎        | 93/690 [00:00<00:02, 293.83 Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:  18%|█▊        | 123/690 [00:00<00:01, 285.88 Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:  22%|██▏       | 153/690 [00:00<00:01, 289.21 Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:  26%|██▋       | 182/690 [00:00<00:01, 286.57 Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:  31%|███▏      | 217/690 [00:00<00:01, 303.28 Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:  36%|███▌      | 248/690 [00:00<00:01, 303.55 Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:  40%|████      | 279/690 [00:00<00:01, 295.90 Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:  45%|████▍     | 309/690 [00:01<00:01, 287.17 Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:  49%|████▉     | 338/690 [00:01<00:01, 286.66 Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:  53%|█████▎    | 367/690 [00:01<00:01, 284.22 Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:  57%|█████▋    | 396/690 [00:01<00:01, 279.48 Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:  62%|██████▏   | 430/690 [00:01<00:00, 295.08 Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:  67%|██████▋   | 462/690 [00:01<00:00, 299.97 Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:  71%|███████▏  | 493/690 [00:01<00:00, 302.63 Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:  76%|███████▌  | 524/690 [00:01<00:00, 292.46 Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:  80%|████████  | 554/690 [00:01<00:00, 287.83 Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:  84%|████████▍ | 583/690 [00:02<00:00, 281.24 Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:  89%|████████▊ | 612/690 [00:02<00:00, 280.60 Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:  93%|█████████▎| 641/690 [00:02<00:00, 282.91 Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:  97%|█████████▋| 670/690 [00:02<00:00, 281.06 Segments/s]\u001B[A\n",
      "Overall Progress:  97%|█████████▋| 90/93 [02:37<00:06,  2.06s/ Computational Sequence Entries]\n",
      "  0%|          | 0/581 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:   0%|          | 0/581 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:   4%|▍         | 23/581 [00:00<00:02, 221.94 Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:   8%|▊         | 48/581 [00:00<00:02, 236.17 Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:  13%|█▎        | 78/581 [00:00<00:01, 263.78 Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:  18%|█▊        | 107/581 [00:00<00:01, 272.19 Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:  23%|██▎       | 135/581 [00:00<00:01, 252.66 Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:  28%|██▊       | 161/581 [00:00<00:01, 251.56 Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:  33%|███▎      | 191/581 [00:00<00:01, 266.01 Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:  38%|███▊      | 221/581 [00:00<00:01, 276.21 Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:  43%|████▎     | 249/581 [00:00<00:01, 276.26 Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:  48%|████▊     | 277/581 [00:01<00:01, 273.17 Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:  52%|█████▏    | 305/581 [00:01<00:01, 271.42 Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:  57%|█████▋    | 333/581 [00:01<00:00, 267.74 Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:  63%|██████▎   | 365/581 [00:01<00:00, 281.49 Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:  68%|██████▊   | 394/581 [00:01<00:00, 271.51 Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:  73%|███████▎  | 422/581 [00:01<00:00, 271.95 Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:  78%|███████▊  | 454/581 [00:01<00:00, 285.08 Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:  83%|████████▎ | 483/581 [00:01<00:00, 283.15 Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:  88%|████████▊ | 512/581 [00:01<00:00, 275.32 Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:  93%|█████████▎| 541/581 [00:01<00:00, 278.55 Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:  98%|█████████▊| 571/581 [00:02<00:00, 283.90 Segments/s]\u001B[A\n",
      "Overall Progress:  98%|█████████▊| 91/93 [02:39<00:04,  2.08s/ Computational Sequence Entries]\n",
      "  0%|          | 0/616 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:   0%|          | 0/616 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:   5%|▍         | 29/616 [00:00<00:02, 288.90 Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:  10%|▉         | 59/616 [00:00<00:01, 291.62 Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:  14%|█▍        | 89/616 [00:00<00:01, 285.92 Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:  20%|█▉        | 121/616 [00:00<00:01, 295.99 Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:  25%|██▍       | 151/616 [00:00<00:01, 290.57 Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:  30%|██▉       | 183/616 [00:00<00:01, 296.73 Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:  35%|███▍      | 214/616 [00:00<00:01, 298.89 Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:  40%|███▉      | 244/616 [00:00<00:01, 293.79 Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:  45%|████▍     | 275/616 [00:00<00:01, 296.94 Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:  50%|████▉     | 306/616 [00:01<00:01, 299.73 Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:  55%|█████▌    | 341/616 [00:01<00:00, 312.05 Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:  61%|██████    | 376/616 [00:01<00:00, 321.40 Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:  66%|██████▋   | 409/616 [00:01<00:00, 320.86 Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:  72%|███████▏  | 444/616 [00:01<00:00, 329.35 Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:  77%|███████▋  | 477/616 [00:01<00:00, 318.22 Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:  83%|████████▎ | 509/616 [00:01<00:00, 317.10 Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:  88%|████████▊ | 541/616 [00:01<00:00, 309.15 Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:  93%|█████████▎| 572/616 [00:01<00:00, 302.39 Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:  98%|█████████▊| 605/616 [00:01<00:00, 309.85 Segments/s]\u001B[A\n",
      "Overall Progress:  99%|█████████▉| 92/93 [02:41<00:02,  2.07s/ Computational Sequence Entries]\n",
      "  0%|          | 0/676 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:   0%|          | 0/676 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:   5%|▍         | 33/676 [00:00<00:01, 328.10 Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:  10%|▉         | 66/676 [00:00<00:01, 311.56 Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:  14%|█▍        | 98/676 [00:00<00:02, 267.68 Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:  19%|█▊        | 126/676 [00:00<00:02, 262.09 Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:  23%|██▎       | 155/676 [00:00<00:01, 270.30 Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:  27%|██▋       | 183/676 [00:00<00:01, 268.13 Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:  32%|███▏      | 213/676 [00:00<00:01, 277.30 Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:  36%|███▌      | 241/676 [00:00<00:01, 274.11 Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:  40%|████      | 272/676 [00:00<00:01, 284.81 Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:  45%|████▍     | 301/676 [00:01<00:01, 263.27 Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:  49%|████▊     | 328/676 [00:01<00:01, 259.33 Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:  53%|█████▎    | 359/676 [00:01<00:01, 270.94 Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:  58%|█████▊    | 391/676 [00:01<00:01, 284.15 Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:  62%|██████▏   | 420/676 [00:01<00:00, 272.29 Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:  67%|██████▋   | 450/676 [00:01<00:00, 279.11 Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:  71%|███████   | 479/676 [00:01<00:00, 269.41 Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:  76%|███████▌  | 513/676 [00:01<00:00, 285.51 Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:  80%|████████  | 542/676 [00:01<00:00, 278.58 Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:  85%|████████▍ | 574/676 [00:02<00:00, 287.71 Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:  89%|████████▉ | 603/676 [00:02<00:00, 284.73 Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:  94%|█████████▎| 633/676 [00:02<00:00, 286.09 Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:  98%|█████████▊| 663/676 [00:02<00:00, 288.40 Segments/s]\u001B[A\n",
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-02 19:13:01.776] | Success | \u001B[0mAlignment to <CMU_MOSI_TimestampedWords> complete.\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:01.776] | Status  | \u001B[0mReplacing dataset content with aligned computational sequences\n",
      "\u001B[92m\u001B[1m[2024-12-02 19:13:01.785] | Success | \u001B[0mInitialized empty <CMU_MOSI_TimestampedWords> computational sequence.\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:01.786] | Status  | \u001B[0mChecking the format of the data in <CMU_MOSI_TimestampedWords> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-02 19:13:01.924] | Success | \u001B[0m<CMU_MOSI_TimestampedWords> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:01.924] | Status  | \u001B[0mChecking the format of the metadata in <CMU_MOSI_TimestampedWords> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2024-12-02 19:13:01.924] | Warning | \u001B[0m<CMU_MOSI_TimestampedWords> computational sequence does not have all the required metadata ... continuing \n",
      "\u001B[92m\u001B[1m[2024-12-02 19:13:01.924] | Success | \u001B[0mInitialized empty <CMU_MOSI_TimestampedWordVectors> computational sequence.\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:01.924] | Status  | \u001B[0mChecking the format of the data in <CMU_MOSI_TimestampedWordVectors> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-02 19:13:02.054] | Success | \u001B[0m<CMU_MOSI_TimestampedWordVectors> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:02.054] | Status  | \u001B[0mChecking the format of the metadata in <CMU_MOSI_TimestampedWordVectors> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2024-12-02 19:13:02.054] | Warning | \u001B[0m<CMU_MOSI_TimestampedWordVectors> computational sequence does not have all the required metadata ... continuing \n",
      "\u001B[92m\u001B[1m[2024-12-02 19:13:02.054] | Success | \u001B[0mInitialized empty <CMU_MOSI_Visual_Facet_41> computational sequence.\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:02.054] | Status  | \u001B[0mChecking the format of the data in <CMU_MOSI_Visual_Facet_41> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-02 19:13:02.176] | Success | \u001B[0m<CMU_MOSI_Visual_Facet_41> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:02.176] | Status  | \u001B[0mChecking the format of the metadata in <CMU_MOSI_Visual_Facet_41> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2024-12-02 19:13:02.176] | Warning | \u001B[0m<CMU_MOSI_Visual_Facet_41> computational sequence does not have all the required metadata ... continuing \n",
      "\u001B[92m\u001B[1m[2024-12-02 19:13:02.176] | Success | \u001B[0mInitialized empty <CMU_MOSI_COVAREP> computational sequence.\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:02.176] | Status  | \u001B[0mChecking the format of the data in <CMU_MOSI_COVAREP> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-02 19:13:02.314] | Success | \u001B[0m<CMU_MOSI_COVAREP> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:02.314] | Status  | \u001B[0mChecking the format of the metadata in <CMU_MOSI_COVAREP> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2024-12-02 19:13:02.314] | Warning | \u001B[0m<CMU_MOSI_COVAREP> computational sequence does not have all the required metadata ... continuing \n"
     ]
    }
   ],
   "source": [
    "# we define a simple averaging function that does not depend on intervals\n",
    "def avg(intervals: np.array, features: np.array) -> np.array:\n",
    "    try:\n",
    "        return np.average(features, axis=0)\n",
    "    except:\n",
    "        return features\n",
    "\n",
    "# first we align to words with averaging, collapse_function receives a list of functions\n",
    "dataset.align(text_field_Words, collapse_functions=[avg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append annotations to the dataset and get the data points\n",
    "\n",
    "Now that we have a preprocessed dataset, all we need to do is to apply annotations to the data. Annotations are also computational sequences, since they are also just some values distributed on different time spans (e.g 1-3s is 'angry', 12-26s is 'neutral'). Hence, we just add the label computational sequence to the dataset and then align to the labels. Since we (may) want to preserve the whole sequences, this time we don't specify any collapse functions when aligning. \n",
    "\n",
    "Note that after alignment, the keys in the dataset changes from `video_id` to `video_id[segment_no]`, because alignment will segment each datapoint based on the segmentation of the pivot modality (in this case, it is segmented based on labels, which is what we need, and yes, one code block ago they are segmented to word level, which I didn't show you).\n",
    "\n",
    "***Important: DO NOT add the labels together at the beginning, the labels will be segmented during the first alignment to words. This also holds for any situation where you want to do multiple levels of alignment.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T19:13:16.206449400Z",
     "start_time": "2024-12-02T19:13:02.406721600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-02 19:13:02.445] | Success | \u001B[0mComputational sequence read from file C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\data\\http__immortal.multicomp.cs.cmu.edu\\CMU-MOSI\\labels\\CMU_MOSI_Opinion_Labels.csd ...\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:02.485] | Status  | \u001B[0mChecking the integrity of the <Opinion Segment Labels> computational sequence ...\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:02.485] | Status  | \u001B[0mChecking the format of the data in <Opinion Segment Labels> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-02 19:13:02.581] | Success | \u001B[0m<Opinion Segment Labels> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:02.583] | Status  | \u001B[0mChecking the format of the metadata in <Opinion Segment Labels> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2024-12-02 19:13:02.583] | Warning | \u001B[0m<Opinion Segment Labels> computational sequence does not have all the required metadata ... continuing \n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:02.584] | Status  | \u001B[0mUnify was called ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-02 19:13:02.793] | Success | \u001B[0mUnify completed ...\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:02.797] | Status  | \u001B[0mPre-alignment based on <CMU_MOSI_Opinion_Labels> computational sequence started ...\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:03.032] | Status  | \u001B[0mPre-alignment done for <CMU_MOSI_COVAREP> ...\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:03.241] | Status  | \u001B[0mPre-alignment done for <CMU_MOSI_Visual_Facet_41> ...\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:03.560] | Status  | \u001B[0mPre-alignment done for <CMU_MOSI_TimestampedWordVectors> ...\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:03.756] | Status  | \u001B[0mPre-alignment done for <CMU_MOSI_TimestampedWords> ...\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:03.763] | Status  | \u001B[0mAlignment starting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:   0%|          | 0/93 [00:00<?, ? Computational Sequence Entries/s]\n",
      "  0%|          | 0/13 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 03bSnISJMiM:   0%|          | 0/13 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/25 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 0h-zjBukYpk:   0%|          | 0/25 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/14 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 1DmNV9C1hbY:   0%|          | 0/14 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:   3%|▎         | 3/93 [00:00<00:03, 23.75 Computational Sequence Entries/s]\n",
      "  0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 1iG0909rllw:   0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/63 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:   0%|          | 0/63 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:  56%|█████▌    | 35/63 [00:00<00:00, 343.21 Segments/s]\u001B[A\n",
      "                                                                             \u001B[A\n",
      "  0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:   0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:   6%|▋         | 6/93 [00:00<00:06, 13.31 Computational Sequence Entries/s]\n",
      "  0%|          | 0/24 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 5W7Z1C_fDaE:   0%|          | 0/24 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/12 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 6Egk_28TtTM:   0%|          | 0/12 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/14 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 6_0THN4chvY:   0%|          | 0/14 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  10%|▉         | 9/93 [00:00<00:04, 17.09 Computational Sequence Entries/s]\n",
      "  0%|          | 0/19 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 73jzhE8R1TQ:   0%|          | 0/19 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/39 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:   0%|          | 0/39 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/23 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:   0%|          | 0/23 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  13%|█▎        | 12/93 [00:00<00:04, 17.73 Computational Sequence Entries/s]\n",
      "  0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 8d-gEyoeBzc:   0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/26 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 8qrpnFRGt2A:   0%|          | 0/26 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  15%|█▌        | 14/93 [00:00<00:04, 17.72 Computational Sequence Entries/s]\n",
      "  0%|          | 0/25 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 9J25DZhivz8:   0%|          | 0/25 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/25 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:   0%|          | 0/25 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  17%|█▋        | 16/93 [00:00<00:04, 17.77 Computational Sequence Entries/s]\n",
      "  0%|          | 0/12 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 9c67fiY0wGQ:   0%|          | 0/12 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/33 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:   0%|          | 0/33 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  19%|█▉        | 18/93 [00:01<00:04, 18.34 Computational Sequence Entries/s]\n",
      "  0%|          | 0/31 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:   0%|          | 0/31 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/31 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning BI97DNYfe5I:   0%|          | 0/31 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  22%|██▏       | 20/93 [00:01<00:04, 17.35 Computational Sequence Entries/s]\n",
      "  0%|          | 0/31 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning BXuRRbG0Ugk:   0%|          | 0/31 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Bfr499ggo-0:   0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  24%|██▎       | 22/93 [00:01<00:04, 17.62 Computational Sequence Entries/s]\n",
      "  0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:   0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/26 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:   0%|          | 0/26 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  26%|██▌       | 24/93 [00:01<00:03, 17.63 Computational Sequence Entries/s]\n",
      "  0%|          | 0/44 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:   0%|          | 0/44 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/31 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Clx4VXItLTE:   0%|          | 0/31 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  28%|██▊       | 26/93 [00:01<00:04, 16.52 Computational Sequence Entries/s]\n",
      "  0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Dg_0XKD0Mf4:   0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/21 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning G-xst2euQUc:   0%|          | 0/21 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/29 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:   0%|          | 0/29 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  31%|███       | 29/93 [00:01<00:03, 17.85 Computational Sequence Entries/s]\n",
      "  0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning GWuJjcEuzt8:   0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/34 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning HEsqda8_d0Q:   0%|          | 0/34 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  33%|███▎      | 31/93 [00:01<00:03, 17.26 Computational Sequence Entries/s]\n",
      "  0%|          | 0/39 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning I5y0__X72p0:   0%|          | 0/39 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Iu2PFX3z_1s:   0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  35%|███▌      | 33/93 [00:01<00:03, 16.54 Computational Sequence Entries/s]\n",
      "  0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning IumbAb8q2dM:   0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/20 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Jkswaaud0hk:   0%|          | 0/20 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  38%|███▊      | 35/93 [00:02<00:03, 16.93 Computational Sequence Entries/s]\n",
      "  0%|          | 0/29 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:   0%|          | 0/29 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning MLal-t_vJPM:   0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  40%|███▉      | 37/93 [00:02<00:03, 16.51 Computational Sequence Entries/s]\n",
      "  0%|          | 0/13 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Njd1F0vZSm4:   0%|          | 0/13 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/32 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Nzq88NnDkEk:   0%|          | 0/32 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  42%|████▏     | 39/93 [00:02<00:03, 17.17 Computational Sequence Entries/s]\n",
      "  0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning OQvJTdtJ2H4:   0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/24 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning OtBXNcAL_lE:   0%|          | 0/24 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/25 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:   0%|          | 0/25 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  45%|████▌     | 42/93 [00:02<00:02, 18.28 Computational Sequence Entries/s]\n",
      "  0%|          | 0/13 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning POKffnXeBds:   0%|          | 0/13 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/12 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning PZ-lDQFboO8:   0%|          | 0/12 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:   0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  48%|████▊     | 45/93 [00:02<00:02, 20.78 Computational Sequence Entries/s]\n",
      "  0%|          | 0/14 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Qr1Ca94K55A:   0%|          | 0/14 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:   0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/15 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning TvyZBvOMOTc:   0%|          | 0/15 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  52%|█████▏    | 48/93 [00:02<00:02, 21.73 Computational Sequence Entries/s]\n",
      "  0%|          | 0/17 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:   0%|          | 0/17 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/55 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:   0%|          | 0/55 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/9 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Vj1wYRQjB-o:   0%|          | 0/9 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  55%|█████▍    | 51/93 [00:02<00:02, 19.59 Computational Sequence Entries/s]\n",
      "  0%|          | 0/32 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning W8NXH0Djyww:   0%|          | 0/32 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning WKA5OygbEKI:   0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/11 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning X3j2zQgwYgE:   0%|          | 0/11 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  58%|█████▊    | 54/93 [00:02<00:01, 19.69 Computational Sequence Entries/s]\n",
      "  0%|          | 0/9 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning ZAIRrfG22O0:   0%|          | 0/9 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                  \u001B[A\n",
      "  0%|          | 0/34 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning ZUXBRvtny7o:   0%|          | 0/34 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/28 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:   0%|          | 0/28 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  61%|██████▏   | 57/93 [00:03<00:01, 19.47 Computational Sequence Entries/s]\n",
      "  0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning aiEXnCPZubE:   0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/21 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning atnd_PF-Lbs:   0%|          | 0/21 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  63%|██████▎   | 59/93 [00:03<00:01, 18.81 Computational Sequence Entries/s]\n",
      "  0%|          | 0/34 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning bOL9jKpeJRs:   0%|          | 0/34 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/25 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:   0%|          | 0/25 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  66%|██████▌   | 61/93 [00:03<00:01, 17.75 Computational Sequence Entries/s]\n",
      "  0%|          | 0/15 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:   0%|          | 0/15 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/33 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning c7UH_rxdZv4:   0%|          | 0/33 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  68%|██████▊   | 63/93 [00:03<00:01, 17.12 Computational Sequence Entries/s]\n",
      "  0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:   0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/24 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning cW1FSBF59ik:   0%|          | 0/24 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  70%|██████▉   | 65/93 [00:03<00:01, 17.65 Computational Sequence Entries/s]\n",
      "  0%|          | 0/29 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:   0%|          | 0/29 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/19 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:   0%|          | 0/19 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  72%|███████▏  | 67/93 [00:03<00:01, 17.35 Computational Sequence Entries/s]\n",
      "  0%|          | 0/43 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning d6hH302o4v8:   0%|          | 0/43 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/15 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning dq3Nf_lMPnE:   0%|          | 0/15 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  74%|███████▍  | 69/93 [00:03<00:01, 16.36 Computational Sequence Entries/s]\n",
      "  0%|          | 0/19 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:   0%|          | 0/19 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning f9O3YtZ2VfI:   0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  76%|███████▋  | 71/93 [00:03<00:01, 17.21 Computational Sequence Entries/s]\n",
      "  0%|          | 0/15 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning f_pcplsH_V0:   0%|          | 0/15 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/14 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:   0%|          | 0/14 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning iiK8YX8oH1E:   0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  80%|███████▉  | 74/93 [00:04<00:00, 20.12 Computational Sequence Entries/s]\n",
      "  0%|          | 0/27 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:   0%|          | 0/27 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/31 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:   0%|          | 0/31 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:   0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  83%|████████▎ | 77/93 [00:04<00:00, 18.53 Computational Sequence Entries/s]\n",
      "  0%|          | 0/10 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0:   0%|          | 0/10 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/24 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning nzpVDcQ0ywM:   0%|          | 0/24 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/14 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning ob23OKe5a9Q:   0%|          | 0/14 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  86%|████████▌ | 80/93 [00:04<00:00, 20.22 Computational Sequence Entries/s]\n",
      "  0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning pLTX3ipuDJI:   0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/21 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:   0%|          | 0/21 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:   0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  89%|████████▉ | 83/93 [00:04<00:00, 20.50 Computational Sequence Entries/s]\n",
      "  0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning tIrG4oNLFzE:   0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning tStelxIAHjw:   0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/20 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning tmZoasNr4rU:   0%|          | 0/20 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  92%|█████████▏| 86/93 [00:04<00:00, 21.43 Computational Sequence Entries/s]\n",
      "  0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning v0zCBqDeKcE:   0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/12 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:   0%|          | 0/12 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:   0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  96%|█████████▌| 89/93 [00:04<00:00, 22.18 Computational Sequence Entries/s]\n",
      "  0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:   0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/24 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:   0%|          | 0/24 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/23 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:   0%|          | 0/23 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  99%|█████████▉| 92/93 [00:04<00:00, 20.05 Computational Sequence Entries/s]\n",
      "  0%|          | 0/35 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:   0%|          | 0/35 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-02 19:13:08.820] | Success | \u001B[0mAlignment to <CMU_MOSI_Opinion_Labels> complete.\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:08.820] | Status  | \u001B[0mReplacing dataset content with aligned computational sequences\n",
      "\u001B[92m\u001B[1m[2024-12-02 19:13:09.077] | Success | \u001B[0mInitialized empty <CMU_MOSI_TimestampedWords> computational sequence.\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:09.077] | Status  | \u001B[0mChecking the format of the data in <CMU_MOSI_TimestampedWords> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-02 19:13:09.088] | Success | \u001B[0m<CMU_MOSI_TimestampedWords> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:09.088] | Status  | \u001B[0mChecking the format of the metadata in <CMU_MOSI_TimestampedWords> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2024-12-02 19:13:09.088] | Warning | \u001B[0m<CMU_MOSI_TimestampedWords> computational sequence does not have all the required metadata ... continuing \n",
      "\u001B[92m\u001B[1m[2024-12-02 19:13:09.088] | Success | \u001B[0mInitialized empty <CMU_MOSI_TimestampedWordVectors> computational sequence.\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:09.088] | Status  | \u001B[0mChecking the format of the data in <CMU_MOSI_TimestampedWordVectors> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-02 19:13:09.097] | Success | \u001B[0m<CMU_MOSI_TimestampedWordVectors> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:09.097] | Status  | \u001B[0mChecking the format of the metadata in <CMU_MOSI_TimestampedWordVectors> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2024-12-02 19:13:09.097] | Warning | \u001B[0m<CMU_MOSI_TimestampedWordVectors> computational sequence does not have all the required metadata ... continuing \n",
      "\u001B[92m\u001B[1m[2024-12-02 19:13:09.097] | Success | \u001B[0mInitialized empty <CMU_MOSI_Visual_Facet_41> computational sequence.\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:09.097] | Status  | \u001B[0mChecking the format of the data in <CMU_MOSI_Visual_Facet_41> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-02 19:13:09.106] | Success | \u001B[0m<CMU_MOSI_Visual_Facet_41> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:09.106] | Status  | \u001B[0mChecking the format of the metadata in <CMU_MOSI_Visual_Facet_41> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2024-12-02 19:13:09.107] | Warning | \u001B[0m<CMU_MOSI_Visual_Facet_41> computational sequence does not have all the required metadata ... continuing \n",
      "\u001B[92m\u001B[1m[2024-12-02 19:13:09.107] | Success | \u001B[0mInitialized empty <CMU_MOSI_COVAREP> computational sequence.\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:09.107] | Status  | \u001B[0mChecking the format of the data in <CMU_MOSI_COVAREP> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-02 19:13:09.117] | Success | \u001B[0m<CMU_MOSI_COVAREP> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:09.117] | Status  | \u001B[0mChecking the format of the metadata in <CMU_MOSI_COVAREP> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2024-12-02 19:13:09.117] | Warning | \u001B[0m<CMU_MOSI_COVAREP> computational sequence does not have all the required metadata ... continuing \n",
      "\u001B[92m\u001B[1m[2024-12-02 19:13:09.117] | Success | \u001B[0mInitialized empty <CMU_MOSI_Opinion_Labels> computational sequence.\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:09.117] | Status  | \u001B[0mChecking the format of the data in <CMU_MOSI_Opinion_Labels> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2024-12-02 19:13:09.129] | Success | \u001B[0m<CMU_MOSI_Opinion_Labels> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2024-12-02 19:13:09.129] | Status  | \u001B[0mChecking the format of the metadata in <CMU_MOSI_Opinion_Labels> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2024-12-02 19:13:09.129] | Warning | \u001B[0m<CMU_MOSI_Opinion_Labels> computational sequence does not have all the required metadata ... continuing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "label_field = 'CMU_MOSI_Opinion_Labels'\n",
    "\n",
    "# we add and align to lables to obtain labeled segments\n",
    "# this time we don't apply collapse functions so that the temporal sequences are preserved\n",
    "label_recipe = {label_field: os.path.join(DATA_PATH, \"http__immortal.multicomp.cs.cmu.edu\", \"CMU-MOSI\", \"labels\", label_field) + '.csd'}\n",
    "dataset.add_computational_sequences(label_recipe, destination=None)\n",
    "dataset.align(label_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T19:13:16.219697Z",
     "start_time": "2024-12-02T19:13:09.168925200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1iG0909rllw[3]\n"
     ]
    }
   ],
   "source": [
    "# check out what the keys look like now\n",
    "print(list(dataset[text_field_Words].keys())[55])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of segments: 2198\n"
     ]
    }
   ],
   "source": [
    "num_segments = len(dataset[visual_field_Facet41].keys())  # Assuming all fields have the same segment keys\n",
    "print(f\"Number of segments: {num_segments}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T19:13:16.228211900Z",
     "start_time": "2024-12-02T19:13:09.186515100Z"
    }
   },
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[91m\u001B[1m[2024-12-02 19:13:09.233] | Error   | \u001B[0mComputational sequence does not exist ...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Computational sequence does not exist ...",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[33], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Compute lengths of segments for each modality\u001B[39;00m\n\u001B[0;32m      2\u001B[0m segment_lengths_visual \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m      3\u001B[0m     visual_field_Facet41: [dataset[visual_field_Facet41][seg][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeatures\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m seg \u001B[38;5;129;01min\u001B[39;00m dataset[visual_field_Facet41]\u001B[38;5;241m.\u001B[39mkeys()],\n\u001B[1;32m----> 4\u001B[0m     visual_field_Facet42: [dataset[visual_field_Facet42][seg][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeatures\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m seg \u001B[38;5;129;01min\u001B[39;00m \u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43mvisual_field_Facet42\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mkeys()],\n\u001B[0;32m      5\u001B[0m     visual_field_OpenFace1: [dataset[visual_field_OpenFace1][seg][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeatures\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m seg \u001B[38;5;129;01min\u001B[39;00m dataset[visual_field_OpenFace1]\u001B[38;5;241m.\u001B[39mkeys()],\n\u001B[0;32m      6\u001B[0m }\n\u001B[0;32m      8\u001B[0m segment_lengths_acoustic \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m      9\u001B[0m     acoustic_field_COVAREP: [dataset[acoustic_field_COVAREP][seg][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeatures\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m seg \u001B[38;5;129;01min\u001B[39;00m dataset[acoustic_field_COVAREP]\u001B[38;5;241m.\u001B[39mkeys()],\n\u001B[0;32m     10\u001B[0m     acoustic_field_OpenSmile_EB10: [dataset[acoustic_field_OpenSmile_EB10][seg][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeatures\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m seg \u001B[38;5;129;01min\u001B[39;00m dataset[acoustic_field_OpenSmile_EB10]\u001B[38;5;241m.\u001B[39mkeys()],\n\u001B[0;32m     11\u001B[0m }\n\u001B[0;32m     13\u001B[0m segment_lengths_text \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     14\u001B[0m     text_field_Words: [dataset[text_field_Words][seg][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeatures\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m seg \u001B[38;5;129;01min\u001B[39;00m dataset[text_field_Words]\u001B[38;5;241m.\u001B[39mkeys()],\n\u001B[0;32m     15\u001B[0m     text_field_WordVectors: [dataset[text_field_WordVectors][seg][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeatures\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m seg \u001B[38;5;129;01min\u001B[39;00m dataset[text_field_WordVectors]\u001B[38;5;241m.\u001B[39mkeys()],\n\u001B[0;32m     16\u001B[0m }\n",
      "File \u001B[1;32m~\\Documents\\Thesis\\CMU-MultimodalSDK\\mmsdk\\mmdatasdk\\dataset\\dataset.py:46\u001B[0m, in \u001B[0;36mmmdataset.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m,key):\n\u001B[0;32m     45\u001B[0m \t\u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcomputational_sequences\u001B[38;5;241m.\u001B[39mkeys()):\n\u001B[1;32m---> 46\u001B[0m \t\t\u001B[43mlog\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merror\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mComputational sequence does not exist ...\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43merror\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     47\u001B[0m \t\u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcomputational_sequences[key]\n",
      "File \u001B[1;32m~\\Documents\\Thesis\\CMU-MultimodalSDK\\mmsdk\\mmdatasdk\\log\\log.py:95\u001B[0m, in \u001B[0;36merror\u001B[1;34m(msgstring, error, errorType, destination, verbose)\u001B[0m\n\u001B[0;32m     93\u001B[0m \t\u001B[38;5;28;01mfor\u001B[39;00m dest \u001B[38;5;129;01min\u001B[39;00m destination:\n\u001B[0;32m     94\u001B[0m \t\t\u001B[38;5;28mprint\u001B[39m (bcolors\u001B[38;5;241m.\u001B[39mFAIL \u001B[38;5;241m+\u001B[39mbcolors\u001B[38;5;241m.\u001B[39mBOLD\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m] | Error   | \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m%\u001B[39mnow\u001B[38;5;241m+\u001B[39mbcolors\u001B[38;5;241m.\u001B[39mENDC \u001B[38;5;241m+\u001B[39m msgstring,file\u001B[38;5;241m=\u001B[39mdest)\n\u001B[1;32m---> 95\u001B[0m \t\u001B[38;5;28;01mraise\u001B[39;00m errorType(msgstring)\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     97\u001B[0m \t\u001B[38;5;28;01mfor\u001B[39;00m dest \u001B[38;5;129;01min\u001B[39;00m destination:\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Computational sequence does not exist ..."
     ]
    }
   ],
   "source": [
    "# Compute lengths of segments for each modality\n",
    "segment_lengths_visual = {\n",
    "    visual_field_Facet41: [dataset[visual_field_Facet41][seg]['features'].shape[0] for seg in dataset[visual_field_Facet41].keys()],\n",
    "    visual_field_Facet42: [dataset[visual_field_Facet42][seg]['features'].shape[0] for seg in dataset[visual_field_Facet42].keys()],\n",
    "    visual_field_OpenFace1: [dataset[visual_field_OpenFace1][seg]['features'].shape[0] for seg in dataset[visual_field_OpenFace1].keys()],\n",
    "}\n",
    "\n",
    "segment_lengths_acoustic = {\n",
    "    acoustic_field_COVAREP: [dataset[acoustic_field_COVAREP][seg]['features'].shape[0] for seg in dataset[acoustic_field_COVAREP].keys()],\n",
    "    acoustic_field_OpenSmile_EB10: [dataset[acoustic_field_OpenSmile_EB10][seg]['features'].shape[0] for seg in dataset[acoustic_field_OpenSmile_EB10].keys()],\n",
    "}\n",
    "\n",
    "segment_lengths_text = {\n",
    "    text_field_Words: [dataset[text_field_Words][seg]['features'].shape[0] for seg in dataset[text_field_Words].keys()],\n",
    "    text_field_WordVectors: [dataset[text_field_WordVectors][seg]['features'].shape[0] for seg in dataset[text_field_WordVectors].keys()],\n",
    "}\n",
    "\n",
    "# Calculate maximum and minimum lengths for each modality\n",
    "max_length_visual = {modality: max(lengths) for modality, lengths in segment_lengths_visual.items()}\n",
    "min_length_visual = {modality: min(lengths) for modality, lengths in segment_lengths_visual.items()}\n",
    "\n",
    "max_length_acoustic = {modality: max(lengths) for modality, lengths in segment_lengths_acoustic.items()}\n",
    "min_length_acoustic = {modality: min(lengths) for modality, lengths in segment_lengths_acoustic.items()}\n",
    "\n",
    "max_length_text = {modality: max(lengths) for modality, lengths in segment_lengths_text.items()}\n",
    "min_length_text = {modality: min(lengths) for modality, lengths in segment_lengths_text.items()}\n",
    "\n",
    "# Print the results for each modality\n",
    "for modality, max_len in max_length_visual.items():\n",
    "    print(f\"Visual modality {modality}: Max length = {max_len}, Min length = {min_length_visual[modality]}\")\n",
    "\n",
    "for modality, max_len in max_length_acoustic.items():\n",
    "    print(f\"Acoustic modality {modality}: Max length = {max_len}, Min length = {min_length_acoustic[modality]}\")\n",
    "\n",
    "for modality, max_len in max_length_text.items():\n",
    "    print(f\"Text modality {modality}: Max length = {max_len}, Min length = {min_length_text[modality]}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T19:13:16.249196500Z",
     "start_time": "2024-12-02T19:13:09.223317100Z"
    }
   },
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Iterate over each segment in the dataset (assuming all modalities have the same segment keys)\n",
    "for seg in dataset[visual_field_Facet41].keys():  \n",
    "    # Compute the length for each modality and feature\n",
    "    visual_length_Facet41 = dataset[visual_field_Facet41][seg]['features'].shape[0]\n",
    "    visual_length_Facet42 = dataset[visual_field_Facet42][seg]['features'].shape[0]\n",
    "    visual_length_OpenFace1 = dataset[visual_field_OpenFace1][seg]['features'].shape[0]\n",
    "    \n",
    "    acoustic_length_COVAREP = dataset[acoustic_field_COVAREP][seg]['features'].shape[0]\n",
    "    acoustic_length_OpenSmile_EB10 = dataset[acoustic_field_OpenSmile_EB10][seg]['features'].shape[0]\n",
    "    \n",
    "    text_length_Words = dataset[text_field_Words][seg]['features'].shape[0]\n",
    "    text_length_WordVectors = dataset[text_field_WordVectors][seg]['features'].shape[0]\n",
    "    \n",
    "    # Print the lengths for all features of the current segment\n",
    "    print(f\"Segment {seg}:\")\n",
    "    print(f\"  Visual (Facet41) length = {visual_length_Facet41}\")\n",
    "    print(f\"  Visual (Facet42) length = {visual_length_Facet42}\")\n",
    "    print(f\"  Visual (OpenFace1) length = {visual_length_OpenFace1}\")\n",
    "    print(f\"  Acoustic (COVAREP) length = {acoustic_length_COVAREP}\")\n",
    "    print(f\"  Acoustic (OpenSmile_EB10) length = {acoustic_length_OpenSmile_EB10}\")\n",
    "    print(f\"  Text (Words) length = {text_length_Words}\")\n",
    "    print(f\"  Text (WordVectors) length = {text_length_WordVectors}\")\n",
    "    print('-' * 50)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-02T19:13:09.345364100Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Extract unique video IDs\n",
    "video_ids = set(seg.split(\"[\")[0] for seg in dataset[visual_field_Facet41].keys())\n",
    "\n",
    "# Count the number of unique video IDs\n",
    "num_unique_ids = len(video_ids)\n",
    "\n",
    "# Count segments for each video ID\n",
    "video_segment_counts = {video_id: sum(seg.startswith(video_id) for seg in dataset[visual_field_Facet41].keys()) for video_id in video_ids}\n",
    "\n",
    "# Print the total number of unique video IDs\n",
    "print(f\"Total number of unique video IDs: {num_unique_ids}\\n\")\n",
    "\n",
    "# Print the segment counts for each video ID\n",
    "for video_id, count in video_segment_counts.items():\n",
    "    print(f\"Video {video_id}: {count} segments\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-02T19:13:09.348849700Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset\n",
    "\n",
    "Now it comes to our final step: splitting the dataset into train/dev/test splits. This code block is a bit long in itself, so be patience and step through carefully with the explanatory comments.\n",
    "\n",
    "The SDK provides the splits in terms of video IDs (which video belong to which split), however, after alignment our dataset keys already changed from `video_id` to `video_id[segment_no]`. Hence, we need to extract the video ID when looping through the data to determine which split each data point belongs to.\n",
    "\n",
    "In the following data processing, I also include instance-wise Z-normalization (subtract by mean and divide by standard dev) and converted words to unique IDs.\n",
    "\n",
    "This example is based on PyTorch so I am using PyTorch related utils, but the same procedure should be easy to adapt to other frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-02T19:13:09.352319400Z"
    }
   },
   "outputs": [],
   "source": [
    "# obtain the train/dev/test splits - these splits are based on video IDs\n",
    "train_split = DATASET.standard_folds.standard_train_fold\n",
    "dev_split = DATASET.standard_folds.standard_valid_fold\n",
    "test_split = DATASET.standard_folds.standard_test_fold\n",
    "\n",
    "# inspect the splits: they only contain video IDs\n",
    "print(f\"lengths: train {len(train_split)}, dev {len(dev_split)}, test {len(test_split)}\\n\")\n",
    "print(train_split)\n",
    "print(dev_split)\n",
    "print(test_split)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# we can see they are in the format of 'video_id[segment_no]', but the splits was specified with video_id only\n",
    "# we need to use regex or something to match the video IDs...\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm_notebook\n",
    "from collections import defaultdict\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-02T19:13:09.357146800Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_hist(visual, acoustic, title=\"Segment\"):\n",
    "    # Create the folder if it doesn't exist\n",
    "    folder_name = \"Value distributions\"\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "    \n",
    "    # Plot the histograms\n",
    "    plt.hist(visual.flatten(), bins=100, alpha=0.5, label='Visual')\n",
    "    plt.hist(acoustic.flatten(), bins=100, alpha=0.5, label='Acoustic')\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Value Distribution for {title}\")\n",
    "    plt.show()\n",
    "    plt.close()  # Close the plot to free memory/\n",
    "\n",
    "    # \n",
    "    # # Save the figure to the specified folder with the given title\n",
    "    # file_name = f\"value_distribution_{title}.png\"\n",
    "    # file_path = os.path.join(folder_name, file_name)\n",
    "    # plt.savefig(file_path)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-02T19:13:09.360529400Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# A sentinel epsilon for safe division, avoiding division by zero\n",
    "EPS = 1e-8\n",
    "\n",
    "word2id = defaultdict(lambda: len(word2id))\n",
    "UNK = word2id['<unk>']\n",
    "PAD = word2id['<pad>']\n",
    "EOS = word2id['<eos>']\n",
    "BOS = word2id['<bos>']\n",
    "# SEP = word2id['<sep>']\n",
    "DUMMY = word2id['<dummy>']\n",
    "\n",
    "pattern = re.compile('(.*)\\[.*\\]')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-02T19:13:09.366345400Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Assuming the input features are already defined elsewhere\n",
    "# _words, _visual_Facet41, _visual_Facet42, _visual_OpenFace1, _acoustic_COVAREP, _acoustic_OpenSmile_EB10, _wordvectors\n",
    "# Also assuming train_split, dev_split, test_split are already defined\n",
    "\n",
    "# Placeholders for final train/dev/test dataset\n",
    "train = []\n",
    "dev = []\n",
    "test = []\n",
    "\n",
    "# Iterate over the segments in the dataset\n",
    "num_drop = 0  # Counter to track the number of dropped data points\n",
    "\n",
    "for segment in dataset[label_field].keys():\n",
    "    # Get the video ID and features\n",
    "    vid = re.search(pattern, segment).group(1)\n",
    "    label = dataset[label_field][segment]['features']\n",
    "    _words = dataset[text_field_Words][segment]['features']\n",
    "    \n",
    "    # Collect all visual and acoustic features\n",
    "    _visual_Facet41 = dataset[visual_field_Facet41][segment]['features']\n",
    "    # _visual_Facet42 = dataset[visual_field_Facet42][segment]['features']\n",
    "    # _visual_OpenFace1 = dataset[visual_field_OpenFace1][segment]['features']\n",
    "    \n",
    "    _acoustic_COVAREP = dataset[acoustic_field_COVAREP][segment]['features']\n",
    "    # _acoustic_OpenSmile_EB10 = dataset[acoustic_field_OpenSmile_EB10][segment]['features']\n",
    "    \n",
    "    # _wordvectors = dataset[text_field_WordVectors][segment]['features']\n",
    "\n",
    "    # # Check if all modalities have the same number of elements (length of sequence)\n",
    "    # if not (_words.shape[0] == _visual_Facet41.shape[0] == _visual_Facet42.shape[0] == _visual_OpenFace1.shape[0] == \n",
    "    #         _acoustic_COVAREP.shape[0] == _acoustic_OpenSmile_EB10.shape[0] == _wordvectors.shape[0]):\n",
    "    #     print(f\"Error: Inconsistent sequence lengths for segment {vid}\")\n",
    "    #     num_drop += 1\n",
    "    #     continue  # Skip this segment and continue with the next one\n",
    "    \n",
    "    \n",
    "     # Check if all modalities have the same number of elements (length of sequence)\n",
    "    if not (_words.shape[0] == _visual_Facet41.shape[0] == _acoustic_COVAREP.shape[0]):\n",
    "            #  == _wordvectors.shape[0]):\n",
    "        print(f\"Error: Inconsistent sequence lengths for segment {vid}\")\n",
    "        num_drop += 1\n",
    "        continue  # Skip this segment and continue with the next one\n",
    "\n",
    "    # Lists to hold the processed data for each modality\n",
    "    words = []\n",
    "    visual = []\n",
    "    acoustic = []\n",
    "    # wordvectors = []\n",
    "\n",
    "    # Remove speech pauses (um, uhh, etc.)\n",
    "    for i, word in enumerate(_words):\n",
    "        if word[0] != b'sp':  # Remove speech pauses\n",
    "            words.append(word2id[word[0].decode('utf-8')])  # Decode bytes to string and add to words\n",
    "            \n",
    "            # FIGURE OUT HERE WHAT YOU NEED TO DO - how do you work with the vectors?\n",
    "            \n",
    "            \n",
    "            # Append visual features (check the shape of each feature)\n",
    "            visual.append(_visual_Facet41[i, :])  # Facet41\n",
    "            # visual.append(_visual_Facet42[i, :])  # Facet42\n",
    "            # visual.append(_visual_OpenFace1[i, :])  # OpenFace1\n",
    "            \n",
    "            # Append acoustic features (check the shape of each feature)\n",
    "            acoustic.append(_acoustic_COVAREP[i, :])  # COVAREP\n",
    "            # acoustic.append(_acoustic_OpenSmile_EB10[i, :])  # OpenSmile_EB10\n",
    "            \n",
    "            # combined_acoustic = np.vstack((_acoustic_COVAREP[i, :], _acoustic_OpenSmile_EB10[i, :]))\n",
    "            # acoustic.append(combined_acoustic)\n",
    "            \n",
    "            # Append word vectors\n",
    "            # wordvectors.append(_wordvectors[i, :])  # Word vectors\n",
    "            \n",
    "            \n",
    "    # LOOK AT THE SHAPES\n",
    "\n",
    "    # Check the shapes of the collected features before converting to numpy arrays\n",
    "    # print(f\"Word vectors shape: {np.asarray(wordvectors).shape}\")\n",
    "    print(f\"Words shape: {np.asarray(words).shape}\")\n",
    "    print(f\"Acoustic shape: {np.asarray(acoustic).shape}\")\n",
    "\n",
    "    print(f\"Visual shape: {np.asarray(visual).shape}\")\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    words = np.asarray(words)\n",
    "    visual = np.asarray(visual)\n",
    "    acoustic = np.asarray(acoustic)\n",
    "    # wordvectors = np.asarray(wordvectors)\n",
    "\n",
    "    # Z-normalization for visual modality (across all visual features)\n",
    "    std_dev_visual = np.std(visual, axis=0, keepdims=True)\n",
    "    visual = np.nan_to_num((visual - visual.mean(0, keepdims=True)) / (EPS + std_dev_visual))\n",
    "    visual[:, std_dev_visual.flatten() == 0] = EPS  # Safeguard for zero standard deviation\n",
    "\n",
    "    # Z-normalization for acoustic modality (across all acoustic features)\n",
    "    acoustic_mean = np.nanmean(acoustic, axis=0, keepdims=True)\n",
    "    std_dev_acoustic = np.nanstd(acoustic, axis=0, keepdims=True)\n",
    "    std_dev_acoustic = np.nan_to_num(std_dev_acoustic)\n",
    "    std_dev_acoustic[std_dev_acoustic == 0] = EPS  # Safeguard for zero standard deviation\n",
    "\n",
    "    acoustic = np.nan_to_num((acoustic - acoustic_mean) / (EPS + std_dev_acoustic))\n",
    "\n",
    "    # # Z-normalization for word vectors\n",
    "    # wordvectors_mean = np.nanmean(wordvectors, axis=0, keepdims=True)\n",
    "    # std_dev_wordvectors = np.nanstd(wordvectors, axis=0, keepdims=True)\n",
    "    # std_dev_wordvectors = np.nan_to_num(std_dev_wordvectors)\n",
    "    # std_dev_wordvectors[std_dev_wordvectors == 0] = EPS  # Safeguard for zero standard deviation\n",
    "    # wordvectors = np.nan_to_num((wordvectors - wordvectors_mean) / (EPS + std_dev_wordvectors))\n",
    "\n",
    "    # Ensure no NaN or Inf values in the data\n",
    "    if np.any(np.isnan(acoustic)) or np.any(np.isinf(acoustic)):\n",
    "        print(f\"Error in acoustic data for segment {vid}\")\n",
    "    if np.any(np.isnan(visual)) or np.any(np.isinf(visual)):\n",
    "        print(f\"Error in visual data for segment {vid}\")\n",
    "    if np.any(np.isnan(words)) or np.any(np.isinf(words)):\n",
    "        print(f\"Error in wordvectors data for segment {vid}\")\n",
    "\n",
    "    # Add the data to the appropriate split\n",
    "    if vid in train_split:\n",
    "        train.append(((words, visual, acoustic), label, segment))\n",
    "    elif vid in dev_split:\n",
    "        dev.append(((words, visual, acoustic), label, segment))\n",
    "    elif vid in test_split:\n",
    "        test.append(((words, visual, acoustic), label, segment))\n",
    "    else:\n",
    "        print(f\"Found video that doesn't belong to any splits: {vid}\")\n",
    "\n",
    "# Output number of dropped datapoints\n",
    "print(f\"Total number of {num_drop} datapoints have been dropped.\")\n",
    "vocab_size = len(word2id)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-02T19:13:09.370916600Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_hist2(wordvectors, acoustic, title=\"Segment\"):\n",
    "    # Create the folder if it doesn't exist\n",
    "    folder_name = \"Value distributions\"\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "    \n",
    "    # Plot the histograms\n",
    "    plt.hist(wordvectors.flatten(), bins=100, alpha=0.5, label='Wordvectors')\n",
    "    plt.hist(acoustic.flatten(), bins=100, alpha=0.5, label='Acoustic')\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Value Distribution for {title}\")\n",
    "    plt.show()\n",
    "    plt.close() "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-02T19:13:09.375334100Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# vocab_size = len(word2id)\n",
    "# print(f\"Vocabulary size: {vocab_size}\")\n",
    "# \n",
    "# \n",
    "# # Assuming the input features are already defined elsewhere\n",
    "# # _words, _visual_Facet41, _visual_Facet42, _visual_OpenFace1, _acoustic_COVAREP, _acoustic_OpenSmile_EB10, _wordvectors\n",
    "# # Also assuming train_split, dev_split, test_split are already defined\n",
    "# \n",
    "# # Placeholders for final train/dev/test dataset\n",
    "# train = []\n",
    "# dev = []\n",
    "# test = []\n",
    "# \n",
    "# # Iterate over the segments in the dataset\n",
    "# num_drop = 0  # Counter to track the number of dropped data points\n",
    "# \n",
    "# for segment in dataset[label_field].keys():\n",
    "#     # Get the video ID and features\n",
    "#     vid = re.search(pattern, segment).group(1)\n",
    "#     label = dataset[label_field][segment]['features']\n",
    "#     _words = dataset[text_field_Words][segment]['features']\n",
    "#     \n",
    "#     # Collect all visual and acoustic features\n",
    "#     _visual_Facet41 = dataset[visual_field_Facet41][segment]['features']\n",
    "#     # _visual_Facet42 = dataset[visual_field_Facet42][segment]['features']\n",
    "#     # _visual_OpenFace1 = dataset[visual_field_OpenFace1][segment]['features']\n",
    "#     \n",
    "#     _acoustic_COVAREP = dataset[acoustic_field_COVAREP][segment]['features']\n",
    "#     # _acoustic_OpenSmile_EB10 = dataset[acoustic_field_OpenSmile_EB10][segment]['features']\n",
    "#     \n",
    "#     _wordvectors = dataset[text_field_WordVectors][segment]['features']\n",
    "# \n",
    "#     # # Check if all modalities have the same number of elements (length of sequence)\n",
    "#     # if not (_words.shape[0] == _visual_Facet41.shape[0] == _visual_Facet42.shape[0] == _visual_OpenFace1.shape[0] == \n",
    "#     #         _acoustic_COVAREP.shape[0] == _acoustic_OpenSmile_EB10.shape[0] == _wordvectors.shape[0]):\n",
    "#     #     print(f\"Error: Inconsistent sequence lengths for segment {vid}\")\n",
    "#     #     num_drop += 1\n",
    "#     #     continue  # Skip this segment and continue with the next one\n",
    "#     \n",
    "#     \n",
    "#      # Check if all modalities have the same number of elements (length of sequence)\n",
    "#     if not (_words.shape[0] == _visual_Facet41.shape[0] == _acoustic_COVAREP.shape[0]\n",
    "#                     == _wordvectors.shape[0]):\n",
    "#         print(f\"Error: Inconsistent sequence lengths for segment {vid}\")\n",
    "#         num_drop += 1\n",
    "#         continue  # Skip this segment and continue with the next one\n",
    "# \n",
    "#     # Lists to hold the processed data for each modality\n",
    "#     words = []\n",
    "#     visual = []\n",
    "#     acoustic = []\n",
    "#     wordvectors = []\n",
    "# \n",
    "#     # Remove speech pauses (um, uhh, etc.)\n",
    "#     for i, word in enumerate(_words):\n",
    "#         if word[0] != b'sp':  # Remove speech pauses\n",
    "#             words.append(word2id[word[0].decode('utf-8')])  # Decode bytes to string and add to words\n",
    "#             \n",
    "#             # FIGURE OUT HERE WHAT YOU NEED TO DO - how do you work with the vectors?\n",
    "#             \n",
    "#             \n",
    "#             # Append visual features (check the shape of each feature)\n",
    "#             visual.append(_visual_Facet41[i, :])  # Facet41\n",
    "#             # visual.append(_visual_Facet42[i, :])  # Facet42\n",
    "#             # visual.append(_visual_OpenFace1[i, :])  # OpenFace1\n",
    "#             \n",
    "#             # Append acoustic features (check the shape of each feature)\n",
    "#             acoustic.append(_acoustic_COVAREP[i, :])  # COVAREP\n",
    "#             # acoustic.append(_acoustic_OpenSmile_EB10[i, :])  # OpenSmile_EB10\n",
    "#             \n",
    "#             # combined_acoustic = np.vstack((_acoustic_COVAREP[i, :], _acoustic_OpenSmile_EB10[i, :]))\n",
    "#             # acoustic.append(combined_acoustic)\n",
    "#             \n",
    "#             # Append word vectors\n",
    "#             wordvectors.append(_wordvectors[i, :])  # Word vectors\n",
    "#             \n",
    "#             \n",
    "#     # LOOK AT THE SHAPES\n",
    "# \n",
    "#     # Check the shapes of the collected features before converting to numpy arrays\n",
    "#     # print(f\"Word vectors shape: {np.asarray(wordvectors).shape}\")\n",
    "#     print(f\"Words shape: {np.asarray(words).shape}\")\n",
    "#     print(f\"WordVectors shape: {np.asarray(wordvectors).shape}\")\n",
    "#     print(f\"Acoustic shape: {np.asarray(acoustic).shape}\")\n",
    "# \n",
    "#     print(f\"Visual shape: {np.asarray(visual).shape}\")\n",
    "# \n",
    "#     # Convert lists to numpy arrays\n",
    "#     words = np.asarray(words)\n",
    "#     visual = np.asarray(visual)\n",
    "#     acoustic = np.asarray(acoustic)\n",
    "#     wordvectors = np.asarray(wordvectors)\n",
    "# \n",
    "#     # Z-normalization for visual modality (across all visual features)\n",
    "#     std_dev_visual = np.std(visual, axis=0, keepdims=True)\n",
    "#     visual = np.nan_to_num((visual - visual.mean(0, keepdims=True)) / (EPS + std_dev_visual))\n",
    "#     visual[:, std_dev_visual.flatten() == 0] = EPS  # Safeguard for zero standard deviation\n",
    "# \n",
    "#     # Z-normalization for acoustic modality (across all acoustic features)\n",
    "#     acoustic_mean = np.nanmean(acoustic, axis=0, keepdims=True)\n",
    "#     std_dev_acoustic = np.nanstd(acoustic, axis=0, keepdims=True)\n",
    "#     std_dev_acoustic = np.nan_to_num(std_dev_acoustic)\n",
    "#     std_dev_acoustic[std_dev_acoustic == 0] = EPS  # Safeguard for zero standard deviation\n",
    "# \n",
    "#     acoustic = np.nan_to_num((acoustic - acoustic_mean) / (EPS + std_dev_acoustic))\n",
    "# \n",
    "#     # Z-normalization for word vectors\n",
    "#     wordvectors_mean = np.nanmean(wordvectors, axis=0, keepdims=True)\n",
    "#     std_dev_wordvectors = np.nanstd(wordvectors, axis=0, keepdims=True)\n",
    "#     std_dev_wordvectors = np.nan_to_num(std_dev_wordvectors)\n",
    "#     std_dev_wordvectors[std_dev_wordvectors == 0] = EPS  # Safeguard for zero standard deviation\n",
    "#     wordvectors = np.nan_to_num((wordvectors - wordvectors_mean) / (EPS + std_dev_wordvectors))\n",
    "#     \n",
    "#     # plot_hist2(wordvectors, acoustic)\n",
    "# \n",
    "#     # Ensure no NaN or Inf values in the data\n",
    "#     if np.any(np.isnan(acoustic)) or np.any(np.isinf(acoustic)):\n",
    "#         print(f\"Error in acoustic data for segment {vid}\")\n",
    "#     if np.any(np.isnan(visual)) or np.any(np.isinf(visual)):\n",
    "#         print(f\"Error in visual data for segment {vid}\")\n",
    "#     if np.any(np.isnan(words)) or np.any(np.isinf(words)):\n",
    "#         print(f\"Error in wordvectors data for segment {vid}\")\n",
    "# \n",
    "#     # Add the data to the appropriate split\n",
    "#     if vid in train_split:\n",
    "#         train.append(((words, visual, acoustic), label, segment))\n",
    "#     elif vid in dev_split:\n",
    "#         dev.append(((words, visual, acoustic), label, segment))\n",
    "#     elif vid in test_split:\n",
    "#         test.append(((words, visual, acoustic), label, segment))\n",
    "#     else:\n",
    "#         print(f\"Found video that doesn't belong to any splits: {vid}\")\n",
    "# \n",
    "# # Output number of dropped datapoints\n",
    "# print(f\"Total number of {num_drop} datapoints have been dropped.\")\n",
    "# # Check how many words are in the vocabulary\n",
    "# vocab_size = len(word2id)\n",
    "# print(f\"Vocabulary size: {vocab_size}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-02T19:13:09.378773400Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import random\n",
    "# Ensure the train dataset has elements before sampling\n",
    "if len(train) > 0:\n",
    "    # Randomly sample one processed segment\n",
    "    sample = random.choice(train)\n",
    "\n",
    "    # Extract components\n",
    "    (words, visual, acoustic, wordvectors), label, segment = sample\n",
    "\n",
    "    # Display the details\n",
    "    print(f\"Segment: {segment}\")\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"Words (sample, first 10 if too long): {words[:10] if len(words) > 10 else words}\")\n",
    "    print(f\"Words shape: {words.shape}\")\n",
    "    print(f\"Visual shape: {visual.shape}\")\n",
    "    print(f\"Acoustic shape: {acoustic.shape}\")\n",
    "    print(f\"WordVectors shape: {wordvectors.shape}\")\n",
    "else:\n",
    "    print(\"The train dataset is empty. Check the preprocessing loop for issues.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-02T19:13:09.381996700Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T18:35:56.010606500Z",
     "start_time": "2024-12-02T18:35:55.867273400Z"
    }
   },
   "outputs": [],
   "source": [
    "# turn off the word2id - define a named function here to allow for pickling\n",
    "def return_unk():\n",
    "    return UNK\n",
    "word2id.default_factory = return_unk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the dataset\n",
    "\n",
    "Now that we have loaded the data, we can check the sizes of each split, data point shapes, vocabulary size, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Frame Index and Time: frameIndex and frameTime indicate the time alignment of the features.\n",
    "Loudness features (pcm_loudness_sma_*): These are statistical attributes (e.g., mean, standard deviation, kurtosis, and quartiles) related to loudness.\n",
    "MFCC features (pcm_fftMag_mfcc_sma*): These are Mel-Frequency Cepstral Coefficients and their derived statistics.\n",
    "Log Mel Frequency Band features (logMelFreqBand_sma*): These represent the energy in specific mel-scale frequency bands.\n",
    "Regression coefficients and errors (*_linregc1, *_linregc2, *_linregerrA, etc.): These describe trends and variations in features across frames.\n",
    "\n",
    "\n",
    "\n",
    "Voicing and Pitch (voicingFinalUnclipped):\n",
    "\n",
    "Parameters such as sma_maxPos, sma_minPos, sma_amean, and sma_stddev indicate characteristics of voicing activity (presence of voice or sound).\n",
    "The skewness, kurtosis, and percentiles reflect the distribution of these features over time.\n",
    "Linreg coefficients (linregc1, linregc2) suggest trends over the analyzed time window (e.g., rising or falling pitch).\n",
    "Loudness (pcm_loudness_sma):\n",
    "\n",
    "Metrics such as de_maxPos, de_minPos, de_amean highlight loudness levels, which are important for detecting intensity and energy in speech.\n",
    "Statistical properties like stddev, skewness, and kurtosis describe the variability and asymmetry of loudness.\n",
    "Percentile and quartile-based features offer insight into loudness thresholds (e.g., how much time was spent above a certain loudness level).\n",
    "Mel-Frequency Cepstral Coefficients (MFCCs):\n",
    "\n",
    "Features such as pcm_fftMag_mfcc_sma_deX for X = 0 to 14 represent frequency-domain characteristics of the audio signal.\n",
    "These coefficients are crucial in audio and speech processing, capturing the timbre and spectral properties of sound.\n",
    "\n",
    "Up-Level Time Metrics: (upleveltime75, upleveltime90) indicate how long the signal remains above certain thresholds, reflecting sustained vocal effort or loudness.\n",
    "Percentile Features: Help capture the extremes and typical ranges of the data.\n",
    "IQR (Interquartile Range): Measures variability and could reflect vocal modulation or consistency.\n",
    "\n",
    "\n",
    "lspFreq_sma_deX:\n",
    "\n",
    "These features pertain to Line Spectral Pairs (LSP) frequencies derived from speech signals. They describe spectral envelope characteristics and are sensitive to phoneme-level variations.\n",
    "X indicates different LSP frequency bands (de0, de1, ..., de7) or derivations of them.\n",
    "Common statistical summaries:\n",
    "maxPos/minPos: Time position of the maximum/minimum values in the speech segment.\n",
    "amean: Arithmetic mean (average) value of the feature over the segment.\n",
    "linregc1/linregc2: Linear regression coefficients describing the trend of the feature (e.g., increasing or decreasing).\n",
    "linregerrA/Q: Absolute or quadratic error of the regression model—indicating fit quality.\n",
    "stddev: Standard deviation, showing variation or spread of the feature.\n",
    "skewness/kurtosis: Higher-order statistical moments—describe asymmetry (skewness) or \"peakedness\" (kurtosis) of the distribution.\n",
    "quartile1/2/3: 25th, 50th (median), and 75th percentiles, splitting the data distribution into quartiles.\n",
    "iqrX-Y: Interquartile range between quartileX and quartileY.\n",
    "percentile1.0/percentile99.0: Values below which 1% or 99% of the data lie.\n",
    "upleveltime75/90: Percentage of time the feature exceeds 75% or 90% of its range.\n",
    "F0finEnv_sma_de:\n",
    "\n",
    "Represents the pitch envelope or fundamental frequency (F0) final value’s dynamics. The sma suffix indicates smoothing (simple moving average), and de represents derived (e.g., delta) features.\n",
    "Includes the same statistical parameters as lspFreq.\n",
    "voicingFinalUnclipped_sma_de:\n",
    "\n",
    "Measures the degree of voicing in the speech (whether vocal folds are vibrating or not).\n",
    "\"Unclipped\" indicates no thresholding applied to separate voiced/unvoiced segments.\n",
    "Provides detailed analysis using similar statistical measures.\n",
    "F0final_sma and F0final_sma_de:\n",
    "\n",
    "Final pitch values (smoothed or derived) from the speech signal, critical for prosody and intonation analysis.\n",
    "These features include mean, variability, skewness, and trends of the pitch over time.\n",
    "jitterLocal_sma and jitterDDP_sma:\n",
    "\n",
    "These are measures of pitch perturbation or variability:\n",
    "JitterLocal: Variability of pitch period duration, indicating instability in vocal fold vibration.\n",
    "JitterDDP (Difference of Differences of Periods): More refined pitch irregularity metric.\n",
    "shimmerLocal_sma:\n",
    "\n",
    "A measure of amplitude perturbation, reflecting variability in speech loudness (e.g., voice breaks or instability).\n",
    "Turn_numOnsets and Turn_duration:\n",
    "\n",
    "Turn_numOnsets: Number of distinct voiced segments or syllables within a turn (speaking segment).\n",
    "Turn_duration: Duration of the entire turn, often used to measure speaking rate.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T15:06:50.015411900Z",
     "start_time": "2024-12-02T15:06:49.976352800Z"
    }
   },
   "execution_count": 200
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collate function in PyTorch\n",
    "\n",
    "Collate functions are functions used by PyTorch dataloader to gather batched data from dataset. It loads multiple data points from an iterable dataset object and put them in a certain format. Here we just use the lists we've constructed as the dataset and assume PyTorch dataloader will operate on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-02T19:13:09.385390Z"
    }
   },
   "outputs": [],
   "source": [
    "def multi_collate(batch):\n",
    "    '''\n",
    "    Collate functions assume batch = [Dataset[i] for i in index_set]\n",
    "    '''\n",
    "    # for later use we sort the batch in descending order of length\n",
    "    batch = sorted(batch, key=lambda x: x[0][0].shape[0], reverse=True)\n",
    "    \n",
    "    # get the data out of the batch - use pad sequence util functions from PyTorch to pad things\n",
    "    labels = torch.cat([torch.from_numpy(sample[1]) for sample in batch], dim=0)\n",
    "    sentences = pad_sequence([torch.LongTensor(sample[0][0]) for sample in batch], padding_value=PAD)\n",
    "    visual = pad_sequence([torch.FloatTensor(sample[0][1]) for sample in batch])\n",
    "    acoustic = pad_sequence([torch.FloatTensor(sample[0][2]) for sample in batch])\n",
    "    \n",
    "    # lengths are useful later in using RNNs\n",
    "    lengths = torch.LongTensor([sample[0][0].shape[0] for sample in batch])\n",
    "    return sentences, visual, acoustic, labels, lengths\n",
    "\n",
    "# construct dataloaders, dev and test could use around ~X3 times batch size since no_grad is used during eval\n",
    "batch_sz = 56\n",
    "train_loader = DataLoader(train, shuffle=True, batch_size=batch_sz, collate_fn=multi_collate)\n",
    "dev_loader = DataLoader(dev, shuffle=False, batch_size=batch_sz*3, collate_fn=multi_collate)\n",
    "test_loader = DataLoader(test, shuffle=False, batch_size=batch_sz*3, collate_fn=multi_collate)\n",
    "\n",
    "# let's create a temporary dataloader just to see how the batch looks like\n",
    "temp_loader = iter(DataLoader(test, shuffle=True, batch_size=8, collate_fn=multi_collate))\n",
    "batch = next(temp_loader)\n",
    "\n",
    "print(batch[0].shape) # word vectors, padded to maxlen\n",
    "print(batch[1].shape) # visual features\n",
    "print(batch[2].shape) # acoustic features\n",
    "print(batch[3]) # labels\n",
    "print(batch[4]) # lengths"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 2733\n"
     ]
    }
   ],
   "source": [
    "# Check how many words are in the vocabulary\n",
    "vocab_size = len(word2id)\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T15:06:56.050351500Z",
     "start_time": "2024-12-02T15:06:56.000444600Z"
    }
   },
   "execution_count": 202
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T15:06:56.411117400Z",
     "start_time": "2024-12-02T15:06:56.332065400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the the whole movie i was you know thinking this as bad as ive heard and it um\n",
      "[[1.2]]\n",
      "Dg_0XKD0Mf4[11]\n"
     ]
    }
   ],
   "source": [
    "# Let's actually inspect the transcripts to ensure it's correct\n",
    "id2word = {v:k for k, v in word2id.items()}\n",
    "examine_target = train\n",
    "idx = np.random.randint(0, len(examine_target))\n",
    "print(' '.join(list(map(lambda x: id2word[x], examine_target[idx][0][0].tolist()))))\n",
    "\n",
    "\n",
    "# print(' '.join(examine_target[idx][0]))\n",
    "print(examine_target[idx][1]) #label\n",
    "print(examine_target[idx][2]) #segment"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Text: anyhow it was really good\n",
      "Length: 5\n",
      "Label: [[2.4]]\n",
      "Segment: 03bSnISJMiM[0]\n",
      "----------------------------------------\n",
      "Example 2:\n",
      "Text: they didnt really do a whole bunch of background info on why she has to fight and be prepared\n",
      "Length: 19\n",
      "Label: [[-0.8]]\n",
      "Segment: 03bSnISJMiM[1]\n",
      "----------------------------------------\n",
      "Example 3:\n",
      "Text: i mean they did a little bit of it\n",
      "Length: 9\n",
      "Label: [[-1.]]\n",
      "Segment: 03bSnISJMiM[2]\n",
      "----------------------------------------\n",
      "Example 4:\n",
      "Text: but not a whole bunch\n",
      "Length: 5\n",
      "Label: [[-1.75]]\n",
      "Segment: 03bSnISJMiM[3]\n",
      "----------------------------------------\n",
      "Example 5:\n",
      "Text: and they i guess\n",
      "Length: 4\n",
      "Label: [[0.]]\n",
      "Segment: 03bSnISJMiM[4]\n",
      "----------------------------------------\n",
      "Example 6:\n",
      "Text: they live up with more\n",
      "Length: 5\n",
      "Label: [[0.]]\n",
      "Segment: 03bSnISJMiM[5]\n",
      "----------------------------------------\n",
      "Example 7:\n",
      "Text: and but besides that it was all over pretty good\n",
      "Length: 10\n",
      "Label: [[0.8]]\n",
      "Segment: 03bSnISJMiM[6]\n",
      "----------------------------------------\n",
      "Example 8:\n",
      "Text: and there is like someone while someone there was a lot of action\n",
      "Length: 13\n",
      "Label: [[0.]]\n",
      "Segment: 03bSnISJMiM[7]\n",
      "----------------------------------------\n",
      "Example 9:\n",
      "Text: oh my god a lot of action\n",
      "Length: 7\n",
      "Label: [[0.2]]\n",
      "Segment: 03bSnISJMiM[8]\n",
      "----------------------------------------\n",
      "Example 10:\n",
      "Text: there is sad part\n",
      "Length: 4\n",
      "Label: [[-1.2]]\n",
      "Segment: 03bSnISJMiM[9]\n",
      "----------------------------------------\n",
      "Example 11:\n",
      "Text: a lot of sad parts\n",
      "Length: 5\n",
      "Label: [[-0.5]]\n",
      "Segment: 03bSnISJMiM[10]\n",
      "----------------------------------------\n",
      "Example 12:\n",
      "Text: but it was really really awesome\n",
      "Length: 6\n",
      "Label: [[2.2]]\n",
      "Segment: 03bSnISJMiM[11]\n",
      "----------------------------------------\n",
      "Example 13:\n",
      "Text: and its a really funny\n",
      "Length: 5\n",
      "Label: [[1.8]]\n",
      "Segment: 03bSnISJMiM[12]\n",
      "----------------------------------------\n",
      "Example 14:\n",
      "Text: now the title of the movie basically says it all\n",
      "Length: 10\n",
      "Label: [[-0.4]]\n",
      "Segment: 0h-zjBukYpk[0]\n",
      "----------------------------------------\n",
      "Example 15:\n",
      "Text: now im not even gonna sugar coat this this movie frustrated me to such an extreme extent that i was loudly exclaiming why at the end of the film\n",
      "Length: 29\n",
      "Label: [[-2.8]]\n",
      "Segment: 0h-zjBukYpk[1]\n",
      "----------------------------------------\n",
      "Example 16:\n",
      "Text: my reason im a comic book fan\n",
      "Length: 7\n",
      "Label: [[-0.2]]\n",
      "Segment: 0h-zjBukYpk[2]\n",
      "----------------------------------------\n",
      "Example 17:\n",
      "Text: that like to see comic book characters treated responsibly\n",
      "Length: 9\n",
      "Label: [[-1.4]]\n",
      "Segment: 0h-zjBukYpk[3]\n",
      "----------------------------------------\n",
      "Example 18:\n",
      "Text: that huh before we go on with that i must say that this had a surprisingly decent cast\n",
      "Length: 18\n",
      "Label: [[0.8]]\n",
      "Segment: 0h-zjBukYpk[4]\n",
      "----------------------------------------\n",
      "Example 19:\n",
      "Text: strange since one of my biggest grapes with the series was and always is the now\n",
      "Length: 16\n",
      "Label: [[-1.4]]\n",
      "Segment: 0h-zjBukYpk[5]\n",
      "----------------------------------------\n",
      "Example 20:\n",
      "Text: now hugh jackman was always the best choice to play wolverine i will admit that\n",
      "Length: 15\n",
      "Label: [[1.8]]\n",
      "Segment: 0h-zjBukYpk[6]\n",
      "----------------------------------------\n",
      "Example 21:\n",
      "Text: and in my opinion he carried the movie fine\n",
      "Length: 9\n",
      "Label: [[0.8]]\n",
      "Segment: 0h-zjBukYpk[7]\n",
      "----------------------------------------\n",
      "Example 22:\n",
      "Text: you know nothing great\n",
      "Length: 4\n",
      "Label: [[-1.]]\n",
      "Segment: 0h-zjBukYpk[8]\n",
      "----------------------------------------\n",
      "Example 23:\n",
      "Text: but you know he did it\n",
      "Length: 6\n",
      "Label: [[-0.6]]\n",
      "Segment: 0h-zjBukYpk[9]\n",
      "----------------------------------------\n",
      "Example 24:\n",
      "Text: hes a star of the movie\n",
      "Length: 6\n",
      "Label: [[0.4]]\n",
      "Segment: 0h-zjBukYpk[10]\n",
      "----------------------------------------\n",
      "Example 25:\n",
      "Text: nothing special\n",
      "Length: 2\n",
      "Label: [[-0.8]]\n",
      "Segment: 0h-zjBukYpk[11]\n",
      "----------------------------------------\n",
      "Example 26:\n",
      "Text: he carried it\n",
      "Length: 3\n",
      "Label: [[1.25]]\n",
      "Segment: 0h-zjBukYpk[12]\n",
      "----------------------------------------\n",
      "Example 27:\n",
      "Text: which is a smart move since you know you have to be real comic book fan to get what hes name is supposed to be\n",
      "Length: 25\n",
      "Label: [[1.4]]\n",
      "Segment: 0h-zjBukYpk[13]\n",
      "----------------------------------------\n",
      "Example 28:\n",
      "Text: but its pretty but\n",
      "Length: 4\n",
      "Label: [[0.]]\n",
      "Segment: 0h-zjBukYpk[14]\n",
      "----------------------------------------\n",
      "Example 29:\n",
      "Text: um i actually think that schreiber is a good actor\n",
      "Length: 10\n",
      "Label: [[0.6]]\n",
      "Segment: 0h-zjBukYpk[15]\n",
      "----------------------------------------\n",
      "Example 30:\n",
      "Text: and he almost looks exactly the same as this character in defiance\n",
      "Length: 12\n",
      "Label: [[0.2]]\n",
      "Segment: 0h-zjBukYpk[16]\n",
      "----------------------------------------\n",
      "Example 31:\n",
      "Text: i mean it was like he was too lazy to take off the costume or something\n",
      "Length: 16\n",
      "Label: [[-2.]]\n",
      "Segment: 0h-zjBukYpk[17]\n",
      "----------------------------------------\n",
      "Example 32:\n",
      "Text: now other performances are borderline\n",
      "Length: 5\n",
      "Label: [[-0.4]]\n",
      "Segment: 0h-zjBukYpk[18]\n",
      "----------------------------------------\n",
      "Example 33:\n",
      "Text: ok but the two big character appearances in this movie are easily and gambit\n",
      "Length: 14\n",
      "Label: [[0.6]]\n",
      "Segment: 0h-zjBukYpk[19]\n",
      "----------------------------------------\n",
      "Example 34:\n",
      "Text: actually i liked him a lot\n",
      "Length: 6\n",
      "Label: [[2.]]\n",
      "Segment: 0h-zjBukYpk[20]\n",
      "----------------------------------------\n",
      "Example 35:\n",
      "Text: and i thought he made a good actor for the dead poor character\n",
      "Length: 13\n",
      "Label: [[1.8]]\n",
      "Segment: 0h-zjBukYpk[21]\n",
      "----------------------------------------\n",
      "Example 36:\n",
      "Text: now hes seen at the beginning that really sold me\n",
      "Length: 10\n",
      "Label: [[2.6]]\n",
      "Segment: 0h-zjBukYpk[22]\n",
      "----------------------------------------\n",
      "Example 37:\n",
      "Text: i mean that was impressive\n",
      "Length: 5\n",
      "Label: [[2.6]]\n",
      "Segment: 0h-zjBukYpk[23]\n",
      "----------------------------------------\n",
      "Example 38:\n",
      "Text: i liked that scene where he had a swords in there and theres bunch of people that are gonna shoot him boom boom boom boom take him down take him down bam bam bam bam bam take that with my magical swords\n",
      "Length: 42\n",
      "Label: [[2.2]]\n",
      "Segment: 0h-zjBukYpk[24]\n",
      "----------------------------------------\n",
      "Example 39:\n",
      "Text: but for this one i just didnt feel like it\n",
      "Length: 10\n",
      "Label: [[-2.]]\n",
      "Segment: 1DmNV9C1hbY[0]\n",
      "----------------------------------------\n",
      "Example 40:\n",
      "Text: um i loved the very first alvin and the movie\n",
      "Length: 10\n",
      "Label: [[1.6]]\n",
      "Segment: 1DmNV9C1hbY[1]\n",
      "----------------------------------------\n",
      "Example 41:\n",
      "Text: because it had a real nostalgic feel to it\n",
      "Length: 9\n",
      "Label: [[1.]]\n",
      "Segment: 1DmNV9C1hbY[2]\n",
      "----------------------------------------\n",
      "Example 42:\n",
      "Text: it reminded me of getting up on a saturday morning and eating fruit loops and um watching cartoons\n",
      "Length: 18\n",
      "Label: [[2.]]\n",
      "Segment: 1DmNV9C1hbY[3]\n",
      "----------------------------------------\n",
      "Example 43:\n",
      "Text: but you know for this one i just didnt care\n",
      "Length: 10\n",
      "Label: [[-1.8]]\n",
      "Segment: 1DmNV9C1hbY[4]\n",
      "----------------------------------------\n",
      "Example 44:\n",
      "Text: um i saw no reason why they needed to bring back the villain from the first one\n",
      "Length: 17\n",
      "Label: [[-1.6]]\n",
      "Segment: 1DmNV9C1hbY[5]\n",
      "----------------------------------------\n",
      "Example 45:\n",
      "Text: and um while the trailer made the film look real nice and cute\n",
      "Length: 13\n",
      "Label: [[-1.6]]\n",
      "Segment: 1DmNV9C1hbY[6]\n",
      "----------------------------------------\n",
      "Example 46:\n",
      "Text: it was just flat\n",
      "Length: 4\n",
      "Label: [[-1.8]]\n",
      "Segment: 1DmNV9C1hbY[7]\n",
      "----------------------------------------\n",
      "Example 47:\n",
      "Text: um im sure kids are gonna love it\n",
      "Length: 8\n",
      "Label: [[2.2]]\n",
      "Segment: 1DmNV9C1hbY[8]\n",
      "----------------------------------------\n",
      "Example 48:\n",
      "Text: kids are gonna love the film\n",
      "Length: 6\n",
      "Label: [[2.6]]\n",
      "Segment: 1DmNV9C1hbY[9]\n",
      "----------------------------------------\n",
      "Example 49:\n",
      "Text: but for me i was just a little bored\n",
      "Length: 9\n",
      "Label: [[-1.8]]\n",
      "Segment: 1DmNV9C1hbY[10]\n",
      "----------------------------------------\n",
      "Example 50:\n",
      "Text: sure there were cute money parts in the of the film\n",
      "Length: 11\n",
      "Label: [[0.4]]\n",
      "Segment: 1DmNV9C1hbY[11]\n",
      "----------------------------------------\n",
      "Example 51:\n",
      "Text: but otherwise i dont know\n",
      "Length: 5\n",
      "Label: [[-1.25]]\n",
      "Segment: 1DmNV9C1hbY[12]\n",
      "----------------------------------------\n",
      "Example 52:\n",
      "Text: i didnt even care for it\n",
      "Length: 6\n",
      "Label: [[-2.]]\n",
      "Segment: 1DmNV9C1hbY[13]\n",
      "----------------------------------------\n",
      "Example 53:\n",
      "Text: and i thought they were average\n",
      "Length: 6\n",
      "Label: [[-0.4]]\n",
      "Segment: 1iG0909rllw[0]\n",
      "----------------------------------------\n",
      "Example 54:\n",
      "Text: lets face it they are really not master pieces\n",
      "Length: 9\n",
      "Label: [[-1.75]]\n",
      "Segment: 1iG0909rllw[1]\n",
      "----------------------------------------\n",
      "Example 55:\n",
      "Text: i thought twilight directed by catherine hardwicke was actually really rather enjoyable\n",
      "Length: 12\n",
      "Label: [[2.]]\n",
      "Segment: 1iG0909rllw[2]\n",
      "----------------------------------------\n",
      "Example 56:\n",
      "Text: um i mean obviously it had its flaws\n",
      "Length: 8\n",
      "Label: [[-1.2]]\n",
      "Segment: 1iG0909rllw[3]\n",
      "----------------------------------------\n",
      "Example 57:\n",
      "Text: but i thought it was good quite good\n",
      "Length: 8\n",
      "Label: [[2.2]]\n",
      "Segment: 1iG0909rllw[4]\n",
      "----------------------------------------\n",
      "Example 58:\n",
      "Text: it was enjoyable\n",
      "Length: 3\n",
      "Label: [[1.6]]\n",
      "Segment: 1iG0909rllw[5]\n",
      "----------------------------------------\n",
      "Example 59:\n",
      "Text: i thinking on hearing that chris weitz was gonna start the new moon because of the destruction that was phillip pullman the golden thought\n",
      "Length: 24\n",
      "Label: [[-0.6]]\n",
      "Segment: 1iG0909rllw[6]\n",
      "----------------------------------------\n",
      "Example 60:\n",
      "Text: that film was awful\n",
      "Length: 4\n",
      "Label: [[-2.4]]\n",
      "Segment: 1iG0909rllw[7]\n",
      "----------------------------------------\n",
      "Example 61:\n",
      "Text: and i i really know what to expect from new moon um in terms of his direction\n",
      "Length: 17\n",
      "Label: [[-0.2]]\n",
      "Segment: 1iG0909rllw[8]\n",
      "----------------------------------------\n",
      "Example 62:\n",
      "Text: overall new moon was it was ok just average\n",
      "Length: 9\n",
      "Label: [[0.6]]\n",
      "Segment: 1iG0909rllw[9]\n",
      "----------------------------------------\n",
      "Example 63:\n",
      "Text: the thing is its a very good translation of the book\n",
      "Length: 11\n",
      "Label: [[2.2]]\n",
      "Segment: 1iG0909rllw[10]\n",
      "----------------------------------------\n",
      "Example 64:\n",
      "Text: its very very loyal to the book\n",
      "Length: 7\n",
      "Label: [[1.6]]\n",
      "Segment: 1iG0909rllw[11]\n",
      "----------------------------------------\n",
      "Example 65:\n",
      "Text: and i really appreciate that loyalty\n",
      "Length: 6\n",
      "Label: [[1.4]]\n",
      "Segment: 1iG0909rllw[12]\n",
      "----------------------------------------\n",
      "Example 66:\n",
      "Text: um however it is this loyalty to the original source that gives it its flaws\n",
      "Length: 15\n",
      "Label: [[-0.2]]\n",
      "Segment: 1iG0909rllw[13]\n",
      "----------------------------------------\n",
      "Example 67:\n",
      "Text: book is not necessarily the most thrilling book ever\n",
      "Length: 9\n",
      "Label: [[-1.4]]\n",
      "Segment: 1iG0909rllw[14]\n",
      "----------------------------------------\n",
      "Example 68:\n",
      "Text: i mean the entire is bella swan kristen stewards character around completely depressed\n",
      "Length: 13\n",
      "Label: [[-1.4]]\n",
      "Segment: 1iG0909rllw[15]\n",
      "----------------------------------------\n",
      "Example 69:\n",
      "Text: it really the best the most thrilling read ever ill say that\n",
      "Length: 12\n",
      "Label: [[-1.4]]\n",
      "Segment: 1iG0909rllw[16]\n",
      "----------------------------------------\n",
      "Example 70:\n",
      "Text: so moon even with the bigger better budgets huh it was still too long\n",
      "Length: 14\n",
      "Label: [[-1.8]]\n",
      "Segment: 1iG0909rllw[17]\n",
      "----------------------------------------\n",
      "Example 71:\n",
      "Text: the too moments withdrawn out to the max as far as can go\n",
      "Length: 13\n",
      "Label: [[-1.]]\n",
      "Segment: 1iG0909rllw[18]\n",
      "----------------------------------------\n",
      "Example 72:\n",
      "Text: and the script it left all the key plots and emotion from the characters to be exposed through dialogue\n",
      "Length: 19\n",
      "Label: [[0.4]]\n",
      "Segment: 1iG0909rllw[19]\n",
      "----------------------------------------\n",
      "Example 73:\n",
      "Text: i think it was empire magazines review of new moon that said that kristen relied heavily on the tactic of tactic of blinking a lot which she really does do a lot\n",
      "Length: 32\n",
      "Label: [[-0.4]]\n",
      "Segment: 1iG0909rllw[20]\n",
      "----------------------------------------\n",
      "Example 74:\n",
      "Text: but at the same goes for rob pattinson as edward and taylor lautner as jacob they do a lot of frowning im a manly man and i frown\n",
      "Length: 28\n",
      "Label: [[-0.2]]\n",
      "Segment: 1iG0909rllw[21]\n",
      "----------------------------------------\n",
      "Example 75:\n",
      "Text: for the moment in this the whole cinema was and\n",
      "Length: 10\n",
      "Label: [[1.8]]\n",
      "Segment: 1iG0909rllw[22]\n",
      "----------------------------------------\n",
      "Example 76:\n",
      "Text: and you knew you be laughing\n",
      "Length: 6\n",
      "Label: [[-1.]]\n",
      "Segment: 1iG0909rllw[23]\n",
      "----------------------------------------\n",
      "Example 77:\n",
      "Text: my favorite scene would be the um\n",
      "Length: 7\n",
      "Label: [[2.]]\n",
      "Segment: 1iG0909rllw[24]\n",
      "----------------------------------------\n",
      "Example 78:\n",
      "Text: um then my wins on screen i mean they were really worn in a lots which is a shame because i thought really rather good\n",
      "Length: 25\n",
      "Label: [[-0.6]]\n",
      "Segment: 1iG0909rllw[25]\n",
      "----------------------------------------\n",
      "Example 79:\n",
      "Text: and um michael sheen as aro as well he was rather enjoyable to watch\n",
      "Length: 14\n",
      "Label: [[1.8]]\n",
      "Segment: 1iG0909rllw[26]\n",
      "----------------------------------------\n",
      "Example 80:\n",
      "Text: and i think the that was my exciting bit of the entire film\n",
      "Length: 13\n",
      "Label: [[1.2]]\n",
      "Segment: 1iG0909rllw[27]\n",
      "----------------------------------------\n",
      "Example 81:\n",
      "Text: the rest of the film was just watching kristen just mob around\n",
      "Length: 12\n",
      "Label: [[-1.4]]\n",
      "Segment: 1iG0909rllw[28]\n",
      "----------------------------------------\n",
      "Example 82:\n",
      "Text: and that was really boring\n",
      "Length: 5\n",
      "Label: [[-1.6]]\n",
      "Segment: 1iG0909rllw[29]\n",
      "----------------------------------------\n",
      "Example 83:\n",
      "Text: much say that i really enjoyed cowboys and aliens\n",
      "Length: 9\n",
      "Label: [[2.]]\n",
      "Segment: 2WGyTLYerpo[0]\n",
      "----------------------------------------\n",
      "Example 84:\n",
      "Text: there was a lot of fun\n",
      "Length: 6\n",
      "Label: [[0.4]]\n",
      "Segment: 2WGyTLYerpo[1]\n",
      "----------------------------------------\n",
      "Example 85:\n",
      "Text: you guys dont know what youre gonna go and see when you go walk into the movie called cowboys and aliens\n",
      "Length: 21\n",
      "Label: [[0.]]\n",
      "Segment: 2WGyTLYerpo[2]\n",
      "----------------------------------------\n",
      "Example 86:\n",
      "Text: if youre expecting some artsy serious oscar contender than youre wrong\n",
      "Length: 11\n",
      "Label: [[-0.4]]\n",
      "Segment: 2WGyTLYerpo[3]\n",
      "----------------------------------------\n",
      "Example 87:\n",
      "Text: the only oscar that i can even thing of is maybe like best cinematography\n",
      "Length: 14\n",
      "Label: [[0.]]\n",
      "Segment: 2WGyTLYerpo[4]\n",
      "----------------------------------------\n",
      "Example 88:\n",
      "Text: because the cinematography in this movie is great\n",
      "Length: 8\n",
      "Label: [[2.4]]\n",
      "Segment: 2WGyTLYerpo[5]\n",
      "----------------------------------------\n",
      "Example 89:\n",
      "Text: and maybe best visual effects\n",
      "Length: 5\n",
      "Label: [[1.6]]\n",
      "Segment: 2WGyTLYerpo[6]\n",
      "----------------------------------------\n",
      "Example 90:\n",
      "Text: coz the visual effects are pretty cool\n",
      "Length: 7\n",
      "Label: [[1.8]]\n",
      "Segment: 2WGyTLYerpo[7]\n",
      "----------------------------------------\n",
      "Example 91:\n",
      "Text: but again you you cant expect a huge like surreal mind bender from the movie called cowboys and aliens yo\n",
      "Length: 20\n",
      "Label: [[-0.4]]\n",
      "Segment: 2WGyTLYerpo[8]\n",
      "----------------------------------------\n",
      "Example 92:\n",
      "Text: and its satisfactory\n",
      "Length: 3\n",
      "Label: [[0.8]]\n",
      "Segment: 2WGyTLYerpo[9]\n",
      "----------------------------------------\n",
      "Example 93:\n",
      "Text: the action is really intense which surprised me\n",
      "Length: 8\n",
      "Label: [[2.2]]\n",
      "Segment: 2WGyTLYerpo[10]\n",
      "----------------------------------------\n",
      "Example 94:\n",
      "Text: i didnt expect the action to be so intense\n",
      "Length: 9\n",
      "Label: [[1.2]]\n",
      "Segment: 2WGyTLYerpo[11]\n",
      "----------------------------------------\n",
      "Example 95:\n",
      "Text: theres some really intense action scenes especially the scene when the aliens first invade\n",
      "Length: 14\n",
      "Label: [[2.]]\n",
      "Segment: 2WGyTLYerpo[12]\n",
      "----------------------------------------\n",
      "Example 96:\n",
      "Text: that scene is like crazy\n",
      "Length: 5\n",
      "Label: [[0.2]]\n",
      "Segment: 2WGyTLYerpo[13]\n",
      "----------------------------------------\n",
      "Example 97:\n",
      "Text: it gave me chills\n",
      "Length: 4\n",
      "Label: [[0.5]]\n",
      "Segment: 2WGyTLYerpo[14]\n",
      "----------------------------------------\n",
      "Example 98:\n",
      "Text: i its a lot of fun\n",
      "Length: 6\n",
      "Label: [[2.]]\n",
      "Segment: 2WGyTLYerpo[15]\n",
      "----------------------------------------\n",
      "Example 99:\n",
      "Text: the action is really cool\n",
      "Length: 5\n",
      "Label: [[2.6]]\n",
      "Segment: 2WGyTLYerpo[16]\n",
      "----------------------------------------\n",
      "Example 100:\n",
      "Text: the aliens are really cool\n",
      "Length: 5\n",
      "Label: [[2.2]]\n",
      "Segment: 2WGyTLYerpo[17]\n",
      "----------------------------------------\n",
      "Example 101:\n",
      "Text: one thing i like with the aliens is that a they are not just weak links that hide behind the technology\n",
      "Length: 21\n",
      "Label: [[1.4]]\n",
      "Segment: 2WGyTLYerpo[18]\n",
      "----------------------------------------\n",
      "Example 102:\n",
      "Text: they are huge\n",
      "Length: 3\n",
      "Label: [[1.]]\n",
      "Segment: 2WGyTLYerpo[19]\n",
      "----------------------------------------\n",
      "Example 103:\n",
      "Text: theyre really strong\n",
      "Length: 3\n",
      "Label: [[0.8]]\n",
      "Segment: 2WGyTLYerpo[20]\n",
      "----------------------------------------\n",
      "Example 104:\n",
      "Text: and theyre kind of scary looking\n",
      "Length: 6\n",
      "Label: [[-0.8]]\n",
      "Segment: 2WGyTLYerpo[21]\n",
      "----------------------------------------\n",
      "Example 105:\n",
      "Text: i didnt expect that\n",
      "Length: 4\n",
      "Label: [[0.]]\n",
      "Segment: 2WGyTLYerpo[22]\n",
      "----------------------------------------\n",
      "Example 106:\n",
      "Text: and also i like how its kind of upfront to show them to us instead of hiding them like showing a little like an arm on scene or something no they just straight up show it to us\n",
      "Length: 38\n",
      "Label: [[1.6]]\n",
      "Segment: 2WGyTLYerpo[23]\n",
      "----------------------------------------\n",
      "Example 107:\n",
      "Text: and i really enjoyed that\n",
      "Length: 5\n",
      "Label: [[1.8]]\n",
      "Segment: 2WGyTLYerpo[24]\n",
      "----------------------------------------\n",
      "Example 108:\n",
      "Text: i it was really cool when they did that\n",
      "Length: 9\n",
      "Label: [[1.8]]\n",
      "Segment: 2WGyTLYerpo[25]\n",
      "----------------------------------------\n",
      "Example 109:\n",
      "Text: coz the aliens were really cool looking\n",
      "Length: 7\n",
      "Label: [[1.8]]\n",
      "Segment: 2WGyTLYerpo[26]\n",
      "----------------------------------------\n",
      "Example 110:\n",
      "Text: daniel craig does a very good job here\n",
      "Length: 8\n",
      "Label: [[2.4]]\n",
      "Segment: 2WGyTLYerpo[27]\n",
      "----------------------------------------\n",
      "Example 111:\n",
      "Text: he kind of channels the man with no name clint eastwood\n",
      "Length: 11\n",
      "Label: [[0.6]]\n",
      "Segment: 2WGyTLYerpo[28]\n",
      "----------------------------------------\n",
      "Example 112:\n",
      "Text: and a lot of people have been saying that\n",
      "Length: 9\n",
      "Label: [[-0.2]]\n",
      "Segment: 2WGyTLYerpo[29]\n",
      "----------------------------------------\n",
      "Example 113:\n",
      "Text: i think he does a great job at what he does\n",
      "Length: 11\n",
      "Label: [[2.]]\n",
      "Segment: 2WGyTLYerpo[30]\n",
      "----------------------------------------\n",
      "Example 114:\n",
      "Text: hes a really bad ass\n",
      "Length: 5\n",
      "Label: [[2.2]]\n",
      "Segment: 2WGyTLYerpo[31]\n",
      "----------------------------------------\n",
      "Example 115:\n",
      "Text: is really really hard core\n",
      "Length: 5\n",
      "Label: [[1.2]]\n",
      "Segment: 2WGyTLYerpo[32]\n",
      "----------------------------------------\n",
      "Example 116:\n",
      "Text: he doesnt take crap from anybody\n",
      "Length: 6\n",
      "Label: [[0.6]]\n",
      "Segment: 2WGyTLYerpo[33]\n",
      "----------------------------------------\n",
      "Example 117:\n",
      "Text: and he does a really good job\n",
      "Length: 7\n",
      "Label: [[2.2]]\n",
      "Segment: 2WGyTLYerpo[34]\n",
      "----------------------------------------\n",
      "Example 118:\n",
      "Text: also his innocent accent is pretty convincing\n",
      "Length: 7\n",
      "Label: [[1.2]]\n",
      "Segment: 2WGyTLYerpo[35]\n",
      "----------------------------------------\n",
      "Example 119:\n",
      "Text: harrison ford is also good\n",
      "Length: 5\n",
      "Label: [[1.4]]\n",
      "Segment: 2WGyTLYerpo[36]\n",
      "----------------------------------------\n",
      "Example 120:\n",
      "Text: hes he gives an entertaining performance as the kind of like the leader the of the town\n",
      "Length: 17\n",
      "Label: [[1.]]\n",
      "Segment: 2WGyTLYerpo[37]\n",
      "----------------------------------------\n",
      "Example 121:\n",
      "Text: at first hes just kind of like grumpy old guy\n",
      "Length: 10\n",
      "Label: [[-0.6]]\n",
      "Segment: 2WGyTLYerpo[38]\n",
      "----------------------------------------\n",
      "Example 122:\n",
      "Text: but he becomes more likeable\n",
      "Length: 5\n",
      "Label: [[0.6]]\n",
      "Segment: 2WGyTLYerpo[39]\n",
      "----------------------------------------\n",
      "Example 123:\n",
      "Text: his guts developed more as more likeable character\n",
      "Length: 8\n",
      "Label: [[0.6]]\n",
      "Segment: 2WGyTLYerpo[40]\n",
      "----------------------------------------\n",
      "Example 124:\n",
      "Text: so you can care about him\n",
      "Length: 6\n",
      "Label: [[0.]]\n",
      "Segment: 2WGyTLYerpo[41]\n",
      "----------------------------------------\n",
      "Example 125:\n",
      "Text: and olivia wild pretty good\n",
      "Length: 5\n",
      "Label: [[2.]]\n",
      "Segment: 2WGyTLYerpo[42]\n",
      "----------------------------------------\n",
      "Example 126:\n",
      "Text: and not a bad actor\n",
      "Length: 5\n",
      "Label: [[0.2]]\n",
      "Segment: 2WGyTLYerpo[44]\n",
      "----------------------------------------\n",
      "Example 127:\n",
      "Text: actually pretty good\n",
      "Length: 3\n",
      "Label: [[1.4]]\n",
      "Segment: 2WGyTLYerpo[45]\n",
      "----------------------------------------\n",
      "Example 128:\n",
      "Text: everything nowadays\n",
      "Length: 2\n",
      "Label: [[0.]]\n",
      "Segment: 2WGyTLYerpo[46]\n",
      "----------------------------------------\n",
      "Example 129:\n",
      "Text: there are some flaws here\n",
      "Length: 5\n",
      "Label: [[-1.]]\n",
      "Segment: 2WGyTLYerpo[47]\n",
      "----------------------------------------\n",
      "Example 130:\n",
      "Text: and there but theyre not huge glaring flaws\n",
      "Length: 8\n",
      "Label: [[-0.6]]\n",
      "Segment: 2WGyTLYerpo[48]\n",
      "----------------------------------------\n",
      "Example 131:\n",
      "Text: but they are flaws\n",
      "Length: 4\n",
      "Label: [[-1.8]]\n",
      "Segment: 2WGyTLYerpo[49]\n",
      "----------------------------------------\n",
      "Example 132:\n",
      "Text: such as sometimes the aliens in the western setting do look a little goofy\n",
      "Length: 14\n",
      "Label: [[-0.6]]\n",
      "Segment: 2WGyTLYerpo[50]\n",
      "----------------------------------------\n",
      "Example 133:\n",
      "Text: but i was kind of expecting that\n",
      "Length: 7\n",
      "Label: [[0.]]\n",
      "Segment: 2WGyTLYerpo[51]\n",
      "----------------------------------------\n",
      "Example 134:\n",
      "Text: i a huge fan of it\n",
      "Length: 6\n",
      "Label: [[-1.]]\n",
      "Segment: 2WGyTLYerpo[52]\n",
      "----------------------------------------\n",
      "Example 135:\n",
      "Text: i just thought it was kind of stupid\n",
      "Length: 8\n",
      "Label: [[-2.]]\n",
      "Segment: 2WGyTLYerpo[53]\n",
      "----------------------------------------\n",
      "Example 136:\n",
      "Text: and sometimes it kind of veers into cliche action movie territory\n",
      "Length: 11\n",
      "Label: [[-1.]]\n",
      "Segment: 2WGyTLYerpo[54]\n",
      "----------------------------------------\n",
      "Example 137:\n",
      "Text: like a movie called cowboys and aliens a lot of people would think would be kind of like crazy\n",
      "Length: 19\n",
      "Label: [[-0.4]]\n",
      "Segment: 2WGyTLYerpo[55]\n",
      "----------------------------------------\n",
      "Example 138:\n",
      "Text: but sometimes it just veers entirely cliche action movie territory again\n",
      "Length: 11\n",
      "Label: [[-1.6]]\n",
      "Segment: 2WGyTLYerpo[56]\n",
      "----------------------------------------\n",
      "Example 139:\n",
      "Text: not a huge flaw but its there and its overall\n",
      "Length: 10\n",
      "Label: [[-1.4]]\n",
      "Segment: 2WGyTLYerpo[57]\n",
      "----------------------------------------\n",
      "Example 140:\n",
      "Text: overall i really enjoyed cowboys and aliens\n",
      "Length: 7\n",
      "Label: [[2.]]\n",
      "Segment: 2WGyTLYerpo[58]\n",
      "----------------------------------------\n",
      "Example 141:\n",
      "Text: and im gonna give it an eight out of ten\n",
      "Length: 10\n",
      "Label: [[2.2]]\n",
      "Segment: 2WGyTLYerpo[59]\n",
      "----------------------------------------\n",
      "Example 142:\n",
      "Text: it was really fun\n",
      "Length: 4\n",
      "Label: [[1.4]]\n",
      "Segment: 2WGyTLYerpo[60]\n",
      "----------------------------------------\n",
      "Example 143:\n",
      "Text: a very good time\n",
      "Length: 4\n",
      "Label: [[2.2]]\n",
      "Segment: 2WGyTLYerpo[61]\n",
      "----------------------------------------\n",
      "Example 144:\n",
      "Text: and i recommend you check it out in theaters\n",
      "Length: 9\n",
      "Label: [[2.2]]\n",
      "Segment: 2WGyTLYerpo[62]\n",
      "----------------------------------------\n",
      "Example 145:\n",
      "Text: before i went in to see the green lantern ive been hearing all these like critics basically just trashing this movie left and right\n",
      "Length: 24\n",
      "Label: [[-0.5]]\n",
      "Segment: 2iD-tVS8NPw[0]\n",
      "----------------------------------------\n",
      "Example 146:\n",
      "Text: but i at the same time i do wanna just say that i enjoyed this movie\n",
      "Length: 16\n",
      "Label: [[2.2]]\n",
      "Segment: 2iD-tVS8NPw[1]\n",
      "----------------------------------------\n",
      "Example 147:\n",
      "Text: i enjoyed it for what it was you know\n",
      "Length: 9\n",
      "Label: [[1.4]]\n",
      "Segment: 2iD-tVS8NPw[2]\n",
      "----------------------------------------\n",
      "Example 148:\n",
      "Text: its a huge sort of spectacle movie that is great for this summer time you know\n",
      "Length: 16\n",
      "Label: [[2.2]]\n",
      "Segment: 2iD-tVS8NPw[3]\n",
      "----------------------------------------\n",
      "Example 149:\n",
      "Text: this is a movie that youre gonna go out and see\n",
      "Length: 11\n",
      "Label: [[2.]]\n",
      "Segment: 2iD-tVS8NPw[4]\n",
      "----------------------------------------\n",
      "Example 150:\n",
      "Text: and you wanna see it in because\n",
      "Length: 7\n",
      "Label: [[2.]]\n",
      "Segment: 2iD-tVS8NPw[5]\n",
      "----------------------------------------\n",
      "Example 151:\n",
      "Text: because i i would actually say this probably is one of the first movies this year that ive seen this year that you wanna see in especially for just the opening portion\n",
      "Length: 32\n",
      "Label: [[2.4]]\n",
      "Segment: 2iD-tVS8NPw[6]\n",
      "----------------------------------------\n",
      "Example 152:\n",
      "Text: it looks really good\n",
      "Length: 4\n",
      "Label: [[1.8]]\n",
      "Segment: 2iD-tVS8NPw[7]\n",
      "----------------------------------------\n",
      "Example 153:\n",
      "Text: and the rest of it does look good as well\n",
      "Length: 10\n",
      "Label: [[1.4]]\n",
      "Segment: 2iD-tVS8NPw[8]\n",
      "----------------------------------------\n",
      "Example 154:\n",
      "Text: and i just had fun watching this movie\n",
      "Length: 8\n",
      "Label: [[2.2]]\n",
      "Segment: 2iD-tVS8NPw[9]\n",
      "----------------------------------------\n",
      "Example 155:\n",
      "Text: its not like a dark movie or anything\n",
      "Length: 8\n",
      "Label: [[0.2]]\n",
      "Segment: 2iD-tVS8NPw[10]\n",
      "----------------------------------------\n",
      "Example 156:\n",
      "Text: its very much a light hearted\n",
      "Length: 6\n",
      "Label: [[1.2]]\n",
      "Segment: 2iD-tVS8NPw[11]\n",
      "----------------------------------------\n",
      "Example 157:\n",
      "Text: so its perfect for kids as well as just like teenagers as well who just wanna see a lot of explosions and some crazy stuff\n",
      "Length: 25\n",
      "Label: [[2.2]]\n",
      "Segment: 2iD-tVS8NPw[12]\n",
      "----------------------------------------\n",
      "Example 158:\n",
      "Text: and you know going into it or these watching the trailers before head i was really kind of hesitant about seeing the green lantern in the first place\n",
      "Length: 28\n",
      "Label: [[-1.]]\n",
      "Segment: 2iD-tVS8NPw[13]\n",
      "----------------------------------------\n",
      "Example 159:\n",
      "Text: because it looks like a cartoon\n",
      "Length: 6\n",
      "Label: [[-1.5]]\n",
      "Segment: 2iD-tVS8NPw[14]\n",
      "----------------------------------------\n",
      "Example 160:\n",
      "Text: im not really a huge fan of having like all these characters\n",
      "Length: 12\n",
      "Label: [[-1.6]]\n",
      "Segment: 2iD-tVS8NPw[15]\n",
      "----------------------------------------\n",
      "Example 161:\n",
      "Text: because i think why not just make this you know movie this live action movie and talk cartoon\n",
      "Length: 18\n",
      "Label: [[-0.6]]\n",
      "Segment: 2iD-tVS8NPw[16]\n",
      "----------------------------------------\n",
      "Example 162:\n",
      "Text: thats really the that youre gonna go\n",
      "Length: 7\n",
      "Label: [[0.33333334]]\n",
      "Segment: 2iD-tVS8NPw[17]\n",
      "----------------------------------------\n",
      "Example 163:\n",
      "Text: and it seemed like they were gonna go that but\n",
      "Length: 10\n",
      "Label: [[0.]]\n",
      "Segment: 2iD-tVS8NPw[18]\n",
      "----------------------------------------\n",
      "Example 164:\n",
      "Text: but i think there was also some sort of like um tone within the actual um powers of the green lantern and himself and that you can basically think up of anything and you can project that into the real life\n",
      "Length: 41\n",
      "Label: [[0.8]]\n",
      "Segment: 2iD-tVS8NPw[19]\n",
      "----------------------------------------\n",
      "Example 165:\n",
      "Text: and i think having this sort of superpower almost this power to just imagine anything kind of just um helped me get passed that you know these are all characters and set\n",
      "Length: 32\n",
      "Label: [[1.]]\n",
      "Segment: 2iD-tVS8NPw[20]\n",
      "----------------------------------------\n",
      "Example 166:\n",
      "Text: this is a playground and their imaginary playground and anything can happen anything that what also made the film exciting\n",
      "Length: 20\n",
      "Label: [[2.2]]\n",
      "Segment: 2iD-tVS8NPw[21]\n",
      "----------------------------------------\n",
      "Example 167:\n",
      "Text: because you dont entirely know whats coming next\n",
      "Length: 8\n",
      "Label: [[0.2]]\n",
      "Segment: 2iD-tVS8NPw[22]\n",
      "----------------------------------------\n",
      "Example 168:\n",
      "Text: but then you kind of like walk out of the movie and youre like well i i get what happened i understand what happened\n",
      "Length: 24\n",
      "Label: [[-1.]]\n",
      "Segment: 2iD-tVS8NPw[23]\n",
      "----------------------------------------\n",
      "Example 169:\n",
      "Text: but what what would you do for green lantern movie that would be even like worth while now\n",
      "Length: 18\n",
      "Label: [[-0.8]]\n",
      "Segment: 2iD-tVS8NPw[24]\n",
      "----------------------------------------\n",
      "Example 170:\n",
      "Text: because i mean if hes able to do all of this sort of stuff like how youre supposed to really put up a force that can push him to the next level or or destroy him at the same time\n",
      "Length: 40\n",
      "Label: [[0.]]\n",
      "Segment: 2iD-tVS8NPw[25]\n",
      "----------------------------------------\n",
      "Example 171:\n",
      "Text: and it does kind of a lea helps alleviate what that whole was is about fighting the ultimate enemy within this first movie and that the threat is still there potentially speaking\n",
      "Length: 32\n",
      "Label: [[1.4]]\n",
      "Segment: 2iD-tVS8NPw[26]\n",
      "----------------------------------------\n",
      "Example 172:\n",
      "Text: so its kind of interesting to see um where theyre gonna be going with that\n",
      "Length: 15\n",
      "Label: [[1.6]]\n",
      "Segment: 2iD-tVS8NPw[27]\n",
      "----------------------------------------\n",
      "Example 173:\n",
      "Text: im looking forward to it ive got to say\n",
      "Length: 9\n",
      "Label: [[2.]]\n",
      "Segment: 2iD-tVS8NPw[28]\n",
      "----------------------------------------\n",
      "Example 174:\n",
      "Text: its not like the green lantern is the next batman begins or or the dark\n",
      "Length: 15\n",
      "Label: [[-0.4]]\n",
      "Segment: 2iD-tVS8NPw[29]\n",
      "----------------------------------------\n",
      "Example 175:\n",
      "Text: probably one of the probably one of the sundance um\n",
      "Length: 10\n",
      "Label: [[2.]]\n",
      "Segment: 5W7Z1C_fDaE[0]\n",
      "----------------------------------------\n",
      "Example 176:\n",
      "Text: um as really the best way to describe this film is its big\n",
      "Length: 13\n",
      "Label: [[1.4]]\n",
      "Segment: 5W7Z1C_fDaE[1]\n",
      "----------------------------------------\n",
      "Example 177:\n",
      "Text: its bold\n",
      "Length: 2\n",
      "Label: [[0.8]]\n",
      "Segment: 5W7Z1C_fDaE[2]\n",
      "----------------------------------------\n",
      "Example 178:\n",
      "Text: its strong\n",
      "Length: 2\n",
      "Label: [[0.4]]\n",
      "Segment: 5W7Z1C_fDaE[3]\n",
      "----------------------------------------\n",
      "Example 179:\n",
      "Text: it makes big statements\n",
      "Length: 4\n",
      "Label: [[2.]]\n",
      "Segment: 5W7Z1C_fDaE[4]\n",
      "----------------------------------------\n",
      "Example 180:\n",
      "Text: it doesnt hold back\n",
      "Length: 4\n",
      "Label: [[0.5]]\n",
      "Segment: 5W7Z1C_fDaE[5]\n",
      "----------------------------------------\n",
      "Example 181:\n",
      "Text: everything from the way its being released to the performances and to the story itself is absolutely the top impressive\n",
      "Length: 20\n",
      "Label: [[2.2]]\n",
      "Segment: 5W7Z1C_fDaE[6]\n",
      "----------------------------------------\n",
      "Example 182:\n",
      "Text: and really well done\n",
      "Length: 4\n",
      "Label: [[2.6]]\n",
      "Segment: 5W7Z1C_fDaE[7]\n",
      "----------------------------------------\n",
      "Example 183:\n",
      "Text: its a huge break through for kevin smith\n",
      "Length: 8\n",
      "Label: [[2.4]]\n",
      "Segment: 5W7Z1C_fDaE[8]\n",
      "----------------------------------------\n",
      "Example 184:\n",
      "Text: its completely different from anything weve ever seen him do before\n",
      "Length: 11\n",
      "Label: [[0.4]]\n",
      "Segment: 5W7Z1C_fDaE[9]\n",
      "----------------------------------------\n",
      "Example 185:\n",
      "Text: john goodman absolutely amazing\n",
      "Length: 4\n",
      "Label: [[2.6]]\n",
      "Segment: 5W7Z1C_fDaE[10]\n",
      "----------------------------------------\n",
      "Example 186:\n",
      "Text: melissa leo will have you out to your inner core with her tiny little smile\n",
      "Length: 15\n",
      "Label: [[0.8]]\n",
      "Segment: 5W7Z1C_fDaE[11]\n",
      "----------------------------------------\n",
      "Example 187:\n",
      "Text: its so well done\n",
      "Length: 4\n",
      "Label: [[2.6]]\n",
      "Segment: 5W7Z1C_fDaE[12]\n",
      "----------------------------------------\n",
      "Example 188:\n",
      "Text: for all of those people who are hating on it i dont know what they are complaining about it\n",
      "Length: 19\n",
      "Label: [[1.8]]\n",
      "Segment: 5W7Z1C_fDaE[13]\n",
      "----------------------------------------\n",
      "Example 189:\n",
      "Text: its a horror film ia a true sense\n",
      "Length: 8\n",
      "Label: [[0.25]]\n",
      "Segment: 5W7Z1C_fDaE[14]\n",
      "----------------------------------------\n",
      "Example 190:\n",
      "Text: and it is absolutely horrifying\n",
      "Length: 5\n",
      "Label: [[-2.]]\n",
      "Segment: 5W7Z1C_fDaE[15]\n",
      "----------------------------------------\n",
      "Example 191:\n",
      "Text: um it is it is one of those films thats not gonna be easy for you to find\n",
      "Length: 18\n",
      "Label: [[0.2]]\n",
      "Segment: 5W7Z1C_fDaE[16]\n",
      "----------------------------------------\n",
      "Example 192:\n",
      "Text: its being released in a very interesting way\n",
      "Length: 8\n",
      "Label: [[1.2]]\n",
      "Segment: 5W7Z1C_fDaE[17]\n",
      "----------------------------------------\n",
      "Example 193:\n",
      "Text: whenever it comes to your town do not miss it\n",
      "Length: 10\n",
      "Label: [[2.8]]\n",
      "Segment: 5W7Z1C_fDaE[18]\n",
      "----------------------------------------\n",
      "Example 194:\n",
      "Text: its well made\n",
      "Length: 3\n",
      "Label: [[2.8]]\n",
      "Segment: 5W7Z1C_fDaE[19]\n",
      "----------------------------------------\n",
      "Example 195:\n",
      "Text: its dare i say fun to watch in a really messed up kind of way\n",
      "Length: 15\n",
      "Label: [[2.]]\n",
      "Segment: 5W7Z1C_fDaE[20]\n",
      "----------------------------------------\n",
      "Example 196:\n",
      "Text: its dare i say fun to watch in a really messed up kind of way and even now its a horror film\n",
      "Length: 22\n",
      "Label: [[1.6]]\n",
      "Segment: 5W7Z1C_fDaE[21]\n",
      "----------------------------------------\n",
      "Example 197:\n",
      "Text: its got some fun kevin smith moments in it for you to laugh with um\n",
      "Length: 15\n",
      "Label: [[1.8]]\n",
      "Segment: 5W7Z1C_fDaE[22]\n",
      "----------------------------------------\n",
      "Example 198:\n",
      "Text: absolutely not to be\n",
      "Length: 4\n",
      "Label: [[2.4]]\n",
      "Segment: 5W7Z1C_fDaE[23]\n",
      "----------------------------------------\n",
      "Example 199:\n",
      "Text: i just got finished watching an excellent movie called mars needs moms\n",
      "Length: 12\n",
      "Label: [[3.]]\n",
      "Segment: 6Egk_28TtTM[0]\n",
      "----------------------------------------\n",
      "Example 200:\n",
      "Text: and my favorite characters in the movie would have to be milo milos mother and gribble\n",
      "Length: 16\n",
      "Label: [[2.]]\n",
      "Segment: 6Egk_28TtTM[1]\n",
      "----------------------------------------\n",
      "Example 201:\n",
      "Text: i liked gribble because he helped milo get milos mother away from the which\n",
      "Length: 14\n",
      "Label: [[1.8]]\n",
      "Segment: 6Egk_28TtTM[2]\n",
      "----------------------------------------\n",
      "Example 202:\n",
      "Text: which i thought was awesome\n",
      "Length: 5\n",
      "Label: [[2.8]]\n",
      "Segment: 6Egk_28TtTM[3]\n",
      "----------------------------------------\n",
      "Example 203:\n",
      "Text: and my favorite part in the movie was when milo has to save gribble\n",
      "Length: 14\n",
      "Label: [[2.2]]\n",
      "Segment: 6Egk_28TtTM[4]\n",
      "----------------------------------------\n",
      "Example 204:\n",
      "Text: and i would recommend this movie for ages and up\n",
      "Length: 10\n",
      "Label: [[2.]]\n",
      "Segment: 6Egk_28TtTM[5]\n",
      "----------------------------------------\n",
      "Example 205:\n",
      "Text: because it is a good movie\n",
      "Length: 6\n",
      "Label: [[2.2]]\n",
      "Segment: 6Egk_28TtTM[6]\n",
      "----------------------------------------\n",
      "Example 206:\n",
      "Text: and it depends what age you are and how you to how you feel like see the movie\n",
      "Length: 18\n",
      "Label: [[0.8]]\n",
      "Segment: 6Egk_28TtTM[7]\n",
      "----------------------------------------\n",
      "Example 207:\n",
      "Text: like for example my brother is five years old and he didnt think this movie was scary at all\n",
      "Length: 19\n",
      "Label: [[-0.4]]\n",
      "Segment: 6Egk_28TtTM[8]\n",
      "----------------------------------------\n",
      "Example 208:\n",
      "Text: i am eight years old and i thought it was really s kind of scary\n",
      "Length: 15\n",
      "Label: [[0.6]]\n",
      "Segment: 6Egk_28TtTM[9]\n",
      "----------------------------------------\n",
      "Example 209:\n",
      "Text: and i think i why i would be scared is because i would feel scared and kind of sad if i lost my own mother\n",
      "Length: 25\n",
      "Label: [[-1.2]]\n",
      "Segment: 6Egk_28TtTM[10]\n",
      "----------------------------------------\n",
      "Example 210:\n",
      "Text: but it all turns out great in the end\n",
      "Length: 9\n",
      "Label: [[2.4]]\n",
      "Segment: 6Egk_28TtTM[11]\n",
      "----------------------------------------\n",
      "Example 211:\n",
      "Text: and so i was kind of curious to see maybe if that was what disney was going for and it was what were going for\n",
      "Length: 25\n",
      "Label: [[1.6]]\n",
      "Segment: 6_0THN4chvY[0]\n",
      "----------------------------------------\n",
      "Example 212:\n",
      "Text: but i bet if you put them next to the new film that the style would be similar enough that you wouldnt be able to really tell what the difference is\n",
      "Length: 31\n",
      "Label: [[0.6]]\n",
      "Segment: 6_0THN4chvY[1]\n",
      "----------------------------------------\n",
      "Example 213:\n",
      "Text: um its its great if you remember that was old films\n",
      "Length: 11\n",
      "Label: [[2.]]\n",
      "Segment: 6_0THN4chvY[2]\n",
      "----------------------------------------\n",
      "Example 214:\n",
      "Text: would be great for kids too\n",
      "Length: 6\n",
      "Label: [[2.]]\n",
      "Segment: 6_0THN4chvY[3]\n",
      "----------------------------------------\n",
      "Example 215:\n",
      "Text: the story is pretty simple\n",
      "Length: 5\n",
      "Label: [[0.]]\n",
      "Segment: 6_0THN4chvY[4]\n",
      "----------------------------------------\n",
      "Example 216:\n",
      "Text: weve got great jokes\n",
      "Length: 4\n",
      "Label: [[1.6]]\n",
      "Segment: 6_0THN4chvY[5]\n",
      "----------------------------------------\n",
      "Example 217:\n",
      "Text: um funny jokes that the kids would get\n",
      "Length: 8\n",
      "Label: [[0.8]]\n",
      "Segment: 6_0THN4chvY[6]\n",
      "----------------------------------------\n",
      "Example 218:\n",
      "Text: um i love the scene where and pooh think that owl is getting sick\n",
      "Length: 14\n",
      "Label: [[2.]]\n",
      "Segment: 6_0THN4chvY[7]\n",
      "----------------------------------------\n",
      "Example 219:\n",
      "Text: because he says issue and they think he is saying at you\n",
      "Length: 12\n",
      "Label: [[-0.6]]\n",
      "Segment: 6_0THN4chvY[8]\n",
      "----------------------------------------\n",
      "Example 220:\n",
      "Text: um that was probably part of the trailer that got me to go and see the movie\n",
      "Length: 17\n",
      "Label: [[0.4]]\n",
      "Segment: 6_0THN4chvY[9]\n",
      "----------------------------------------\n",
      "Example 221:\n",
      "Text: wanted to see how they could frame that\n",
      "Length: 8\n",
      "Label: [[0.25]]\n",
      "Segment: 6_0THN4chvY[10]\n",
      "----------------------------------------\n",
      "Example 222:\n",
      "Text: so um if you seen winnie the pooh and you like family films go see it\n",
      "Length: 16\n",
      "Label: [[1.8]]\n",
      "Segment: 6_0THN4chvY[11]\n",
      "----------------------------------------\n",
      "Example 223:\n",
      "Text: its a great one\n",
      "Length: 4\n",
      "Label: [[2.2]]\n",
      "Segment: 6_0THN4chvY[12]\n",
      "----------------------------------------\n",
      "Example 224:\n",
      "Text: i recommend it\n",
      "Length: 3\n",
      "Label: [[2.2]]\n",
      "Segment: 6_0THN4chvY[13]\n",
      "----------------------------------------\n",
      "Example 225:\n",
      "Text: um so there are things that i liked about the movie better than i liked about the book and vice verse\n",
      "Length: 21\n",
      "Label: [[1.]]\n",
      "Segment: 73jzhE8R1TQ[0]\n",
      "----------------------------------------\n",
      "Example 226:\n",
      "Text: it like it like oh the book was so much harder than movie\n",
      "Length: 13\n",
      "Label: [[-0.8]]\n",
      "Segment: 73jzhE8R1TQ[1]\n",
      "----------------------------------------\n",
      "Example 227:\n",
      "Text: maybe because number four was not my all time favorite book\n",
      "Length: 11\n",
      "Label: [[-0.8]]\n",
      "Segment: 73jzhE8R1TQ[2]\n",
      "----------------------------------------\n",
      "Example 228:\n",
      "Text: it was a good book\n",
      "Length: 5\n",
      "Label: [[1.6]]\n",
      "Segment: 73jzhE8R1TQ[3]\n",
      "----------------------------------------\n",
      "Example 229:\n",
      "Text: but but um i crazy about it\n",
      "Length: 7\n",
      "Label: [[-0.8]]\n",
      "Segment: 73jzhE8R1TQ[4]\n",
      "----------------------------------------\n",
      "Example 230:\n",
      "Text: so yeah and the movie was pretty good in my opinion\n",
      "Length: 11\n",
      "Label: [[1.8]]\n",
      "Segment: 73jzhE8R1TQ[5]\n",
      "----------------------------------------\n",
      "Example 231:\n",
      "Text: so i liked the movie\n",
      "Length: 5\n",
      "Label: [[1.4]]\n",
      "Segment: 73jzhE8R1TQ[6]\n",
      "----------------------------------------\n",
      "Example 232:\n",
      "Text: because it did a good job of explaining the back story in the book\n",
      "Length: 14\n",
      "Label: [[1.8]]\n",
      "Segment: 73jzhE8R1TQ[7]\n",
      "----------------------------------------\n",
      "Example 233:\n",
      "Text: good job of explaining thing with lorain the the\n",
      "Length: 9\n",
      "Label: [[0.5]]\n",
      "Segment: 73jzhE8R1TQ[8]\n",
      "----------------------------------------\n",
      "Example 234:\n",
      "Text: the numbers they and they kind of stuck to the book of it so i like that\n",
      "Length: 17\n",
      "Label: [[1.4]]\n",
      "Segment: 73jzhE8R1TQ[9]\n",
      "----------------------------------------\n",
      "Example 235:\n",
      "Text: and but were too hollywood for me\n",
      "Length: 7\n",
      "Label: [[-1.2]]\n",
      "Segment: 73jzhE8R1TQ[10]\n",
      "----------------------------------------\n",
      "Example 236:\n",
      "Text: like th this thing really a big deal but um i i like the fact that john had an because\n",
      "Length: 20\n",
      "Label: [[-1.2]]\n",
      "Segment: 73jzhE8R1TQ[11]\n",
      "----------------------------------------\n",
      "Example 237:\n",
      "Text: because think about it if you if your top priority is survival than why would you be worried about having the latest technology you know what i mean\n",
      "Length: 28\n",
      "Label: [[-0.6]]\n",
      "Segment: 73jzhE8R1TQ[12]\n",
      "----------------------------------------\n",
      "Example 238:\n",
      "Text: so since were not really sure what their financial situation is they could be like scraping by or they could be totally rich\n",
      "Length: 23\n",
      "Label: [[0.]]\n",
      "Segment: 73jzhE8R1TQ[13]\n",
      "----------------------------------------\n",
      "Example 239:\n",
      "Text: but my like he have an he care about the latest trends so thats really what the lieutenant i\n",
      "Length: 19\n",
      "Label: [[-1.6]]\n",
      "Segment: 73jzhE8R1TQ[14]\n",
      "----------------------------------------\n",
      "Example 240:\n",
      "Text: i thought it was all too commercial in that aspect\n",
      "Length: 10\n",
      "Label: [[-0.2]]\n",
      "Segment: 73jzhE8R1TQ[15]\n",
      "----------------------------------------\n",
      "Example 241:\n",
      "Text: um like i said it big deal\n",
      "Length: 7\n",
      "Label: [[-0.4]]\n",
      "Segment: 73jzhE8R1TQ[16]\n",
      "----------------------------------------\n",
      "Example 242:\n",
      "Text: and you probably dont think so but you know just one of those little things that that hurt you for some reason you know what i mean\n",
      "Length: 27\n",
      "Label: [[-1.6]]\n",
      "Segment: 73jzhE8R1TQ[17]\n",
      "----------------------------------------\n",
      "Example 243:\n",
      "Text: um another thing that did bother me were the um\n",
      "Length: 10\n",
      "Label: [[-1.2]]\n",
      "Segment: 73jzhE8R1TQ[18]\n",
      "----------------------------------------\n",
      "Example 244:\n",
      "Text: um graphics were incredible\n",
      "Length: 4\n",
      "Label: [[1.8]]\n",
      "Segment: 7JsX8y1ysxY[0]\n",
      "----------------------------------------\n",
      "Example 245:\n",
      "Text: um some really good acting\n",
      "Length: 5\n",
      "Label: [[2.2]]\n",
      "Segment: 7JsX8y1ysxY[1]\n",
      "----------------------------------------\n",
      "Example 246:\n",
      "Text: some really acting\n",
      "Length: 3\n",
      "Label: [[-2.6]]\n",
      "Segment: 7JsX8y1ysxY[2]\n",
      "----------------------------------------\n",
      "Example 247:\n",
      "Text: so this was pretty funny\n",
      "Length: 5\n",
      "Label: [[1.4]]\n",
      "Segment: 7JsX8y1ysxY[3]\n",
      "----------------------------------------\n",
      "Example 248:\n",
      "Text: coz people were like eating popcorn and you see the first show and people you hear like this this ripple effect of whispering oh my god is that a is that am i looking at this right what\n",
      "Length: 38\n",
      "Label: [[1.]]\n",
      "Segment: 7JsX8y1ysxY[4]\n",
      "----------------------------------------\n",
      "Example 249:\n",
      "Text: i thought that was really funny\n",
      "Length: 6\n",
      "Label: [[1.6]]\n",
      "Segment: 7JsX8y1ysxY[5]\n",
      "----------------------------------------\n",
      "Example 250:\n",
      "Text: um there been less blue nudity\n",
      "Length: 6\n",
      "Label: [[-1.6]]\n",
      "Segment: 7JsX8y1ysxY[6]\n",
      "----------------------------------------\n",
      "Example 251:\n",
      "Text: because what was weird was the fact that in part of the movie hes wearing like a blue um overall thing medal thing so i was like why not wear the whole whole time you know why why you got to go command on us\n",
      "Length: 45\n",
      "Label: [[-1.2]]\n",
      "Segment: 7JsX8y1ysxY[7]\n",
      "----------------------------------------\n",
      "Example 252:\n",
      "Text: it was funny though\n",
      "Length: 4\n",
      "Label: [[1.8]]\n",
      "Segment: 7JsX8y1ysxY[8]\n",
      "----------------------------------------\n",
      "Example 253:\n",
      "Text: hes funny\n",
      "Length: 2\n",
      "Label: [[2.]]\n",
      "Segment: 7JsX8y1ysxY[9]\n",
      "----------------------------------------\n",
      "Example 254:\n",
      "Text: its kind of weird\n",
      "Length: 4\n",
      "Label: [[-1.]]\n",
      "Segment: 7JsX8y1ysxY[10]\n",
      "----------------------------------------\n",
      "Example 255:\n",
      "Text: i dont know classic superhero kind of getting on kind of thing\n",
      "Length: 12\n",
      "Label: [[0.6]]\n",
      "Segment: 7JsX8y1ysxY[11]\n",
      "----------------------------------------\n",
      "Example 256:\n",
      "Text: all right so enough of the nudity\n",
      "Length: 7\n",
      "Label: [[-1.6]]\n",
      "Segment: 7JsX8y1ysxY[12]\n",
      "----------------------------------------\n",
      "Example 257:\n",
      "Text: um but what sucked what was bad was malin akerman the girl who plays the silk spectre um\n",
      "Length: 18\n",
      "Label: [[-2.2]]\n",
      "Segment: 7JsX8y1ysxY[13]\n",
      "----------------------------------------\n",
      "Example 258:\n",
      "Text: um junior lady girl i know i i mean she looked fan fantastic\n",
      "Length: 13\n",
      "Label: [[-0.4]]\n",
      "Segment: 7JsX8y1ysxY[14]\n",
      "----------------------------------------\n",
      "Example 259:\n",
      "Text: she looked phenomenal\n",
      "Length: 3\n",
      "Label: [[2.2]]\n",
      "Segment: 7JsX8y1ysxY[15]\n",
      "----------------------------------------\n",
      "Example 260:\n",
      "Text: she looked like a superhero\n",
      "Length: 5\n",
      "Label: [[0.8]]\n",
      "Segment: 7JsX8y1ysxY[16]\n",
      "----------------------------------------\n",
      "Example 261:\n",
      "Text: but she acted like power ranger\n",
      "Length: 6\n",
      "Label: [[-0.4]]\n",
      "Segment: 7JsX8y1ysxY[17]\n",
      "----------------------------------------\n",
      "Example 262:\n",
      "Text: and theres a vast difference between those two things\n",
      "Length: 9\n",
      "Label: [[-0.2]]\n",
      "Segment: 7JsX8y1ysxY[18]\n",
      "----------------------------------------\n",
      "Example 263:\n",
      "Text: ill tell you who made the movie\n",
      "Length: 7\n",
      "Label: [[0.8]]\n",
      "Segment: 7JsX8y1ysxY[19]\n",
      "----------------------------------------\n",
      "Example 264:\n",
      "Text: who was just kick ass of time was the guy that played our rorschach\n",
      "Length: 14\n",
      "Label: [[1.8]]\n",
      "Segment: 7JsX8y1ysxY[20]\n",
      "----------------------------------------\n",
      "Example 265:\n",
      "Text: but anyways he was awesome\n",
      "Length: 5\n",
      "Label: [[2.6]]\n",
      "Segment: 7JsX8y1ysxY[21]\n",
      "----------------------------------------\n",
      "Example 266:\n",
      "Text: i thought that was very cool\n",
      "Length: 6\n",
      "Label: [[2.4]]\n",
      "Segment: 7JsX8y1ysxY[22]\n",
      "----------------------------------------\n",
      "Example 267:\n",
      "Text: um he was awesome\n",
      "Length: 4\n",
      "Label: [[2.4]]\n",
      "Segment: 7JsX8y1ysxY[23]\n",
      "----------------------------------------\n",
      "Example 268:\n",
      "Text: like he was incredible\n",
      "Length: 4\n",
      "Label: [[2.6]]\n",
      "Segment: 7JsX8y1ysxY[24]\n",
      "----------------------------------------\n",
      "Example 269:\n",
      "Text: the other guy that did a really good job was um jeffrey dean morgan\n",
      "Length: 14\n",
      "Label: [[1.8]]\n",
      "Segment: 7JsX8y1ysxY[25]\n",
      "----------------------------------------\n",
      "Example 270:\n",
      "Text: he did a very good job\n",
      "Length: 6\n",
      "Label: [[2.]]\n",
      "Segment: 7JsX8y1ysxY[26]\n",
      "----------------------------------------\n",
      "Example 271:\n",
      "Text: very dark\n",
      "Length: 2\n",
      "Label: [[-1.25]]\n",
      "Segment: 7JsX8y1ysxY[27]\n",
      "----------------------------------------\n",
      "Example 272:\n",
      "Text: um i really liked guy\n",
      "Length: 5\n",
      "Label: [[-1.5]]\n",
      "Segment: 7JsX8y1ysxY[28]\n",
      "----------------------------------------\n",
      "Example 273:\n",
      "Text: but um he did a really good job at acting\n",
      "Length: 10\n",
      "Label: [[2.2]]\n",
      "Segment: 7JsX8y1ysxY[29]\n",
      "----------------------------------------\n",
      "Example 274:\n",
      "Text: i was very impressed\n",
      "Length: 4\n",
      "Label: [[2.2]]\n",
      "Segment: 7JsX8y1ysxY[30]\n",
      "----------------------------------------\n",
      "Example 275:\n",
      "Text: so overall its its like a blend of youve got alternative history\n",
      "Length: 12\n",
      "Label: [[0.6]]\n",
      "Segment: 7JsX8y1ysxY[31]\n",
      "----------------------------------------\n",
      "Example 276:\n",
      "Text: and its very very interesting\n",
      "Length: 5\n",
      "Label: [[1.4]]\n",
      "Segment: 7JsX8y1ysxY[32]\n",
      "----------------------------------------\n",
      "Example 277:\n",
      "Text: um but its extremely dark\n",
      "Length: 5\n",
      "Label: [[-0.6]]\n",
      "Segment: 7JsX8y1ysxY[33]\n",
      "----------------------------------------\n",
      "Example 278:\n",
      "Text: i warn you its a very very dark\n",
      "Length: 8\n",
      "Label: [[-1.]]\n",
      "Segment: 7JsX8y1ysxY[34]\n",
      "----------------------------------------\n",
      "Example 279:\n",
      "Text: and um theres not in my opinion there very much of a balance between sort of like the good evil kind of thing\n",
      "Length: 23\n",
      "Label: [[-1.6]]\n",
      "Segment: 7JsX8y1ysxY[35]\n",
      "----------------------------------------\n",
      "Example 280:\n",
      "Text: and it seemed like everything was sort of overwhelmingly bad\n",
      "Length: 10\n",
      "Label: [[-1.6]]\n",
      "Segment: 7JsX8y1ysxY[36]\n",
      "----------------------------------------\n",
      "Example 281:\n",
      "Text: um so at the end theres not really a whole lot of redeeming value that i think you come up with\n",
      "Length: 21\n",
      "Label: [[-1.8]]\n",
      "Segment: 7JsX8y1ysxY[37]\n",
      "----------------------------------------\n",
      "Example 282:\n",
      "Text: but um you know overall it was good\n",
      "Length: 8\n",
      "Label: [[1.8]]\n",
      "Segment: 7JsX8y1ysxY[38]\n",
      "----------------------------------------\n",
      "Example 283:\n",
      "Text: which is where all great relationships should start\n",
      "Length: 8\n",
      "Label: [[0.4]]\n",
      "Segment: 8OtFthrtaJM[0]\n",
      "----------------------------------------\n",
      "Example 284:\n",
      "Text: and just its very its very chaotic at the end of this movie\n",
      "Length: 13\n",
      "Label: [[-1.]]\n",
      "Segment: 8OtFthrtaJM[1]\n",
      "----------------------------------------\n",
      "Example 285:\n",
      "Text: i literally said out loud what que what is this movie that i am seeing what is this\n",
      "Length: 18\n",
      "Label: [[-2.4]]\n",
      "Segment: 8OtFthrtaJM[2]\n",
      "----------------------------------------\n",
      "Example 286:\n",
      "Text: i do not understand this movie\n",
      "Length: 6\n",
      "Label: [[-2.]]\n",
      "Segment: 8OtFthrtaJM[3]\n",
      "----------------------------------------\n",
      "Example 287:\n",
      "Text: but theres a reason for that theres a reason for why i was confused\n",
      "Length: 14\n",
      "Label: [[-0.2]]\n",
      "Segment: 8OtFthrtaJM[4]\n",
      "----------------------------------------\n",
      "Example 288:\n",
      "Text: first off the commercial makes the terrible terrible mistake of saying that it is more thought provoking than inception\n",
      "Length: 19\n",
      "Label: [[-2.6]]\n",
      "Segment: 8OtFthrtaJM[5]\n",
      "----------------------------------------\n",
      "Example 289:\n",
      "Text: thanks a lot commercial\n",
      "Length: 4\n",
      "Label: [[-1.4]]\n",
      "Segment: 8OtFthrtaJM[6]\n",
      "----------------------------------------\n",
      "Example 290:\n",
      "Text: the entire time i was constantly comparing it to inception\n",
      "Length: 10\n",
      "Label: [[-0.2]]\n",
      "Segment: 8OtFthrtaJM[7]\n",
      "----------------------------------------\n",
      "Example 291:\n",
      "Text: but i must say those are some pretty big shoes to fill so i thought maybe it has a chance\n",
      "Length: 20\n",
      "Label: [[0.4]]\n",
      "Segment: 8OtFthrtaJM[8]\n",
      "----------------------------------------\n",
      "Example 292:\n",
      "Text: i i should give it a shot you know\n",
      "Length: 9\n",
      "Label: [[0.6]]\n",
      "Segment: 8OtFthrtaJM[9]\n",
      "----------------------------------------\n",
      "Example 293:\n",
      "Text: i was just waiting for joseph gordon levitt to come out just jump out any time and say its a paradox\n",
      "Length: 21\n",
      "Label: [[-0.5]]\n",
      "Segment: 8OtFthrtaJM[10]\n",
      "----------------------------------------\n",
      "Example 294:\n",
      "Text: now the only part that i found in the first thirty minutes of the movie was when matt damon first discovers the bureau in the first place\n",
      "Length: 27\n",
      "Label: [[-0.8]]\n",
      "Segment: 8OtFthrtaJM[11]\n",
      "----------------------------------------\n",
      "Example 295:\n",
      "Text: which kind of just ruins the suspense right there because if youve got some convenient guy in a fedora to just tell you oh yes we are the bureau and this is what we do you know its just kind of ruins the suspense\n",
      "Length: 44\n",
      "Label: [[-2.2]]\n",
      "Segment: 8OtFthrtaJM[12]\n",
      "----------------------------------------\n",
      "Example 296:\n",
      "Text: and now im not im not excited anymore\n",
      "Length: 8\n",
      "Label: [[-1.4]]\n",
      "Segment: 8OtFthrtaJM[13]\n",
      "----------------------------------------\n",
      "Example 297:\n",
      "Text: interestingly it turned out to be more of a romantic comedy than it was a thriller\n",
      "Length: 16\n",
      "Label: [[0.]]\n",
      "Segment: 8OtFthrtaJM[14]\n",
      "----------------------------------------\n",
      "Example 298:\n",
      "Text: um you know it had some interesting writing\n",
      "Length: 8\n",
      "Label: [[0.6]]\n",
      "Segment: 8OtFthrtaJM[15]\n",
      "----------------------------------------\n",
      "Example 299:\n",
      "Text: you know it was it was funny at times\n",
      "Length: 9\n",
      "Label: [[1.]]\n",
      "Segment: 8OtFthrtaJM[16]\n",
      "----------------------------------------\n",
      "Example 300:\n",
      "Text: matt damon is a you know hes a pretty funny guy\n",
      "Length: 11\n",
      "Label: [[1.4]]\n",
      "Segment: 8OtFthrtaJM[17]\n",
      "----------------------------------------\n",
      "Example 301:\n",
      "Text: but just aside from that they really dropped the ball on the parts\n",
      "Length: 13\n",
      "Label: [[-2.2]]\n",
      "Segment: 8OtFthrtaJM[18]\n",
      "----------------------------------------\n",
      "Example 302:\n",
      "Text: overall overall it had far too many plot holes\n",
      "Length: 9\n",
      "Label: [[-1.8]]\n",
      "Segment: 8OtFthrtaJM[19]\n",
      "----------------------------------------\n",
      "Example 303:\n",
      "Text: and just not enough depth to be interesting\n",
      "Length: 8\n",
      "Label: [[-2.2]]\n",
      "Segment: 8OtFthrtaJM[20]\n",
      "----------------------------------------\n",
      "Example 304:\n",
      "Text: i have to say my favorite character in the entire movie is the character thompson\n",
      "Length: 15\n",
      "Label: [[2.]]\n",
      "Segment: 8OtFthrtaJM[21]\n",
      "----------------------------------------\n",
      "Example 305:\n",
      "Text: but hes just the old guy ever see in your life he stands over people when theyre asleep just staring at them\n",
      "Length: 22\n",
      "Label: [[-1.]]\n",
      "Segment: 8OtFthrtaJM[22]\n",
      "----------------------------------------\n",
      "Example 306:\n",
      "Text: um im gonna give the reasons why i like him\n",
      "Length: 10\n",
      "Label: [[1.2]]\n",
      "Segment: 8d-gEyoeBzc[0]\n",
      "----------------------------------------\n",
      "Example 307:\n",
      "Text: but mostly im gonna give the reasons of why i dont think hes gonna be a classic in the same way as the first movie predator or aliens\n",
      "Length: 28\n",
      "Label: [[-0.8]]\n",
      "Segment: 8d-gEyoeBzc[1]\n",
      "----------------------------------------\n",
      "Example 308:\n",
      "Text: um which i think was going for he th th he always said that he was gonna do the sequel um he wanted this to be um th the predator equivalent of aliens\n",
      "Length: 33\n",
      "Label: [[-0.2]]\n",
      "Segment: 8d-gEyoeBzc[2]\n",
      "----------------------------------------\n",
      "Example 309:\n",
      "Text: um as um you know as aliens was to alien\n",
      "Length: 10\n",
      "Label: [[-0.2]]\n",
      "Segment: 8d-gEyoeBzc[3]\n",
      "----------------------------------------\n",
      "Example 310:\n",
      "Text: um and im gonna really point out why that i dont think he really pulled he pulled that off\n",
      "Length: 19\n",
      "Label: [[-2.]]\n",
      "Segment: 8d-gEyoeBzc[4]\n",
      "----------------------------------------\n",
      "Example 311:\n",
      "Text: um why was a mistake really to try and do that\n",
      "Length: 11\n",
      "Label: [[-1.5]]\n",
      "Segment: 8d-gEyoeBzc[5]\n",
      "----------------------------------------\n",
      "Example 312:\n",
      "Text: um but i did enjoy it\n",
      "Length: 6\n",
      "Label: [[0.2]]\n",
      "Segment: 8d-gEyoeBzc[6]\n",
      "----------------------------------------\n",
      "Example 313:\n",
      "Text: so um im gonna point out the stuff i did like there were some action scenes in it\n",
      "Length: 18\n",
      "Label: [[1.2]]\n",
      "Segment: 8d-gEyoeBzc[7]\n",
      "----------------------------------------\n",
      "Example 314:\n",
      "Text: the characters were well developed um not all of the characters\n",
      "Length: 11\n",
      "Label: [[1.4]]\n",
      "Segment: 8d-gEyoeBzc[8]\n",
      "----------------------------------------\n",
      "Example 315:\n",
      "Text: but um i would say that um there was theres good there were four good characters in there\n",
      "Length: 18\n",
      "Label: [[0.6]]\n",
      "Segment: 8d-gEyoeBzc[9]\n",
      "----------------------------------------\n",
      "Example 316:\n",
      "Text: um i i liked agent character\n",
      "Length: 6\n",
      "Label: [[1.6]]\n",
      "Segment: 8d-gEyoeBzc[10]\n",
      "----------------------------------------\n",
      "Example 317:\n",
      "Text: i thought he was um well developed\n",
      "Length: 7\n",
      "Label: [[1.6]]\n",
      "Segment: 8d-gEyoeBzc[11]\n",
      "----------------------------------------\n",
      "Example 318:\n",
      "Text: you know well drawn out character\n",
      "Length: 6\n",
      "Label: [[1.4]]\n",
      "Segment: 8d-gEyoeBzc[12]\n",
      "----------------------------------------\n",
      "Example 319:\n",
      "Text: someone you cared about\n",
      "Length: 4\n",
      "Label: [[0.]]\n",
      "Segment: 8d-gEyoeBzc[13]\n",
      "----------------------------------------\n",
      "Example 320:\n",
      "Text: i liked the girl who was the israeli sniper\n",
      "Length: 9\n",
      "Label: [[0.8]]\n",
      "Segment: 8d-gEyoeBzc[14]\n",
      "----------------------------------------\n",
      "Example 321:\n",
      "Text: i thought she was the number one well drawn character\n",
      "Length: 10\n",
      "Label: [[1.2]]\n",
      "Segment: 8d-gEyoeBzc[15]\n",
      "----------------------------------------\n",
      "Example 322:\n",
      "Text: um i liked the russian guy i\n",
      "Length: 7\n",
      "Label: [[1.]]\n",
      "Segment: 8d-gEyoeBzc[16]\n",
      "----------------------------------------\n",
      "Example 323:\n",
      "Text: um you cared you there was enough in there for you to care about him\n",
      "Length: 15\n",
      "Label: [[0.6]]\n",
      "Segment: 8d-gEyoeBzc[17]\n",
      "----------------------------------------\n",
      "Example 324:\n",
      "Text: and was an interesting character\n",
      "Length: 5\n",
      "Label: [[1.6]]\n",
      "Segment: 8d-gEyoeBzc[18]\n",
      "----------------------------------------\n",
      "Example 325:\n",
      "Text: um he had some funny he had a few one lines that was quite quite funny\n",
      "Length: 16\n",
      "Label: [[1.2]]\n",
      "Segment: 8d-gEyoeBzc[19]\n",
      "----------------------------------------\n",
      "Example 326:\n",
      "Text: yeah once unfortunately um i think in the writing somewhere they they just um developed enough fear to care about them um and that includes is it graces i think i think his name was his character um\n",
      "Length: 38\n",
      "Label: [[-2.]]\n",
      "Segment: 8d-gEyoeBzc[20]\n",
      "----------------------------------------\n",
      "Example 327:\n",
      "Text: um i just didnt think it was well developed enough and um i also i i include in that laurence character as well\n",
      "Length: 23\n",
      "Label: [[-1.]]\n",
      "Segment: 8d-gEyoeBzc[21]\n",
      "----------------------------------------\n",
      "Example 328:\n",
      "Text: who i think when he wrote the mo wrote the movie was going for a marlon brando now type of character\n",
      "Length: 21\n",
      "Label: [[-0.4]]\n",
      "Segment: 8d-gEyoeBzc[22]\n",
      "----------------------------------------\n",
      "Example 329:\n",
      "Text: but he actually found um when hes seen come up it slowed the movie down um and this is the problem um with predator to predators compared to predator\n",
      "Length: 29\n",
      "Label: [[-1.4]]\n",
      "Segment: 8d-gEyoeBzc[23]\n",
      "----------------------------------------\n",
      "Example 330:\n",
      "Text: predator is really well paced movie\n",
      "Length: 6\n",
      "Label: [[1.8]]\n",
      "Segment: 8d-gEyoeBzc[24]\n",
      "----------------------------------------\n",
      "Example 331:\n",
      "Text: and it picks up speed and never lets go ev even in the same where they they slow you know they meant to have some dialogue and and talk about whats going on yo you know\n",
      "Length: 36\n",
      "Label: [[1.]]\n",
      "Segment: 8d-gEyoeBzc[25]\n",
      "----------------------------------------\n",
      "Example 332:\n",
      "Text: it felt the movie slowed down it in the middle of this\n",
      "Length: 12\n",
      "Label: [[-1.4]]\n",
      "Segment: 8d-gEyoeBzc[26]\n",
      "----------------------------------------\n",
      "Example 333:\n",
      "Text: when when they they with um laurence fishburne character it does slow down a great deal\n",
      "Length: 16\n",
      "Label: [[-0.8]]\n",
      "Segment: 8d-gEyoeBzc[27]\n",
      "----------------------------------------\n",
      "Example 334:\n",
      "Text: i didnt really feel um the inclusion of his was necessary\n",
      "Length: 11\n",
      "Label: [[-1.4]]\n",
      "Segment: 8d-gEyoeBzc[28]\n",
      "----------------------------------------\n",
      "Example 335:\n",
      "Text: um it been written out\n",
      "Length: 5\n",
      "Label: [[-0.8]]\n",
      "Segment: 8d-gEyoeBzc[29]\n",
      "----------------------------------------\n",
      "Example 336:\n",
      "Text: and um i have to admit i was watching this i put it on because i figured it would be something that would be stupid that i could fall asleep in the middle of and not miss too much\n",
      "Length: 39\n",
      "Label: [[-1.4]]\n",
      "Segment: 8qrpnFRGt2A[0]\n",
      "----------------------------------------\n",
      "Example 337:\n",
      "Text: just wanted something to watch while i was falling asleep\n",
      "Length: 10\n",
      "Label: [[-0.4]]\n",
      "Segment: 8qrpnFRGt2A[1]\n",
      "----------------------------------------\n",
      "Example 338:\n",
      "Text: so i didnt didnt have very high expectations for this movie\n",
      "Length: 11\n",
      "Label: [[-1.6]]\n",
      "Segment: 8qrpnFRGt2A[2]\n",
      "----------------------------------------\n",
      "Example 339:\n",
      "Text: and i um pretty much it pretty much met my low expectations for the most part\n",
      "Length: 16\n",
      "Label: [[-1.4]]\n",
      "Segment: 8qrpnFRGt2A[3]\n",
      "----------------------------------------\n",
      "Example 340:\n",
      "Text: because i three major complaints i have about this movie\n",
      "Length: 10\n",
      "Label: [[-1.4]]\n",
      "Segment: 8qrpnFRGt2A[4]\n",
      "----------------------------------------\n",
      "Example 341:\n",
      "Text: um biggest one is the effects were just terrible\n",
      "Length: 9\n",
      "Label: [[-2.6]]\n",
      "Segment: 8qrpnFRGt2A[5]\n",
      "----------------------------------------\n",
      "Example 342:\n",
      "Text: and um the story was pretty weird\n",
      "Length: 7\n",
      "Label: [[-1.6]]\n",
      "Segment: 8qrpnFRGt2A[6]\n",
      "----------------------------------------\n",
      "Example 343:\n",
      "Text: um and again i i if i had to pay closer attention i might have followed it more\n",
      "Length: 18\n",
      "Label: [[-0.8]]\n",
      "Segment: 8qrpnFRGt2A[7]\n",
      "----------------------------------------\n",
      "Example 344:\n",
      "Text: and might have been it might have made more sense\n",
      "Length: 10\n",
      "Label: [[-1.]]\n",
      "Segment: 8qrpnFRGt2A[8]\n",
      "----------------------------------------\n",
      "Example 345:\n",
      "Text: um um this movie this movie um by half way through i was checking the time and saw that this movie was two hours long\n",
      "Length: 25\n",
      "Label: [[-2.2]]\n",
      "Segment: 8qrpnFRGt2A[9]\n",
      "----------------------------------------\n",
      "Example 346:\n",
      "Text: which i mean for a movie about ji joe minutes is enough\n",
      "Length: 12\n",
      "Label: [[-0.8]]\n",
      "Segment: 8qrpnFRGt2A[10]\n",
      "----------------------------------------\n",
      "Example 347:\n",
      "Text: ok i dont need a three hour mini about ji joe\n",
      "Length: 11\n",
      "Label: [[-2.]]\n",
      "Segment: 8qrpnFRGt2A[11]\n",
      "----------------------------------------\n",
      "Example 348:\n",
      "Text: but thats just me\n",
      "Length: 4\n",
      "Label: [[-0.33333334]]\n",
      "Segment: 8qrpnFRGt2A[12]\n",
      "----------------------------------------\n",
      "Example 349:\n",
      "Text: i thought that two hours was way too long for this movie\n",
      "Length: 12\n",
      "Label: [[-1.8]]\n",
      "Segment: 8qrpnFRGt2A[13]\n",
      "----------------------------------------\n",
      "Example 350:\n",
      "Text: and the last big thing was um just the the it it i know its about you know obviously its gonna be about the army but it just felt like um like um military propaganda kind of like you know\n",
      "Length: 40\n",
      "Label: [[-1.6]]\n",
      "Segment: 8qrpnFRGt2A[14]\n",
      "----------------------------------------\n",
      "Example 351:\n",
      "Text: it fell like i was watching one of those army of one commercials sometimes\n",
      "Length: 14\n",
      "Label: [[-1.]]\n",
      "Segment: 8qrpnFRGt2A[15]\n",
      "----------------------------------------\n",
      "Example 352:\n",
      "Text: of course its too much\n",
      "Length: 5\n",
      "Label: [[-0.6666667]]\n",
      "Segment: 8qrpnFRGt2A[16]\n",
      "----------------------------------------\n",
      "Example 353:\n",
      "Text: of course its gonna be making them look good just fine\n",
      "Length: 11\n",
      "Label: [[0.6]]\n",
      "Segment: 8qrpnFRGt2A[17]\n",
      "----------------------------------------\n",
      "Example 354:\n",
      "Text: i i guess um but the funny thing is um i mean funny thing is despite as despite everything bad about this movie i ended up half way liking it\n",
      "Length: 30\n",
      "Label: [[0.6]]\n",
      "Segment: 8qrpnFRGt2A[18]\n",
      "----------------------------------------\n",
      "Example 355:\n",
      "Text: and thats because about half way through the movie i realized that this is just its really just a cartoon\n",
      "Length: 20\n",
      "Label: [[-0.8]]\n",
      "Segment: 8qrpnFRGt2A[19]\n",
      "----------------------------------------\n",
      "Example 356:\n",
      "Text: if you look at it as a live action movie you youre gonna be disappointed\n",
      "Length: 15\n",
      "Label: [[-2.]]\n",
      "Segment: 8qrpnFRGt2A[20]\n",
      "----------------------------------------\n",
      "Example 357:\n",
      "Text: but if you look at it as a cartoon which is pretty much mostly is with all the and\n",
      "Length: 19\n",
      "Label: [[-1.]]\n",
      "Segment: 8qrpnFRGt2A[21]\n",
      "----------------------------------------\n",
      "Example 358:\n",
      "Text: and and there is a lot of it\n",
      "Length: 8\n",
      "Label: [[-0.33333334]]\n",
      "Segment: 8qrpnFRGt2A[22]\n",
      "----------------------------------------\n",
      "Example 359:\n",
      "Text: i mean this movie makes um makes um star wars pretty close\n",
      "Length: 12\n",
      "Label: [[0.]]\n",
      "Segment: 8qrpnFRGt2A[23]\n",
      "----------------------------------------\n",
      "Example 360:\n",
      "Text: i mean its its about that level star war is\n",
      "Length: 10\n",
      "Label: [[0.2]]\n",
      "Segment: 8qrpnFRGt2A[24]\n",
      "----------------------------------------\n",
      "Example 361:\n",
      "Text: pretty close as far as just heavy like this time its what its like human face and everything around that face is cartoon computer effects\n",
      "Length: 25\n",
      "Label: [[-1.2]]\n",
      "Segment: 8qrpnFRGt2A[25]\n",
      "----------------------------------------\n",
      "Example 362:\n",
      "Text: this movie is adorable\n",
      "Length: 4\n",
      "Label: [[2.2]]\n",
      "Segment: 9J25DZhivz8[0]\n",
      "----------------------------------------\n",
      "Example 363:\n",
      "Text: this movie is just too adorable\n",
      "Length: 6\n",
      "Label: [[2.4]]\n",
      "Segment: 9J25DZhivz8[1]\n",
      "----------------------------------------\n",
      "Example 364:\n",
      "Text: there were some really good things about this movie\n",
      "Length: 9\n",
      "Label: [[2.]]\n",
      "Segment: 9J25DZhivz8[2]\n",
      "----------------------------------------\n",
      "Example 365:\n",
      "Text: the voice acting excellent\n",
      "Length: 4\n",
      "Label: [[2.8]]\n",
      "Segment: 9J25DZhivz8[3]\n",
      "----------------------------------------\n",
      "Example 366:\n",
      "Text: the visuals were great\n",
      "Length: 4\n",
      "Label: [[1.8]]\n",
      "Segment: 9J25DZhivz8[4]\n",
      "----------------------------------------\n",
      "Example 367:\n",
      "Text: this was probably the best movie ive seen in a long time coz it actually used toy\n",
      "Length: 17\n",
      "Label: [[2.8]]\n",
      "Segment: 9J25DZhivz8[5]\n",
      "----------------------------------------\n",
      "Example 368:\n",
      "Text: toy story had elements of it but this movie played with and um different ways to come at you out of the screen\n",
      "Length: 23\n",
      "Label: [[2.2]]\n",
      "Segment: 9J25DZhivz8[6]\n",
      "----------------------------------------\n",
      "Example 369:\n",
      "Text: so i liked that a lot\n",
      "Length: 6\n",
      "Label: [[2.2]]\n",
      "Segment: 9J25DZhivz8[7]\n",
      "----------------------------------------\n",
      "Example 370:\n",
      "Text: the voice acting in this was incredible\n",
      "Length: 7\n",
      "Label: [[2.6]]\n",
      "Segment: 9J25DZhivz8[8]\n",
      "----------------------------------------\n",
      "Example 371:\n",
      "Text: steve voices and russell brand actually really impressed me with his old man voice for the doctor\n",
      "Length: 17\n",
      "Label: [[1.8]]\n",
      "Segment: 9J25DZhivz8[9]\n",
      "----------------------------------------\n",
      "Example 372:\n",
      "Text: of i couldnt i couldnt even believe it was russell brand\n",
      "Length: 11\n",
      "Label: [[0.8]]\n",
      "Segment: 9J25DZhivz8[10]\n",
      "----------------------------------------\n",
      "Example 373:\n",
      "Text: i kept i was listening bored\n",
      "Length: 6\n",
      "Label: [[0.2]]\n",
      "Segment: 9J25DZhivz8[11]\n",
      "----------------------------------------\n",
      "Example 374:\n",
      "Text: and there was maybe one time when i thought i actually heard russell brand himself\n",
      "Length: 15\n",
      "Label: [[-0.25]]\n",
      "Segment: 9J25DZhivz8[12]\n",
      "----------------------------------------\n",
      "Example 375:\n",
      "Text: but otherwise i thought he was for\n",
      "Length: 7\n",
      "Label: [[1.8]]\n",
      "Segment: 9J25DZhivz8[13]\n",
      "----------------------------------------\n",
      "Example 376:\n",
      "Text: i say yes\n",
      "Length: 3\n",
      "Label: [[1.]]\n",
      "Segment: 9J25DZhivz8[14]\n",
      "----------------------------------------\n",
      "Example 377:\n",
      "Text: theres one scene in this movie that makes entirely worth it\n",
      "Length: 11\n",
      "Label: [[2.4]]\n",
      "Segment: 9J25DZhivz8[15]\n",
      "----------------------------------------\n",
      "Example 378:\n",
      "Text: and some people might think that theres a lot of cheap tricks\n",
      "Length: 12\n",
      "Label: [[0.5]]\n",
      "Segment: 9J25DZhivz8[16]\n",
      "----------------------------------------\n",
      "Example 379:\n",
      "Text: but theres a roller coaster scene and if you are um get a little bit motion sick you might not wanna see it in because feel like youre on this coaster\n",
      "Length: 31\n",
      "Label: [[0.6]]\n",
      "Segment: 9J25DZhivz8[17]\n",
      "----------------------------------------\n",
      "Example 380:\n",
      "Text: i mean my stomach was almost going as we went down the big drop\n",
      "Length: 14\n",
      "Label: [[0.6]]\n",
      "Segment: 9J25DZhivz8[18]\n",
      "----------------------------------------\n",
      "Example 381:\n",
      "Text: i thought it was really cool\n",
      "Length: 6\n",
      "Label: [[2.4]]\n",
      "Segment: 9J25DZhivz8[19]\n",
      "----------------------------------------\n",
      "Example 382:\n",
      "Text: that was a great effect\n",
      "Length: 5\n",
      "Label: [[1.2]]\n",
      "Segment: 9J25DZhivz8[20]\n",
      "----------------------------------------\n",
      "Example 383:\n",
      "Text: there was a lot of cheap child which\n",
      "Length: 8\n",
      "Label: [[-0.8]]\n",
      "Segment: 9J25DZhivz8[21]\n",
      "----------------------------------------\n",
      "Example 384:\n",
      "Text: which everyone can relate to\n",
      "Length: 5\n",
      "Label: [[1.2]]\n",
      "Segment: 9J25DZhivz8[22]\n",
      "----------------------------------------\n",
      "Example 385:\n",
      "Text: and i i always think thats hilarious\n",
      "Length: 7\n",
      "Label: [[1.2]]\n",
      "Segment: 9J25DZhivz8[23]\n",
      "----------------------------------------\n",
      "Example 386:\n",
      "Text: but what made this movie really fun was some of the adult jabs\n",
      "Length: 13\n",
      "Label: [[2.]]\n",
      "Segment: 9J25DZhivz8[24]\n",
      "----------------------------------------\n",
      "Example 387:\n",
      "Text: watch this fucking movie\n",
      "Length: 4\n",
      "Label: [[-0.5]]\n",
      "Segment: 9T9Hf74oK10[0]\n",
      "----------------------------------------\n",
      "Example 388:\n",
      "Text: and um particularly the movies that i feel like gotten nominated but didnt and never let me go is actually one of those movies\n",
      "Length: 24\n",
      "Label: [[1.6]]\n",
      "Segment: 9T9Hf74oK10[1]\n",
      "----------------------------------------\n",
      "Example 389:\n",
      "Text: i think a lot of people are really split about this movie\n",
      "Length: 12\n",
      "Label: [[-0.4]]\n",
      "Segment: 9T9Hf74oK10[2]\n",
      "----------------------------------------\n",
      "Example 390:\n",
      "Text: theres a certain deadpan nature to it\n",
      "Length: 7\n",
      "Label: [[-0.8]]\n",
      "Segment: 9T9Hf74oK10[3]\n",
      "----------------------------------------\n",
      "Example 391:\n",
      "Text: it was a pretty slow movie for the most part\n",
      "Length: 10\n",
      "Label: [[-1.8]]\n",
      "Segment: 9T9Hf74oK10[4]\n",
      "----------------------------------------\n",
      "Example 392:\n",
      "Text: and it was it was but\n",
      "Length: 6\n",
      "Label: [[1.]]\n",
      "Segment: 9T9Hf74oK10[5]\n",
      "----------------------------------------\n",
      "Example 393:\n",
      "Text: but there are you know critics of movies that are sometimes too in a way and i think that would never let me go\n",
      "Length: 24\n",
      "Label: [[-0.8]]\n",
      "Segment: 9T9Hf74oK10[6]\n",
      "----------------------------------------\n",
      "Example 394:\n",
      "Text: a lot of critics said that it relied too much on the audience to um explore the themes in the film and you know tightly so i guess which\n",
      "Length: 29\n",
      "Label: [[-1.8]]\n",
      "Segment: 9T9Hf74oK10[7]\n",
      "----------------------------------------\n",
      "Example 395:\n",
      "Text: um in a way a lot of the themes in never let me go which were very profound and deep\n",
      "Length: 20\n",
      "Label: [[1.6]]\n",
      "Segment: 9T9Hf74oK10[8]\n",
      "----------------------------------------\n",
      "Example 396:\n",
      "Text: they fully explored\n",
      "Length: 3\n",
      "Label: [[-1.2]]\n",
      "Segment: 9T9Hf74oK10[9]\n",
      "----------------------------------------\n",
      "Example 397:\n",
      "Text: and i think that the movie did rely on you to kind of figure it out and kind of deal with those ideas by yourself\n",
      "Length: 25\n",
      "Label: [[0.]]\n",
      "Segment: 9T9Hf74oK10[10]\n",
      "----------------------------------------\n",
      "Example 398:\n",
      "Text: but regardless i thought it was a very good movie\n",
      "Length: 10\n",
      "Label: [[2.2]]\n",
      "Segment: 9T9Hf74oK10[11]\n",
      "----------------------------------------\n",
      "Example 399:\n",
      "Text: those three are some of the best young actors of today\n",
      "Length: 11\n",
      "Label: [[2.6]]\n",
      "Segment: 9T9Hf74oK10[12]\n",
      "----------------------------------------\n",
      "Example 400:\n",
      "Text: she and everything she does she has so much grace to it and so much fluidity\n",
      "Length: 16\n",
      "Label: [[2.]]\n",
      "Segment: 9T9Hf74oK10[13]\n",
      "----------------------------------------\n",
      "Example 401:\n",
      "Text: and i mean everybody knows her from the pirates of the carribean\n",
      "Length: 12\n",
      "Label: [[-0.4]]\n",
      "Segment: 9T9Hf74oK10[14]\n",
      "----------------------------------------\n",
      "Example 402:\n",
      "Text: but i mean in her other works like pride and prejudice just been fantastic\n",
      "Length: 14\n",
      "Label: [[2.6]]\n",
      "Segment: 9T9Hf74oK10[15]\n",
      "----------------------------------------\n",
      "Example 403:\n",
      "Text: and andrew garfield of course everybody knows him form the social network\n",
      "Length: 12\n",
      "Label: [[0.]]\n",
      "Segment: 9T9Hf74oK10[16]\n",
      "----------------------------------------\n",
      "Example 404:\n",
      "Text: so look out for that that should be interesting\n",
      "Length: 9\n",
      "Label: [[1.2]]\n",
      "Segment: 9T9Hf74oK10[17]\n",
      "----------------------------------------\n",
      "Example 405:\n",
      "Text: but anyways they did um they did act very well\n",
      "Length: 10\n",
      "Label: [[1.4]]\n",
      "Segment: 9T9Hf74oK10[18]\n",
      "----------------------------------------\n",
      "Example 406:\n",
      "Text: and you dont exactly know what is going on\n",
      "Length: 9\n",
      "Label: [[-0.8]]\n",
      "Segment: 9T9Hf74oK10[19]\n",
      "----------------------------------------\n",
      "Example 407:\n",
      "Text: i think it takes place sometime um its i dont think its present day\n",
      "Length: 14\n",
      "Label: [[0.]]\n",
      "Segment: 9T9Hf74oK10[20]\n",
      "----------------------------------------\n",
      "Example 408:\n",
      "Text: but its um its someone modern i would say\n",
      "Length: 9\n",
      "Label: [[0.4]]\n",
      "Segment: 9T9Hf74oK10[21]\n",
      "----------------------------------------\n",
      "Example 409:\n",
      "Text: its not its not like a period piece or anything\n",
      "Length: 10\n",
      "Label: [[0.2]]\n",
      "Segment: 9T9Hf74oK10[22]\n",
      "----------------------------------------\n",
      "Example 410:\n",
      "Text: and you dont exactly know whats going on\n",
      "Length: 8\n",
      "Label: [[-1.]]\n",
      "Segment: 9T9Hf74oK10[23]\n",
      "----------------------------------------\n",
      "Example 411:\n",
      "Text: and i think early on the twist is revealed\n",
      "Length: 9\n",
      "Label: [[-0.6]]\n",
      "Segment: 9T9Hf74oK10[24]\n",
      "----------------------------------------\n",
      "Example 412:\n",
      "Text: at first i thought the movie would appeal more to younger audience\n",
      "Length: 12\n",
      "Label: [[-0.2]]\n",
      "Segment: 9c67fiY0wGQ[0]\n",
      "----------------------------------------\n",
      "Example 413:\n",
      "Text: but i actually found myself enjoying the movie and laughing\n",
      "Length: 10\n",
      "Label: [[1.8]]\n",
      "Segment: 9c67fiY0wGQ[1]\n",
      "----------------------------------------\n",
      "Example 414:\n",
      "Text: i think the movie really depicted the liveliness of new york city while since im a new yorker myself\n",
      "Length: 19\n",
      "Label: [[2.]]\n",
      "Segment: 9c67fiY0wGQ[2]\n",
      "----------------------------------------\n",
      "Example 415:\n",
      "Text: i also liked how the storyline of the movie worked together smoothly\n",
      "Length: 12\n",
      "Label: [[2.]]\n",
      "Segment: 9c67fiY0wGQ[3]\n",
      "----------------------------------------\n",
      "Example 416:\n",
      "Text: the movie also delivers many meaningful messages\n",
      "Length: 7\n",
      "Label: [[2.]]\n",
      "Segment: 9c67fiY0wGQ[4]\n",
      "----------------------------------------\n",
      "Example 417:\n",
      "Text: i also thought some parts of the movie were funny for example um cat facial expressions\n",
      "Length: 16\n",
      "Label: [[1.8]]\n",
      "Segment: 9c67fiY0wGQ[5]\n",
      "----------------------------------------\n",
      "Example 418:\n",
      "Text: theyre so hilarious and similar to person with that\n",
      "Length: 9\n",
      "Label: [[2.]]\n",
      "Segment: 9c67fiY0wGQ[6]\n",
      "----------------------------------------\n",
      "Example 419:\n",
      "Text: i recommend this film to children six and up\n",
      "Length: 9\n",
      "Label: [[2.2]]\n",
      "Segment: 9c67fiY0wGQ[7]\n",
      "----------------------------------------\n",
      "Example 420:\n",
      "Text: it is a fun family film\n",
      "Length: 6\n",
      "Label: [[1.8]]\n",
      "Segment: 9c67fiY0wGQ[8]\n",
      "----------------------------------------\n",
      "Example 421:\n",
      "Text: parents will find themselves laughing as they reminisce they childhood\n",
      "Length: 10\n",
      "Label: [[1.6]]\n",
      "Segment: 9c67fiY0wGQ[9]\n",
      "----------------------------------------\n",
      "Example 422:\n",
      "Text: and children will like the movie\n",
      "Length: 6\n",
      "Label: [[1.6]]\n",
      "Segment: 9c67fiY0wGQ[10]\n",
      "----------------------------------------\n",
      "Example 423:\n",
      "Text: since the smurfs are so adorable and they go on thrilling adventures\n",
      "Length: 12\n",
      "Label: [[2.]]\n",
      "Segment: 9c67fiY0wGQ[11]\n",
      "----------------------------------------\n",
      "Example 424:\n",
      "Text: or what i would like to call leather shoe and suit porn\n",
      "Length: 12\n",
      "Label: [[-0.8]]\n",
      "Segment: 9qR7uwkblbs[0]\n",
      "----------------------------------------\n",
      "Example 425:\n",
      "Text: but i actually really fucking love this movie\n",
      "Length: 8\n",
      "Label: [[2.8]]\n",
      "Segment: 9qR7uwkblbs[1]\n",
      "----------------------------------------\n",
      "Example 426:\n",
      "Text: so theres not gonna be any of bad shit\n",
      "Length: 9\n",
      "Label: [[0.8]]\n",
      "Segment: 9qR7uwkblbs[2]\n",
      "----------------------------------------\n",
      "Example 427:\n",
      "Text: so anyway the movie was really fucking awesome\n",
      "Length: 8\n",
      "Label: [[3.]]\n",
      "Segment: 9qR7uwkblbs[3]\n",
      "----------------------------------------\n",
      "Example 428:\n",
      "Text: i think that that they personally thought that rachel withers really fucking love suits and ryan so they made this movie with me in mind\n",
      "Length: 25\n",
      "Label: [[0.8]]\n",
      "Segment: 9qR7uwkblbs[4]\n",
      "----------------------------------------\n",
      "Example 429:\n",
      "Text: no really like rachel needs some fucking fat material\n",
      "Length: 9\n",
      "Label: [[-2.2]]\n",
      "Segment: 9qR7uwkblbs[5]\n",
      "----------------------------------------\n",
      "Example 430:\n",
      "Text: i wish i was ryan ryan\n",
      "Length: 6\n",
      "Label: [[1.6]]\n",
      "Segment: 9qR7uwkblbs[6]\n",
      "----------------------------------------\n",
      "Example 431:\n",
      "Text: ryan the best part in the not\n",
      "Length: 7\n",
      "Label: [[1.]]\n",
      "Segment: 9qR7uwkblbs[7]\n",
      "----------------------------------------\n",
      "Example 432:\n",
      "Text: gonna fucking spoil anything for you just because that would be rude\n",
      "Length: 12\n",
      "Label: [[-1.2]]\n",
      "Segment: 9qR7uwkblbs[8]\n",
      "----------------------------------------\n",
      "Example 433:\n",
      "Text: and you should all go out and see it and you know stuff\n",
      "Length: 13\n",
      "Label: [[1.6]]\n",
      "Segment: 9qR7uwkblbs[9]\n",
      "----------------------------------------\n",
      "Example 434:\n",
      "Text: best part of the fucking ass movie was this one scene where ryan was just standing there in a fucking suit eating pizza in slow ass motion\n",
      "Length: 27\n",
      "Label: [[1.2]]\n",
      "Segment: 9qR7uwkblbs[10]\n",
      "----------------------------------------\n",
      "Example 435:\n",
      "Text: that was just like hu like zooming in on him and im just like sitting here like any mother drop\n",
      "Length: 20\n",
      "Label: [[-0.8]]\n",
      "Segment: 9qR7uwkblbs[11]\n",
      "----------------------------------------\n",
      "Example 436:\n",
      "Text: emma stone was in this movie as well and you wouldnt really know it coz she was hardly in it\n",
      "Length: 20\n",
      "Label: [[-1.6]]\n",
      "Segment: 9qR7uwkblbs[12]\n",
      "----------------------------------------\n",
      "Example 437:\n",
      "Text: and i was really upset about it\n",
      "Length: 7\n",
      "Label: [[-2.2]]\n",
      "Segment: 9qR7uwkblbs[13]\n",
      "----------------------------------------\n",
      "Example 438:\n",
      "Text: coz you know apparently according to people on the internet aka tumbler because everyone on tumbler is on crack they all think i look like her or like sound like her or act like her\n",
      "Length: 35\n",
      "Label: [[-0.75]]\n",
      "Segment: 9qR7uwkblbs[14]\n",
      "----------------------------------------\n",
      "Example 439:\n",
      "Text: i dont know i guess we both have like that like male sounding voice\n",
      "Length: 14\n",
      "Label: [[0.]]\n",
      "Segment: 9qR7uwkblbs[15]\n",
      "----------------------------------------\n",
      "Example 440:\n",
      "Text: like i kind of sound like i might have a penis\n",
      "Length: 11\n",
      "Label: [[-0.5]]\n",
      "Segment: 9qR7uwkblbs[16]\n",
      "----------------------------------------\n",
      "Example 441:\n",
      "Text: and yeah i know we both have that like an easy way\n",
      "Length: 12\n",
      "Label: [[0.2]]\n",
      "Segment: 9qR7uwkblbs[17]\n",
      "----------------------------------------\n",
      "Example 442:\n",
      "Text: we both like in shit\n",
      "Length: 5\n",
      "Label: [[-0.25]]\n",
      "Segment: 9qR7uwkblbs[18]\n",
      "----------------------------------------\n",
      "Example 443:\n",
      "Text: and she didnt really act like me at all\n",
      "Length: 9\n",
      "Label: [[-0.5]]\n",
      "Segment: 9qR7uwkblbs[19]\n",
      "----------------------------------------\n",
      "Example 444:\n",
      "Text: and i was kind of upset about it\n",
      "Length: 8\n",
      "Label: [[-1.6]]\n",
      "Segment: 9qR7uwkblbs[20]\n",
      "----------------------------------------\n",
      "Example 445:\n",
      "Text: because like she been an animal and she and\n",
      "Length: 9\n",
      "Label: [[-0.5]]\n",
      "Segment: 9qR7uwkblbs[21]\n",
      "----------------------------------------\n",
      "Example 446:\n",
      "Text: and i was thinkin like if i can be mother fucking emma stone and chris can be and that would be just great didnt really happen in the movie\n",
      "Length: 29\n",
      "Label: [[-1.4]]\n",
      "Segment: 9qR7uwkblbs[22]\n",
      "----------------------------------------\n",
      "Example 447:\n",
      "Text: i was kind of upset about that\n",
      "Length: 7\n",
      "Label: [[-1.]]\n",
      "Segment: 9qR7uwkblbs[23]\n",
      "----------------------------------------\n",
      "Example 448:\n",
      "Text: theres a giant ass twist to this movie at the end\n",
      "Length: 11\n",
      "Label: [[1.6]]\n",
      "Segment: 9qR7uwkblbs[24]\n",
      "----------------------------------------\n",
      "Example 449:\n",
      "Text: like its not like a serious fucking movie or anything\n",
      "Length: 10\n",
      "Label: [[-1.]]\n",
      "Segment: 9qR7uwkblbs[25]\n",
      "----------------------------------------\n",
      "Example 450:\n",
      "Text: its comedy romantic im\n",
      "Length: 4\n",
      "Label: [[0.2]]\n",
      "Segment: 9qR7uwkblbs[26]\n",
      "----------------------------------------\n",
      "Example 451:\n",
      "Text: im a little disappointed in myself for not the twist before it actually twisted\n",
      "Length: 14\n",
      "Label: [[-1.]]\n",
      "Segment: 9qR7uwkblbs[27]\n",
      "----------------------------------------\n",
      "Example 452:\n",
      "Text: because like what the fuck like thats what im good at\n",
      "Length: 11\n",
      "Label: [[-1.25]]\n",
      "Segment: 9qR7uwkblbs[28]\n",
      "----------------------------------------\n",
      "Example 453:\n",
      "Text: im gonna spoil skins right now i totally knew manny and rick were gonna be related i fucking knew it like i knew it\n",
      "Length: 24\n",
      "Label: [[-0.5]]\n",
      "Segment: 9qR7uwkblbs[29]\n",
      "----------------------------------------\n",
      "Example 454:\n",
      "Text: i knew that inception that they were gonna be dreaming\n",
      "Length: 10\n",
      "Label: [[0.]]\n",
      "Segment: 9qR7uwkblbs[30]\n",
      "----------------------------------------\n",
      "Example 455:\n",
      "Text: but it was a good good\n",
      "Length: 6\n",
      "Label: [[2.4]]\n",
      "Segment: 9qR7uwkblbs[31]\n",
      "----------------------------------------\n",
      "Example 456:\n",
      "Text: soundtrack\n",
      "Length: 1\n",
      "Label: [[0.]]\n",
      "Segment: 9qR7uwkblbs[32]\n",
      "----------------------------------------\n",
      "Example 457:\n",
      "Text: i cant express my thoughts and feelings about this movie without describing some specific things in the third act of the movie\n",
      "Length: 22\n",
      "Label: [[-0.75]]\n",
      "Segment: Af8D0E4ZXaw[0]\n",
      "----------------------------------------\n",
      "Example 458:\n",
      "Text: widely believed that a of green lantern movie would lead warner brothers to adapt the flash and wonder woman among possibly others\n",
      "Length: 22\n",
      "Label: [[0.8]]\n",
      "Segment: Af8D0E4ZXaw[1]\n",
      "----------------------------------------\n",
      "Example 459:\n",
      "Text: and put them in a justice movie with the ritual batman and superman\n",
      "Length: 13\n",
      "Label: [[0.25]]\n",
      "Segment: Af8D0E4ZXaw[2]\n",
      "----------------------------------------\n",
      "Example 460:\n",
      "Text: so not only that this movie have to deal with the burden of telling its own story and setting up its own inevitable sequels\n",
      "Length: 24\n",
      "Label: [[-0.4]]\n",
      "Segment: Af8D0E4ZXaw[3]\n",
      "----------------------------------------\n",
      "Example 461:\n",
      "Text: it had to deal with the expectations of potentially setting up all that others stuff\n",
      "Length: 15\n",
      "Label: [[-0.2]]\n",
      "Segment: Af8D0E4ZXaw[4]\n",
      "----------------------------------------\n",
      "Example 462:\n",
      "Text: yeah not good\n",
      "Length: 3\n",
      "Label: [[-2.]]\n",
      "Segment: Af8D0E4ZXaw[5]\n",
      "----------------------------------------\n",
      "Example 463:\n",
      "Text: to all the green lantern fans out there i am so sorry\n",
      "Length: 12\n",
      "Label: [[-2.]]\n",
      "Segment: Af8D0E4ZXaw[6]\n",
      "----------------------------------------\n",
      "Example 464:\n",
      "Text: i say that for two reasons first because someone owes you an and\n",
      "Length: 13\n",
      "Label: [[-1.]]\n",
      "Segment: Af8D0E4ZXaw[7]\n",
      "----------------------------------------\n",
      "Example 465:\n",
      "Text: and warner brothers is never gonna give you one\n",
      "Length: 9\n",
      "Label: [[-1.]]\n",
      "Segment: Af8D0E4ZXaw[8]\n",
      "----------------------------------------\n",
      "Example 466:\n",
      "Text: and secondly because as a marvell geek i have experienced my fair share of disappointments over the last decade and i can with you\n",
      "Length: 24\n",
      "Label: [[-0.75]]\n",
      "Segment: Af8D0E4ZXaw[9]\n",
      "----------------------------------------\n",
      "Example 467:\n",
      "Text: before i get to the negatives of the movie let me list off a few of the positives\n",
      "Length: 18\n",
      "Label: [[0.4]]\n",
      "Segment: Af8D0E4ZXaw[10]\n",
      "----------------------------------------\n",
      "Example 468:\n",
      "Text: i love jeffrey rush and michael clarke duncan as the voice actors\n",
      "Length: 12\n",
      "Label: [[1.4]]\n",
      "Segment: Af8D0E4ZXaw[11]\n",
      "----------------------------------------\n",
      "Example 469:\n",
      "Text: they do a great job with their roles\n",
      "Length: 8\n",
      "Label: [[2.]]\n",
      "Segment: Af8D0E4ZXaw[12]\n",
      "----------------------------------------\n",
      "Example 470:\n",
      "Text: they are great additions\n",
      "Length: 4\n",
      "Label: [[1.6]]\n",
      "Segment: Af8D0E4ZXaw[13]\n",
      "----------------------------------------\n",
      "Example 471:\n",
      "Text: i also love the casting of mark strong as hes\n",
      "Length: 10\n",
      "Label: [[2.]]\n",
      "Segment: Af8D0E4ZXaw[14]\n",
      "----------------------------------------\n",
      "Example 472:\n",
      "Text: hes perfect for that role\n",
      "Length: 5\n",
      "Label: [[2.2]]\n",
      "Segment: Af8D0E4ZXaw[15]\n",
      "----------------------------------------\n",
      "Example 473:\n",
      "Text: and um finally a particular stand out scene for me was the fighter jet sequence\n",
      "Length: 15\n",
      "Label: [[1.4]]\n",
      "Segment: Af8D0E4ZXaw[16]\n",
      "----------------------------------------\n",
      "Example 474:\n",
      "Text: it was by far my favorite action seen in the movie\n",
      "Length: 11\n",
      "Label: [[2.2]]\n",
      "Segment: Af8D0E4ZXaw[17]\n",
      "----------------------------------------\n",
      "Example 475:\n",
      "Text: i thought it was really well put together\n",
      "Length: 8\n",
      "Label: [[2.4]]\n",
      "Segment: Af8D0E4ZXaw[18]\n",
      "----------------------------------------\n",
      "Example 476:\n",
      "Text: and um i thought it worked worked pretty well\n",
      "Length: 9\n",
      "Label: [[1.6]]\n",
      "Segment: Af8D0E4ZXaw[19]\n",
      "----------------------------------------\n",
      "Example 477:\n",
      "Text: um and in fact in spite of all the negatives im about to mention i thought the movie was working for a while for about the first third um but at the end of act one two significant things happened\n",
      "Length: 40\n",
      "Label: [[-0.8]]\n",
      "Segment: Af8D0E4ZXaw[20]\n",
      "----------------------------------------\n",
      "Example 478:\n",
      "Text: and starts chewing scenery like its a two dollar steak\n",
      "Length: 10\n",
      "Label: [[-1.6]]\n",
      "Segment: Af8D0E4ZXaw[21]\n",
      "----------------------------------------\n",
      "Example 479:\n",
      "Text: and how jordan flies off to the green lantern core planet oh and the movie starts sequel baiting\n",
      "Length: 18\n",
      "Label: [[-1.]]\n",
      "Segment: Af8D0E4ZXaw[22]\n",
      "----------------------------------------\n",
      "Example 480:\n",
      "Text: these two developments together caused what was up to that point a noble effort to start falling apart at the seams\n",
      "Length: 21\n",
      "Label: [[-1.6]]\n",
      "Segment: Af8D0E4ZXaw[23]\n",
      "----------------------------------------\n",
      "Example 481:\n",
      "Text: and it was painful to watch\n",
      "Length: 6\n",
      "Label: [[-2.6]]\n",
      "Segment: Af8D0E4ZXaw[24]\n",
      "----------------------------------------\n",
      "Example 482:\n",
      "Text: i dont even know why i really should begin with listing off the negatives but im going to start with a few of the superficial things\n",
      "Length: 26\n",
      "Label: [[-2.4]]\n",
      "Segment: Af8D0E4ZXaw[25]\n",
      "----------------------------------------\n",
      "Example 483:\n",
      "Text: the acting ranges from mediocrity to from the live action actors\n",
      "Length: 11\n",
      "Label: [[-1.6]]\n",
      "Segment: Af8D0E4ZXaw[26]\n",
      "----------------------------------------\n",
      "Example 484:\n",
      "Text: but i cant really blame them for that\n",
      "Length: 8\n",
      "Label: [[-0.2]]\n",
      "Segment: Af8D0E4ZXaw[27]\n",
      "----------------------------------------\n",
      "Example 485:\n",
      "Text: this is star wars territory\n",
      "Length: 5\n",
      "Label: [[-0.4]]\n",
      "Segment: Af8D0E4ZXaw[28]\n",
      "----------------------------------------\n",
      "Example 486:\n",
      "Text: the acting is not that bad\n",
      "Length: 6\n",
      "Label: [[-0.8]]\n",
      "Segment: Af8D0E4ZXaw[29]\n",
      "----------------------------------------\n",
      "Example 487:\n",
      "Text: but still its that kind of movie making\n",
      "Length: 8\n",
      "Label: [[-0.4]]\n",
      "Segment: Af8D0E4ZXaw[30]\n",
      "----------------------------------------\n",
      "Example 488:\n",
      "Text: and it was actually pretty good\n",
      "Length: 6\n",
      "Label: [[2.]]\n",
      "Segment: BI97DNYfe5I[0]\n",
      "----------------------------------------\n",
      "Example 489:\n",
      "Text: um i was expecting seth rogan to be a little bit more serious in this movie but he he\n",
      "Length: 19\n",
      "Label: [[-1.]]\n",
      "Segment: BI97DNYfe5I[1]\n",
      "----------------------------------------\n",
      "Example 490:\n",
      "Text: he was the same old goofy seth rogan that we all know\n",
      "Length: 12\n",
      "Label: [[-0.2]]\n",
      "Segment: BI97DNYfe5I[2]\n",
      "----------------------------------------\n",
      "Example 491:\n",
      "Text: um but it was still a good film\n",
      "Length: 8\n",
      "Label: [[1.4]]\n",
      "Segment: BI97DNYfe5I[3]\n",
      "----------------------------------------\n",
      "Example 492:\n",
      "Text: um i think that i mean i had fun with it\n",
      "Length: 11\n",
      "Label: [[1.4]]\n",
      "Segment: BI97DNYfe5I[4]\n",
      "----------------------------------------\n",
      "Example 493:\n",
      "Text: so to me thats a pretty good movie\n",
      "Length: 8\n",
      "Label: [[1.4]]\n",
      "Segment: BI97DNYfe5I[5]\n",
      "----------------------------------------\n",
      "Example 494:\n",
      "Text: and um because of that i was expecting seth rogan to maybe try to be a little bit more serious but he but\n",
      "Length: 23\n",
      "Label: [[-0.8]]\n",
      "Segment: BI97DNYfe5I[6]\n",
      "----------------------------------------\n",
      "Example 495:\n",
      "Text: but you know thats ok i guess\n",
      "Length: 7\n",
      "Label: [[0.4]]\n",
      "Segment: BI97DNYfe5I[7]\n",
      "----------------------------------------\n",
      "Example 496:\n",
      "Text: um i still had fun with it\n",
      "Length: 7\n",
      "Label: [[1.4]]\n",
      "Segment: BI97DNYfe5I[8]\n",
      "----------------------------------------\n",
      "Example 497:\n",
      "Text: um the car the black beauty that was amazing all the guns even the car over there that was really sweet\n",
      "Length: 21\n",
      "Label: [[2.8]]\n",
      "Segment: BI97DNYfe5I[9]\n",
      "----------------------------------------\n",
      "Example 498:\n",
      "Text: and all the action scenes were great\n",
      "Length: 7\n",
      "Label: [[2.]]\n",
      "Segment: BI97DNYfe5I[10]\n",
      "----------------------------------------\n",
      "Example 499:\n",
      "Text: the special effects were great and the guy who played kato whose first name is j\n",
      "Length: 16\n",
      "Label: [[1.6]]\n",
      "Segment: BI97DNYfe5I[11]\n",
      "----------------------------------------\n",
      "Example 500:\n",
      "Text: um he was good\n",
      "Length: 4\n",
      "Label: [[1.4]]\n",
      "Segment: BI97DNYfe5I[12]\n",
      "----------------------------------------\n",
      "Example 501:\n",
      "Text: he played kato perfectly\n",
      "Length: 4\n",
      "Label: [[2.]]\n",
      "Segment: BI97DNYfe5I[13]\n",
      "----------------------------------------\n",
      "Example 502:\n",
      "Text: and he did a great job\n",
      "Length: 6\n",
      "Label: [[2.]]\n",
      "Segment: BI97DNYfe5I[14]\n",
      "----------------------------------------\n",
      "Example 503:\n",
      "Text: um the acting was was pretty good\n",
      "Length: 7\n",
      "Label: [[1.2]]\n",
      "Segment: BI97DNYfe5I[15]\n",
      "----------------------------------------\n",
      "Example 504:\n",
      "Text: and the action was good\n",
      "Length: 5\n",
      "Label: [[1.6]]\n",
      "Segment: BI97DNYfe5I[16]\n",
      "----------------------------------------\n",
      "Example 505:\n",
      "Text: um i would recommend you go see it in theaters\n",
      "Length: 10\n",
      "Label: [[2.2]]\n",
      "Segment: BI97DNYfe5I[17]\n",
      "----------------------------------------\n",
      "Example 506:\n",
      "Text: coz take a bunch of your friends because you you guys will have a good time\n",
      "Length: 16\n",
      "Label: [[1.6]]\n",
      "Segment: BI97DNYfe5I[18]\n",
      "----------------------------------------\n",
      "Example 507:\n",
      "Text: fun\n",
      "Length: 1\n",
      "Label: [[0.]]\n",
      "Segment: BI97DNYfe5I[19]\n",
      "----------------------------------------\n",
      "Example 508:\n",
      "Text: and laugh\n",
      "Length: 2\n",
      "Label: [[1.2]]\n",
      "Segment: BI97DNYfe5I[20]\n",
      "----------------------------------------\n",
      "Example 509:\n",
      "Text: it is funny its a funny movie\n",
      "Length: 7\n",
      "Label: [[2.2]]\n",
      "Segment: BI97DNYfe5I[21]\n",
      "----------------------------------------\n",
      "Example 510:\n",
      "Text: lots of lots of laugh out loud moment i guess you could say\n",
      "Length: 13\n",
      "Label: [[1.6]]\n",
      "Segment: BI97DNYfe5I[22]\n",
      "----------------------------------------\n",
      "Example 511:\n",
      "Text: but um yeah go check it out\n",
      "Length: 7\n",
      "Label: [[1.4]]\n",
      "Segment: BI97DNYfe5I[23]\n",
      "----------------------------------------\n",
      "Example 512:\n",
      "Text: its one its one to check out in theaters i would say\n",
      "Length: 12\n",
      "Label: [[1.2]]\n",
      "Segment: BI97DNYfe5I[24]\n",
      "----------------------------------------\n",
      "Example 513:\n",
      "Text: um but yeah so the green hornet it was ok\n",
      "Length: 10\n",
      "Label: [[1.]]\n",
      "Segment: BI97DNYfe5I[25]\n",
      "----------------------------------------\n",
      "Example 514:\n",
      "Text: i expected a little bit more seriousness\n",
      "Length: 7\n",
      "Label: [[-1.]]\n",
      "Segment: BI97DNYfe5I[26]\n",
      "----------------------------------------\n",
      "Example 515:\n",
      "Text: but it was still get\n",
      "Length: 5\n",
      "Label: [[1.2]]\n",
      "Segment: BI97DNYfe5I[27]\n",
      "----------------------------------------\n",
      "Example 516:\n",
      "Text: it gets pretty serious\n",
      "Length: 4\n",
      "Label: [[0.2]]\n",
      "Segment: BI97DNYfe5I[28]\n",
      "----------------------------------------\n",
      "Example 517:\n",
      "Text: and um fun at the end\n",
      "Length: 6\n",
      "Label: [[1.2]]\n",
      "Segment: BI97DNYfe5I[29]\n",
      "----------------------------------------\n",
      "Example 518:\n",
      "Text: too pretty intense at the end\n",
      "Length: 6\n",
      "Label: [[1.]]\n",
      "Segment: BI97DNYfe5I[30]\n",
      "----------------------------------------\n",
      "Example 519:\n",
      "Text: cowboys and aliens speaking is like one of those teams that has the talent to be a super bowl champion but instead ends up being a wild cart team that just gets dismissed in the first round of playoffs\n",
      "Length: 39\n",
      "Label: [[-1.]]\n",
      "Segment: BXuRRbG0Ugk[0]\n",
      "----------------------------------------\n",
      "Example 520:\n",
      "Text: yeah job pretty well done\n",
      "Length: 5\n",
      "Label: [[0.8]]\n",
      "Segment: BXuRRbG0Ugk[1]\n",
      "----------------------------------------\n",
      "Example 521:\n",
      "Text: i mean it a bad year\n",
      "Length: 6\n",
      "Label: [[-0.4]]\n",
      "Segment: BXuRRbG0Ugk[2]\n",
      "----------------------------------------\n",
      "Example 522:\n",
      "Text: but there was a lot of potential left on the table\n",
      "Length: 11\n",
      "Label: [[0.]]\n",
      "Segment: BXuRRbG0Ugk[3]\n",
      "----------------------------------------\n",
      "Example 523:\n",
      "Text: and that describes cowboys and aliens pretty well\n",
      "Length: 8\n",
      "Label: [[0.]]\n",
      "Segment: BXuRRbG0Ugk[4]\n",
      "----------------------------------------\n",
      "Example 524:\n",
      "Text: though i guess i should be grateful that it turned out as good as it did\n",
      "Length: 16\n",
      "Label: [[1.4]]\n",
      "Segment: BXuRRbG0Ugk[5]\n",
      "----------------------------------------\n",
      "Example 525:\n",
      "Text: because given all the strikes that it had going against before wonder production it could have been much much worse\n",
      "Length: 20\n",
      "Label: [[0.2]]\n",
      "Segment: BXuRRbG0Ugk[6]\n",
      "----------------------------------------\n",
      "Example 526:\n",
      "Text: some good decisions were made before the camara started rolling\n",
      "Length: 10\n",
      "Label: [[1.75]]\n",
      "Segment: BXuRRbG0Ugk[7]\n",
      "----------------------------------------\n",
      "Example 527:\n",
      "Text: but this probably had the unfortunate side effect of raising bad expectations to unreasonable levels\n",
      "Length: 15\n",
      "Label: [[-1.2]]\n",
      "Segment: BXuRRbG0Ugk[8]\n",
      "----------------------------------------\n",
      "Example 528:\n",
      "Text: when i saw the first trailer back in november of last year this movie immediately shot up near the top of my list of must see movies for the\n",
      "Length: 29\n",
      "Label: [[2.4]]\n",
      "Segment: BXuRRbG0Ugk[9]\n",
      "----------------------------------------\n",
      "Example 529:\n",
      "Text: the final product ultimately doesnt live up to the high order of that first trailer\n",
      "Length: 15\n",
      "Label: [[-1.6]]\n",
      "Segment: BXuRRbG0Ugk[10]\n",
      "----------------------------------------\n",
      "Example 530:\n",
      "Text: but its still a pretty enjoyable ride if you go in wanting to see a bunch of cowboys battle a bunch of aliens yeah pretty much get your fill\n",
      "Length: 29\n",
      "Label: [[1.2]]\n",
      "Segment: BXuRRbG0Ugk[11]\n",
      "----------------------------------------\n",
      "Example 531:\n",
      "Text: but if thats all youre looking for actually miss the best thing about this movie\n",
      "Length: 15\n",
      "Label: [[0.6]]\n",
      "Segment: BXuRRbG0Ugk[12]\n",
      "----------------------------------------\n",
      "Example 532:\n",
      "Text: jon favreau is probably not the guy that i would hire if i was looking for a director for an action movie\n",
      "Length: 22\n",
      "Label: [[-1.6]]\n",
      "Segment: BXuRRbG0Ugk[13]\n",
      "----------------------------------------\n",
      "Example 533:\n",
      "Text: i mean yeah hes a competent action director\n",
      "Length: 8\n",
      "Label: [[-0.6]]\n",
      "Segment: BXuRRbG0Ugk[14]\n",
      "----------------------------------------\n",
      "Example 534:\n",
      "Text: hes action sequences are certainly a lot better than the incoherent impossible to follow slope that we see in a typical michael bay movie\n",
      "Length: 24\n",
      "Label: [[0.]]\n",
      "Segment: BXuRRbG0Ugk[15]\n",
      "----------------------------------------\n",
      "Example 535:\n",
      "Text: but its action memorable\n",
      "Length: 4\n",
      "Label: [[-1.6]]\n",
      "Segment: BXuRRbG0Ugk[16]\n",
      "----------------------------------------\n",
      "Example 536:\n",
      "Text: and the action the most memorable thing about any on those movies\n",
      "Length: 12\n",
      "Label: [[-1.4]]\n",
      "Segment: BXuRRbG0Ugk[17]\n",
      "----------------------------------------\n",
      "Example 537:\n",
      "Text: the films are fondly remembered mostly for robert jr not the action\n",
      "Length: 12\n",
      "Label: [[0.2]]\n",
      "Segment: BXuRRbG0Ugk[18]\n",
      "----------------------------------------\n",
      "Example 538:\n",
      "Text: and the same thing has more or less happened here yeah thats right\n",
      "Length: 13\n",
      "Label: [[-0.4]]\n",
      "Segment: BXuRRbG0Ugk[19]\n",
      "----------------------------------------\n",
      "Example 539:\n",
      "Text: the movie called cowboys and aliens daniel craig steels the whole damn show\n",
      "Length: 13\n",
      "Label: [[2.4]]\n",
      "Segment: BXuRRbG0Ugk[20]\n",
      "----------------------------------------\n",
      "Example 540:\n",
      "Text: hes playing a variation of the man with no name character that was made famous by clint eastwood\n",
      "Length: 18\n",
      "Label: [[0.5]]\n",
      "Segment: BXuRRbG0Ugk[21]\n",
      "----------------------------------------\n",
      "Example 541:\n",
      "Text: and now that ive seen him in the role i cant imagine any other current actor trying ot pull it off\n",
      "Length: 21\n",
      "Label: [[1.4]]\n",
      "Segment: BXuRRbG0Ugk[22]\n",
      "----------------------------------------\n",
      "Example 542:\n",
      "Text: he is perfect from start to ford\n",
      "Length: 7\n",
      "Label: [[2.4]]\n",
      "Segment: BXuRRbG0Ugk[23]\n",
      "----------------------------------------\n",
      "Example 543:\n",
      "Text: is a long for the ride and having a blast as the second lead\n",
      "Length: 14\n",
      "Label: [[1.]]\n",
      "Segment: BXuRRbG0Ugk[24]\n",
      "----------------------------------------\n",
      "Example 544:\n",
      "Text: and the cast is pretty well rounded out with performance from guys like sam rockwell as the doc\n",
      "Length: 18\n",
      "Label: [[1.6]]\n",
      "Segment: BXuRRbG0Ugk[25]\n",
      "----------------------------------------\n",
      "Example 545:\n",
      "Text: theyre all playing cliched stock western characters\n",
      "Length: 7\n",
      "Label: [[-0.4]]\n",
      "Segment: BXuRRbG0Ugk[26]\n",
      "----------------------------------------\n",
      "Example 546:\n",
      "Text: but i really dont care that the characters are walking cliches when they are this well done\n",
      "Length: 17\n",
      "Label: [[1.6]]\n",
      "Segment: BXuRRbG0Ugk[27]\n",
      "----------------------------------------\n",
      "Example 547:\n",
      "Text: and the actors do such a good job of carrying of their particular arcs\n",
      "Length: 14\n",
      "Label: [[2.]]\n",
      "Segment: BXuRRbG0Ugk[28]\n",
      "----------------------------------------\n",
      "Example 548:\n",
      "Text: cowboys and aliens problem is the screenplay\n",
      "Length: 7\n",
      "Label: [[-2.]]\n",
      "Segment: BXuRRbG0Ugk[29]\n",
      "----------------------------------------\n",
      "Example 549:\n",
      "Text: six different people got writing credit for this movie and the results are exactly what you would expect\n",
      "Length: 18\n",
      "Label: [[-0.4]]\n",
      "Segment: BXuRRbG0Ugk[30]\n",
      "----------------------------------------\n",
      "Example 550:\n",
      "Text: snap most of the critics are right\n",
      "Length: 7\n",
      "Label: [[-1.75]]\n",
      "Segment: Bfr499ggo-0[0]\n",
      "----------------------------------------\n",
      "Example 551:\n",
      "Text: it just really heh\n",
      "Length: 4\n",
      "Label: [[-1.]]\n",
      "Segment: Bfr499ggo-0[1]\n",
      "----------------------------------------\n",
      "Example 552:\n",
      "Text: but if you loved the series and you also liked the first movie than youre still gonna have fun\n",
      "Length: 19\n",
      "Label: [[1.6]]\n",
      "Segment: Bfr499ggo-0[2]\n",
      "----------------------------------------\n",
      "Example 553:\n",
      "Text: just go in with low if\n",
      "Length: 6\n",
      "Label: [[-1.2]]\n",
      "Segment: Bfr499ggo-0[3]\n",
      "----------------------------------------\n",
      "Example 554:\n",
      "Text: if your pet carrie wore those horrendous hideous hats they were not catching the ball\n",
      "Length: 15\n",
      "Label: [[-1.8]]\n",
      "Segment: Bfr499ggo-0[4]\n",
      "----------------------------------------\n",
      "Example 555:\n",
      "Text: and a few times i didnt like the fashion\n",
      "Length: 9\n",
      "Label: [[-1.2]]\n",
      "Segment: Bfr499ggo-0[5]\n",
      "----------------------------------------\n",
      "Example 556:\n",
      "Text: a few times i thought that was bumped way over the top\n",
      "Length: 12\n",
      "Label: [[-1.]]\n",
      "Segment: Bfr499ggo-0[6]\n",
      "----------------------------------------\n",
      "Example 557:\n",
      "Text: and they kind of looked like clowns the desert scene was one of them\n",
      "Length: 14\n",
      "Label: [[-1.2]]\n",
      "Segment: Bfr499ggo-0[7]\n",
      "----------------------------------------\n",
      "Example 558:\n",
      "Text: um but you know the premise is ok\n",
      "Length: 8\n",
      "Label: [[0.4]]\n",
      "Segment: Bfr499ggo-0[8]\n",
      "----------------------------------------\n",
      "Example 559:\n",
      "Text: and there are a few nice moments\n",
      "Length: 7\n",
      "Label: [[1.]]\n",
      "Segment: Bfr499ggo-0[9]\n",
      "----------------------------------------\n",
      "Example 560:\n",
      "Text: the movie is really too long\n",
      "Length: 6\n",
      "Label: [[-0.8]]\n",
      "Segment: Bfr499ggo-0[10]\n",
      "----------------------------------------\n",
      "Example 561:\n",
      "Text: they just cut the wedding in the beginning\n",
      "Length: 8\n",
      "Label: [[-1.4]]\n",
      "Segment: Bfr499ggo-0[11]\n",
      "----------------------------------------\n",
      "Example 562:\n",
      "Text: its not even necessary for the plot\n",
      "Length: 7\n",
      "Label: [[-1.6]]\n",
      "Segment: Bfr499ggo-0[12]\n",
      "----------------------------------------\n",
      "Example 563:\n",
      "Text: i also thought that desert riding the camels all troup stopped looking like clowns\n",
      "Length: 14\n",
      "Label: [[-0.2]]\n",
      "Segment: Bfr499ggo-0[13]\n",
      "----------------------------------------\n",
      "Example 564:\n",
      "Text: but also not necessary\n",
      "Length: 4\n",
      "Label: [[-1.]]\n",
      "Segment: Bfr499ggo-0[14]\n",
      "----------------------------------------\n",
      "Example 565:\n",
      "Text: but i love the moment with charlotte in the closet because who experienced that\n",
      "Length: 14\n",
      "Label: [[2.2]]\n",
      "Segment: Bfr499ggo-0[15]\n",
      "----------------------------------------\n",
      "Example 566:\n",
      "Text: and um it was just fun to see your old friends again\n",
      "Length: 12\n",
      "Label: [[1.4]]\n",
      "Segment: Bfr499ggo-0[16]\n",
      "----------------------------------------\n",
      "Example 567:\n",
      "Text: so if your a fan id do it\n",
      "Length: 8\n",
      "Label: [[0.8]]\n",
      "Segment: Bfr499ggo-0[17]\n",
      "----------------------------------------\n",
      "Example 568:\n",
      "Text: but dont expect much\n",
      "Length: 4\n",
      "Label: [[-1.8]]\n",
      "Segment: Bfr499ggo-0[18]\n",
      "----------------------------------------\n",
      "Example 569:\n",
      "Text: the writing as good as the first\n",
      "Length: 7\n",
      "Label: [[-1.6]]\n",
      "Segment: Bfr499ggo-0[19]\n",
      "----------------------------------------\n",
      "Example 570:\n",
      "Text: the storyline this good\n",
      "Length: 4\n",
      "Label: [[-2.]]\n",
      "Segment: Bfr499ggo-0[20]\n",
      "----------------------------------------\n",
      "Example 571:\n",
      "Text: but if you dont expect a lot i think enjoy it\n",
      "Length: 11\n",
      "Label: [[1.]]\n",
      "Segment: Bfr499ggo-0[21]\n",
      "----------------------------------------\n",
      "Example 572:\n",
      "Text: im a big fan of the first tron\n",
      "Length: 8\n",
      "Label: [[1.4]]\n",
      "Segment: BioHAh1qJAQ[0]\n",
      "----------------------------------------\n",
      "Example 573:\n",
      "Text: um i thought this is the perfect time to have a tron sequel\n",
      "Length: 13\n",
      "Label: [[2.2]]\n",
      "Segment: BioHAh1qJAQ[1]\n",
      "----------------------------------------\n",
      "Example 574:\n",
      "Text: because um in at the beginning of the people thought that computers can do every every anything\n",
      "Length: 17\n",
      "Label: [[0.4]]\n",
      "Segment: BioHAh1qJAQ[2]\n",
      "----------------------------------------\n",
      "Example 575:\n",
      "Text: and everything and now technology actually does anything and everything\n",
      "Length: 10\n",
      "Label: [[0.25]]\n",
      "Segment: BioHAh1qJAQ[3]\n",
      "----------------------------------------\n",
      "Example 576:\n",
      "Text: because it kinda controls our lives so it was the perfect time for a tron sequel\n",
      "Length: 16\n",
      "Label: [[1.4]]\n",
      "Segment: BioHAh1qJAQ[4]\n",
      "----------------------------------------\n",
      "Example 577:\n",
      "Text: unfortunately um the writers and i were not exactly on the same wavelength\n",
      "Length: 13\n",
      "Label: [[-1.8]]\n",
      "Segment: BioHAh1qJAQ[5]\n",
      "----------------------------------------\n",
      "Example 578:\n",
      "Text: lip smacking but i will say that the first third of this movie is amazing\n",
      "Length: 15\n",
      "Label: [[2.6]]\n",
      "Segment: BioHAh1qJAQ[6]\n",
      "----------------------------------------\n",
      "Example 579:\n",
      "Text: its the best summer movie ive seen all year\n",
      "Length: 9\n",
      "Label: [[2.4]]\n",
      "Segment: BioHAh1qJAQ[7]\n",
      "----------------------------------------\n",
      "Example 580:\n",
      "Text: but you know the pacing is so good\n",
      "Length: 8\n",
      "Label: [[2.]]\n",
      "Segment: BioHAh1qJAQ[8]\n",
      "----------------------------------------\n",
      "Example 581:\n",
      "Text: it gets straight into the story\n",
      "Length: 6\n",
      "Label: [[1.]]\n",
      "Segment: BioHAh1qJAQ[9]\n",
      "----------------------------------------\n",
      "Example 582:\n",
      "Text: you have lots of uh references to the first movie\n",
      "Length: 10\n",
      "Label: [[0.2]]\n",
      "Segment: BioHAh1qJAQ[10]\n",
      "----------------------------------------\n",
      "Example 583:\n",
      "Text: you have new characters that actually have a connection to the old ones\n",
      "Length: 13\n",
      "Label: [[0.6666667]]\n",
      "Segment: BioHAh1qJAQ[11]\n",
      "----------------------------------------\n",
      "Example 584:\n",
      "Text: and once sam flynn enters the grid you know the soundtrack draws you in\n",
      "Length: 14\n",
      "Label: [[1.4]]\n",
      "Segment: BioHAh1qJAQ[12]\n",
      "----------------------------------------\n",
      "Example 585:\n",
      "Text: the special effects look amazing\n",
      "Length: 5\n",
      "Label: [[2.6]]\n",
      "Segment: BioHAh1qJAQ[13]\n",
      "----------------------------------------\n",
      "Example 586:\n",
      "Text: uh they dont waste a lot of time on exposition\n",
      "Length: 10\n",
      "Label: [[-0.4]]\n",
      "Segment: BioHAh1qJAQ[14]\n",
      "----------------------------------------\n",
      "Example 587:\n",
      "Text: because the minute the enters the grid he is put in the games\n",
      "Length: 13\n",
      "Label: [[0.25]]\n",
      "Segment: BioHAh1qJAQ[15]\n",
      "----------------------------------------\n",
      "Example 588:\n",
      "Text: and let me tell you the games look great\n",
      "Length: 9\n",
      "Label: [[2.4]]\n",
      "Segment: BioHAh1qJAQ[16]\n",
      "----------------------------------------\n",
      "Example 589:\n",
      "Text: all those action sequences in involving the games were great to watch\n",
      "Length: 12\n",
      "Label: [[2.]]\n",
      "Segment: BioHAh1qJAQ[17]\n",
      "----------------------------------------\n",
      "Example 590:\n",
      "Text: um the cho the choreography of the fights the special effects i was so happy to be back in the grid that i really thinking about the story or where the story was going\n",
      "Length: 34\n",
      "Label: [[1.8]]\n",
      "Segment: BioHAh1qJAQ[18]\n",
      "----------------------------------------\n",
      "Example 591:\n",
      "Text: but then sam flynn meets his father and tron basically turns into a star wars after that one\n",
      "Length: 18\n",
      "Label: [[-1.4]]\n",
      "Segment: BioHAh1qJAQ[19]\n",
      "----------------------------------------\n",
      "Example 592:\n",
      "Text: disconnection then that happens at that point\n",
      "Length: 7\n",
      "Label: [[-0.8]]\n",
      "Segment: BioHAh1qJAQ[20]\n",
      "----------------------------------------\n",
      "Example 593:\n",
      "Text: the writers just pull this out of their ass\n",
      "Length: 9\n",
      "Label: [[-2.2]]\n",
      "Segment: BioHAh1qJAQ[21]\n",
      "----------------------------------------\n",
      "Example 594:\n",
      "Text: and the whole movie becomes about these crazy i i theyre\n",
      "Length: 11\n",
      "Label: [[-2.]]\n",
      "Segment: BioHAh1qJAQ[22]\n",
      "----------------------------------------\n",
      "Example 595:\n",
      "Text: and its just like or why do we need these things\n",
      "Length: 11\n",
      "Label: [[-1.4]]\n",
      "Segment: BioHAh1qJAQ[23]\n",
      "----------------------------------------\n",
      "Example 596:\n",
      "Text: it doesnt make any sense\n",
      "Length: 5\n",
      "Label: [[-1.6]]\n",
      "Segment: BioHAh1qJAQ[24]\n",
      "----------------------------------------\n",
      "Example 597:\n",
      "Text: because when the old flynn finds these things whatever they are theyre so wise and naive kinda like now that i think about it\n",
      "Length: 24\n",
      "Label: [[0.8]]\n",
      "Segment: BioHAh1qJAQ[25]\n",
      "----------------------------------------\n",
      "Example 598:\n",
      "Text: clue which is the program that he created in the first movie kinda pulls a bunny in the boiler moment in the sense that he turns into a crazy jealous psycho stalker bitch\n",
      "Length: 33\n",
      "Label: [[0.]]\n",
      "Segment: BioHAh1qJAQ[26]\n",
      "----------------------------------------\n",
      "Example 599:\n",
      "Text: and clue has to be one of the most idiotic villains ever cause what is a what is clue\n",
      "Length: 19\n",
      "Label: [[-2.]]\n",
      "Segment: BioHAh1qJAQ[27]\n",
      "----------------------------------------\n",
      "Example 600:\n",
      "Text: for some kind of freaky or\n",
      "Length: 6\n",
      "Label: [[0.]]\n",
      "Segment: BioHAh1qJAQ[28]\n",
      "----------------------------------------\n",
      "Example 601:\n",
      "Text: and its like youre a computer program okay if you want to take over the world using real people its the worst way you could possibly do that infiltrate some computer system somewhere and detonate some nukes or\n",
      "Length: 38\n",
      "Label: [[-2.]]\n",
      "Segment: BioHAh1qJAQ[29]\n",
      "----------------------------------------\n",
      "Example 602:\n",
      "Text: i was very impressed with his work on the first one\n",
      "Length: 11\n",
      "Label: [[1.6]]\n",
      "Segment: BvYR0L6f2Ig[0]\n",
      "----------------------------------------\n",
      "Example 603:\n",
      "Text: i thought the first one was creative and inventive and really brought something new to the cinema\n",
      "Length: 17\n",
      "Label: [[2.]]\n",
      "Segment: BvYR0L6f2Ig[1]\n",
      "----------------------------------------\n",
      "Example 604:\n",
      "Text: but the second one it didnt in some ways take to the next level\n",
      "Length: 14\n",
      "Label: [[0.4]]\n",
      "Segment: BvYR0L6f2Ig[2]\n",
      "----------------------------------------\n",
      "Example 605:\n",
      "Text: but in some ways the first one was better\n",
      "Length: 9\n",
      "Label: [[-1.]]\n",
      "Segment: BvYR0L6f2Ig[3]\n",
      "----------------------------------------\n",
      "Example 606:\n",
      "Text: so it was just about equal to the first one\n",
      "Length: 10\n",
      "Label: [[-0.2]]\n",
      "Segment: BvYR0L6f2Ig[4]\n",
      "----------------------------------------\n",
      "Example 607:\n",
      "Text: now um but some of the brush plot that you mey think i hated this movie\n",
      "Length: 16\n",
      "Label: [[-0.8]]\n",
      "Segment: BvYR0L6f2Ig[5]\n",
      "----------------------------------------\n",
      "Example 608:\n",
      "Text: now um but some of the brush plot that you mey think i hated this movie but youre wrong actually i did\n",
      "Length: 22\n",
      "Label: [[1.2]]\n",
      "Segment: BvYR0L6f2Ig[6]\n",
      "----------------------------------------\n",
      "Example 609:\n",
      "Text: i really liked it\n",
      "Length: 4\n",
      "Label: [[0.8]]\n",
      "Segment: BvYR0L6f2Ig[7]\n",
      "----------------------------------------\n",
      "Example 610:\n",
      "Text: first im gonna get into the acting which was much much better than the second one\n",
      "Length: 16\n",
      "Label: [[2.2]]\n",
      "Segment: BvYR0L6f2Ig[8]\n",
      "----------------------------------------\n",
      "Example 611:\n",
      "Text: the second one had wooden acting in some places im sorry\n",
      "Length: 11\n",
      "Label: [[-1.8]]\n",
      "Segment: BvYR0L6f2Ig[9]\n",
      "----------------------------------------\n",
      "Example 612:\n",
      "Text: i did like the second one\n",
      "Length: 6\n",
      "Label: [[0.6]]\n",
      "Segment: BvYR0L6f2Ig[10]\n",
      "----------------------------------------\n",
      "Example 613:\n",
      "Text: but there most of the actors we so witty may be the police cop and kim kimberly\n",
      "Length: 17\n",
      "Label: [[0.4]]\n",
      "Segment: BvYR0L6f2Ig[11]\n",
      "----------------------------------------\n",
      "Example 614:\n",
      "Text: but the rest of the actors were so wooden\n",
      "Length: 9\n",
      "Label: [[-1.4]]\n",
      "Segment: BvYR0L6f2Ig[12]\n",
      "----------------------------------------\n",
      "Example 615:\n",
      "Text: they were just theyre just they just why acting what theyre doing anyway\n",
      "Length: 13\n",
      "Label: [[-1.8]]\n",
      "Segment: BvYR0L6f2Ig[13]\n",
      "----------------------------------------\n",
      "Example 616:\n",
      "Text: i dont know they do seem they need to learn acting better\n",
      "Length: 12\n",
      "Label: [[-1.2]]\n",
      "Segment: BvYR0L6f2Ig[14]\n",
      "----------------------------------------\n",
      "Example 617:\n",
      "Text: anyway the further i went acting was much much better in the second one\n",
      "Length: 14\n",
      "Label: [[1.8]]\n",
      "Segment: BvYR0L6f2Ig[15]\n",
      "----------------------------------------\n",
      "Example 618:\n",
      "Text: anyway mary elizabeth winstead oh my god she is a nice\n",
      "Length: 11\n",
      "Label: [[2.]]\n",
      "Segment: BvYR0L6f2Ig[16]\n",
      "----------------------------------------\n",
      "Example 619:\n",
      "Text: looking as well\n",
      "Length: 3\n",
      "Label: [[0.]]\n",
      "Segment: BvYR0L6f2Ig[17]\n",
      "----------------------------------------\n",
      "Example 620:\n",
      "Text: but she is also a actress\n",
      "Length: 6\n",
      "Label: [[2.2]]\n",
      "Segment: BvYR0L6f2Ig[18]\n",
      "----------------------------------------\n",
      "Example 621:\n",
      "Text: this is one of the best performances ive ever seen out of hers\n",
      "Length: 13\n",
      "Label: [[2.8]]\n",
      "Segment: BvYR0L6f2Ig[19]\n",
      "----------------------------------------\n",
      "Example 622:\n",
      "Text: ive not seen one bad movie that been into\n",
      "Length: 9\n",
      "Label: [[1.6]]\n",
      "Segment: BvYR0L6f2Ig[20]\n",
      "----------------------------------------\n",
      "Example 623:\n",
      "Text: that\n",
      "Length: 1\n",
      "Label: [[-1.]]\n",
      "Segment: BvYR0L6f2Ig[21]\n",
      "----------------------------------------\n",
      "Example 624:\n",
      "Text: but mary elizabeth winstead i must say she is a and beautiful and talented she\n",
      "Length: 15\n",
      "Label: [[2.4]]\n",
      "Segment: BvYR0L6f2Ig[22]\n",
      "----------------------------------------\n",
      "Example 625:\n",
      "Text: she displays the emotional distress of her character so well\n",
      "Length: 10\n",
      "Label: [[1.6]]\n",
      "Segment: BvYR0L6f2Ig[23]\n",
      "----------------------------------------\n",
      "Example 626:\n",
      "Text: you actually feel for her character\n",
      "Length: 6\n",
      "Label: [[1.8]]\n",
      "Segment: BvYR0L6f2Ig[24]\n",
      "----------------------------------------\n",
      "Example 627:\n",
      "Text: you know going through the stress and you feel sorry for her and you wanna help her\n",
      "Length: 17\n",
      "Label: [[1.]]\n",
      "Segment: BvYR0L6f2Ig[25]\n",
      "----------------------------------------\n",
      "Example 628:\n",
      "Text: because im still excited about it\n",
      "Length: 6\n",
      "Label: [[1.8]]\n",
      "Segment: Ci-AH39fi3Y[0]\n",
      "----------------------------------------\n",
      "Example 629:\n",
      "Text: as some of you might not notice i was excited about saw ok\n",
      "Length: 13\n",
      "Label: [[2.]]\n",
      "Segment: Ci-AH39fi3Y[1]\n",
      "----------------------------------------\n",
      "Example 630:\n",
      "Text: ok all of you knew that obviously\n",
      "Length: 7\n",
      "Label: [[0.]]\n",
      "Segment: Ci-AH39fi3Y[2]\n",
      "----------------------------------------\n",
      "Example 631:\n",
      "Text: so i was you know really hyped up\n",
      "Length: 8\n",
      "Label: [[1.8]]\n",
      "Segment: Ci-AH39fi3Y[3]\n",
      "----------------------------------------\n",
      "Example 632:\n",
      "Text: and excited to see it\n",
      "Length: 5\n",
      "Label: [[1.6]]\n",
      "Segment: Ci-AH39fi3Y[4]\n",
      "----------------------------------------\n",
      "Example 633:\n",
      "Text: and i have to say that it was better than the saw not\n",
      "Length: 13\n",
      "Label: [[1.6]]\n",
      "Segment: Ci-AH39fi3Y[5]\n",
      "----------------------------------------\n",
      "Example 634:\n",
      "Text: not what i was expecting\n",
      "Length: 5\n",
      "Label: [[0.6]]\n",
      "Segment: Ci-AH39fi3Y[6]\n",
      "----------------------------------------\n",
      "Example 635:\n",
      "Text: but it was still really really really good\n",
      "Length: 8\n",
      "Label: [[2.2]]\n",
      "Segment: Ci-AH39fi3Y[7]\n",
      "----------------------------------------\n",
      "Example 636:\n",
      "Text: and um its just made me really really for saw now\n",
      "Length: 11\n",
      "Label: [[2.4]]\n",
      "Segment: Ci-AH39fi3Y[8]\n",
      "----------------------------------------\n",
      "Example 637:\n",
      "Text: one of them was great\n",
      "Length: 5\n",
      "Label: [[1.]]\n",
      "Segment: Ci-AH39fi3Y[9]\n",
      "----------------------------------------\n",
      "Example 638:\n",
      "Text: and the other one was completely irrelevant as far as i can tell\n",
      "Length: 13\n",
      "Label: [[-1.8]]\n",
      "Segment: Ci-AH39fi3Y[10]\n",
      "----------------------------------------\n",
      "Example 639:\n",
      "Text: the great plot was with hoffman tying up all loose ends and stuff\n",
      "Length: 13\n",
      "Label: [[2.2]]\n",
      "Segment: Ci-AH39fi3Y[11]\n",
      "----------------------------------------\n",
      "Example 640:\n",
      "Text: and the irrelevant plot was with five strangers\n",
      "Length: 8\n",
      "Label: [[-1.2]]\n",
      "Segment: Ci-AH39fi3Y[12]\n",
      "----------------------------------------\n",
      "Example 641:\n",
      "Text: kind of like in saw who\n",
      "Length: 6\n",
      "Label: [[0.]]\n",
      "Segment: Ci-AH39fi3Y[13]\n",
      "----------------------------------------\n",
      "Example 642:\n",
      "Text: but i totally missed how it tied it to the movie at all\n",
      "Length: 13\n",
      "Label: [[-0.8]]\n",
      "Segment: Ci-AH39fi3Y[14]\n",
      "----------------------------------------\n",
      "Example 643:\n",
      "Text: and im pretty sure thats because it didnt tie in to the movie at all\n",
      "Length: 15\n",
      "Label: [[-1.6]]\n",
      "Segment: Ci-AH39fi3Y[15]\n",
      "----------------------------------------\n",
      "Example 644:\n",
      "Text: so that was really and i didnt care about the characters at all\n",
      "Length: 13\n",
      "Label: [[-2.6]]\n",
      "Segment: Ci-AH39fi3Y[16]\n",
      "----------------------------------------\n",
      "Example 645:\n",
      "Text: because they you know introduced well really\n",
      "Length: 7\n",
      "Label: [[-1.2]]\n",
      "Segment: Ci-AH39fi3Y[17]\n",
      "----------------------------------------\n",
      "Example 646:\n",
      "Text: so it was just really really strange\n",
      "Length: 7\n",
      "Label: [[-0.8]]\n",
      "Segment: Ci-AH39fi3Y[18]\n",
      "----------------------------------------\n",
      "Example 647:\n",
      "Text: but luckily story um was a really really really awesome\n",
      "Length: 10\n",
      "Label: [[2.8]]\n",
      "Segment: Ci-AH39fi3Y[19]\n",
      "----------------------------------------\n",
      "Example 648:\n",
      "Text: and um it totally made up for that so thats ok\n",
      "Length: 11\n",
      "Label: [[1.2]]\n",
      "Segment: Ci-AH39fi3Y[20]\n",
      "----------------------------------------\n",
      "Example 649:\n",
      "Text: and i guess thats sort of true\n",
      "Length: 7\n",
      "Label: [[0.4]]\n",
      "Segment: Ci-AH39fi3Y[21]\n",
      "----------------------------------------\n",
      "Example 650:\n",
      "Text: because i sure didnt see the end coming\n",
      "Length: 8\n",
      "Label: [[0.]]\n",
      "Segment: Ci-AH39fi3Y[22]\n",
      "----------------------------------------\n",
      "Example 651:\n",
      "Text: but the end was really you you know\n",
      "Length: 8\n",
      "Label: [[-1.]]\n",
      "Segment: Ci-AH39fi3Y[23]\n",
      "----------------------------------------\n",
      "Example 652:\n",
      "Text: but i thought the best part of saw was the storyline like in general\n",
      "Length: 14\n",
      "Label: [[1.8]]\n",
      "Segment: Ci-AH39fi3Y[24]\n",
      "----------------------------------------\n",
      "Example 653:\n",
      "Text: the ending was not you know crazy shocking or anything like usual\n",
      "Length: 12\n",
      "Label: [[-0.8]]\n",
      "Segment: Ci-AH39fi3Y[25]\n",
      "----------------------------------------\n",
      "Example 654:\n",
      "Text: it was not a real huge saw twist moment\n",
      "Length: 9\n",
      "Label: [[-0.6]]\n",
      "Segment: Ci-AH39fi3Y[26]\n",
      "----------------------------------------\n",
      "Example 655:\n",
      "Text: um so you know that was a little surprising i guess\n",
      "Length: 11\n",
      "Label: [[0.4]]\n",
      "Segment: Ci-AH39fi3Y[27]\n",
      "----------------------------------------\n",
      "Example 656:\n",
      "Text: thats not to say that the ending good because it really was\n",
      "Length: 12\n",
      "Label: [[1.4]]\n",
      "Segment: Ci-AH39fi3Y[28]\n",
      "----------------------------------------\n",
      "Example 657:\n",
      "Text: but it was not what i was expecting and se seriously everything leading up to the end was better than the ending\n",
      "Length: 22\n",
      "Label: [[-1.]]\n",
      "Segment: Ci-AH39fi3Y[29]\n",
      "----------------------------------------\n",
      "Example 658:\n",
      "Text: which is still good\n",
      "Length: 4\n",
      "Label: [[1.4]]\n",
      "Segment: Ci-AH39fi3Y[30]\n",
      "----------------------------------------\n",
      "Example 659:\n",
      "Text: because the movie is good\n",
      "Length: 5\n",
      "Label: [[2.]]\n",
      "Segment: Ci-AH39fi3Y[31]\n",
      "----------------------------------------\n",
      "Example 660:\n",
      "Text: saw has left like no closure at all at the end of the movie\n",
      "Length: 14\n",
      "Label: [[-2.]]\n",
      "Segment: Ci-AH39fi3Y[32]\n",
      "----------------------------------------\n",
      "Example 661:\n",
      "Text: and it pretty much just left the door wide open for saw which\n",
      "Length: 13\n",
      "Label: [[0.2]]\n",
      "Segment: Ci-AH39fi3Y[33]\n",
      "----------------------------------------\n",
      "Example 662:\n",
      "Text: but man oh man it really left the door open\n",
      "Length: 10\n",
      "Label: [[0.8]]\n",
      "Segment: Ci-AH39fi3Y[34]\n",
      "----------------------------------------\n",
      "Example 663:\n",
      "Text: and it didnt even you know try to close it at all like the wind gonna blow it over or anything its just open\n",
      "Length: 24\n",
      "Label: [[-1.5]]\n",
      "Segment: Ci-AH39fi3Y[35]\n",
      "----------------------------------------\n",
      "Example 664:\n",
      "Text: but like i said the plot of hoffman and everything that was really really awesome\n",
      "Length: 15\n",
      "Label: [[2.6]]\n",
      "Segment: Ci-AH39fi3Y[36]\n",
      "----------------------------------------\n",
      "Example 665:\n",
      "Text: and it fit very well into the saw series in my opinion\n",
      "Length: 12\n",
      "Label: [[1.8]]\n",
      "Segment: Ci-AH39fi3Y[37]\n",
      "----------------------------------------\n",
      "Example 666:\n",
      "Text: so congratulations to the writers for that\n",
      "Length: 7\n",
      "Label: [[2.]]\n",
      "Segment: Ci-AH39fi3Y[38]\n",
      "----------------------------------------\n",
      "Example 667:\n",
      "Text: but ill smack them in the face for the other irrelevant and\n",
      "Length: 12\n",
      "Label: [[-2.6]]\n",
      "Segment: Ci-AH39fi3Y[39]\n",
      "----------------------------------------\n",
      "Example 668:\n",
      "Text: and dont know what the hell they were thinking\n",
      "Length: 9\n",
      "Label: [[-2.2]]\n",
      "Segment: Ci-AH39fi3Y[40]\n",
      "----------------------------------------\n",
      "Example 669:\n",
      "Text: it was pretty much just and excuse to put traps in the movie because it was literally completely irrelevant\n",
      "Length: 19\n",
      "Label: [[-2.2]]\n",
      "Segment: Ci-AH39fi3Y[41]\n",
      "----------------------------------------\n",
      "Example 670:\n",
      "Text: like i said i loved the storyline\n",
      "Length: 7\n",
      "Label: [[2.2]]\n",
      "Segment: Ci-AH39fi3Y[42]\n",
      "----------------------------------------\n",
      "Example 671:\n",
      "Text: so you know i guess it balances out\n",
      "Length: 8\n",
      "Label: [[0.2]]\n",
      "Segment: Ci-AH39fi3Y[43]\n",
      "----------------------------------------\n",
      "Example 672:\n",
      "Text: and it is jumpy for people who dont like getting scared or jumpy or anything\n",
      "Length: 15\n",
      "Label: [[-1.]]\n",
      "Segment: Clx4VXItLTE[0]\n",
      "----------------------------------------\n",
      "Example 673:\n",
      "Text: but for someone like me who loves horror movies\n",
      "Length: 9\n",
      "Label: [[0.6]]\n",
      "Segment: Clx4VXItLTE[1]\n",
      "----------------------------------------\n",
      "Example 674:\n",
      "Text: and like i do jump\n",
      "Length: 5\n",
      "Label: [[0.4]]\n",
      "Segment: Clx4VXItLTE[2]\n",
      "----------------------------------------\n",
      "Example 675:\n",
      "Text: but i dont exactly get scared\n",
      "Length: 6\n",
      "Label: [[-0.8]]\n",
      "Segment: Clx4VXItLTE[3]\n",
      "----------------------------------------\n",
      "Example 676:\n",
      "Text: so i think im like immune to them\n",
      "Length: 8\n",
      "Label: [[-0.6]]\n",
      "Segment: Clx4VXItLTE[4]\n",
      "----------------------------------------\n",
      "Example 677:\n",
      "Text: and the only he mo film that im really scared about is small soldiers\n",
      "Length: 14\n",
      "Label: [[-0.4]]\n",
      "Segment: Clx4VXItLTE[5]\n",
      "----------------------------------------\n",
      "Example 678:\n",
      "Text: i just thats freaky as hell um\n",
      "Length: 7\n",
      "Label: [[0.5]]\n",
      "Segment: Clx4VXItLTE[6]\n",
      "----------------------------------------\n",
      "Example 679:\n",
      "Text: but insidious um star really good\n",
      "Length: 6\n",
      "Label: [[0.8]]\n",
      "Segment: Clx4VXItLTE[7]\n",
      "----------------------------------------\n",
      "Example 680:\n",
      "Text: like it cracked on streight away with what the hell is going on\n",
      "Length: 13\n",
      "Label: [[-1.]]\n",
      "Segment: Clx4VXItLTE[8]\n",
      "----------------------------------------\n",
      "Example 681:\n",
      "Text: like it just like and i was at um theres a problem theres a story like its like streight away fun storyline started\n",
      "Length: 23\n",
      "Label: [[0.2]]\n",
      "Segment: Clx4VXItLTE[9]\n",
      "----------------------------------------\n",
      "Example 682:\n",
      "Text: and some of the acting is a little bit like oh my god you wouldnt really do that\n",
      "Length: 18\n",
      "Label: [[-1.2]]\n",
      "Segment: Clx4VXItLTE[10]\n",
      "----------------------------------------\n",
      "Example 683:\n",
      "Text: but thats like old movies its just like i wouldnt say bad casting\n",
      "Length: 13\n",
      "Label: [[-1.4]]\n",
      "Segment: Clx4VXItLTE[11]\n",
      "----------------------------------------\n",
      "Example 684:\n",
      "Text: but its just sometimes its just a little bit like oh god they have done that cringe\n",
      "Length: 17\n",
      "Label: [[-0.6]]\n",
      "Segment: Clx4VXItLTE[12]\n",
      "----------------------------------------\n",
      "Example 685:\n",
      "Text: um but really good\n",
      "Length: 4\n",
      "Label: [[1.6]]\n",
      "Segment: Clx4VXItLTE[13]\n",
      "----------------------------------------\n",
      "Example 686:\n",
      "Text: like really jumped me my friend\n",
      "Length: 6\n",
      "Label: [[-0.75]]\n",
      "Segment: Clx4VXItLTE[14]\n",
      "----------------------------------------\n",
      "Example 687:\n",
      "Text: and she wanted to go home and thats like seeing a lot for her coz she likes horror movies as much as i do\n",
      "Length: 24\n",
      "Label: [[-1.2]]\n",
      "Segment: Clx4VXItLTE[15]\n",
      "----------------------------------------\n",
      "Example 688:\n",
      "Text: but it really surprised as i said what you wanna go home\n",
      "Length: 12\n",
      "Label: [[-0.8]]\n",
      "Segment: Clx4VXItLTE[16]\n",
      "----------------------------------------\n",
      "Example 689:\n",
      "Text: huh but i am it was jumpy\n",
      "Length: 7\n",
      "Label: [[-0.5]]\n",
      "Segment: Clx4VXItLTE[17]\n",
      "----------------------------------------\n",
      "Example 690:\n",
      "Text: i jumped hell of a lot times\n",
      "Length: 7\n",
      "Label: [[1.4]]\n",
      "Segment: Clx4VXItLTE[18]\n",
      "----------------------------------------\n",
      "Example 691:\n",
      "Text: and i would go to the cinema again to see it\n",
      "Length: 11\n",
      "Label: [[1.2]]\n",
      "Segment: Clx4VXItLTE[19]\n",
      "----------------------------------------\n",
      "Example 692:\n",
      "Text: because that atmosphere like everyone just and\n",
      "Length: 7\n",
      "Label: [[0.4]]\n",
      "Segment: Clx4VXItLTE[20]\n",
      "----------------------------------------\n",
      "Example 693:\n",
      "Text: and just and its just its so funny\n",
      "Length: 8\n",
      "Label: [[0.8]]\n",
      "Segment: Clx4VXItLTE[21]\n",
      "----------------------------------------\n",
      "Example 694:\n",
      "Text: um something like what i do like if i jump a lot\n",
      "Length: 12\n",
      "Label: [[1.75]]\n",
      "Segment: Clx4VXItLTE[22]\n",
      "----------------------------------------\n",
      "Example 695:\n",
      "Text: hah so everyone like everyone in cinema was kind like me\n",
      "Length: 11\n",
      "Label: [[0.8]]\n",
      "Segment: Clx4VXItLTE[23]\n",
      "----------------------------------------\n",
      "Example 696:\n",
      "Text: because everytime that was like a jump everyone jumped\n",
      "Length: 9\n",
      "Label: [[0.8]]\n",
      "Segment: Clx4VXItLTE[24]\n",
      "----------------------------------------\n",
      "Example 697:\n",
      "Text: you could feel the jump in\n",
      "Length: 6\n",
      "Label: [[1.]]\n",
      "Segment: Clx4VXItLTE[25]\n",
      "----------------------------------------\n",
      "Example 698:\n",
      "Text: and everyone was laughing afterwards\n",
      "Length: 5\n",
      "Label: [[1.]]\n",
      "Segment: Clx4VXItLTE[26]\n",
      "----------------------------------------\n",
      "Example 699:\n",
      "Text: i think thats how they cope with getting like scared and jump and stuff\n",
      "Length: 14\n",
      "Label: [[0.4]]\n",
      "Segment: Clx4VXItLTE[27]\n",
      "----------------------------------------\n",
      "Example 700:\n",
      "Text: from there it does get a bit like huh not as real as what has been going on\n",
      "Length: 18\n",
      "Label: [[-1.]]\n",
      "Segment: Clx4VXItLTE[28]\n",
      "----------------------------------------\n",
      "Example 701:\n",
      "Text: its kind of like quite fake like i just i couldnt believe it i was like what what are you doing\n",
      "Length: 21\n",
      "Label: [[-2.25]]\n",
      "Segment: Clx4VXItLTE[29]\n",
      "----------------------------------------\n",
      "Example 702:\n",
      "Text: because there is people that wanna go and see it seen it yet and might see this video\n",
      "Length: 18\n",
      "Label: [[0.2]]\n",
      "Segment: Clx4VXItLTE[30]\n",
      "----------------------------------------\n",
      "Example 703:\n",
      "Text: i mean it starts out really slow\n",
      "Length: 7\n",
      "Label: [[-1.]]\n",
      "Segment: Dg_0XKD0Mf4[0]\n",
      "----------------------------------------\n",
      "Example 704:\n",
      "Text: but overall um go see it\n",
      "Length: 6\n",
      "Label: [[0.8]]\n",
      "Segment: Dg_0XKD0Mf4[1]\n",
      "----------------------------------------\n",
      "Example 705:\n",
      "Text: it was a cool movie\n",
      "Length: 5\n",
      "Label: [[1.4]]\n",
      "Segment: Dg_0XKD0Mf4[2]\n",
      "----------------------------------------\n",
      "Example 706:\n",
      "Text: the acting was allright\n",
      "Length: 4\n",
      "Label: [[0.2]]\n",
      "Segment: Dg_0XKD0Mf4[3]\n",
      "----------------------------------------\n",
      "Example 707:\n",
      "Text: um i thought they kind of well\n",
      "Length: 7\n",
      "Label: [[1.]]\n",
      "Segment: Dg_0XKD0Mf4[4]\n",
      "----------------------------------------\n",
      "Example 708:\n",
      "Text: but what really threw me off was the dialogue very dialogue\n",
      "Length: 11\n",
      "Label: [[-2.4]]\n",
      "Segment: Dg_0XKD0Mf4[5]\n",
      "----------------------------------------\n",
      "Example 709:\n",
      "Text: oh my god the whole movie had a really dry dialogue\n",
      "Length: 11\n",
      "Label: [[-1.6]]\n",
      "Segment: Dg_0XKD0Mf4[6]\n",
      "----------------------------------------\n",
      "Example 710:\n",
      "Text: there were a couple funny parts\n",
      "Length: 6\n",
      "Label: [[0.4]]\n",
      "Segment: Dg_0XKD0Mf4[7]\n",
      "----------------------------------------\n",
      "Example 711:\n",
      "Text: but i dont think the redeemed the movie from being so bad in the dialogue department\n",
      "Length: 16\n",
      "Label: [[-1.8]]\n",
      "Segment: Dg_0XKD0Mf4[8]\n",
      "----------------------------------------\n",
      "Example 712:\n",
      "Text: whoever wrote this the writer but\n",
      "Length: 6\n",
      "Label: [[-1.6]]\n",
      "Segment: Dg_0XKD0Mf4[9]\n",
      "----------------------------------------\n",
      "Example 713:\n",
      "Text: but overall i enjoyed it\n",
      "Length: 5\n",
      "Label: [[1.6]]\n",
      "Segment: Dg_0XKD0Mf4[10]\n",
      "----------------------------------------\n",
      "Example 714:\n",
      "Text: the the whole movie i was you know thinking this as bad as ive heard and it um\n",
      "Length: 18\n",
      "Label: [[1.2]]\n",
      "Segment: Dg_0XKD0Mf4[11]\n",
      "----------------------------------------\n",
      "Example 715:\n",
      "Text: um and the movie was pretty short\n",
      "Length: 7\n",
      "Label: [[-0.6]]\n",
      "Segment: Dg_0XKD0Mf4[12]\n",
      "----------------------------------------\n",
      "Example 716:\n",
      "Text: and the dialogue threw me off\n",
      "Length: 6\n",
      "Label: [[-1.]]\n",
      "Segment: Dg_0XKD0Mf4[13]\n",
      "----------------------------------------\n",
      "Example 717:\n",
      "Text: other than that um i think it was and ok movie\n",
      "Length: 11\n",
      "Label: [[0.8]]\n",
      "Segment: Dg_0XKD0Mf4[14]\n",
      "----------------------------------------\n",
      "Example 718:\n",
      "Text: a little bit above average\n",
      "Length: 5\n",
      "Label: [[1.2]]\n",
      "Segment: Dg_0XKD0Mf4[15]\n",
      "----------------------------------------\n",
      "Example 719:\n",
      "Text: i dont think its as bad as you probably read on reviews\n",
      "Length: 12\n",
      "Label: [[0.2]]\n",
      "Segment: Dg_0XKD0Mf4[16]\n",
      "----------------------------------------\n",
      "Example 720:\n",
      "Text: so yeah go see it\n",
      "Length: 5\n",
      "Label: [[1.4]]\n",
      "Segment: Dg_0XKD0Mf4[17]\n",
      "----------------------------------------\n",
      "Example 721:\n",
      "Text: a really cute movie\n",
      "Length: 4\n",
      "Label: [[2.]]\n",
      "Segment: G-xst2euQUc[0]\n",
      "----------------------------------------\n",
      "Example 722:\n",
      "Text: i did not think i was gonna like it\n",
      "Length: 9\n",
      "Label: [[0.]]\n",
      "Segment: G-xst2euQUc[1]\n",
      "----------------------------------------\n",
      "Example 723:\n",
      "Text: i really didnt wanna go see it\n",
      "Length: 7\n",
      "Label: [[-1.4]]\n",
      "Segment: G-xst2euQUc[2]\n",
      "----------------------------------------\n",
      "Example 724:\n",
      "Text: and it seems to me than when production companies start pushing movies that far ahead and when they were gonna be released that means that they are not gonna be great\n",
      "Length: 31\n",
      "Label: [[-2.]]\n",
      "Segment: G-xst2euQUc[3]\n",
      "----------------------------------------\n",
      "Example 725:\n",
      "Text: and i was pleasantly surprised by this movie\n",
      "Length: 8\n",
      "Label: [[1.8]]\n",
      "Segment: G-xst2euQUc[4]\n",
      "----------------------------------------\n",
      "Example 726:\n",
      "Text: i was i thoroughly enjoyed it\n",
      "Length: 6\n",
      "Label: [[2.4]]\n",
      "Segment: G-xst2euQUc[5]\n",
      "----------------------------------------\n",
      "Example 727:\n",
      "Text: um this is a great family movie to take your whole family to this movie\n",
      "Length: 15\n",
      "Label: [[2.2]]\n",
      "Segment: G-xst2euQUc[6]\n",
      "----------------------------------------\n",
      "Example 728:\n",
      "Text: its great for all ages\n",
      "Length: 5\n",
      "Label: [[2.2]]\n",
      "Segment: G-xst2euQUc[7]\n",
      "----------------------------------------\n",
      "Example 729:\n",
      "Text: um i thought the story line was really cute\n",
      "Length: 9\n",
      "Label: [[2.]]\n",
      "Segment: G-xst2euQUc[8]\n",
      "----------------------------------------\n",
      "Example 730:\n",
      "Text: and again it does really tug at the heart with the little baby animals at the beginning\n",
      "Length: 17\n",
      "Label: [[1.4]]\n",
      "Segment: G-xst2euQUc[9]\n",
      "----------------------------------------\n",
      "Example 731:\n",
      "Text: um it has it has a very predictable story\n",
      "Length: 9\n",
      "Label: [[-1.4]]\n",
      "Segment: G-xst2euQUc[10]\n",
      "----------------------------------------\n",
      "Example 732:\n",
      "Text: that so what is still a really great movie to take your whole family to\n",
      "Length: 15\n",
      "Label: [[1.8]]\n",
      "Segment: G-xst2euQUc[11]\n",
      "----------------------------------------\n",
      "Example 733:\n",
      "Text: but if it was anne hathaway who did the singing she did a great job\n",
      "Length: 15\n",
      "Label: [[2.4]]\n",
      "Segment: G-xst2euQUc[12]\n",
      "----------------------------------------\n",
      "Example 734:\n",
      "Text: i had no idea that anne hathaway could really sing\n",
      "Length: 10\n",
      "Label: [[-0.6]]\n",
      "Segment: G-xst2euQUc[13]\n",
      "----------------------------------------\n",
      "Example 735:\n",
      "Text: anyway um i would recommend it if if youre like me and you dont normally go to see animated movies\n",
      "Length: 20\n",
      "Label: [[1.2]]\n",
      "Segment: G-xst2euQUc[14]\n",
      "----------------------------------------\n",
      "Example 736:\n",
      "Text: and im im not really in a big hurry at my age to go see animated movies\n",
      "Length: 17\n",
      "Label: [[-0.2]]\n",
      "Segment: G-xst2euQUc[15]\n",
      "----------------------------------------\n",
      "Example 737:\n",
      "Text: um but there really been much to has come out this year so far that im dying to go see\n",
      "Length: 20\n",
      "Label: [[-0.2]]\n",
      "Segment: G-xst2euQUc[16]\n",
      "----------------------------------------\n",
      "Example 738:\n",
      "Text: and we really wanted to get out of the house um last night\n",
      "Length: 13\n",
      "Label: [[0.]]\n",
      "Segment: G-xst2euQUc[17]\n",
      "----------------------------------------\n",
      "Example 739:\n",
      "Text: and i was thoroughly um surprised\n",
      "Length: 6\n",
      "Label: [[0.6]]\n",
      "Segment: G-xst2euQUc[18]\n",
      "----------------------------------------\n",
      "Example 740:\n",
      "Text: at how much i really did enjoy i\n",
      "Length: 8\n",
      "Label: [[2.]]\n",
      "Segment: G-xst2euQUc[19]\n",
      "----------------------------------------\n",
      "Example 741:\n",
      "Text: would recommend this movie\n",
      "Length: 4\n",
      "Label: [[1.4]]\n",
      "Segment: G-xst2euQUc[20]\n",
      "----------------------------------------\n",
      "Example 742:\n",
      "Text: i would put money on it that it is going to be the blockbuster hit of the summer in terms of when you look at all the movies\n",
      "Length: 28\n",
      "Label: [[2.6]]\n",
      "Segment: G6GlGvlkxAQ[0]\n",
      "----------------------------------------\n",
      "Example 743:\n",
      "Text: i im a cap guy captain america fan\n",
      "Length: 8\n",
      "Label: [[1.]]\n",
      "Segment: G6GlGvlkxAQ[1]\n",
      "----------------------------------------\n",
      "Example 744:\n",
      "Text: i think that would do very well\n",
      "Length: 7\n",
      "Label: [[1.2]]\n",
      "Segment: G6GlGvlkxAQ[2]\n",
      "----------------------------------------\n",
      "Example 745:\n",
      "Text: um so i think thor is really gonna do well\n",
      "Length: 10\n",
      "Label: [[1.]]\n",
      "Segment: G6GlGvlkxAQ[3]\n",
      "----------------------------------------\n",
      "Example 746:\n",
      "Text: i think its gonna catapult chris to be even a bigger star\n",
      "Length: 12\n",
      "Label: [[1.6]]\n",
      "Segment: G6GlGvlkxAQ[4]\n",
      "----------------------------------------\n",
      "Example 747:\n",
      "Text: um great movie for those who seen it\n",
      "Length: 8\n",
      "Label: [[2.8]]\n",
      "Segment: G6GlGvlkxAQ[5]\n",
      "----------------------------------------\n",
      "Example 748:\n",
      "Text: charlie sheen was winning there\n",
      "Length: 5\n",
      "Label: [[1.6]]\n",
      "Segment: G6GlGvlkxAQ[6]\n",
      "----------------------------------------\n",
      "Example 749:\n",
      "Text: and hes winning no\n",
      "Length: 4\n",
      "Label: [[0.5]]\n",
      "Segment: G6GlGvlkxAQ[7]\n",
      "----------------------------------------\n",
      "Example 750:\n",
      "Text: so they could um um kind of get a little bit of chris star power into that\n",
      "Length: 17\n",
      "Label: [[0.8]]\n",
      "Segment: G6GlGvlkxAQ[8]\n",
      "----------------------------------------\n",
      "Example 751:\n",
      "Text: um great movie overall\n",
      "Length: 4\n",
      "Label: [[2.2]]\n",
      "Segment: G6GlGvlkxAQ[9]\n",
      "----------------------------------------\n",
      "Example 752:\n",
      "Text: they did very well to establish the character of thor\n",
      "Length: 10\n",
      "Label: [[1.6]]\n",
      "Segment: G6GlGvlkxAQ[10]\n",
      "----------------------------------------\n",
      "Example 753:\n",
      "Text: the problem with a lot of comic book shows and movies\n",
      "Length: 11\n",
      "Label: [[-1.2]]\n",
      "Segment: G6GlGvlkxAQ[11]\n",
      "----------------------------------------\n",
      "Example 754:\n",
      "Text: and you saw this with the recent flop of the cape which is a show i love\n",
      "Length: 17\n",
      "Label: [[-0.2]]\n",
      "Segment: G6GlGvlkxAQ[12]\n",
      "----------------------------------------\n",
      "Example 755:\n",
      "Text: but the audience that was watching it they needed they needed a pay off right away\n",
      "Length: 16\n",
      "Label: [[-0.2]]\n",
      "Segment: G6GlGvlkxAQ[13]\n",
      "----------------------------------------\n",
      "Example 756:\n",
      "Text: and they needed character established right away\n",
      "Length: 7\n",
      "Label: [[-1.4]]\n",
      "Segment: G6GlGvlkxAQ[14]\n",
      "----------------------------------------\n",
      "Example 757:\n",
      "Text: um what you get in the sitcoms in terms of comic books and kind of the movies that take so loud to build that\n",
      "Length: 24\n",
      "Label: [[0.]]\n",
      "Segment: G6GlGvlkxAQ[15]\n",
      "----------------------------------------\n",
      "Example 758:\n",
      "Text: and why is this person wearing tights\n",
      "Length: 7\n",
      "Label: [[-0.8]]\n",
      "Segment: G6GlGvlkxAQ[16]\n",
      "----------------------------------------\n",
      "Example 759:\n",
      "Text: or why are they carrying a hammer\n",
      "Length: 7\n",
      "Label: [[-0.6666667]]\n",
      "Segment: G6GlGvlkxAQ[17]\n",
      "----------------------------------------\n",
      "Example 760:\n",
      "Text: you know why what is their mission\n",
      "Length: 7\n",
      "Label: [[-0.4]]\n",
      "Segment: G6GlGvlkxAQ[18]\n",
      "----------------------------------------\n",
      "Example 761:\n",
      "Text: or why why are they here\n",
      "Length: 6\n",
      "Label: [[0.]]\n",
      "Segment: G6GlGvlkxAQ[19]\n",
      "----------------------------------------\n",
      "Example 762:\n",
      "Text: you have to that fairly quickly\n",
      "Length: 6\n",
      "Label: [[0.]]\n",
      "Segment: G6GlGvlkxAQ[20]\n",
      "----------------------------------------\n",
      "Example 763:\n",
      "Text: and i think that directors of thor and the script writers did that right away\n",
      "Length: 15\n",
      "Label: [[0.6]]\n",
      "Segment: G6GlGvlkxAQ[21]\n",
      "----------------------------------------\n",
      "Example 764:\n",
      "Text: you saw thor for how hes in the comics pompous an individual\n",
      "Length: 12\n",
      "Label: [[-1.4]]\n",
      "Segment: G6GlGvlkxAQ[22]\n",
      "----------------------------------------\n",
      "Example 765:\n",
      "Text: um but they also did a great job in building the of jane foster played by natalie portman and her crew and how they relate to thor\n",
      "Length: 27\n",
      "Label: [[2.]]\n",
      "Segment: G6GlGvlkxAQ[23]\n",
      "----------------------------------------\n",
      "Example 766:\n",
      "Text: so i think that was really good\n",
      "Length: 7\n",
      "Label: [[1.8]]\n",
      "Segment: G6GlGvlkxAQ[24]\n",
      "----------------------------------------\n",
      "Example 767:\n",
      "Text: they didnt belabored thor on earth\n",
      "Length: 6\n",
      "Label: [[0.25]]\n",
      "Segment: G6GlGvlkxAQ[25]\n",
      "----------------------------------------\n",
      "Example 768:\n",
      "Text: he sounded like he didnt learn from the earthlings\n",
      "Length: 9\n",
      "Label: [[-0.4]]\n",
      "Segment: G6GlGvlkxAQ[26]\n",
      "----------------------------------------\n",
      "Example 769:\n",
      "Text: um so that makes sense\n",
      "Length: 5\n",
      "Label: [[0.]]\n",
      "Segment: G6GlGvlkxAQ[27]\n",
      "----------------------------------------\n",
      "Example 770:\n",
      "Text: you get other whole shield involvement which is cool to see that a lot of cooler references that at one point they reference im a doctor with gama radiation\n",
      "Length: 29\n",
      "Label: [[2.4]]\n",
      "Segment: G6GlGvlkxAQ[28]\n",
      "----------------------------------------\n",
      "Example 771:\n",
      "Text: um first things first christina i swear the um\n",
      "Length: 9\n",
      "Label: [[1.5]]\n",
      "Segment: GWuJjcEuzt8[0]\n",
      "----------------------------------------\n",
      "Example 772:\n",
      "Text: um why i said that is because she is god a crazy crazy voice\n",
      "Length: 14\n",
      "Label: [[0.75]]\n",
      "Segment: GWuJjcEuzt8[1]\n",
      "----------------------------------------\n",
      "Example 773:\n",
      "Text: and she sure can sing really really well in this movie you know\n",
      "Length: 13\n",
      "Label: [[2.]]\n",
      "Segment: GWuJjcEuzt8[2]\n",
      "----------------------------------------\n",
      "Example 774:\n",
      "Text: and you know it makes you wanna know who else you know in the history of nowadays has the voice like that and you know its noone\n",
      "Length: 27\n",
      "Label: [[-0.4]]\n",
      "Segment: GWuJjcEuzt8[3]\n",
      "----------------------------------------\n",
      "Example 775:\n",
      "Text: but she still looks like and\n",
      "Length: 6\n",
      "Label: [[-1.6]]\n",
      "Segment: GWuJjcEuzt8[4]\n",
      "----------------------------------------\n",
      "Example 776:\n",
      "Text: and her face doesnt move at all\n",
      "Length: 7\n",
      "Label: [[-1.4]]\n",
      "Segment: GWuJjcEuzt8[5]\n",
      "----------------------------------------\n",
      "Example 777:\n",
      "Text: coz when you see her face moves it feels like you know you feel worried for her\n",
      "Length: 17\n",
      "Label: [[0.75]]\n",
      "Segment: GWuJjcEuzt8[6]\n",
      "----------------------------------------\n",
      "Example 778:\n",
      "Text: you feel like her face is going to fall apart\n",
      "Length: 10\n",
      "Label: [[-1.2]]\n",
      "Segment: GWuJjcEuzt8[7]\n",
      "----------------------------------------\n",
      "Example 779:\n",
      "Text: and overall the movies quite entertaining\n",
      "Length: 6\n",
      "Label: [[1.6]]\n",
      "Segment: GWuJjcEuzt8[8]\n",
      "----------------------------------------\n",
      "Example 780:\n",
      "Text: that the dancers um wonderful\n",
      "Length: 5\n",
      "Label: [[2.2]]\n",
      "Segment: GWuJjcEuzt8[9]\n",
      "----------------------------------------\n",
      "Example 781:\n",
      "Text: its sexy but not you\n",
      "Length: 5\n",
      "Label: [[1.4]]\n",
      "Segment: GWuJjcEuzt8[10]\n",
      "----------------------------------------\n",
      "Example 782:\n",
      "Text: who is drop dead gorgeous by the way\n",
      "Length: 8\n",
      "Label: [[1.4]]\n",
      "Segment: GWuJjcEuzt8[11]\n",
      "----------------------------------------\n",
      "Example 783:\n",
      "Text: um the songs in the movie are wonderful\n",
      "Length: 8\n",
      "Label: [[1.6]]\n",
      "Segment: GWuJjcEuzt8[12]\n",
      "----------------------------------------\n",
      "Example 784:\n",
      "Text: you know it matches the whole theme of the movie you know cabaret and you know the looks\n",
      "Length: 18\n",
      "Label: [[1.]]\n",
      "Segment: GWuJjcEuzt8[13]\n",
      "----------------------------------------\n",
      "Example 785:\n",
      "Text: and overall probably id give it about stars you know popcorn movie and you know\n",
      "Length: 15\n",
      "Label: [[0.8]]\n",
      "Segment: GWuJjcEuzt8[14]\n",
      "----------------------------------------\n",
      "Example 786:\n",
      "Text: considering all the awesome movies that we had and inception the black swan and you know the social network\n",
      "Length: 19\n",
      "Label: [[0.2]]\n",
      "Segment: GWuJjcEuzt8[15]\n",
      "----------------------------------------\n",
      "Example 787:\n",
      "Text: this one you know probably in the middle so stars\n",
      "Length: 10\n",
      "Label: [[-0.2]]\n",
      "Segment: GWuJjcEuzt8[16]\n",
      "----------------------------------------\n",
      "Example 788:\n",
      "Text: and if you have money to spend go ahead\n",
      "Length: 9\n",
      "Label: [[-0.2]]\n",
      "Segment: GWuJjcEuzt8[17]\n",
      "----------------------------------------\n",
      "Example 789:\n",
      "Text: it was premiere\n",
      "Length: 3\n",
      "Label: [[2.8]]\n",
      "Segment: HEsqda8_d0Q[0]\n",
      "----------------------------------------\n",
      "Example 790:\n",
      "Text: itself was really cool\n",
      "Length: 4\n",
      "Label: [[1.8]]\n",
      "Segment: HEsqda8_d0Q[1]\n",
      "----------------------------------------\n",
      "Example 791:\n",
      "Text: and i actually liked the film a lot\n",
      "Length: 8\n",
      "Label: [[2.2]]\n",
      "Segment: HEsqda8_d0Q[2]\n",
      "----------------------------------------\n",
      "Example 792:\n",
      "Text: and i expecting to\n",
      "Length: 4\n",
      "Label: [[0.2]]\n",
      "Segment: HEsqda8_d0Q[3]\n",
      "----------------------------------------\n",
      "Example 793:\n",
      "Text: because i thought how the hell is dickens and disney gonna work together like this\n",
      "Length: 15\n",
      "Label: [[-1.]]\n",
      "Segment: HEsqda8_d0Q[4]\n",
      "----------------------------------------\n",
      "Example 794:\n",
      "Text: but i thought they actually worked pretty well\n",
      "Length: 8\n",
      "Label: [[2.]]\n",
      "Segment: HEsqda8_d0Q[5]\n",
      "----------------------------------------\n",
      "Example 795:\n",
      "Text: and the end part is really really funny\n",
      "Length: 8\n",
      "Label: [[2.4]]\n",
      "Segment: HEsqda8_d0Q[6]\n",
      "----------------------------------------\n",
      "Example 796:\n",
      "Text: because hes been such a grumpy character and hes really scared and in the end hes so changed and hes really funny\n",
      "Length: 22\n",
      "Label: [[1.4]]\n",
      "Segment: HEsqda8_d0Q[7]\n",
      "----------------------------------------\n",
      "Example 797:\n",
      "Text: hes like what a delightful child\n",
      "Length: 6\n",
      "Label: [[1.4]]\n",
      "Segment: HEsqda8_d0Q[8]\n",
      "----------------------------------------\n",
      "Example 798:\n",
      "Text: and its all kind of its hard to explain\n",
      "Length: 9\n",
      "Label: [[0.25]]\n",
      "Segment: HEsqda8_d0Q[9]\n",
      "----------------------------------------\n",
      "Example 799:\n",
      "Text: the animation was amazing\n",
      "Length: 4\n",
      "Label: [[2.8]]\n",
      "Segment: HEsqda8_d0Q[10]\n",
      "----------------------------------------\n",
      "Example 800:\n",
      "Text: i expecting that much\n",
      "Length: 4\n",
      "Label: [[-0.4]]\n",
      "Segment: HEsqda8_d0Q[11]\n",
      "----------------------------------------\n",
      "Example 801:\n",
      "Text: because sometimes really that good\n",
      "Length: 5\n",
      "Label: [[-1.]]\n",
      "Segment: HEsqda8_d0Q[12]\n",
      "----------------------------------------\n",
      "Example 802:\n",
      "Text: but it was you\n",
      "Length: 4\n",
      "Label: [[2.6]]\n",
      "Segment: HEsqda8_d0Q[13]\n",
      "----------------------------------------\n",
      "Example 803:\n",
      "Text: you kind of forget about the fact that it is the\n",
      "Length: 11\n",
      "Label: [[1.]]\n",
      "Segment: HEsqda8_d0Q[14]\n",
      "----------------------------------------\n",
      "Example 804:\n",
      "Text: the voices are really good\n",
      "Length: 5\n",
      "Label: [[2.2]]\n",
      "Segment: HEsqda8_d0Q[15]\n",
      "----------------------------------------\n",
      "Example 805:\n",
      "Text: that was one of my other concerns\n",
      "Length: 7\n",
      "Label: [[-0.8]]\n",
      "Segment: HEsqda8_d0Q[16]\n",
      "----------------------------------------\n",
      "Example 806:\n",
      "Text: was that as an english person i get really annoyed when american shows and films have an english character\n",
      "Length: 19\n",
      "Label: [[-1.8]]\n",
      "Segment: HEsqda8_d0Q[17]\n",
      "----------------------------------------\n",
      "Example 807:\n",
      "Text: but than its so obviously not an english character\n",
      "Length: 9\n",
      "Label: [[-0.2]]\n",
      "Segment: HEsqda8_d0Q[18]\n",
      "----------------------------------------\n",
      "Example 808:\n",
      "Text: but yeah generally the accents were really really good\n",
      "Length: 9\n",
      "Label: [[2.6]]\n",
      "Segment: HEsqda8_d0Q[19]\n",
      "----------------------------------------\n",
      "Example 809:\n",
      "Text: so good one you america for doing that\n",
      "Length: 8\n",
      "Label: [[1.4]]\n",
      "Segment: HEsqda8_d0Q[20]\n",
      "----------------------------------------\n",
      "Example 810:\n",
      "Text: i doubt that theyre gonna do this for all the screenings because it was the premiere\n",
      "Length: 16\n",
      "Label: [[0.4]]\n",
      "Segment: HEsqda8_d0Q[21]\n",
      "----------------------------------------\n",
      "Example 811:\n",
      "Text: not have chosen to go and see that\n",
      "Length: 8\n",
      "Label: [[0.]]\n",
      "Segment: HEsqda8_d0Q[22]\n",
      "----------------------------------------\n",
      "Example 812:\n",
      "Text: but im really really really glad i saw it\n",
      "Length: 9\n",
      "Label: [[1.6]]\n",
      "Segment: HEsqda8_d0Q[23]\n",
      "----------------------------------------\n",
      "Example 813:\n",
      "Text: and i would recommend it to other people its true\n",
      "Length: 10\n",
      "Label: [[1.8]]\n",
      "Segment: HEsqda8_d0Q[24]\n",
      "----------------------------------------\n",
      "Example 814:\n",
      "Text: even though i was like hu im gonna hate it\n",
      "Length: 10\n",
      "Label: [[-0.5]]\n",
      "Segment: HEsqda8_d0Q[25]\n",
      "----------------------------------------\n",
      "Example 815:\n",
      "Text: but im just gonna have to say it\n",
      "Length: 8\n",
      "Label: [[0.]]\n",
      "Segment: HEsqda8_d0Q[26]\n",
      "----------------------------------------\n",
      "Example 816:\n",
      "Text: its my favorite film ever\n",
      "Length: 5\n",
      "Label: [[2.]]\n",
      "Segment: HEsqda8_d0Q[27]\n",
      "----------------------------------------\n",
      "Example 817:\n",
      "Text: um its not my favorite film ever\n",
      "Length: 7\n",
      "Label: [[-0.4]]\n",
      "Segment: HEsqda8_d0Q[28]\n",
      "----------------------------------------\n",
      "Example 818:\n",
      "Text: but i would watch it again\n",
      "Length: 6\n",
      "Label: [[2.]]\n",
      "Segment: HEsqda8_d0Q[29]\n",
      "----------------------------------------\n",
      "Example 819:\n",
      "Text: i can imagine getting this on and watching it at christmas at time because it makes you feel so like huh its not about commercialization its about you know families being together\n",
      "Length: 32\n",
      "Label: [[2.4]]\n",
      "Segment: HEsqda8_d0Q[30]\n",
      "----------------------------------------\n",
      "Example 820:\n",
      "Text: and ill tell you all about like the cool premiere and stuff\n",
      "Length: 12\n",
      "Label: [[0.8]]\n",
      "Segment: HEsqda8_d0Q[31]\n",
      "----------------------------------------\n",
      "Example 821:\n",
      "Text: but i just wanted to put this up soon\n",
      "Length: 9\n",
      "Label: [[0.4]]\n",
      "Segment: HEsqda8_d0Q[32]\n",
      "----------------------------------------\n",
      "Example 822:\n",
      "Text: which were um a so\n",
      "Length: 5\n",
      "Label: [[-1.6]]\n",
      "Segment: HEsqda8_d0Q[33]\n",
      "----------------------------------------\n",
      "Example 823:\n",
      "Text: and i was pretty open to to it being good\n",
      "Length: 10\n",
      "Label: [[0.6]]\n",
      "Segment: I5y0__X72p0[0]\n",
      "----------------------------------------\n",
      "Example 824:\n",
      "Text: i at first when i saw the previews i thought it was gonna be stupid to be perfectly honest\n",
      "Length: 19\n",
      "Label: [[-0.8]]\n",
      "Segment: I5y0__X72p0[1]\n",
      "----------------------------------------\n",
      "Example 825:\n",
      "Text: i was like theres no way that theyre gonna be able to convince me that a sixteen year old girl can take down like six adult dudes\n",
      "Length: 27\n",
      "Label: [[-1.6]]\n",
      "Segment: I5y0__X72p0[2]\n",
      "----------------------------------------\n",
      "Example 826:\n",
      "Text: so i saw some other reviews and i was like okay i was surprised\n",
      "Length: 14\n",
      "Label: [[0.4]]\n",
      "Segment: I5y0__X72p0[3]\n",
      "----------------------------------------\n",
      "Example 827:\n",
      "Text: and they both liked it\n",
      "Length: 5\n",
      "Label: [[1.4]]\n",
      "Segment: I5y0__X72p0[4]\n",
      "----------------------------------------\n",
      "Example 828:\n",
      "Text: they s and all the people walking out of the theatre and beyond the trailer really liked it\n",
      "Length: 18\n",
      "Label: [[1.6]]\n",
      "Segment: I5y0__X72p0[5]\n",
      "----------------------------------------\n",
      "Example 829:\n",
      "Text: and i gotta say i blown away by it\n",
      "Length: 9\n",
      "Label: [[-1.4]]\n",
      "Segment: I5y0__X72p0[6]\n",
      "----------------------------------------\n",
      "Example 830:\n",
      "Text: i didnt think it was great or epic or just fantastic\n",
      "Length: 11\n",
      "Label: [[-0.2]]\n",
      "Segment: I5y0__X72p0[7]\n",
      "----------------------------------------\n",
      "Example 831:\n",
      "Text: it was good\n",
      "Length: 3\n",
      "Label: [[1.6]]\n",
      "Segment: I5y0__X72p0[8]\n",
      "----------------------------------------\n",
      "Example 832:\n",
      "Text: i mean i dont regret seeing it\n",
      "Length: 7\n",
      "Label: [[1.2]]\n",
      "Segment: I5y0__X72p0[9]\n",
      "----------------------------------------\n",
      "Example 833:\n",
      "Text: it was it was an it was an okay movie\n",
      "Length: 10\n",
      "Label: [[0.6]]\n",
      "Segment: I5y0__X72p0[10]\n",
      "----------------------------------------\n",
      "Example 834:\n",
      "Text: eric decides to train to be this most paranoid chick in the world\n",
      "Length: 13\n",
      "Label: [[-0.6]]\n",
      "Segment: I5y0__X72p0[11]\n",
      "----------------------------------------\n",
      "Example 835:\n",
      "Text: anyways skipping past that got this like kick a attitude\n",
      "Length: 10\n",
      "Label: [[0.4]]\n",
      "Segment: I5y0__X72p0[12]\n",
      "----------------------------------------\n",
      "Example 836:\n",
      "Text: so its it kind of feels like a sundance film festival type of movie\n",
      "Length: 14\n",
      "Label: [[-0.4]]\n",
      "Segment: I5y0__X72p0[13]\n",
      "----------------------------------------\n",
      "Example 837:\n",
      "Text: its good\n",
      "Length: 2\n",
      "Label: [[0.6]]\n",
      "Segment: I5y0__X72p0[14]\n",
      "----------------------------------------\n",
      "Example 838:\n",
      "Text: but its not great\n",
      "Length: 4\n",
      "Label: [[-1.]]\n",
      "Segment: I5y0__X72p0[15]\n",
      "----------------------------------------\n",
      "Example 839:\n",
      "Text: its not polished quite as much as i would like it to be\n",
      "Length: 13\n",
      "Label: [[-1.]]\n",
      "Segment: I5y0__X72p0[16]\n",
      "----------------------------------------\n",
      "Example 840:\n",
      "Text: it is good though\n",
      "Length: 4\n",
      "Label: [[1.8]]\n",
      "Segment: I5y0__X72p0[17]\n",
      "----------------------------------------\n",
      "Example 841:\n",
      "Text: like they convinced me like this chick could probably take that dude down which is pretty hard\n",
      "Length: 17\n",
      "Label: [[1.]]\n",
      "Segment: I5y0__X72p0[18]\n",
      "----------------------------------------\n",
      "Example 842:\n",
      "Text: because i went into the movie thinking theres no way\n",
      "Length: 10\n",
      "Label: [[-1.25]]\n",
      "Segment: I5y0__X72p0[19]\n",
      "----------------------------------------\n",
      "Example 843:\n",
      "Text: and so they kind of explain it a little bit but not really\n",
      "Length: 13\n",
      "Label: [[-1.]]\n",
      "Segment: I5y0__X72p0[20]\n",
      "----------------------------------------\n",
      "Example 844:\n",
      "Text: um i i at the end of the movie the friends i was with uh one of them goes was there a plot to this movie\n",
      "Length: 26\n",
      "Label: [[-1.6]]\n",
      "Segment: I5y0__X72p0[21]\n",
      "----------------------------------------\n",
      "Example 845:\n",
      "Text: it doesnt have a deep seeded plot\n",
      "Length: 7\n",
      "Label: [[-2.]]\n",
      "Segment: I5y0__X72p0[22]\n",
      "----------------------------------------\n",
      "Example 846:\n",
      "Text: theres not like a really good twist\n",
      "Length: 7\n",
      "Label: [[-2.]]\n",
      "Segment: I5y0__X72p0[23]\n",
      "----------------------------------------\n",
      "Example 847:\n",
      "Text: its a good action movie\n",
      "Length: 5\n",
      "Label: [[1.8]]\n",
      "Segment: I5y0__X72p0[24]\n",
      "----------------------------------------\n",
      "Example 848:\n",
      "Text: its like bourne identity meets willy theres\n",
      "Length: 7\n",
      "Label: [[-0.6]]\n",
      "Segment: I5y0__X72p0[25]\n",
      "----------------------------------------\n",
      "Example 849:\n",
      "Text: theres some really strange characters in this movie\n",
      "Length: 8\n",
      "Label: [[-1.6]]\n",
      "Segment: I5y0__X72p0[26]\n",
      "----------------------------------------\n",
      "Example 850:\n",
      "Text: it was it did add to the movie though it\n",
      "Length: 10\n",
      "Label: [[1.4]]\n",
      "Segment: I5y0__X72p0[27]\n",
      "----------------------------------------\n",
      "Example 851:\n",
      "Text: and it visually its kinda cool how they show her confusion because she grows up in the woods\n",
      "Length: 18\n",
      "Label: [[1.8]]\n",
      "Segment: I5y0__X72p0[28]\n",
      "----------------------------------------\n",
      "Example 852:\n",
      "Text: so it it was and interesting movie\n",
      "Length: 7\n",
      "Label: [[1.6]]\n",
      "Segment: I5y0__X72p0[29]\n",
      "----------------------------------------\n",
      "Example 853:\n",
      "Text: it was original\n",
      "Length: 3\n",
      "Label: [[1.6]]\n",
      "Segment: I5y0__X72p0[30]\n",
      "----------------------------------------\n",
      "Example 854:\n",
      "Text: and i liked it\n",
      "Length: 4\n",
      "Label: [[1.5]]\n",
      "Segment: I5y0__X72p0[31]\n",
      "----------------------------------------\n",
      "Example 855:\n",
      "Text: the soundtrack was interesting\n",
      "Length: 4\n",
      "Label: [[1.2]]\n",
      "Segment: I5y0__X72p0[32]\n",
      "----------------------------------------\n",
      "Example 856:\n",
      "Text: um it bad\n",
      "Length: 3\n",
      "Label: [[0.8]]\n",
      "Segment: I5y0__X72p0[33]\n",
      "----------------------------------------\n",
      "Example 857:\n",
      "Text: but it was it was interesting\n",
      "Length: 6\n",
      "Label: [[1.8]]\n",
      "Segment: I5y0__X72p0[34]\n",
      "----------------------------------------\n",
      "Example 858:\n",
      "Text: it the it the usual\n",
      "Length: 5\n",
      "Label: [[-1.2]]\n",
      "Segment: I5y0__X72p0[35]\n",
      "----------------------------------------\n",
      "Example 859:\n",
      "Text: i did like kind of like the action\n",
      "Length: 8\n",
      "Label: [[1.]]\n",
      "Segment: I5y0__X72p0[36]\n",
      "----------------------------------------\n",
      "Example 860:\n",
      "Text: the music kinda drove a lot of the action\n",
      "Length: 9\n",
      "Label: [[0.2]]\n",
      "Segment: I5y0__X72p0[37]\n",
      "----------------------------------------\n",
      "Example 861:\n",
      "Text: which is cool\n",
      "Length: 3\n",
      "Label: [[1.2]]\n",
      "Segment: I5y0__X72p0[38]\n",
      "----------------------------------------\n",
      "Example 862:\n",
      "Text: this is his most engaging yet\n",
      "Length: 6\n",
      "Label: [[2.4]]\n",
      "Segment: Iu2PFX3z_1s[0]\n",
      "----------------------------------------\n",
      "Example 863:\n",
      "Text: and he what he does with hanna is he makes the movie on like anything weve seen before\n",
      "Length: 18\n",
      "Label: [[1.2]]\n",
      "Segment: Iu2PFX3z_1s[1]\n",
      "----------------------------------------\n",
      "Example 864:\n",
      "Text: he takes great actors or in this case like ronan and cate blanchett\n",
      "Length: 13\n",
      "Label: [[1.4]]\n",
      "Segment: Iu2PFX3z_1s[2]\n",
      "----------------------------------------\n",
      "Example 865:\n",
      "Text: and he puts them in very strange and unusual characters\n",
      "Length: 10\n",
      "Label: [[0.]]\n",
      "Segment: Iu2PFX3z_1s[3]\n",
      "----------------------------------------\n",
      "Example 866:\n",
      "Text: um what really need about this movie is the brothers did the soundtracks whats pulse pounding the entire way through\n",
      "Length: 20\n",
      "Label: [[1.4]]\n",
      "Segment: Iu2PFX3z_1s[4]\n",
      "----------------------------------------\n",
      "Example 867:\n",
      "Text: you never know whats gonna happen\n",
      "Length: 6\n",
      "Label: [[0.6]]\n",
      "Segment: Iu2PFX3z_1s[5]\n",
      "----------------------------------------\n",
      "Example 868:\n",
      "Text: theres all these colorful characters\n",
      "Length: 5\n",
      "Label: [[2.]]\n",
      "Segment: Iu2PFX3z_1s[6]\n",
      "----------------------------------------\n",
      "Example 869:\n",
      "Text: now it a great fantastic tell everybody about that kind of movie\n",
      "Length: 12\n",
      "Label: [[0.]]\n",
      "Segment: Iu2PFX3z_1s[7]\n",
      "----------------------------------------\n",
      "Example 870:\n",
      "Text: i gave it a b\n",
      "Length: 5\n",
      "Label: [[1.4]]\n",
      "Segment: Iu2PFX3z_1s[8]\n",
      "----------------------------------------\n",
      "Example 871:\n",
      "Text: but i think its one of those movies thats so unique\n",
      "Length: 11\n",
      "Label: [[2.2]]\n",
      "Segment: Iu2PFX3z_1s[9]\n",
      "----------------------------------------\n",
      "Example 872:\n",
      "Text: that you respect that joe wright tried to do something completely different here\n",
      "Length: 13\n",
      "Label: [[1.2]]\n",
      "Segment: Iu2PFX3z_1s[10]\n",
      "----------------------------------------\n",
      "Example 873:\n",
      "Text: its colorful\n",
      "Length: 2\n",
      "Label: [[1.6]]\n",
      "Segment: Iu2PFX3z_1s[11]\n",
      "----------------------------------------\n",
      "Example 874:\n",
      "Text: its in your face\n",
      "Length: 4\n",
      "Label: [[0.25]]\n",
      "Segment: Iu2PFX3z_1s[12]\n",
      "----------------------------------------\n",
      "Example 875:\n",
      "Text: its really non stop from beginning to end\n",
      "Length: 8\n",
      "Label: [[1.4]]\n",
      "Segment: Iu2PFX3z_1s[13]\n",
      "----------------------------------------\n",
      "Example 876:\n",
      "Text: and i think um what i took away from this was that really tried very hard to make something original\n",
      "Length: 20\n",
      "Label: [[1.8]]\n",
      "Segment: Iu2PFX3z_1s[14]\n",
      "----------------------------------------\n",
      "Example 877:\n",
      "Text: and something that i cant find anything else to compare it to\n",
      "Length: 12\n",
      "Label: [[1.3333334]]\n",
      "Segment: Iu2PFX3z_1s[15]\n",
      "----------------------------------------\n",
      "Example 878:\n",
      "Text: i always like to read the book first\n",
      "Length: 8\n",
      "Label: [[0.5]]\n",
      "Segment: IumbAb8q2dM[0]\n",
      "----------------------------------------\n",
      "Example 879:\n",
      "Text: its a weird thing\n",
      "Length: 4\n",
      "Label: [[-0.5]]\n",
      "Segment: IumbAb8q2dM[1]\n",
      "----------------------------------------\n",
      "Example 880:\n",
      "Text: because priscilla from the gave a such a good review\n",
      "Length: 10\n",
      "Label: [[0.6]]\n",
      "Segment: IumbAb8q2dM[2]\n",
      "----------------------------------------\n",
      "Example 881:\n",
      "Text: um i suggest that you guys go and watch this movie\n",
      "Length: 11\n",
      "Label: [[2.2]]\n",
      "Segment: IumbAb8q2dM[3]\n",
      "----------------------------------------\n",
      "Example 882:\n",
      "Text: it was so good\n",
      "Length: 4\n",
      "Label: [[2.6]]\n",
      "Segment: IumbAb8q2dM[4]\n",
      "----------------------------------------\n",
      "Example 883:\n",
      "Text: um its surpassed my expectations\n",
      "Length: 5\n",
      "Label: [[2.4]]\n",
      "Segment: IumbAb8q2dM[5]\n",
      "----------------------------------------\n",
      "Example 884:\n",
      "Text: um usually im not really a big huge alien kind of fan\n",
      "Length: 12\n",
      "Label: [[-0.6]]\n",
      "Segment: IumbAb8q2dM[6]\n",
      "----------------------------------------\n",
      "Example 885:\n",
      "Text: but um it was really really good\n",
      "Length: 7\n",
      "Label: [[3.]]\n",
      "Segment: IumbAb8q2dM[7]\n",
      "----------------------------------------\n",
      "Example 886:\n",
      "Text: um i really wanna go read the book now\n",
      "Length: 9\n",
      "Label: [[1.8]]\n",
      "Segment: IumbAb8q2dM[8]\n",
      "----------------------------------------\n",
      "Example 887:\n",
      "Text: coz im so curious to see um how the storyline um got to that point\n",
      "Length: 15\n",
      "Label: [[-0.2]]\n",
      "Segment: IumbAb8q2dM[9]\n",
      "----------------------------------------\n",
      "Example 888:\n",
      "Text: i heard that in the book it describes um the plan of the glory a lot better\n",
      "Length: 17\n",
      "Label: [[-1.]]\n",
      "Segment: IumbAb8q2dM[10]\n",
      "----------------------------------------\n",
      "Example 889:\n",
      "Text: um gives more details so i cant wait to get my hands on it now\n",
      "Length: 15\n",
      "Label: [[1.4]]\n",
      "Segment: IumbAb8q2dM[11]\n",
      "----------------------------------------\n",
      "Example 890:\n",
      "Text: um i cant wait until the next one comes out too\n",
      "Length: 11\n",
      "Label: [[1.8]]\n",
      "Segment: IumbAb8q2dM[12]\n",
      "----------------------------------------\n",
      "Example 891:\n",
      "Text: um it it turns out that james fray who um i like\n",
      "Length: 12\n",
      "Label: [[1.2]]\n",
      "Segment: IumbAb8q2dM[13]\n",
      "----------------------------------------\n",
      "Example 892:\n",
      "Text: um he wrote a good book\n",
      "Length: 6\n",
      "Label: [[1.75]]\n",
      "Segment: IumbAb8q2dM[14]\n",
      "----------------------------------------\n",
      "Example 893:\n",
      "Text: um and i cant wait for the next one to come out\n",
      "Length: 12\n",
      "Label: [[2.4]]\n",
      "Segment: IumbAb8q2dM[15]\n",
      "----------------------------------------\n",
      "Example 894:\n",
      "Text: im really excited\n",
      "Length: 3\n",
      "Label: [[2.]]\n",
      "Segment: IumbAb8q2dM[16]\n",
      "----------------------------------------\n",
      "Example 895:\n",
      "Text: um as for alex i am a new alex fan\n",
      "Length: 10\n",
      "Label: [[0.8]]\n",
      "Segment: IumbAb8q2dM[17]\n",
      "----------------------------------------\n",
      "Example 896:\n",
      "Text: he was unbelievable\n",
      "Length: 3\n",
      "Label: [[1.6]]\n",
      "Segment: IumbAb8q2dM[18]\n",
      "----------------------------------------\n",
      "Example 897:\n",
      "Text: so easy on the eyes\n",
      "Length: 5\n",
      "Label: [[2.]]\n",
      "Segment: IumbAb8q2dM[19]\n",
      "----------------------------------------\n",
      "Example 898:\n",
      "Text: um i think hes my new favorite\n",
      "Length: 7\n",
      "Label: [[1.2]]\n",
      "Segment: IumbAb8q2dM[20]\n",
      "----------------------------------------\n",
      "Example 899:\n",
      "Text: yeah so i suggest that you guys all watch this movie\n",
      "Length: 11\n",
      "Label: [[2.2]]\n",
      "Segment: IumbAb8q2dM[21]\n",
      "----------------------------------------\n",
      "Example 900:\n",
      "Text: and justin timberlake i thought they made a great duo\n",
      "Length: 10\n",
      "Label: [[2.4]]\n",
      "Segment: Jkswaaud0hk[0]\n",
      "----------------------------------------\n",
      "Example 901:\n",
      "Text: is gorgeous\n",
      "Length: 2\n",
      "Label: [[2.]]\n",
      "Segment: Jkswaaud0hk[1]\n",
      "----------------------------------------\n",
      "Example 902:\n",
      "Text: theres some great bedroom scenes\n",
      "Length: 5\n",
      "Label: [[2.2]]\n",
      "Segment: Jkswaaud0hk[2]\n",
      "----------------------------------------\n",
      "Example 903:\n",
      "Text: you guys are youre gonna get to enjoy\n",
      "Length: 8\n",
      "Label: [[1.]]\n",
      "Segment: Jkswaaud0hk[3]\n",
      "----------------------------------------\n",
      "Example 904:\n",
      "Text: a fine light weight day movie\n",
      "Length: 6\n",
      "Label: [[1.8]]\n",
      "Segment: Jkswaaud0hk[4]\n",
      "----------------------------------------\n",
      "Example 905:\n",
      "Text: i think some of the women are going to enjoy this more than the certainly\n",
      "Length: 15\n",
      "Label: [[0.4]]\n",
      "Segment: Jkswaaud0hk[5]\n",
      "----------------------------------------\n",
      "Example 906:\n",
      "Text: there are some scenes where i think some of the women are gonna feel more the emotion of it\n",
      "Length: 19\n",
      "Label: [[0.2]]\n",
      "Segment: Jkswaaud0hk[6]\n",
      "----------------------------------------\n",
      "Example 907:\n",
      "Text: there are some funny lines\n",
      "Length: 5\n",
      "Label: [[1.6]]\n",
      "Segment: Jkswaaud0hk[7]\n",
      "----------------------------------------\n",
      "Example 908:\n",
      "Text: great steamy bedroom scenes\n",
      "Length: 4\n",
      "Label: [[1.]]\n",
      "Segment: Jkswaaud0hk[8]\n",
      "----------------------------------------\n",
      "Example 909:\n",
      "Text: i was surprised um the amount of skin they showed\n",
      "Length: 10\n",
      "Label: [[-0.4]]\n",
      "Segment: Jkswaaud0hk[9]\n",
      "----------------------------------------\n",
      "Example 910:\n",
      "Text: but um it was in a good taste\n",
      "Length: 8\n",
      "Label: [[1.8]]\n",
      "Segment: Jkswaaud0hk[10]\n",
      "----------------------------------------\n",
      "Example 911:\n",
      "Text: um and i thought woody harelson was a funny\n",
      "Length: 9\n",
      "Label: [[1.6]]\n",
      "Segment: Jkswaaud0hk[11]\n",
      "----------------------------------------\n",
      "Example 912:\n",
      "Text: he um added a dimension to the movie as well\n",
      "Length: 10\n",
      "Label: [[1.8]]\n",
      "Segment: Jkswaaud0hk[12]\n",
      "----------------------------------------\n",
      "Example 913:\n",
      "Text: storyline was ok\n",
      "Length: 3\n",
      "Label: [[0.6]]\n",
      "Segment: Jkswaaud0hk[13]\n",
      "----------------------------------------\n",
      "Example 914:\n",
      "Text: but overall i thought it was it was a fun picture\n",
      "Length: 11\n",
      "Label: [[2.]]\n",
      "Segment: Jkswaaud0hk[14]\n",
      "----------------------------------------\n",
      "Example 915:\n",
      "Text: i i do think its worth seeing\n",
      "Length: 7\n",
      "Label: [[1.6]]\n",
      "Segment: Jkswaaud0hk[15]\n",
      "----------------------------------------\n",
      "Example 916:\n",
      "Text: um again more of a day movie than um seeing it alone\n",
      "Length: 12\n",
      "Label: [[0.2]]\n",
      "Segment: Jkswaaud0hk[16]\n",
      "----------------------------------------\n",
      "Example 917:\n",
      "Text: unless you ladies go together to see it together\n",
      "Length: 9\n",
      "Label: [[0.6]]\n",
      "Segment: Jkswaaud0hk[17]\n",
      "----------------------------------------\n",
      "Example 918:\n",
      "Text: so id go see it\n",
      "Length: 5\n",
      "Label: [[1.8]]\n",
      "Segment: Jkswaaud0hk[18]\n",
      "----------------------------------------\n",
      "Example 919:\n",
      "Text: thumbs up\n",
      "Length: 2\n",
      "Label: [[1.6]]\n",
      "Segment: Jkswaaud0hk[19]\n",
      "----------------------------------------\n",
      "Example 920:\n",
      "Text: but its actually worth talking about\n",
      "Length: 6\n",
      "Label: [[1.]]\n",
      "Segment: LSi-o-IrDMs[0]\n",
      "----------------------------------------\n",
      "Example 921:\n",
      "Text: because the movie itself is the same old crap from the series\n",
      "Length: 12\n",
      "Label: [[-2.]]\n",
      "Segment: LSi-o-IrDMs[1]\n",
      "----------------------------------------\n",
      "Example 922:\n",
      "Text: and i actually am not finding the series to be very fun and popcorn kind of movie\n",
      "Length: 17\n",
      "Label: [[0.]]\n",
      "Segment: LSi-o-IrDMs[2]\n",
      "----------------------------------------\n",
      "Example 923:\n",
      "Text: you just cant walk in anything other than that\n",
      "Length: 9\n",
      "Label: [[-0.6]]\n",
      "Segment: LSi-o-IrDMs[3]\n",
      "----------------------------------------\n",
      "Example 924:\n",
      "Text: in this case it didnt take much convincing which is a little silly\n",
      "Length: 13\n",
      "Label: [[0.]]\n",
      "Segment: LSi-o-IrDMs[4]\n",
      "----------------------------------------\n",
      "Example 925:\n",
      "Text: but the acting is bad\n",
      "Length: 5\n",
      "Label: [[-2.2]]\n",
      "Segment: LSi-o-IrDMs[5]\n",
      "----------------------------------------\n",
      "Example 926:\n",
      "Text: the plot is you know\n",
      "Length: 5\n",
      "Label: [[-0.2]]\n",
      "Segment: LSi-o-IrDMs[6]\n",
      "----------------------------------------\n",
      "Example 927:\n",
      "Text: actually the acting is ok\n",
      "Length: 5\n",
      "Label: [[0.4]]\n",
      "Segment: LSi-o-IrDMs[7]\n",
      "----------------------------------------\n",
      "Example 928:\n",
      "Text: i guess for this kind of movie the plot is is is threadbare\n",
      "Length: 13\n",
      "Label: [[-1.]]\n",
      "Segment: LSi-o-IrDMs[8]\n",
      "----------------------------------------\n",
      "Example 929:\n",
      "Text: the the um character development is nil\n",
      "Length: 7\n",
      "Label: [[-2.]]\n",
      "Segment: LSi-o-IrDMs[9]\n",
      "----------------------------------------\n",
      "Example 930:\n",
      "Text: but none of those things matter its a fun movie anyway\n",
      "Length: 11\n",
      "Label: [[1.4]]\n",
      "Segment: LSi-o-IrDMs[10]\n",
      "----------------------------------------\n",
      "Example 931:\n",
      "Text: its a popcorn movie\n",
      "Length: 4\n",
      "Label: [[-0.5]]\n",
      "Segment: LSi-o-IrDMs[11]\n",
      "----------------------------------------\n",
      "Example 932:\n",
      "Text: which is a terrible picture\n",
      "Length: 5\n",
      "Label: [[-2.4]]\n",
      "Segment: LSi-o-IrDMs[12]\n",
      "----------------------------------------\n",
      "Example 933:\n",
      "Text: um but um this looks a lot better i think that real d\n",
      "Length: 13\n",
      "Label: [[2.]]\n",
      "Segment: LSi-o-IrDMs[13]\n",
      "----------------------------------------\n",
      "Example 934:\n",
      "Text: i had ideal seats\n",
      "Length: 4\n",
      "Label: [[1.]]\n",
      "Segment: LSi-o-IrDMs[14]\n",
      "----------------------------------------\n",
      "Example 935:\n",
      "Text: because its good to sit right in the middle of the theater with and\n",
      "Length: 14\n",
      "Label: [[0.6]]\n",
      "Segment: LSi-o-IrDMs[15]\n",
      "----------------------------------------\n",
      "Example 936:\n",
      "Text: um but the they looked awesome\n",
      "Length: 6\n",
      "Label: [[1.6]]\n",
      "Segment: LSi-o-IrDMs[16]\n",
      "----------------------------------------\n",
      "Example 937:\n",
      "Text: the itself really had improved\n",
      "Length: 5\n",
      "Label: [[1.2]]\n",
      "Segment: LSi-o-IrDMs[17]\n",
      "----------------------------------------\n",
      "Example 938:\n",
      "Text: um the color looked great\n",
      "Length: 5\n",
      "Label: [[2.]]\n",
      "Segment: LSi-o-IrDMs[18]\n",
      "----------------------------------------\n",
      "Example 939:\n",
      "Text: coz sometimes can mess up the color at least the old i think real d it you know had sort of had sort of tempted but it winds itself its also um not ideal for for the um\n",
      "Length: 38\n",
      "Label: [[-1.2]]\n",
      "Segment: LSi-o-IrDMs[19]\n",
      "----------------------------------------\n",
      "Example 940:\n",
      "Text: um but this looked amazing looked really good\n",
      "Length: 8\n",
      "Label: [[2.8]]\n",
      "Segment: LSi-o-IrDMs[20]\n",
      "----------------------------------------\n",
      "Example 941:\n",
      "Text: and it makes it worth going to see this movie if youve got um the dolby somewhere in your town\n",
      "Length: 20\n",
      "Label: [[1.8]]\n",
      "Segment: LSi-o-IrDMs[21]\n",
      "----------------------------------------\n",
      "Example 942:\n",
      "Text: and i hope this takes over as the new system\n",
      "Length: 10\n",
      "Label: [[1.]]\n",
      "Segment: LSi-o-IrDMs[22]\n",
      "----------------------------------------\n",
      "Example 943:\n",
      "Text: i would love that\n",
      "Length: 4\n",
      "Label: [[1.8]]\n",
      "Segment: LSi-o-IrDMs[23]\n",
      "----------------------------------------\n",
      "Example 944:\n",
      "Text: that be that would be cool to see i mean\n",
      "Length: 10\n",
      "Label: [[0.4]]\n",
      "Segment: LSi-o-IrDMs[24]\n",
      "----------------------------------------\n",
      "Example 945:\n",
      "Text: eventually were gonna get burned out as a as a society\n",
      "Length: 11\n",
      "Label: [[-1.2]]\n",
      "Segment: LSi-o-IrDMs[25]\n",
      "----------------------------------------\n",
      "Example 946:\n",
      "Text: once were gonna be burned out on because\n",
      "Length: 8\n",
      "Label: [[-0.8]]\n",
      "Segment: LSi-o-IrDMs[26]\n",
      "----------------------------------------\n",
      "Example 947:\n",
      "Text: because its it is a gimmick um\n",
      "Length: 7\n",
      "Label: [[-1.6]]\n",
      "Segment: LSi-o-IrDMs[27]\n",
      "----------------------------------------\n",
      "Example 948:\n",
      "Text: um but i will say um with this with this quality of you could almost make you know a regular like a dramatic movie or an action movie or something that was really good movie and you could make it and it wouldnt at\n",
      "Length: 44\n",
      "Label: [[1.4]]\n",
      "Segment: LSi-o-IrDMs[28]\n",
      "----------------------------------------\n",
      "Example 949:\n",
      "Text: i just wanted to let you know that is really ridiculously expensive\n",
      "Length: 12\n",
      "Label: [[-1.2]]\n",
      "Segment: MLal-t_vJPM[0]\n",
      "----------------------------------------\n",
      "Example 950:\n",
      "Text: you know what you should see how to train your dragon\n",
      "Length: 11\n",
      "Label: [[1.8]]\n",
      "Segment: MLal-t_vJPM[1]\n",
      "----------------------------------------\n",
      "Example 951:\n",
      "Text: you should take your kids\n",
      "Length: 5\n",
      "Label: [[1.6]]\n",
      "Segment: MLal-t_vJPM[2]\n",
      "----------------------------------------\n",
      "Example 952:\n",
      "Text: and if you dont have kids you may wanna consider seeing it anyway\n",
      "Length: 13\n",
      "Label: [[1.8]]\n",
      "Segment: MLal-t_vJPM[3]\n",
      "----------------------------------------\n",
      "Example 953:\n",
      "Text: its probably the best thing currently in theaters\n",
      "Length: 8\n",
      "Label: [[2.2]]\n",
      "Segment: MLal-t_vJPM[4]\n",
      "----------------------------------------\n",
      "Example 954:\n",
      "Text: it is its a great story\n",
      "Length: 6\n",
      "Label: [[2.6]]\n",
      "Segment: MLal-t_vJPM[5]\n",
      "----------------------------------------\n",
      "Example 955:\n",
      "Text: its a lot of fun to watch\n",
      "Length: 7\n",
      "Label: [[2.2]]\n",
      "Segment: MLal-t_vJPM[6]\n",
      "----------------------------------------\n",
      "Example 956:\n",
      "Text: its beautifully done\n",
      "Length: 3\n",
      "Label: [[2.6]]\n",
      "Segment: MLal-t_vJPM[7]\n",
      "----------------------------------------\n",
      "Example 957:\n",
      "Text: and its really well written\n",
      "Length: 5\n",
      "Label: [[2.]]\n",
      "Segment: MLal-t_vJPM[8]\n",
      "----------------------------------------\n",
      "Example 958:\n",
      "Text: i have two problems with it\n",
      "Length: 6\n",
      "Label: [[-1.8]]\n",
      "Segment: MLal-t_vJPM[9]\n",
      "----------------------------------------\n",
      "Example 959:\n",
      "Text: number one im getting a little sick of the kind of lead character sort of really awkward boy who is really awkward and stuff you know im getting sick of that character and im tired of it\n",
      "Length: 37\n",
      "Label: [[-2.8]]\n",
      "Segment: MLal-t_vJPM[10]\n",
      "----------------------------------------\n",
      "Example 960:\n",
      "Text: and i get angry about it laughter doesnt play best character in the film\n",
      "Length: 14\n",
      "Label: [[-2.]]\n",
      "Segment: MLal-t_vJPM[11]\n",
      "----------------------------------------\n",
      "Example 961:\n",
      "Text: but he might as well\n",
      "Length: 5\n",
      "Label: [[0.8]]\n",
      "Segment: MLal-t_vJPM[12]\n",
      "----------------------------------------\n",
      "Example 962:\n",
      "Text: so im im im through with that guy\n",
      "Length: 8\n",
      "Label: [[-1.4]]\n",
      "Segment: MLal-t_vJPM[13]\n",
      "----------------------------------------\n",
      "Example 963:\n",
      "Text: second theres one massive plot hole in this film and it is the size of a dragon that is big as a mountain and when you see the film probably know what i mean\n",
      "Length: 34\n",
      "Label: [[-1.]]\n",
      "Segment: MLal-t_vJPM[14]\n",
      "----------------------------------------\n",
      "Example 964:\n",
      "Text: um theres no explanation for this thing\n",
      "Length: 7\n",
      "Label: [[-1.6]]\n",
      "Segment: MLal-t_vJPM[15]\n",
      "----------------------------------------\n",
      "Example 965:\n",
      "Text: and the only explanation i come up with makes this story kind of kind of creepy\n",
      "Length: 16\n",
      "Label: [[-1.]]\n",
      "Segment: MLal-t_vJPM[16]\n",
      "----------------------------------------\n",
      "Example 966:\n",
      "Text: other then those two things this is a really fun film that you will enjoy unless you are piece of so\n",
      "Length: 21\n",
      "Label: [[-0.4]]\n",
      "Segment: MLal-t_vJPM[17]\n",
      "----------------------------------------\n",
      "Example 967:\n",
      "Text: im gonna give this a grade b minus\n",
      "Length: 8\n",
      "Label: [[1.2]]\n",
      "Segment: Njd1F0vZSm4[0]\n",
      "----------------------------------------\n",
      "Example 968:\n",
      "Text: the work the is spectacular\n",
      "Length: 5\n",
      "Label: [[2.8]]\n",
      "Segment: Njd1F0vZSm4[1]\n",
      "----------------------------------------\n",
      "Example 969:\n",
      "Text: the flying sequences are beautiful\n",
      "Length: 5\n",
      "Label: [[2.4]]\n",
      "Segment: Njd1F0vZSm4[2]\n",
      "----------------------------------------\n",
      "Example 970:\n",
      "Text: and the owls are really wonderful\n",
      "Length: 6\n",
      "Label: [[2.2]]\n",
      "Segment: Njd1F0vZSm4[3]\n",
      "----------------------------------------\n",
      "Example 971:\n",
      "Text: and come of real\n",
      "Length: 4\n",
      "Label: [[0.2]]\n",
      "Segment: Njd1F0vZSm4[4]\n",
      "----------------------------------------\n",
      "Example 972:\n",
      "Text: and they do have very nice and\n",
      "Length: 7\n",
      "Label: [[1.6]]\n",
      "Segment: Njd1F0vZSm4[5]\n",
      "----------------------------------------\n",
      "Example 973:\n",
      "Text: but the story is very dark\n",
      "Length: 6\n",
      "Label: [[-1.]]\n",
      "Segment: Njd1F0vZSm4[6]\n",
      "----------------------------------------\n",
      "Example 974:\n",
      "Text: in fact my six years old was scared most of the movie\n",
      "Length: 12\n",
      "Label: [[-1.8]]\n",
      "Segment: Njd1F0vZSm4[7]\n",
      "----------------------------------------\n",
      "Example 975:\n",
      "Text: um my other complaint other than that theres like nothing light or funny in this story to break up the slumber mood is the battle itself\n",
      "Length: 26\n",
      "Label: [[-1.8]]\n",
      "Segment: Njd1F0vZSm4[8]\n",
      "----------------------------------------\n",
      "Example 976:\n",
      "Text: you cant tell which are the good owls which are the bed owls\n",
      "Length: 13\n",
      "Label: [[-0.6]]\n",
      "Segment: Njd1F0vZSm4[9]\n",
      "----------------------------------------\n",
      "Example 977:\n",
      "Text: they really needed to somehow set them apart with armor\n",
      "Length: 10\n",
      "Label: [[-1.6]]\n",
      "Segment: Njd1F0vZSm4[10]\n",
      "----------------------------------------\n",
      "Example 978:\n",
      "Text: anyway this is one you can skip\n",
      "Length: 7\n",
      "Label: [[-1.8]]\n",
      "Segment: Njd1F0vZSm4[11]\n",
      "----------------------------------------\n",
      "Example 979:\n",
      "Text: or you can see up to you\n",
      "Length: 7\n",
      "Label: [[0.2]]\n",
      "Segment: Njd1F0vZSm4[12]\n",
      "----------------------------------------\n",
      "Example 980:\n",
      "Text: which is a i guess it would be the best term for the i believe it was a movie clash of the titans\n",
      "Length: 23\n",
      "Label: [[-0.4]]\n",
      "Segment: Nzq88NnDkEk[0]\n",
      "----------------------------------------\n",
      "Example 981:\n",
      "Text: um im going to have to say this movie was terrible\n",
      "Length: 11\n",
      "Label: [[-2.8]]\n",
      "Segment: Nzq88NnDkEk[1]\n",
      "----------------------------------------\n",
      "Example 982:\n",
      "Text: um i was really looking forward to it\n",
      "Length: 8\n",
      "Label: [[-0.4]]\n",
      "Segment: Nzq88NnDkEk[2]\n",
      "----------------------------------------\n",
      "Example 983:\n",
      "Text: i was a little at know as you are with with you know\n",
      "Length: 13\n",
      "Label: [[-0.8]]\n",
      "Segment: Nzq88NnDkEk[3]\n",
      "----------------------------------------\n",
      "Example 984:\n",
      "Text: is it gonna be good\n",
      "Length: 5\n",
      "Label: [[-0.2]]\n",
      "Segment: Nzq88NnDkEk[4]\n",
      "----------------------------------------\n",
      "Example 985:\n",
      "Text: but as the trailers came out i i really liked what i was seeing\n",
      "Length: 14\n",
      "Label: [[1.8]]\n",
      "Segment: Nzq88NnDkEk[5]\n",
      "----------------------------------------\n",
      "Example 986:\n",
      "Text: i think that music that music they kind of pull it with the soundtrack really got me excited about seeing this movie\n",
      "Length: 22\n",
      "Label: [[1.8]]\n",
      "Segment: Nzq88NnDkEk[6]\n",
      "----------------------------------------\n",
      "Example 987:\n",
      "Text: and and being a fan of the original i was i was looking forward to seeing it\n",
      "Length: 17\n",
      "Label: [[-1.]]\n",
      "Segment: Nzq88NnDkEk[7]\n",
      "----------------------------------------\n",
      "Example 988:\n",
      "Text: but to me someone needs to release the on this movie and just totally destroy it\n",
      "Length: 16\n",
      "Label: [[-3.]]\n",
      "Segment: Nzq88NnDkEk[8]\n",
      "----------------------------------------\n",
      "Example 989:\n",
      "Text: because i just felt like it was it seemed like it was a rushed movie\n",
      "Length: 15\n",
      "Label: [[-1.4]]\n",
      "Segment: Nzq88NnDkEk[9]\n",
      "----------------------------------------\n",
      "Example 990:\n",
      "Text: it seemed like there was no story development in it\n",
      "Length: 10\n",
      "Label: [[-2.]]\n",
      "Segment: Nzq88NnDkEk[10]\n",
      "----------------------------------------\n",
      "Example 991:\n",
      "Text: um i just really didnt have good time\n",
      "Length: 8\n",
      "Label: [[-2.]]\n",
      "Segment: Nzq88NnDkEk[11]\n",
      "----------------------------------------\n",
      "Example 992:\n",
      "Text: i felt like medusa really that scary\n",
      "Length: 7\n",
      "Label: [[-1.8]]\n",
      "Segment: Nzq88NnDkEk[12]\n",
      "----------------------------------------\n",
      "Example 993:\n",
      "Text: maybe it was coz i was a kid back at that day but medusa was a lot scar scarier then\n",
      "Length: 20\n",
      "Label: [[-1.]]\n",
      "Segment: Nzq88NnDkEk[13]\n",
      "----------------------------------------\n",
      "Example 994:\n",
      "Text: um i just think they made her almost looked too you know they tried that you know make her look too beautiful\n",
      "Length: 22\n",
      "Label: [[-1.2]]\n",
      "Segment: Nzq88NnDkEk[14]\n",
      "----------------------------------------\n",
      "Example 995:\n",
      "Text: but um i just in whole really didnt like this movie\n",
      "Length: 11\n",
      "Label: [[-2.2]]\n",
      "Segment: Nzq88NnDkEk[15]\n",
      "----------------------------------------\n",
      "Example 996:\n",
      "Text: the screen you know was that i i kind of found myself you know wanted to lay my head back and take a nap\n",
      "Length: 24\n",
      "Label: [[-2.2]]\n",
      "Segment: Nzq88NnDkEk[16]\n",
      "----------------------------------------\n",
      "Example 997:\n",
      "Text: and actually the guy sitting next to me actually was taking a nap laughter he kept dozing off\n",
      "Length: 18\n",
      "Label: [[-1.4]]\n",
      "Segment: Nzq88NnDkEk[17]\n",
      "----------------------------------------\n",
      "Example 998:\n",
      "Text: and and after the movie um going out into the theater into the lobby i had noone i heard noone say anything good\n",
      "Length: 23\n",
      "Label: [[-2.4]]\n",
      "Segment: Nzq88NnDkEk[18]\n",
      "----------------------------------------\n",
      "Example 999:\n",
      "Text: and my who were there had nothing good to say about it\n",
      "Length: 12\n",
      "Label: [[-2.4]]\n",
      "Segment: Nzq88NnDkEk[19]\n",
      "----------------------------------------\n",
      "Example 1000:\n",
      "Text: so i must say this one is probably gonna be waiting until it comes on or\n",
      "Length: 16\n",
      "Label: [[-1.2]]\n",
      "Segment: Nzq88NnDkEk[20]\n",
      "----------------------------------------\n",
      "Example 1001:\n",
      "Text: or get it at um um red box for a buck\n",
      "Length: 11\n",
      "Label: [[-0.5]]\n",
      "Segment: Nzq88NnDkEk[21]\n",
      "----------------------------------------\n",
      "Example 1002:\n",
      "Text: um i just really didnt like it\n",
      "Length: 7\n",
      "Label: [[-2.]]\n",
      "Segment: Nzq88NnDkEk[22]\n",
      "----------------------------------------\n",
      "Example 1003:\n",
      "Text: um but hey if youre looking to spend some money um go check it out maybe you will like it\n",
      "Length: 20\n",
      "Label: [[-1.]]\n",
      "Segment: Nzq88NnDkEk[23]\n",
      "----------------------------------------\n",
      "Example 1004:\n",
      "Text: but um from my review im gonna say im gonna give it two thumbs down\n",
      "Length: 15\n",
      "Label: [[-2.8]]\n",
      "Segment: Nzq88NnDkEk[24]\n",
      "----------------------------------------\n",
      "Example 1005:\n",
      "Text: release the on this movie dont go see it go see something else how to train the dragon and um thats all im gonna say about that\n",
      "Length: 27\n",
      "Label: [[-2.8]]\n",
      "Segment: Nzq88NnDkEk[25]\n",
      "----------------------------------------\n",
      "Example 1006:\n",
      "Text: so disappointment i\n",
      "Length: 3\n",
      "Label: [[-2.]]\n",
      "Segment: Nzq88NnDkEk[26]\n",
      "----------------------------------------\n",
      "Example 1007:\n",
      "Text: i did not wanna give this movie a bad review\n",
      "Length: 10\n",
      "Label: [[-0.2]]\n",
      "Segment: Nzq88NnDkEk[27]\n",
      "----------------------------------------\n",
      "Example 1008:\n",
      "Text: i im a fan of the original you know loved it\n",
      "Length: 11\n",
      "Label: [[1.2]]\n",
      "Segment: Nzq88NnDkEk[28]\n",
      "----------------------------------------\n",
      "Example 1009:\n",
      "Text: and um but i got to i got to do my duty and let you guys know its a a major suck fest\n",
      "Length: 23\n",
      "Label: [[-3.]]\n",
      "Segment: Nzq88NnDkEk[29]\n",
      "----------------------------------------\n",
      "Example 1010:\n",
      "Text: heard good things about the screenings on that\n",
      "Length: 8\n",
      "Label: [[1.6]]\n",
      "Segment: Nzq88NnDkEk[30]\n",
      "----------------------------------------\n",
      "Example 1011:\n",
      "Text: and um looking really forward to seeing that movie\n",
      "Length: 9\n",
      "Label: [[1.8]]\n",
      "Segment: Nzq88NnDkEk[31]\n",
      "----------------------------------------\n",
      "Example 1012:\n",
      "Text: it been better\n",
      "Length: 3\n",
      "Label: [[-1.]]\n",
      "Segment: OQvJTdtJ2H4[0]\n",
      "----------------------------------------\n",
      "Example 1013:\n",
      "Text: the first one was a lot better\n",
      "Length: 7\n",
      "Label: [[-0.8]]\n",
      "Segment: OQvJTdtJ2H4[1]\n",
      "----------------------------------------\n",
      "Example 1014:\n",
      "Text: they made zeus a little less sparkly it was very distracting\n",
      "Length: 11\n",
      "Label: [[-1.6]]\n",
      "Segment: OQvJTdtJ2H4[2]\n",
      "----------------------------------------\n",
      "Example 1015:\n",
      "Text: um it was very hard to follow\n",
      "Length: 7\n",
      "Label: [[-2.]]\n",
      "Segment: OQvJTdtJ2H4[3]\n",
      "----------------------------------------\n",
      "Example 1016:\n",
      "Text: the first one made more sense\n",
      "Length: 6\n",
      "Label: [[-0.8]]\n",
      "Segment: OQvJTdtJ2H4[4]\n",
      "----------------------------------------\n",
      "Example 1017:\n",
      "Text: and the you know in the preview is like so much hype\n",
      "Length: 12\n",
      "Label: [[-1.]]\n",
      "Segment: OQvJTdtJ2H4[5]\n",
      "----------------------------------------\n",
      "Example 1018:\n",
      "Text: they pretend theres gonna be this big scene it maybe lasts about a minute and i was like is that it\n",
      "Length: 21\n",
      "Label: [[-1.6]]\n",
      "Segment: OQvJTdtJ2H4[6]\n",
      "----------------------------------------\n",
      "Example 1019:\n",
      "Text: and than its not a movie\n",
      "Length: 6\n",
      "Label: [[-0.8]]\n",
      "Segment: OQvJTdtJ2H4[7]\n",
      "----------------------------------------\n",
      "Example 1020:\n",
      "Text: the previews are much more the ne so yeah it was very disappointing\n",
      "Length: 13\n",
      "Label: [[-1.8]]\n",
      "Segment: OQvJTdtJ2H4[8]\n",
      "----------------------------------------\n",
      "Example 1021:\n",
      "Text: i give it about one and a half stars\n",
      "Length: 9\n",
      "Label: [[-2.]]\n",
      "Segment: OQvJTdtJ2H4[9]\n",
      "----------------------------------------\n",
      "Example 1022:\n",
      "Text: so thats thumbs down if you dont understand\n",
      "Length: 8\n",
      "Label: [[-2.2]]\n",
      "Segment: OQvJTdtJ2H4[10]\n",
      "----------------------------------------\n",
      "Example 1023:\n",
      "Text: so it is not a buy\n",
      "Length: 6\n",
      "Label: [[-1.25]]\n",
      "Segment: OQvJTdtJ2H4[11]\n",
      "----------------------------------------\n",
      "Example 1024:\n",
      "Text: but the was great\n",
      "Length: 4\n",
      "Label: [[1.4]]\n",
      "Segment: OQvJTdtJ2H4[12]\n",
      "----------------------------------------\n",
      "Example 1025:\n",
      "Text: and thats how i thought a giant scorpion would look with the piece of driftwood that had blue fire on it\n",
      "Length: 21\n",
      "Label: [[-0.5]]\n",
      "Segment: OQvJTdtJ2H4[13]\n",
      "----------------------------------------\n",
      "Example 1026:\n",
      "Text: um medusa was way different from percy jackson and glandon laws\n",
      "Length: 11\n",
      "Label: [[-0.4]]\n",
      "Segment: OQvJTdtJ2H4[14]\n",
      "----------------------------------------\n",
      "Example 1027:\n",
      "Text: but the best part about the movie i ve got a free pair of glasses\n",
      "Length: 15\n",
      "Label: [[-1.]]\n",
      "Segment: OQvJTdtJ2H4[15]\n",
      "----------------------------------------\n",
      "Example 1028:\n",
      "Text: and a guy who looks a lot like tom cruise\n",
      "Length: 10\n",
      "Label: [[0.2]]\n",
      "Segment: OtBXNcAL_lE[0]\n",
      "----------------------------------------\n",
      "Example 1029:\n",
      "Text: um lip smacking this movie is dumb\n",
      "Length: 7\n",
      "Label: [[-2.6]]\n",
      "Segment: OtBXNcAL_lE[1]\n",
      "----------------------------------------\n",
      "Example 1030:\n",
      "Text: uh i personally think its a waste of money\n",
      "Length: 9\n",
      "Label: [[-1.2]]\n",
      "Segment: OtBXNcAL_lE[2]\n",
      "----------------------------------------\n",
      "Example 1031:\n",
      "Text: just because i cant stand movies that are so predictable\n",
      "Length: 10\n",
      "Label: [[-2.]]\n",
      "Segment: OtBXNcAL_lE[3]\n",
      "----------------------------------------\n",
      "Example 1032:\n",
      "Text: laughing i just just cant stand movies where its like the same plot as like other million movies\n",
      "Length: 18\n",
      "Label: [[-2.8]]\n",
      "Segment: OtBXNcAL_lE[4]\n",
      "----------------------------------------\n",
      "Example 1033:\n",
      "Text: just different just different people playing the roles\n",
      "Length: 8\n",
      "Label: [[0.4]]\n",
      "Segment: OtBXNcAL_lE[5]\n",
      "----------------------------------------\n",
      "Example 1034:\n",
      "Text: i really dont care to see those\n",
      "Length: 7\n",
      "Label: [[-2.]]\n",
      "Segment: OtBXNcAL_lE[6]\n",
      "----------------------------------------\n",
      "Example 1035:\n",
      "Text: but you know what i took a chance\n",
      "Length: 8\n",
      "Label: [[0.2]]\n",
      "Segment: OtBXNcAL_lE[7]\n",
      "----------------------------------------\n",
      "Example 1036:\n",
      "Text: you know i like kate hudson\n",
      "Length: 6\n",
      "Label: [[1.2]]\n",
      "Segment: OtBXNcAL_lE[8]\n",
      "----------------------------------------\n",
      "Example 1037:\n",
      "Text: so i thought this movie would be funny\n",
      "Length: 8\n",
      "Label: [[0.4]]\n",
      "Segment: OtBXNcAL_lE[9]\n",
      "----------------------------------------\n",
      "Example 1038:\n",
      "Text: and dont get me wrong there were you know funny parts in the movie\n",
      "Length: 14\n",
      "Label: [[0.2]]\n",
      "Segment: OtBXNcAL_lE[10]\n",
      "----------------------------------------\n",
      "Example 1039:\n",
      "Text: i just dont care for the plot\n",
      "Length: 7\n",
      "Label: [[-2.]]\n",
      "Segment: OtBXNcAL_lE[11]\n",
      "----------------------------------------\n",
      "Example 1040:\n",
      "Text: i dont care for basically any of it\n",
      "Length: 8\n",
      "Label: [[-2.2]]\n",
      "Segment: OtBXNcAL_lE[12]\n",
      "----------------------------------------\n",
      "Example 1041:\n",
      "Text: because its predictable\n",
      "Length: 3\n",
      "Label: [[-1.]]\n",
      "Segment: OtBXNcAL_lE[13]\n",
      "----------------------------------------\n",
      "Example 1042:\n",
      "Text: its the same you know rise and fall\n",
      "Length: 8\n",
      "Label: [[-0.4]]\n",
      "Segment: OtBXNcAL_lE[14]\n",
      "----------------------------------------\n",
      "Example 1043:\n",
      "Text: but in trouble you know she doesnt wanna tell her best friend blah blah blah\n",
      "Length: 15\n",
      "Label: [[-0.6]]\n",
      "Segment: OtBXNcAL_lE[15]\n",
      "----------------------------------------\n",
      "Example 1044:\n",
      "Text: and so all sad walking in the rain blah blah blah\n",
      "Length: 11\n",
      "Label: [[-1.2]]\n",
      "Segment: OtBXNcAL_lE[16]\n",
      "----------------------------------------\n",
      "Example 1045:\n",
      "Text: and blah blah blah\n",
      "Length: 4\n",
      "Label: [[-0.6]]\n",
      "Segment: OtBXNcAL_lE[17]\n",
      "----------------------------------------\n",
      "Example 1046:\n",
      "Text: ive been saying that a lot in this video blah blah blah blah\n",
      "Length: 13\n",
      "Label: [[-1.8]]\n",
      "Segment: OtBXNcAL_lE[18]\n",
      "----------------------------------------\n",
      "Example 1047:\n",
      "Text: um yea so anyways its really predictable\n",
      "Length: 7\n",
      "Label: [[-1.8]]\n",
      "Segment: OtBXNcAL_lE[19]\n",
      "----------------------------------------\n",
      "Example 1048:\n",
      "Text: i mean you can go see i personally didnt like it\n",
      "Length: 11\n",
      "Label: [[-2.]]\n",
      "Segment: OtBXNcAL_lE[20]\n",
      "----------------------------------------\n",
      "Example 1049:\n",
      "Text: because i just got really bored with it\n",
      "Length: 8\n",
      "Label: [[-2.]]\n",
      "Segment: OtBXNcAL_lE[21]\n",
      "----------------------------------------\n",
      "Example 1050:\n",
      "Text: um and its really unpredictable\n",
      "Length: 5\n",
      "Label: [[-0.25]]\n",
      "Segment: OtBXNcAL_lE[22]\n",
      "----------------------------------------\n",
      "Example 1051:\n",
      "Text: i just get so tired of unpredictable movies\n",
      "Length: 8\n",
      "Label: [[-2.]]\n",
      "Segment: OtBXNcAL_lE[23]\n",
      "----------------------------------------\n",
      "Example 1052:\n",
      "Text: that was pretty funny and um stupid for movies had this really long like really not really long but like really intense rent a about it\n",
      "Length: 26\n",
      "Label: [[1.4]]\n",
      "Segment: Oz06ZWiO20M[0]\n",
      "----------------------------------------\n",
      "Example 1053:\n",
      "Text: um and it it is just like everybody saying it is bad\n",
      "Length: 12\n",
      "Label: [[-2.4]]\n",
      "Segment: Oz06ZWiO20M[1]\n",
      "----------------------------------------\n",
      "Example 1054:\n",
      "Text: i dont think its like the worst movie ive even seen just this year\n",
      "Length: 14\n",
      "Label: [[0.]]\n",
      "Segment: Oz06ZWiO20M[2]\n",
      "----------------------------------------\n",
      "Example 1055:\n",
      "Text: but i would say i i enjoyed sucker punch\n",
      "Length: 9\n",
      "Label: [[1.6]]\n",
      "Segment: Oz06ZWiO20M[3]\n",
      "----------------------------------------\n",
      "Example 1056:\n",
      "Text: like i was more entertained by it than battle la which was just a slog and boring and i just try to totally uninteresting\n",
      "Length: 24\n",
      "Label: [[0.2]]\n",
      "Segment: Oz06ZWiO20M[4]\n",
      "----------------------------------------\n",
      "Example 1057:\n",
      "Text: and sucker punch is a but like a really ambitious weird the interesting idiosyncratic failure\n",
      "Length: 15\n",
      "Label: [[-0.8]]\n",
      "Segment: Oz06ZWiO20M[5]\n",
      "----------------------------------------\n",
      "Example 1058:\n",
      "Text: um it is bad\n",
      "Length: 4\n",
      "Label: [[-2.2]]\n",
      "Segment: Oz06ZWiO20M[6]\n",
      "----------------------------------------\n",
      "Example 1059:\n",
      "Text: but its not bad i think the way most people have been saying its bad\n",
      "Length: 15\n",
      "Label: [[-0.2]]\n",
      "Segment: Oz06ZWiO20M[7]\n",
      "----------------------------------------\n",
      "Example 1060:\n",
      "Text: its not bad in the way i was expecting it to be bad\n",
      "Length: 13\n",
      "Label: [[-0.2]]\n",
      "Segment: Oz06ZWiO20M[8]\n",
      "----------------------------------------\n",
      "Example 1061:\n",
      "Text: um it really is not trying to be a dramatic film or an action film\n",
      "Length: 15\n",
      "Label: [[0.]]\n",
      "Segment: Oz06ZWiO20M[9]\n",
      "----------------------------------------\n",
      "Example 1062:\n",
      "Text: like i think most people thats their knock on it is that its not you know conventionally satisfying as like you know with drama that we dont get to know anything about these characters their play interesting their path to freedom is not compelling and its basically within the first ten minutes of the movie where were sort of told whats gonna happen before it happens\n",
      "Length: 66\n",
      "Label: [[-1.6]]\n",
      "Segment: Oz06ZWiO20M[10]\n",
      "----------------------------------------\n",
      "Example 1063:\n",
      "Text: um and and all those things are true but i dont think its trying to be that\n",
      "Length: 17\n",
      "Label: [[-0.6]]\n",
      "Segment: Oz06ZWiO20M[11]\n",
      "----------------------------------------\n",
      "Example 1064:\n",
      "Text: i think its really much more like a musical\n",
      "Length: 9\n",
      "Label: [[0.6]]\n",
      "Segment: Oz06ZWiO20M[12]\n",
      "----------------------------------------\n",
      "Example 1065:\n",
      "Text: and i know this is gonna sound silly coz its such a broad goofy mainstream cult kind of movie\n",
      "Length: 19\n",
      "Label: [[1.]]\n",
      "Segment: Oz06ZWiO20M[13]\n",
      "----------------------------------------\n",
      "Example 1066:\n",
      "Text: but it really has more in common with a musical or and opera or even a ballet than a regular narrative film\n",
      "Length: 22\n",
      "Label: [[0.2]]\n",
      "Segment: Oz06ZWiO20M[14]\n",
      "----------------------------------------\n",
      "Example 1067:\n",
      "Text: coz like am remains in narrative film is about character development and plot and then spectacle like in third place\n",
      "Length: 20\n",
      "Label: [[-0.2]]\n",
      "Segment: Oz06ZWiO20M[15]\n",
      "----------------------------------------\n",
      "Example 1068:\n",
      "Text: so its like puts some people in it and youre gonna enjoy spending time with them\n",
      "Length: 16\n",
      "Label: [[0.6]]\n",
      "Segment: Oz06ZWiO20M[16]\n",
      "----------------------------------------\n",
      "Example 1069:\n",
      "Text: funny dialogue\n",
      "Length: 2\n",
      "Label: [[1.4]]\n",
      "Segment: Oz06ZWiO20M[17]\n",
      "----------------------------------------\n",
      "Example 1070:\n",
      "Text: make them compelling in their relationships compelling and then have a story thats like at five minutes this happens and at ten minutes this happens that like moves forward and has momentum\n",
      "Length: 32\n",
      "Label: [[0.]]\n",
      "Segment: Oz06ZWiO20M[18]\n",
      "----------------------------------------\n",
      "Example 1071:\n",
      "Text: and then you know put in some action or some romance or sex or whatever like to keep people sort of engaged\n",
      "Length: 22\n",
      "Label: [[0.8]]\n",
      "Segment: Oz06ZWiO20M[19]\n",
      "----------------------------------------\n",
      "Example 1072:\n",
      "Text: um and thats what narrative movies do\n",
      "Length: 7\n",
      "Label: [[0.4]]\n",
      "Segment: Oz06ZWiO20M[20]\n",
      "----------------------------------------\n",
      "Example 1073:\n",
      "Text: and this movie is really much more like the plot is what little there is\n",
      "Length: 15\n",
      "Label: [[-1.6]]\n",
      "Segment: Oz06ZWiO20M[21]\n",
      "----------------------------------------\n",
      "Example 1074:\n",
      "Text: and the characters are they are all just place holders\n",
      "Length: 10\n",
      "Label: [[-1.6]]\n",
      "Segment: Oz06ZWiO20M[22]\n",
      "----------------------------------------\n",
      "Example 1075:\n",
      "Text: its really like like if you went to go see the ballet and its about the spectacles\n",
      "Length: 17\n",
      "Label: [[0.8]]\n",
      "Segment: Oz06ZWiO20M[23]\n",
      "----------------------------------------\n",
      "Example 1076:\n",
      "Text: like the story of swan lake is why people go see swan lake its the movement and the dancing and the music and the sets and the\n",
      "Length: 27\n",
      "Label: [[1.8]]\n",
      "Segment: Oz06ZWiO20M[24]\n",
      "----------------------------------------\n",
      "Example 1077:\n",
      "Text: what can i say im just curious\n",
      "Length: 7\n",
      "Label: [[0.]]\n",
      "Segment: POKffnXeBds[0]\n",
      "----------------------------------------\n",
      "Example 1078:\n",
      "Text: dont get me wrong kate hudson is is pretty fine looking but i just think its kind of stupid everyone says has a fat ass\n",
      "Length: 25\n",
      "Label: [[-0.4]]\n",
      "Segment: POKffnXeBds[1]\n",
      "----------------------------------------\n",
      "Example 1079:\n",
      "Text: yes she has a fat ass in terms of white girls but her ass really that fat\n",
      "Length: 17\n",
      "Label: [[-1.25]]\n",
      "Segment: POKffnXeBds[2]\n",
      "----------------------------------------\n",
      "Example 1080:\n",
      "Text: first of all the movie was boring\n",
      "Length: 7\n",
      "Label: [[-2.]]\n",
      "Segment: POKffnXeBds[3]\n",
      "----------------------------------------\n",
      "Example 1081:\n",
      "Text: i mean the movie really funny at all\n",
      "Length: 8\n",
      "Label: [[-2.]]\n",
      "Segment: POKffnXeBds[4]\n",
      "----------------------------------------\n",
      "Example 1082:\n",
      "Text: all the all the funny parts funny\n",
      "Length: 7\n",
      "Label: [[-2.]]\n",
      "Segment: POKffnXeBds[5]\n",
      "----------------------------------------\n",
      "Example 1083:\n",
      "Text: i mean the movie was i guess it was a waste of time\n",
      "Length: 13\n",
      "Label: [[-1.2]]\n",
      "Segment: POKffnXeBds[6]\n",
      "----------------------------------------\n",
      "Example 1084:\n",
      "Text: i wa hey she might like it but even then its not really funny at all\n",
      "Length: 16\n",
      "Label: [[-2.]]\n",
      "Segment: POKffnXeBds[7]\n",
      "----------------------------------------\n",
      "Example 1085:\n",
      "Text: anne hathaway is really over rated in my opinion\n",
      "Length: 9\n",
      "Label: [[-2.2]]\n",
      "Segment: POKffnXeBds[8]\n",
      "----------------------------------------\n",
      "Example 1086:\n",
      "Text: i mean her acting is like so so and i cant believe she even won a oscar she won an oscar or for best supporting actress or best actress something\n",
      "Length: 30\n",
      "Label: [[-1.8]]\n",
      "Segment: POKffnXeBds[9]\n",
      "----------------------------------------\n",
      "Example 1087:\n",
      "Text: i mean that movie was a waste of time\n",
      "Length: 9\n",
      "Label: [[-2.6]]\n",
      "Segment: POKffnXeBds[10]\n",
      "----------------------------------------\n",
      "Example 1088:\n",
      "Text: its two girls trying too hard\n",
      "Length: 6\n",
      "Label: [[-1.6]]\n",
      "Segment: POKffnXeBds[11]\n",
      "----------------------------------------\n",
      "Example 1089:\n",
      "Text: and it just really good\n",
      "Length: 5\n",
      "Label: [[-2.8]]\n",
      "Segment: POKffnXeBds[12]\n",
      "----------------------------------------\n",
      "Example 1090:\n",
      "Text: i was a little bit disappointed in the film\n",
      "Length: 9\n",
      "Label: [[-1.4]]\n",
      "Segment: PZ-lDQFboO8[0]\n",
      "----------------------------------------\n",
      "Example 1091:\n",
      "Text: but the movie itself was just a little dry\n",
      "Length: 9\n",
      "Label: [[-1.8]]\n",
      "Segment: PZ-lDQFboO8[1]\n",
      "----------------------------------------\n",
      "Example 1092:\n",
      "Text: it didnt have a whole out of humor going on with it at least none that really made you wanna laugh out loud\n",
      "Length: 23\n",
      "Label: [[-1.6]]\n",
      "Segment: PZ-lDQFboO8[2]\n",
      "----------------------------------------\n",
      "Example 1093:\n",
      "Text: um even the kids and the audience itself just kind of chuckled a little bit gave a few laughs\n",
      "Length: 19\n",
      "Label: [[-1.]]\n",
      "Segment: PZ-lDQFboO8[3]\n",
      "----------------------------------------\n",
      "Example 1094:\n",
      "Text: now im not gonna lie a few parts that have great action sequences now even though it is an animated film it did have some great fight scenes\n",
      "Length: 28\n",
      "Label: [[1.4]]\n",
      "Segment: PZ-lDQFboO8[4]\n",
      "----------------------------------------\n",
      "Example 1095:\n",
      "Text: um but as far as humor goes not as much as i was expecting\n",
      "Length: 14\n",
      "Label: [[-1.6]]\n",
      "Segment: PZ-lDQFboO8[5]\n",
      "----------------------------------------\n",
      "Example 1096:\n",
      "Text: everything you see in the trailer itself was pretty much all the humor youre gonna see in the movie\n",
      "Length: 19\n",
      "Label: [[-1.6]]\n",
      "Segment: PZ-lDQFboO8[6]\n",
      "----------------------------------------\n",
      "Example 1097:\n",
      "Text: um um a you know along with the i would probably saying go see this movie an early showing dont spend a lot of money for the night viewing\n",
      "Length: 29\n",
      "Label: [[-0.6]]\n",
      "Segment: PZ-lDQFboO8[7]\n",
      "----------------------------------------\n",
      "Example 1098:\n",
      "Text: um maybe better like next time dreamworks but for this one for me it just what i was hoping it would be\n",
      "Length: 22\n",
      "Label: [[-2.2]]\n",
      "Segment: PZ-lDQFboO8[8]\n",
      "----------------------------------------\n",
      "Example 1099:\n",
      "Text: i love the films\n",
      "Length: 4\n",
      "Label: [[2.]]\n",
      "Segment: PZ-lDQFboO8[9]\n",
      "----------------------------------------\n",
      "Example 1100:\n",
      "Text: i liked ants\n",
      "Length: 3\n",
      "Label: [[0.]]\n",
      "Segment: PZ-lDQFboO8[10]\n",
      "----------------------------------------\n",
      "Example 1101:\n",
      "Text: but as far as kung fu panda goes i was hoping for a lot more it just there for me i dont know\n",
      "Length: 23\n",
      "Label: [[-1.6]]\n",
      "Segment: PZ-lDQFboO8[11]\n",
      "----------------------------------------\n",
      "Example 1102:\n",
      "Text: main draw for me for this movie was just the fact that its set in this like ridiculous world with all these bright beautiful colors and ridiculous action sequences\n",
      "Length: 29\n",
      "Label: [[0.4]]\n",
      "Segment: QN9ZIUWUXsY[0]\n",
      "----------------------------------------\n",
      "Example 1103:\n",
      "Text: and i dont think thats a very good movie\n",
      "Length: 9\n",
      "Label: [[-1.6]]\n",
      "Segment: QN9ZIUWUXsY[1]\n",
      "----------------------------------------\n",
      "Example 1104:\n",
      "Text: but i do think its a very interesting one\n",
      "Length: 9\n",
      "Label: [[1.2]]\n",
      "Segment: QN9ZIUWUXsY[2]\n",
      "----------------------------------------\n",
      "Example 1105:\n",
      "Text: i can tell you that tron legacy is not a good movie\n",
      "Length: 12\n",
      "Label: [[-2.4]]\n",
      "Segment: QN9ZIUWUXsY[3]\n",
      "----------------------------------------\n",
      "Example 1106:\n",
      "Text: but i was still entertained by it\n",
      "Length: 7\n",
      "Label: [[2.6]]\n",
      "Segment: QN9ZIUWUXsY[4]\n",
      "----------------------------------------\n",
      "Example 1107:\n",
      "Text: are these two things possible in the same i really do think so\n",
      "Length: 13\n",
      "Label: [[0.8]]\n",
      "Segment: QN9ZIUWUXsY[5]\n",
      "----------------------------------------\n",
      "Example 1108:\n",
      "Text: tron legacy is a movie where on most counts that i judge movies it kind of fails\n",
      "Length: 17\n",
      "Label: [[-1.]]\n",
      "Segment: QN9ZIUWUXsY[6]\n",
      "----------------------------------------\n",
      "Example 1109:\n",
      "Text: the performances are nah\n",
      "Length: 4\n",
      "Label: [[-1.4]]\n",
      "Segment: QN9ZIUWUXsY[7]\n",
      "----------------------------------------\n",
      "Example 1110:\n",
      "Text: the script can be horrible\n",
      "Length: 5\n",
      "Label: [[-2.]]\n",
      "Segment: QN9ZIUWUXsY[8]\n",
      "----------------------------------------\n",
      "Example 1111:\n",
      "Text: its its a bit of a mixed bag coz there were some very bright moments\n",
      "Length: 15\n",
      "Label: [[0.8]]\n",
      "Segment: QN9ZIUWUXsY[9]\n",
      "----------------------------------------\n",
      "Example 1112:\n",
      "Text: um the direction is a bit its wobbly\n",
      "Length: 8\n",
      "Label: [[-1.2]]\n",
      "Segment: QN9ZIUWUXsY[10]\n",
      "----------------------------------------\n",
      "Example 1113:\n",
      "Text: basically a lot of elements that i could take a movie on its really wobbly\n",
      "Length: 15\n",
      "Label: [[-1.4]]\n",
      "Segment: QN9ZIUWUXsY[11]\n",
      "----------------------------------------\n",
      "Example 1114:\n",
      "Text: but what it lacks in those areas it most makes up for just like sheer visual spectacle\n",
      "Length: 17\n",
      "Label: [[1.8]]\n",
      "Segment: QN9ZIUWUXsY[12]\n",
      "----------------------------------------\n",
      "Example 1115:\n",
      "Text: i mean this movie has the most gorgeous visuals out of any movies since probably me if not prettier\n",
      "Length: 19\n",
      "Label: [[2.6]]\n",
      "Segment: QN9ZIUWUXsY[13]\n",
      "----------------------------------------\n",
      "Example 1116:\n",
      "Text: so many moments in this movie that are just framed and lit so perfectly that so that you just go like kind of huh thats really really cool\n",
      "Length: 28\n",
      "Label: [[2.4]]\n",
      "Segment: QN9ZIUWUXsY[14]\n",
      "----------------------------------------\n",
      "Example 1117:\n",
      "Text: and then take that world that have been set like a crap tunnel of really kinetic really well done action sequences in it and you have tron legacy\n",
      "Length: 28\n",
      "Label: [[2.2]]\n",
      "Segment: QN9ZIUWUXsY[15]\n",
      "----------------------------------------\n",
      "Example 1118:\n",
      "Text: it it doesnt make much sense i know\n",
      "Length: 8\n",
      "Label: [[-1.2]]\n",
      "Segment: QN9ZIUWUXsY[16]\n",
      "----------------------------------------\n",
      "Example 1119:\n",
      "Text: and basically this makes no sense\n",
      "Length: 6\n",
      "Label: [[-1.8]]\n",
      "Segment: QN9ZIUWUXsY[17]\n",
      "----------------------------------------\n",
      "Example 1120:\n",
      "Text: now this movie is just ridiculous and i i thought it was excellent\n",
      "Length: 13\n",
      "Label: [[3.]]\n",
      "Segment: Qr1Ca94K55A[0]\n",
      "----------------------------------------\n",
      "Example 1121:\n",
      "Text: her acting was pretty bad\n",
      "Length: 5\n",
      "Label: [[-2.]]\n",
      "Segment: Qr1Ca94K55A[1]\n",
      "----------------------------------------\n",
      "Example 1122:\n",
      "Text: she didnt really do anything for me\n",
      "Length: 7\n",
      "Label: [[-1.6]]\n",
      "Segment: Qr1Ca94K55A[2]\n",
      "----------------------------------------\n",
      "Example 1123:\n",
      "Text: but the real star that fell out of this movie was william fichtner character or william fichtner\n",
      "Length: 17\n",
      "Label: [[1.4]]\n",
      "Segment: Qr1Ca94K55A[3]\n",
      "----------------------------------------\n",
      "Example 1124:\n",
      "Text: and his acting really good in that movie\n",
      "Length: 8\n",
      "Label: [[-1.6]]\n",
      "Segment: Qr1Ca94K55A[4]\n",
      "----------------------------------------\n",
      "Example 1125:\n",
      "Text: but it made it hysterical and it was just funny with all of these little one liners that he had\n",
      "Length: 20\n",
      "Label: [[2.2]]\n",
      "Segment: Qr1Ca94K55A[5]\n",
      "----------------------------------------\n",
      "Example 1126:\n",
      "Text: and whatever so no im not saying this movie is bad coz its its not\n",
      "Length: 15\n",
      "Label: [[-0.8]]\n",
      "Segment: Qr1Ca94K55A[6]\n",
      "----------------------------------------\n",
      "Example 1127:\n",
      "Text: like i said before it had tacky one liners that were just hysterical\n",
      "Length: 13\n",
      "Label: [[1.6]]\n",
      "Segment: Qr1Ca94K55A[7]\n",
      "----------------------------------------\n",
      "Example 1128:\n",
      "Text: it was it was good\n",
      "Length: 5\n",
      "Label: [[1.8]]\n",
      "Segment: Qr1Ca94K55A[8]\n",
      "----------------------------------------\n",
      "Example 1129:\n",
      "Text: um one of the big things i was disappointed though was i felt that they done a lot more with i\n",
      "Length: 21\n",
      "Label: [[-1.6]]\n",
      "Segment: Qr1Ca94K55A[9]\n",
      "----------------------------------------\n",
      "Example 1130:\n",
      "Text: and some really cool gun fights\n",
      "Length: 6\n",
      "Label: [[2.]]\n",
      "Segment: Qr1Ca94K55A[10]\n",
      "----------------------------------------\n",
      "Example 1131:\n",
      "Text: and i thought it was just gonna be more than that but so i was a little disappointed in that\n",
      "Length: 20\n",
      "Label: [[-1.8]]\n",
      "Segment: Qr1Ca94K55A[11]\n",
      "----------------------------------------\n",
      "Example 1132:\n",
      "Text: um now i dont really recommend this if you go on a date with some girl\n",
      "Length: 16\n",
      "Label: [[-2.]]\n",
      "Segment: Qr1Ca94K55A[12]\n",
      "----------------------------------------\n",
      "Example 1133:\n",
      "Text: um but if youre movie goer like i am i totally recommend seeing this because its just a fun entertaining movie and i think that you will it\n",
      "Length: 28\n",
      "Label: [[2.6]]\n",
      "Segment: Qr1Ca94K55A[13]\n",
      "----------------------------------------\n",
      "Example 1134:\n",
      "Text: i dont really know i dont its so weird\n",
      "Length: 9\n",
      "Label: [[-0.75]]\n",
      "Segment: Sqr0AcuoNnk[0]\n",
      "----------------------------------------\n",
      "Example 1135:\n",
      "Text: i there were times in the movie where i felt really bored\n",
      "Length: 12\n",
      "Label: [[-1.8]]\n",
      "Segment: Sqr0AcuoNnk[1]\n",
      "----------------------------------------\n",
      "Example 1136:\n",
      "Text: and there were times that i thought it was funny\n",
      "Length: 10\n",
      "Label: [[0.6]]\n",
      "Segment: Sqr0AcuoNnk[2]\n",
      "----------------------------------------\n",
      "Example 1137:\n",
      "Text: and there were times that i was just sitting there after they said their jokes and i was like thats not laughing thats not funny\n",
      "Length: 25\n",
      "Label: [[-2.2]]\n",
      "Segment: Sqr0AcuoNnk[3]\n",
      "----------------------------------------\n",
      "Example 1138:\n",
      "Text: i just dont think it was very good\n",
      "Length: 8\n",
      "Label: [[-2.2]]\n",
      "Segment: Sqr0AcuoNnk[4]\n",
      "----------------------------------------\n",
      "Example 1139:\n",
      "Text: and this is the thing friends with benefits and no strings attached they are the same movie different ways of getting to the same point but its the same point\n",
      "Length: 30\n",
      "Label: [[-0.6]]\n",
      "Segment: Sqr0AcuoNnk[5]\n",
      "----------------------------------------\n",
      "Example 1140:\n",
      "Text: so i think that no strings attached was better than friends with benefits\n",
      "Length: 13\n",
      "Label: [[0.8]]\n",
      "Segment: Sqr0AcuoNnk[6]\n",
      "----------------------------------------\n",
      "Example 1141:\n",
      "Text: i was not bored during no strings attached\n",
      "Length: 8\n",
      "Label: [[0.6]]\n",
      "Segment: Sqr0AcuoNnk[7]\n",
      "----------------------------------------\n",
      "Example 1142:\n",
      "Text: i thought it was very funny\n",
      "Length: 6\n",
      "Label: [[2.]]\n",
      "Segment: Sqr0AcuoNnk[8]\n",
      "----------------------------------------\n",
      "Example 1143:\n",
      "Text: um and uh friends with benefits had its moments\n",
      "Length: 9\n",
      "Label: [[0.]]\n",
      "Segment: Sqr0AcuoNnk[9]\n",
      "----------------------------------------\n",
      "Example 1144:\n",
      "Text: had a lot of really bad moments\n",
      "Length: 7\n",
      "Label: [[-1.4]]\n",
      "Segment: Sqr0AcuoNnk[10]\n",
      "----------------------------------------\n",
      "Example 1145:\n",
      "Text: and he is one of my favorite actors ever\n",
      "Length: 9\n",
      "Label: [[2.]]\n",
      "Segment: Sqr0AcuoNnk[11]\n",
      "----------------------------------------\n",
      "Example 1146:\n",
      "Text: he is brilliant there is not a movie that i see him in that i dont end up crying because he is so fantastic and he just breaks your heart whenever he does you know a role that usually his roles do break your heart at some point so definitely did in this movie\n",
      "Length: 54\n",
      "Label: [[2.8]]\n",
      "Segment: Sqr0AcuoNnk[12]\n",
      "----------------------------------------\n",
      "Example 1147:\n",
      "Text: i like up in friends with benefits because of him\n",
      "Length: 10\n",
      "Label: [[1.4]]\n",
      "Segment: Sqr0AcuoNnk[13]\n",
      "----------------------------------------\n",
      "Example 1148:\n",
      "Text: the lady who plays justin sister um i thought she was very good in this movie\n",
      "Length: 16\n",
      "Label: [[2.2]]\n",
      "Segment: Sqr0AcuoNnk[14]\n",
      "----------------------------------------\n",
      "Example 1149:\n",
      "Text: and i thought she was just like really natural and funny\n",
      "Length: 11\n",
      "Label: [[2.]]\n",
      "Segment: Sqr0AcuoNnk[15]\n",
      "----------------------------------------\n",
      "Example 1150:\n",
      "Text: and she looks like renee and helen hunt from a twister movie\n",
      "Length: 12\n",
      "Label: [[-0.2]]\n",
      "Segment: Sqr0AcuoNnk[16]\n",
      "----------------------------------------\n",
      "Example 1151:\n",
      "Text: and she talks like her too\n",
      "Length: 6\n",
      "Label: [[0.2]]\n",
      "Segment: Sqr0AcuoNnk[17]\n",
      "----------------------------------------\n",
      "Example 1152:\n",
      "Text: it was weird\n",
      "Length: 3\n",
      "Label: [[-1.]]\n",
      "Segment: Sqr0AcuoNnk[18]\n",
      "----------------------------------------\n",
      "Example 1153:\n",
      "Text: the whole time i saw her all i thought was helen hunt and renee another\n",
      "Length: 15\n",
      "Label: [[-0.4]]\n",
      "Segment: Sqr0AcuoNnk[19]\n",
      "----------------------------------------\n",
      "Example 1154:\n",
      "Text: another thing was the fact that there was not one healthy relationship or positive good relationship in this whole movie\n",
      "Length: 20\n",
      "Label: [[-2.]]\n",
      "Segment: Sqr0AcuoNnk[20]\n",
      "----------------------------------------\n",
      "Example 1155:\n",
      "Text: but thats kind of depressing\n",
      "Length: 5\n",
      "Label: [[-1.4]]\n",
      "Segment: Sqr0AcuoNnk[21]\n",
      "----------------------------------------\n",
      "Example 1156:\n",
      "Text: which would have been a better name for the movie\n",
      "Length: 10\n",
      "Label: [[-0.2]]\n",
      "Segment: TvyZBvOMOTc[0]\n",
      "----------------------------------------\n",
      "Example 1157:\n",
      "Text: and i really enjoyed it\n",
      "Length: 5\n",
      "Label: [[2.2]]\n",
      "Segment: TvyZBvOMOTc[1]\n",
      "----------------------------------------\n",
      "Example 1158:\n",
      "Text: the countryside which they showed while going across ireland was astoundingly beautiful\n",
      "Length: 12\n",
      "Label: [[2.]]\n",
      "Segment: TvyZBvOMOTc[2]\n",
      "----------------------------------------\n",
      "Example 1159:\n",
      "Text: and in the scene with the destroyed castle it really reminded me why i want to go there so badly\n",
      "Length: 20\n",
      "Label: [[1.4]]\n",
      "Segment: TvyZBvOMOTc[3]\n",
      "----------------------------------------\n",
      "Example 1160:\n",
      "Text: although i enjoyed the movie\n",
      "Length: 5\n",
      "Label: [[1.2]]\n",
      "Segment: TvyZBvOMOTc[4]\n",
      "----------------------------------------\n",
      "Example 1161:\n",
      "Text: if i think about it honestly the plot that great\n",
      "Length: 10\n",
      "Label: [[-1.2]]\n",
      "Segment: TvyZBvOMOTc[5]\n",
      "----------------------------------------\n",
      "Example 1162:\n",
      "Text: its a fun chick flick\n",
      "Length: 5\n",
      "Label: [[1.6]]\n",
      "Segment: TvyZBvOMOTc[6]\n",
      "----------------------------------------\n",
      "Example 1163:\n",
      "Text: but other than that it doesnt really hold up under inspection\n",
      "Length: 11\n",
      "Label: [[-1.6]]\n",
      "Segment: TvyZBvOMOTc[7]\n",
      "----------------------------------------\n",
      "Example 1164:\n",
      "Text: lip smacking all the problems that come to stop them from getting to their destination are although plausible a little weak\n",
      "Length: 21\n",
      "Label: [[-0.8]]\n",
      "Segment: TvyZBvOMOTc[8]\n",
      "----------------------------------------\n",
      "Example 1165:\n",
      "Text: even though the whole movie is based on whether she gets to dublin in time youre never really worried about it because you know she gets there\n",
      "Length: 27\n",
      "Label: [[-0.4]]\n",
      "Segment: TvyZBvOMOTc[9]\n",
      "----------------------------------------\n",
      "Example 1166:\n",
      "Text: lip a lot of this movie brings a cute laugh here and there\n",
      "Length: 13\n",
      "Label: [[1.]]\n",
      "Segment: TvyZBvOMOTc[10]\n",
      "----------------------------------------\n",
      "Example 1167:\n",
      "Text: and both the actors amy adams and matthew goode work well with each other\n",
      "Length: 14\n",
      "Label: [[1.4]]\n",
      "Segment: TvyZBvOMOTc[11]\n",
      "----------------------------------------\n",
      "Example 1168:\n",
      "Text: and seem to be really enjoying themselves the whole way through\n",
      "Length: 11\n",
      "Label: [[1.8]]\n",
      "Segment: TvyZBvOMOTc[12]\n",
      "----------------------------------------\n",
      "Example 1169:\n",
      "Text: even when theyre fighting in the movie though it just seems like its their banter not actual dislike\n",
      "Length: 18\n",
      "Label: [[-0.8]]\n",
      "Segment: TvyZBvOMOTc[13]\n",
      "----------------------------------------\n",
      "Example 1170:\n",
      "Text: all in all if youre looking for a cute romantic comedy with a beautiful setting then this will probably be a good movie for you\n",
      "Length: 25\n",
      "Label: [[2.]]\n",
      "Segment: TvyZBvOMOTc[14]\n",
      "----------------------------------------\n",
      "Example 1171:\n",
      "Text: poop\n",
      "Length: 1\n",
      "Label: [[-2.5]]\n",
      "Segment: VCslbP0mgZI[0]\n",
      "----------------------------------------\n",
      "Example 1172:\n",
      "Text: music in background laughing currently in theatres starring no one youve ever heard of\n",
      "Length: 14\n",
      "Label: [[-0.6]]\n",
      "Segment: VCslbP0mgZI[1]\n",
      "----------------------------------------\n",
      "Example 1173:\n",
      "Text: guardians of owl land whatever that came out and i never saw it\n",
      "Length: 13\n",
      "Label: [[0.]]\n",
      "Segment: VCslbP0mgZI[2]\n",
      "----------------------------------------\n",
      "Example 1174:\n",
      "Text: and this suckers getting this sucker is getting panned like last garbage panned and i wanna say this i did not think it was like last garbage\n",
      "Length: 27\n",
      "Label: [[-2.6]]\n",
      "Segment: VCslbP0mgZI[3]\n",
      "----------------------------------------\n",
      "Example 1175:\n",
      "Text: um why yes stuttering t theres problems with this and i wanna talk about them but you know it looks beautiful\n",
      "Length: 21\n",
      "Label: [[0.4]]\n",
      "Segment: VCslbP0mgZI[4]\n",
      "----------------------------------------\n",
      "Example 1176:\n",
      "Text: there are some really cool uh moments in this\n",
      "Length: 9\n",
      "Label: [[2.]]\n",
      "Segment: VCslbP0mgZI[5]\n",
      "----------------------------------------\n",
      "Example 1177:\n",
      "Text: it actually has some some them thematically it has some cool themes about heroism and about like taking ownership of yourself and things like that which i resonated with and i and which i appreciated\n",
      "Length: 35\n",
      "Label: [[1.8]]\n",
      "Segment: VCslbP0mgZI[6]\n",
      "----------------------------------------\n",
      "Example 1178:\n",
      "Text: but the essential problem with this movie the problem of this movie well maybe this would be the best way to put it um there was a uh a comedian named dave chapelle um and dave chapelle um and another comedian chris rock are um african american and in their comedy they sometimes take on african american culture what they perceive to be african american culture and so they will essentially make fun of black people and the thing with dave chapelle and with chris rock is because theyre black they can kinda do that and theres something about that thats acceptable\n",
      "Length: 102\n",
      "Label: [[-1.6]]\n",
      "Segment: VCslbP0mgZI[7]\n",
      "----------------------------------------\n",
      "Example 1179:\n",
      "Text: um if like me or laughing some other white person or hispanic person or whatever did the same jokes it would not be funny\n",
      "Length: 24\n",
      "Label: [[-2.]]\n",
      "Segment: VCslbP0mgZI[8]\n",
      "----------------------------------------\n",
      "Example 1180:\n",
      "Text: it would be completely inappropriate in fact it would be racist\n",
      "Length: 11\n",
      "Label: [[-2.2]]\n",
      "Segment: VCslbP0mgZI[9]\n",
      "----------------------------------------\n",
      "Example 1181:\n",
      "Text: so zach snyder here is making a movie thats ostensibly about female empowerment but its a movie about female empowerment which includes a lot of clearing throat slapping that includes a lot of women in that includes a lot of violence done against women and ultimately in which most of the women end up completely clapping\n",
      "Length: 56\n",
      "Label: [[-2.6]]\n",
      "Segment: VCslbP0mgZI[10]\n",
      "----------------------------------------\n",
      "Example 1182:\n",
      "Text: clapping laughing so okay if zach snyder were a woman i would say okay making a comment about the way women cant be empowered in male dominated societies in the way men um distract and and hurt and damage women and prevent them from asserting who they really are\n",
      "Length: 49\n",
      "Label: [[-0.4]]\n",
      "Segment: VCslbP0mgZI[11]\n",
      "----------------------------------------\n",
      "Example 1183:\n",
      "Text: i could kinda see that in a sort of chris rock dave chapelle way\n",
      "Length: 14\n",
      "Label: [[1.]]\n",
      "Segment: VCslbP0mgZI[12]\n",
      "----------------------------------------\n",
      "Example 1184:\n",
      "Text: but zach snyder is a guy and because of that this stuff kinda ends up looking like the sh he man woman haters club\n",
      "Length: 24\n",
      "Label: [[-1.6]]\n",
      "Segment: VCslbP0mgZI[13]\n",
      "----------------------------------------\n",
      "Example 1185:\n",
      "Text: so if i give zach snyder the benefit of the doubt this is a movie that looks great has some bad acting\n",
      "Length: 22\n",
      "Label: [[0.4]]\n",
      "Segment: VCslbP0mgZI[14]\n",
      "----------------------------------------\n",
      "Example 1186:\n",
      "Text: and has way too much violence against women\n",
      "Length: 8\n",
      "Label: [[-1.8]]\n",
      "Segment: VCslbP0mgZI[15]\n",
      "----------------------------------------\n",
      "Example 1187:\n",
      "Text: if i dont give zach snyder the benefit of the\n",
      "Length: 10\n",
      "Label: [[-0.6]]\n",
      "Segment: VCslbP0mgZI[16]\n",
      "----------------------------------------\n",
      "Example 1188:\n",
      "Text: and this is the one that i can say was disappointed\n",
      "Length: 11\n",
      "Label: [[-2.2]]\n",
      "Segment: VbQk4H8hgr0[0]\n",
      "----------------------------------------\n",
      "Example 1189:\n",
      "Text: i love the first and the second and\n",
      "Length: 8\n",
      "Label: [[2.]]\n",
      "Segment: VbQk4H8hgr0[1]\n",
      "----------------------------------------\n",
      "Example 1190:\n",
      "Text: and i was really hoping that this one be just as good\n",
      "Length: 12\n",
      "Label: [[-0.8]]\n",
      "Segment: VbQk4H8hgr0[2]\n",
      "----------------------------------------\n",
      "Example 1191:\n",
      "Text: and it just that it anything new to offer\n",
      "Length: 9\n",
      "Label: [[-2.2]]\n",
      "Segment: VbQk4H8hgr0[3]\n",
      "----------------------------------------\n",
      "Example 1192:\n",
      "Text: i was really disappointed with that\n",
      "Length: 6\n",
      "Label: [[-2.2]]\n",
      "Segment: VbQk4H8hgr0[4]\n",
      "----------------------------------------\n",
      "Example 1193:\n",
      "Text: i mean i went in there hoping to see something original and funny like the first two\n",
      "Length: 17\n",
      "Label: [[-1.8]]\n",
      "Segment: VbQk4H8hgr0[5]\n",
      "----------------------------------------\n",
      "Example 1194:\n",
      "Text: and it offered nothing of the such\n",
      "Length: 7\n",
      "Label: [[-2.]]\n",
      "Segment: VbQk4H8hgr0[6]\n",
      "----------------------------------------\n",
      "Example 1195:\n",
      "Text: it funny\n",
      "Length: 2\n",
      "Label: [[-0.4]]\n",
      "Segment: VbQk4H8hgr0[7]\n",
      "----------------------------------------\n",
      "Example 1196:\n",
      "Text: there was a few jokes ok yeah make you giggle or something\n",
      "Length: 12\n",
      "Label: [[0.6]]\n",
      "Segment: VbQk4H8hgr0[8]\n",
      "----------------------------------------\n",
      "Example 1197:\n",
      "Text: but thats nothing major\n",
      "Length: 4\n",
      "Label: [[-0.25]]\n",
      "Segment: VbQk4H8hgr0[9]\n",
      "----------------------------------------\n",
      "Example 1198:\n",
      "Text: nothing really that funny\n",
      "Length: 4\n",
      "Label: [[-1.]]\n",
      "Segment: VbQk4H8hgr0[10]\n",
      "----------------------------------------\n",
      "Example 1199:\n",
      "Text: or anything original\n",
      "Length: 3\n",
      "Label: [[-1.6]]\n",
      "Segment: VbQk4H8hgr0[11]\n",
      "----------------------------------------\n",
      "Example 1200:\n",
      "Text: the characters are all the same\n",
      "Length: 6\n",
      "Label: [[-1.6]]\n",
      "Segment: VbQk4H8hgr0[12]\n",
      "----------------------------------------\n",
      "Example 1201:\n",
      "Text: and not even as good as the first two movies\n",
      "Length: 10\n",
      "Label: [[-1.2]]\n",
      "Segment: VbQk4H8hgr0[13]\n",
      "----------------------------------------\n",
      "Example 1202:\n",
      "Text: and i loved puss in boots\n",
      "Length: 6\n",
      "Label: [[2.]]\n",
      "Segment: VbQk4H8hgr0[14]\n",
      "----------------------------------------\n",
      "Example 1203:\n",
      "Text: and he even that great this time around\n",
      "Length: 8\n",
      "Label: [[-2.]]\n",
      "Segment: VbQk4H8hgr0[15]\n",
      "----------------------------------------\n",
      "Example 1204:\n",
      "Text: the donkey and puss in boots rivalry thats going on it just it as funny the third time around\n",
      "Length: 19\n",
      "Label: [[-1.8]]\n",
      "Segment: VbQk4H8hgr0[16]\n",
      "----------------------------------------\n",
      "Example 1205:\n",
      "Text: and there was nothing new to offer\n",
      "Length: 7\n",
      "Label: [[-2.]]\n",
      "Segment: VbQk4H8hgr0[17]\n",
      "----------------------------------------\n",
      "Example 1206:\n",
      "Text: plain and simply it was dull for me\n",
      "Length: 8\n",
      "Label: [[-2.]]\n",
      "Segment: VbQk4H8hgr0[18]\n",
      "----------------------------------------\n",
      "Example 1207:\n",
      "Text: it been so much better i i i saw it being so much better in my head but it just it\n",
      "Length: 21\n",
      "Label: [[-2.]]\n",
      "Segment: VbQk4H8hgr0[19]\n",
      "----------------------------------------\n",
      "Example 1208:\n",
      "Text: it disappointed me highly\n",
      "Length: 4\n",
      "Label: [[-2.2]]\n",
      "Segment: VbQk4H8hgr0[20]\n",
      "----------------------------------------\n",
      "Example 1209:\n",
      "Text: and i was just sort of discouraged after seeing the movie\n",
      "Length: 11\n",
      "Label: [[-2.6]]\n",
      "Segment: VbQk4H8hgr0[21]\n",
      "----------------------------------------\n",
      "Example 1210:\n",
      "Text: and im wish i had my money back\n",
      "Length: 8\n",
      "Label: [[-3.]]\n",
      "Segment: VbQk4H8hgr0[22]\n",
      "----------------------------------------\n",
      "Example 1211:\n",
      "Text: um it was a waste of my time\n",
      "Length: 8\n",
      "Label: [[-2.8]]\n",
      "Segment: VbQk4H8hgr0[23]\n",
      "----------------------------------------\n",
      "Example 1212:\n",
      "Text: and i dont suggest anyone go see it\n",
      "Length: 8\n",
      "Label: [[-2.2]]\n",
      "Segment: VbQk4H8hgr0[24]\n",
      "----------------------------------------\n",
      "Example 1213:\n",
      "Text: if youre hoping to if you have to have if you have kids and youre forced to go which you probably will if you have kids you know put up with it as a parent\n",
      "Length: 35\n",
      "Label: [[-1.6]]\n",
      "Segment: VbQk4H8hgr0[25]\n",
      "----------------------------------------\n",
      "Example 1214:\n",
      "Text: but on your own dont go see it\n",
      "Length: 8\n",
      "Label: [[-1.8]]\n",
      "Segment: VbQk4H8hgr0[26]\n",
      "----------------------------------------\n",
      "Example 1215:\n",
      "Text: its not really that great\n",
      "Length: 5\n",
      "Label: [[-2.]]\n",
      "Segment: VbQk4H8hgr0[27]\n",
      "----------------------------------------\n",
      "Example 1216:\n",
      "Text: everyone is split on this one just as they were on spiderman\n",
      "Length: 12\n",
      "Label: [[-0.4]]\n",
      "Segment: VbQk4H8hgr0[28]\n",
      "----------------------------------------\n",
      "Example 1217:\n",
      "Text: and just they are with all the other sequels that are coming out an this one\n",
      "Length: 16\n",
      "Label: [[0.]]\n",
      "Segment: VbQk4H8hgr0[29]\n",
      "----------------------------------------\n",
      "Example 1218:\n",
      "Text: i have to agree on the negative side it was not great\n",
      "Length: 12\n",
      "Label: [[-1.4]]\n",
      "Segment: VbQk4H8hgr0[30]\n",
      "----------------------------------------\n",
      "Example 1219:\n",
      "Text: it even remotely good\n",
      "Length: 4\n",
      "Label: [[-2.8]]\n",
      "Segment: VbQk4H8hgr0[31]\n",
      "----------------------------------------\n",
      "Example 1220:\n",
      "Text: i mean theres a few moments yeah that are original and funny\n",
      "Length: 12\n",
      "Label: [[0.4]]\n",
      "Segment: VbQk4H8hgr0[32]\n",
      "----------------------------------------\n",
      "Example 1221:\n",
      "Text: and theres a ne an introduction of a new character justine character already in the film\n",
      "Length: 16\n",
      "Label: [[-0.2]]\n",
      "Segment: VbQk4H8hgr0[33]\n",
      "----------------------------------------\n",
      "Example 1222:\n",
      "Text: but they didnt even give him that much to do the he had only few minor lines\n",
      "Length: 17\n",
      "Label: [[-1.8]]\n",
      "Segment: VbQk4H8hgr0[34]\n",
      "----------------------------------------\n",
      "Example 1223:\n",
      "Text: and none of them were really that great i mean stands out in your mind\n",
      "Length: 15\n",
      "Label: [[-1.4]]\n",
      "Segment: VbQk4H8hgr0[35]\n",
      "----------------------------------------\n",
      "Example 1224:\n",
      "Text: so the addition of this character was pretty pointless\n",
      "Length: 9\n",
      "Label: [[-1.8]]\n",
      "Segment: VbQk4H8hgr0[36]\n",
      "----------------------------------------\n",
      "Example 1225:\n",
      "Text: i mean its to the story\n",
      "Length: 6\n",
      "Label: [[-0.2]]\n",
      "Segment: VbQk4H8hgr0[37]\n",
      "----------------------------------------\n",
      "Example 1226:\n",
      "Text: but i still find it pointless in the end of the movie\n",
      "Length: 12\n",
      "Label: [[-2.]]\n",
      "Segment: VbQk4H8hgr0[38]\n",
      "----------------------------------------\n",
      "Example 1227:\n",
      "Text: and the characters just the same as the first two that i fell in love with them\n",
      "Length: 17\n",
      "Label: [[-1.2]]\n",
      "Segment: VbQk4H8hgr0[39]\n",
      "----------------------------------------\n",
      "Example 1228:\n",
      "Text: it just kind of made me wanna really walk out of the theater\n",
      "Length: 13\n",
      "Label: [[-2.6]]\n",
      "Segment: VbQk4H8hgr0[40]\n",
      "----------------------------------------\n",
      "Example 1229:\n",
      "Text: so that just pissed me off more\n",
      "Length: 7\n",
      "Label: [[-2.4]]\n",
      "Segment: VbQk4H8hgr0[41]\n",
      "----------------------------------------\n",
      "Example 1230:\n",
      "Text: but really i just walked up and left at that moment\n",
      "Length: 11\n",
      "Label: [[-2.4]]\n",
      "Segment: VbQk4H8hgr0[42]\n",
      "----------------------------------------\n",
      "Example 1231:\n",
      "Text: it was boring\n",
      "Length: 3\n",
      "Label: [[-2.]]\n",
      "Segment: VbQk4H8hgr0[43]\n",
      "----------------------------------------\n",
      "Example 1232:\n",
      "Text: and not at all original in my opinion\n",
      "Length: 8\n",
      "Label: [[-2.2]]\n",
      "Segment: VbQk4H8hgr0[44]\n",
      "----------------------------------------\n",
      "Example 1233:\n",
      "Text: it been so much better\n",
      "Length: 5\n",
      "Label: [[-1.8]]\n",
      "Segment: VbQk4H8hgr0[45]\n",
      "----------------------------------------\n",
      "Example 1234:\n",
      "Text: than the second sequel was really great\n",
      "Length: 7\n",
      "Label: [[2.2]]\n",
      "Segment: VbQk4H8hgr0[46]\n",
      "----------------------------------------\n",
      "Example 1235:\n",
      "Text: and i loved it and this one just was a flat of disappointments\n",
      "Length: 13\n",
      "Label: [[-2.2]]\n",
      "Segment: VbQk4H8hgr0[47]\n",
      "----------------------------------------\n",
      "Example 1236:\n",
      "Text: so im gonna rate this one two stars\n",
      "Length: 8\n",
      "Label: [[-1.8]]\n",
      "Segment: VbQk4H8hgr0[48]\n",
      "----------------------------------------\n",
      "Example 1237:\n",
      "Text: it really be one\n",
      "Length: 4\n",
      "Label: [[-1.]]\n",
      "Segment: VbQk4H8hgr0[49]\n",
      "----------------------------------------\n",
      "Example 1238:\n",
      "Text: but im gonna give it a two to be fair\n",
      "Length: 10\n",
      "Label: [[-1.2]]\n",
      "Segment: VbQk4H8hgr0[50]\n",
      "----------------------------------------\n",
      "Example 1239:\n",
      "Text: because the movie did have some points when i was laughing\n",
      "Length: 11\n",
      "Label: [[0.4]]\n",
      "Segment: VbQk4H8hgr0[51]\n",
      "----------------------------------------\n",
      "Example 1240:\n",
      "Text: but very few\n",
      "Length: 3\n",
      "Label: [[-0.8]]\n",
      "Segment: VbQk4H8hgr0[52]\n",
      "----------------------------------------\n",
      "Example 1241:\n",
      "Text: and it worth it in my opinion to go see it\n",
      "Length: 11\n",
      "Label: [[-2.4]]\n",
      "Segment: VbQk4H8hgr0[53]\n",
      "----------------------------------------\n",
      "Example 1242:\n",
      "Text: so i\n",
      "Length: 2\n",
      "Label: [[0.2]]\n",
      "Segment: VbQk4H8hgr0[54]\n",
      "----------------------------------------\n",
      "Example 1243:\n",
      "Text: well he plays that well so hes a good villain\n",
      "Length: 10\n",
      "Label: [[1.4]]\n",
      "Segment: Vj1wYRQjB-o[0]\n",
      "----------------------------------------\n",
      "Example 1244:\n",
      "Text: he also has some really cool guns so that its like a desert eagle but it has to barrels to it\n",
      "Length: 21\n",
      "Label: [[2.2]]\n",
      "Segment: Vj1wYRQjB-o[1]\n",
      "----------------------------------------\n",
      "Example 1245:\n",
      "Text: its pretty pretty scary looking\n",
      "Length: 5\n",
      "Label: [[-0.8]]\n",
      "Segment: Vj1wYRQjB-o[2]\n",
      "----------------------------------------\n",
      "Example 1246:\n",
      "Text: i wouldnt want that pointed at me\n",
      "Length: 7\n",
      "Label: [[-0.8]]\n",
      "Segment: Vj1wYRQjB-o[3]\n",
      "----------------------------------------\n",
      "Example 1247:\n",
      "Text: and i who would i mean\n",
      "Length: 6\n",
      "Label: [[0.5]]\n",
      "Segment: Vj1wYRQjB-o[4]\n",
      "----------------------------------------\n",
      "Example 1248:\n",
      "Text: um like i said i thought the movie was great\n",
      "Length: 10\n",
      "Label: [[2.2]]\n",
      "Segment: Vj1wYRQjB-o[5]\n",
      "----------------------------------------\n",
      "Example 1249:\n",
      "Text: the action they do have is really well done\n",
      "Length: 9\n",
      "Label: [[1.8]]\n",
      "Segment: Vj1wYRQjB-o[6]\n",
      "----------------------------------------\n",
      "Example 1250:\n",
      "Text: um they did a good job with car\n",
      "Length: 8\n",
      "Label: [[1.6]]\n",
      "Segment: Vj1wYRQjB-o[7]\n",
      "----------------------------------------\n",
      "Example 1251:\n",
      "Text: they did a good job with the fight scenes\n",
      "Length: 9\n",
      "Label: [[2.]]\n",
      "Segment: Vj1wYRQjB-o[8]\n",
      "----------------------------------------\n",
      "Example 1252:\n",
      "Text: now was just fantastic\n",
      "Length: 4\n",
      "Label: [[2.8]]\n",
      "Segment: W8NXH0Djyww[0]\n",
      "----------------------------------------\n",
      "Example 1253:\n",
      "Text: surprised me\n",
      "Length: 2\n",
      "Label: [[-0.25]]\n",
      "Segment: W8NXH0Djyww[1]\n",
      "----------------------------------------\n",
      "Example 1254:\n",
      "Text: uh it was so much better than i thought it was going to be\n",
      "Length: 14\n",
      "Label: [[2.4]]\n",
      "Segment: W8NXH0Djyww[2]\n",
      "----------------------------------------\n",
      "Example 1255:\n",
      "Text: and this town was like from a good old western\n",
      "Length: 10\n",
      "Label: [[0.6]]\n",
      "Segment: W8NXH0Djyww[3]\n",
      "----------------------------------------\n",
      "Example 1256:\n",
      "Text: it had all this stereotypical traits of a western town\n",
      "Length: 10\n",
      "Label: [[-0.8]]\n",
      "Segment: W8NXH0Djyww[4]\n",
      "----------------------------------------\n",
      "Example 1257:\n",
      "Text: i but it was it was cool\n",
      "Length: 7\n",
      "Label: [[1.6]]\n",
      "Segment: W8NXH0Djyww[5]\n",
      "----------------------------------------\n",
      "Example 1258:\n",
      "Text: it was a great movie\n",
      "Length: 5\n",
      "Label: [[2.]]\n",
      "Segment: W8NXH0Djyww[6]\n",
      "----------------------------------------\n",
      "Example 1259:\n",
      "Text: and now what i loved about this movie was like the supporting characters in this movie\n",
      "Length: 16\n",
      "Label: [[2.2]]\n",
      "Segment: W8NXH0Djyww[7]\n",
      "----------------------------------------\n",
      "Example 1260:\n",
      "Text: the all the animals were just so funny\n",
      "Length: 8\n",
      "Label: [[2.]]\n",
      "Segment: W8NXH0Djyww[8]\n",
      "----------------------------------------\n",
      "Example 1261:\n",
      "Text: um they all played off each other\n",
      "Length: 7\n",
      "Label: [[0.8]]\n",
      "Segment: W8NXH0Djyww[9]\n",
      "----------------------------------------\n",
      "Example 1262:\n",
      "Text: theyre like the dumb kinda cowboys that dont know what theyre doing always asking dumb questions staying saying stupid shit\n",
      "Length: 20\n",
      "Label: [[-2.2]]\n",
      "Segment: W8NXH0Djyww[10]\n",
      "----------------------------------------\n",
      "Example 1263:\n",
      "Text: and it was just oh it was hysterical\n",
      "Length: 8\n",
      "Label: [[2.4]]\n",
      "Segment: W8NXH0Djyww[11]\n",
      "----------------------------------------\n",
      "Example 1264:\n",
      "Text: and the stuff he said was just it was just so funny\n",
      "Length: 12\n",
      "Label: [[2.2]]\n",
      "Segment: W8NXH0Djyww[12]\n",
      "----------------------------------------\n",
      "Example 1265:\n",
      "Text: and he did a wonderful job\n",
      "Length: 6\n",
      "Label: [[2.2]]\n",
      "Segment: W8NXH0Djyww[13]\n",
      "----------------------------------------\n",
      "Example 1266:\n",
      "Text: all the cinematography in this movie was great\n",
      "Length: 8\n",
      "Label: [[2.4]]\n",
      "Segment: W8NXH0Djyww[14]\n",
      "----------------------------------------\n",
      "Example 1267:\n",
      "Text: like all the sunsets and all the landscapes of the films they just looked so realistic in every almost every scene\n",
      "Length: 21\n",
      "Label: [[2.4]]\n",
      "Segment: W8NXH0Djyww[15]\n",
      "----------------------------------------\n",
      "Example 1268:\n",
      "Text: um like this movie had great action sequences\n",
      "Length: 8\n",
      "Label: [[1.]]\n",
      "Segment: W8NXH0Djyww[16]\n",
      "----------------------------------------\n",
      "Example 1269:\n",
      "Text: this aw this one really cool action sequences where like this ronny uh johnny posse they were getting chased by all these like possums\n",
      "Length: 24\n",
      "Label: [[2.2]]\n",
      "Segment: W8NXH0Djyww[17]\n",
      "----------------------------------------\n",
      "Example 1270:\n",
      "Text: or nah i wouldnt say possums but prairie dogs\n",
      "Length: 9\n",
      "Label: [[-0.75]]\n",
      "Segment: W8NXH0Djyww[18]\n",
      "----------------------------------------\n",
      "Example 1271:\n",
      "Text: im not even sure what they were\n",
      "Length: 7\n",
      "Label: [[-1.]]\n",
      "Segment: W8NXH0Djyww[19]\n",
      "----------------------------------------\n",
      "Example 1272:\n",
      "Text: it was just so cool\n",
      "Length: 5\n",
      "Label: [[2.6]]\n",
      "Segment: W8NXH0Djyww[20]\n",
      "----------------------------------------\n",
      "Example 1273:\n",
      "Text: like a covered wagon horse kinda cowboy chase sequence\n",
      "Length: 9\n",
      "Label: [[-0.2]]\n",
      "Segment: W8NXH0Djyww[21]\n",
      "----------------------------------------\n",
      "Example 1274:\n",
      "Text: oh it was so cool\n",
      "Length: 5\n",
      "Label: [[2.2]]\n",
      "Segment: W8NXH0Djyww[22]\n",
      "----------------------------------------\n",
      "Example 1275:\n",
      "Text: um but this movie it had everything humor romance action\n",
      "Length: 10\n",
      "Label: [[2.6]]\n",
      "Segment: W8NXH0Djyww[23]\n",
      "----------------------------------------\n",
      "Example 1276:\n",
      "Text: of course um it was just it was fun it was a fun entertaining movie\n",
      "Length: 15\n",
      "Label: [[1.8]]\n",
      "Segment: W8NXH0Djyww[24]\n",
      "----------------------------------------\n",
      "Example 1277:\n",
      "Text: uh it was good for the entire family\n",
      "Length: 8\n",
      "Label: [[2.]]\n",
      "Segment: W8NXH0Djyww[25]\n",
      "----------------------------------------\n",
      "Example 1278:\n",
      "Text: um definitely recommend checking seeing this uh checking this movie out\n",
      "Length: 11\n",
      "Label: [[1.4]]\n",
      "Segment: W8NXH0Djyww[26]\n",
      "----------------------------------------\n",
      "Example 1279:\n",
      "Text: uh i rated it four out of five stars\n",
      "Length: 9\n",
      "Label: [[1.8]]\n",
      "Segment: W8NXH0Djyww[27]\n",
      "----------------------------------------\n",
      "Example 1280:\n",
      "Text: um the one thing i didnt like about this movie was they brought the main uh the bad character i should say in kinda late\n",
      "Length: 25\n",
      "Label: [[-1.5]]\n",
      "Segment: W8NXH0Djyww[28]\n",
      "----------------------------------------\n",
      "Example 1281:\n",
      "Text: but that didnt really matter\n",
      "Length: 5\n",
      "Label: [[-0.4]]\n",
      "Segment: W8NXH0Djyww[29]\n",
      "----------------------------------------\n",
      "Example 1282:\n",
      "Text: um everything else held up its own\n",
      "Length: 7\n",
      "Label: [[0.6]]\n",
      "Segment: W8NXH0Djyww[30]\n",
      "----------------------------------------\n",
      "Example 1283:\n",
      "Text: um definitely check out this movie uh in a theatre near you\n",
      "Length: 12\n",
      "Label: [[2.]]\n",
      "Segment: W8NXH0Djyww[31]\n",
      "----------------------------------------\n",
      "Maximum length: 102\n",
      "Minimum length: 1\n",
      "Example with length 1: 1171\n"
     ]
    }
   ],
   "source": [
    "# Reverse mapping from word IDs to words\n",
    "id2word = {v: k for k, v in word2id.items()}\n",
    "\n",
    "\n",
    "# Specify how many examples to examine\n",
    "num_examples = len(train)  # Ensure we don't exceed the dataset size\n",
    "\n",
    "\n",
    "max_length = 0\n",
    "min_length = float('inf')\n",
    "\n",
    "for idx in range(num_examples):\n",
    "    # Convert word IDs to words\n",
    "    words = ' '.join(map(lambda x: id2word[x], train[idx][0][0].tolist()))\n",
    "    label = train[idx][1]  # Label\n",
    "    segment = train[idx][2]  # Segment\n",
    "\n",
    "    length = len(words.split())  # Word count, not character count\n",
    "\n",
    "    # Track the max and min lengths\n",
    "    max_length = max(max_length, length)\n",
    "    min_length = min(min_length, length)\n",
    "\n",
    "    # Display the information\n",
    "    print(f\"Example {idx+1}:\")\n",
    "    print(f\"Text: {words}\")\n",
    "    print(f\"Length: {length}\")\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"Segment: {segment}\")\n",
    "    print(\"-\" * 40)  # Separator for readability\n",
    "    if length==1:\n",
    "        example = idx+1\n",
    "\n",
    "# After the loop, print the max and min lengths\n",
    "print(f\"Maximum length: {max_length}\")\n",
    "print(f\"Minimum length: {min_length}\")\n",
    "print(f\"Example with length 1: {example}\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T15:06:57.698910600Z",
     "start_time": "2024-12-02T15:06:57.577477500Z"
    }
   },
   "execution_count": 204
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Reverse mapping from word IDs to words\n",
    "id2word = {v: k for k, v in word2id.items()}\n",
    "\n",
    "# Specify how many examples to examine\n",
    "num_examples = len(dev)  # Ensure we don't exceed the dataset size\n",
    "\n",
    "max_length = 0\n",
    "min_length = float('inf')\n",
    "\n",
    "for idx in range(num_examples):\n",
    "    # Convert word IDs to words\n",
    "    words = ' '.join(map(lambda x: id2word[x], dev[idx][0][0].tolist()))\n",
    "    label = dev[idx][1]  # Label\n",
    "    segment = dev[idx][2]  # Segment\n",
    "\n",
    "    # Calculate the length of the words (number of words)\n",
    "    length = len(words.split())  # Word count, not character count\n",
    "\n",
    "    # Track the max and min lengths\n",
    "    max_length = max(max_length, length)\n",
    "    min_length = min(min_length, length)\n",
    "\n",
    "    # Display the information\n",
    "    print(f\"Example {idx+1}:\")\n",
    "    print(f\"Text: {words}\")\n",
    "    print(f\"Length: {length}\")\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"Segment: {segment}\")\n",
    "    print(\"-\" * 40)  # Separator for readability\n",
    "\n",
    "# After the loop, print the max and min lengths\n",
    "print(f\"Maximum length: {max_length}\")\n",
    "print(f\"Minimum length: {min_length}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-02T19:13:09.388832500Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Reverse mapping from word IDs to words\n",
    "id2word = {v: k for k, v in word2id.items()}\n",
    "\n",
    "# Specify how many examples to examine\n",
    "num_examples = len(test)  # Ensure we don't exceed the dataset size\n",
    "\n",
    "max_length = 0\n",
    "min_length = float('inf')\n",
    "\n",
    "\n",
    "for idx in range(num_examples):\n",
    "    # Convert word IDs to words\n",
    "    words = ' '.join(map(lambda x: id2word[x], test[idx][0][0].tolist()))\n",
    "    label = test[idx][1]  # Label\n",
    "    segment = test[idx][2]  # Segment\n",
    "\n",
    "    length = len(words.split())  # Word count, not character count\n",
    "\n",
    "    # Track the max and min lengths\n",
    "    max_length = max(max_length, length)\n",
    "    min_length = min(min_length, length)\n",
    "\n",
    "    # Display the information\n",
    "    print(f\"Example {idx+1}:\")\n",
    "    print(f\"Text: {words}\")\n",
    "    print(f\"Length: {length}\")\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"Segment: {segment}\")\n",
    "    print(\"-\" * 40)  # Separator for readability\n",
    "    if length == 1:\n",
    "        example = idx+1\n",
    "\n",
    "# After the loop, print the max and min lengths\n",
    "print(f\"Maximum length: {max_length}\")\n",
    "print(f\"Minimum length: {min_length}\")\n",
    "print(f\"example with length 1: {example}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-02T19:13:09.393217100Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a multimodal model\n",
    "\n",
    "Here we show a simple example of late-fusion LSTM. Late-fusion refers to combining the features from different modalities at the final prediction stage, without introducing any interactions between them before that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-02T19:13:09.397408Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's define a simple model that can deal with multimodal variable length sequence\n",
    "class LFLSTM(nn.Module):\n",
    "    def __init__(self, input_sizes, hidden_sizes, fc1_size, output_size, dropout_rate):\n",
    "        super(LFLSTM, self).__init__()\n",
    "        self.input_size = input_sizes\n",
    "        self.hidden_size = hidden_sizes\n",
    "        self.fc1_size = fc1_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # defining modules - two layer bidirectional LSTM with layer norm in between\n",
    "        self.embed = nn.Embedding(len(word2id), input_sizes[0])\n",
    "        self.trnn1 = nn.LSTM(input_sizes[0], hidden_sizes[0], bidirectional=True)\n",
    "        self.trnn2 = nn.LSTM(2*hidden_sizes[0], hidden_sizes[0], bidirectional=True)\n",
    "        \n",
    "        self.vrnn1 = nn.LSTM(input_sizes[1], hidden_sizes[1], bidirectional=True)\n",
    "        self.vrnn2 = nn.LSTM(2*hidden_sizes[1], hidden_sizes[1], bidirectional=True)\n",
    "        \n",
    "        self.arnn1 = nn.LSTM(input_sizes[2], hidden_sizes[2], bidirectional=True)\n",
    "        self.arnn2 = nn.LSTM(2*hidden_sizes[2], hidden_sizes[2], bidirectional=True)\n",
    "\n",
    "        self.fc1 = nn.Linear(sum(hidden_sizes)*4, fc1_size)\n",
    "        self.fc2 = nn.Linear(fc1_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.tlayer_norm = nn.LayerNorm((hidden_sizes[0]*2,))\n",
    "        self.vlayer_norm = nn.LayerNorm((hidden_sizes[1]*2,))\n",
    "        self.alayer_norm = nn.LayerNorm((hidden_sizes[2]*2,))\n",
    "        self.bn = nn.BatchNorm1d(sum(hidden_sizes)*4)\n",
    "\n",
    "        \n",
    "    def extract_features(self, sequence, lengths, rnn1, rnn2, layer_norm):\n",
    "        packed_sequence = pack_padded_sequence(sequence, lengths)\n",
    "        packed_h1, (final_h1, _) = rnn1(packed_sequence)\n",
    "        padded_h1, _ = pad_packed_sequence(packed_h1)\n",
    "        normed_h1 = layer_norm(padded_h1)\n",
    "        packed_normed_h1 = pack_padded_sequence(normed_h1, lengths)\n",
    "        _, (final_h2, _) = rnn2(packed_normed_h1)\n",
    "        return final_h1, final_h2\n",
    "\n",
    "        \n",
    "    def fusion(self, sentences, visual, acoustic, lengths):\n",
    "        batch_size = lengths.size(0)\n",
    "        sentences = self.embed(sentences)\n",
    "        \n",
    "        # extract features from text modality\n",
    "        final_h1t, final_h2t = self.extract_features(sentences, lengths, self.trnn1, self.trnn2, self.tlayer_norm)\n",
    "        \n",
    "        # extract features from visual modality\n",
    "        final_h1v, final_h2v = self.extract_features(visual, lengths, self.vrnn1, self.vrnn2, self.vlayer_norm)\n",
    "        \n",
    "        # extract features from acoustic modality\n",
    "        final_h1a, final_h2a = self.extract_features(acoustic, lengths, self.arnn1, self.arnn2, self.alayer_norm)\n",
    "\n",
    "        \n",
    "        # simple late fusion -- concatenation + normalization\n",
    "        h = torch.cat((final_h1t, final_h2t, final_h1v, final_h2v, final_h1a, final_h2a),\n",
    "                       dim=2).permute(1, 0, 2).contiguous().view(batch_size, -1)\n",
    "        return self.bn(h)\n",
    "\n",
    "    def forward(self, sentences, visual, acoustic, lengths):\n",
    "        batch_size = lengths.size(0)\n",
    "        h = self.fusion(sentences, visual, acoustic, lengths)\n",
    "        h = self.fc1(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.relu(h)\n",
    "        o = self.fc2(h)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained embeddings\n",
    "\n",
    "We define a function for loading pretrained word embeddings stored in GloVe-style file. Contextualized embeddings obviously cannot be stored and loaded this way, though."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from tqdm import tqdm_notebook"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-02T19:13:09.398819600Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-02T19:13:09.401064100Z"
    }
   },
   "outputs": [],
   "source": [
    "# define a function that loads data from GloVe-like embedding files\n",
    "\n",
    "# 2196017 is the vocab size of GloVe here.\n",
    "\n",
    "def load_emb(w2i, path_to_embedding, embedding_size=300, embedding_vocab=2196017, init_emb=None):\n",
    "    if init_emb is None:\n",
    "        emb_mat = np.random.randn(len(w2i), embedding_size)\n",
    "    else:\n",
    "        emb_mat = init_emb\n",
    "    f = open(path_to_embedding, 'r', encoding='utf-8', errors='replace')\n",
    "    found = 0\n",
    "    for line in tqdm_notebook(f, total=embedding_vocab):\n",
    "        try:\n",
    "            content = line.strip().split()\n",
    "            vector = np.asarray(list(map(lambda x: float(x), content[-300:])))\n",
    "            word = ' '.join(content[:-300])\n",
    "            if word in w2i:\n",
    "                idx = w2i[word]\n",
    "                emb_mat[idx, :] = vector\n",
    "                found += 1\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping invalid line: {line}\")\n",
    "        \n",
    "    print(f\"Found {found} words in the embedding file.\")\n",
    "    return torch.tensor(emb_mat).float()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model\n",
    "\n",
    "Next we train a model. We use Adam with gradient clipping and weight decay for training, and our loss here is Mean Absolute Error (MOSI is a regression dataset). We exclude the embeddings from trainable computation graph to prevent overfitting. We also apply a early-stopping scheme with learning rate annealing based on validation loss."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "from torch.optim import Adam, SGD\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-02T19:13:09.404010400Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory is readable\n",
      "Directory is writable\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = 'C:\\\\Users\\\\Viki\\\\Documents\\\\Thesis\\\\tryout3\\\\data'\n",
    "if os.access(path, os.R_OK):\n",
    "    print(\"Directory is readable\")\n",
    "else:\n",
    "    print(\"No read permission\")\n",
    "if os.access(path, os.W_OK):\n",
    "    print(\"Directory is writable\")\n",
    "else:\n",
    "    print(\"No write permission\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T19:06:56.907358400Z",
     "start_time": "2024-12-02T19:06:56.815275Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-12-02T13:31:05.801448900Z",
     "start_time": "2024-12-02T13:30:56.255556200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Viki\\AppData\\Local\\Temp\\ipykernel_15804\\219306613.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_emb, word2id = torch.load(CACHE_PATH)\n",
      "C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\.venv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "C:\\Users\\Viki\\AppData\\Local\\Temp\\ipykernel_15804\\219306613.py:47: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  train_iter = tqdm_notebook(train_loader)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91d193476fca435fb5a6df90f90c6a2c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[51], line 63\u001B[0m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;66;03m# print(f\"batch_pred: {y_tilde.shape}\")\u001B[39;00m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;66;03m# print(f\"labels: {y.shape}\")\u001B[39;00m\n\u001B[0;32m     62\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(y_tilde, y)\n\u001B[1;32m---> 63\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     64\u001B[0m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mclip_grad_value_([param \u001B[38;5;28;01mfor\u001B[39;00m param \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mparameters() \u001B[38;5;28;01mif\u001B[39;00m param\u001B[38;5;241m.\u001B[39mrequires_grad], grad_clip_value)\n\u001B[0;32m     65\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[1;32m~\\Documents\\Thesis\\tryout3\\.venv\\lib\\site-packages\\torch\\_tensor.py:581\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    572\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    573\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    574\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    579\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    580\u001B[0m     )\n\u001B[1;32m--> 581\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    582\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    583\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Thesis\\tryout3\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Thesis\\tryout3\\.venv\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    823\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    824\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 825\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    826\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    827\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    828\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    829\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed_all(123)\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "MAX_EPOCH = 1000\n",
    "\n",
    "text_size = 300\n",
    "visual_size = 47\n",
    "acoustic_size = 74\n",
    "\n",
    "# define some model settings and hyper-parameters\n",
    "input_sizes = [text_size, visual_size, acoustic_size]\n",
    "hidden_sizes = [int(text_size * 1.5), int(visual_size * 1.5), int(acoustic_size * 1.5)]\n",
    "fc1_size = sum(hidden_sizes) // 2\n",
    "dropout = 0.25\n",
    "output_size = 1\n",
    "curr_patience = patience = 8\n",
    "num_trials = 3\n",
    "grad_clip_value = 1.0\n",
    "weight_decay = 0.1\n",
    "\n",
    "if os.path.exists(CACHE_PATH):\n",
    "    pretrained_emb, word2id = torch.load(CACHE_PATH)\n",
    "elif WORD_EMB_PATH is not None:\n",
    "    pretrained_emb = load_emb(word2id, WORD_EMB_PATH)\n",
    "    torch.save((pretrained_emb, word2id), CACHE_PATH)\n",
    "else:\n",
    "    pretrained_emb = None\n",
    "\n",
    "model = LFLSTM(input_sizes, hidden_sizes, fc1_size, output_size, dropout)\n",
    "if pretrained_emb is not None:\n",
    "    model.embed.weight.data = pretrained_emb\n",
    "model.embed.requires_grad = False\n",
    "optimizer = Adam([param for param in model.parameters() if param.requires_grad], weight_decay=weight_decay)\n",
    "\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "criterion = nn.L1Loss(reduction='sum')\n",
    "criterion_test = nn.L1Loss(reduction='sum')\n",
    "best_valid_loss = float('inf')\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "lr_scheduler.step() # for some reason it seems the StepLR needs to be stepped once first\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "for e in range(MAX_EPOCH):\n",
    "    model.train()\n",
    "    train_iter = tqdm_notebook(train_loader)\n",
    "    train_loss = 0.0\n",
    "    for batch in train_iter:\n",
    "        model.zero_grad()\n",
    "        t, v, a, y, l = batch\n",
    "        batch_size = t.size(0)\n",
    "        if CUDA:\n",
    "            t = t.cuda()\n",
    "            v = v.cuda()\n",
    "            a = a.cuda()\n",
    "            y = y.cuda()\n",
    "            l = l.cuda()\n",
    "        y_tilde = model(t, v, a, l)\n",
    "        # print(f\"batch_pred: {y_tilde.shape}\")\n",
    "        # print(f\"labels: {y.shape}\")\n",
    "        loss = criterion(y_tilde, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_value_([param for param in model.parameters() if param.requires_grad], grad_clip_value)\n",
    "        optimizer.step()\n",
    "        train_iter.set_description(f\"Epoch {e}/{MAX_EPOCH}, current batch loss: {round(loss.item()/batch_size, 4)}\")\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train)\n",
    "    train_losses.append(train_loss)\n",
    "    print(f\"Training loss: {round(train_loss, 4)}\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = 0.0\n",
    "        for batch in dev_loader:\n",
    "            model.zero_grad()\n",
    "            t, v, a, y, l = batch\n",
    "            if CUDA:\n",
    "                t = t.cuda()\n",
    "                v = v.cuda()\n",
    "                a = a.cuda()\n",
    "                y = y.cuda()\n",
    "                l = l.cuda()\n",
    "            y_tilde = model(t, v, a, l)\n",
    "            loss = criterion(y_tilde, y)\n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "    valid_loss = valid_loss/len(dev)\n",
    "    valid_losses.append(valid_loss)\n",
    "    print(f\"Validation loss: {round(valid_loss, 4)}\")\n",
    "    print(f\"Current patience: {curr_patience}, current trial: {num_trials}.\")\n",
    "    if valid_loss <= best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        print(\"Found new best model on dev set!\")\n",
    "        torch.save(model.state_dict(), 'model.std')\n",
    "        torch.save(optimizer.state_dict(), 'optim.std')\n",
    "        curr_patience = patience\n",
    "    else:\n",
    "        curr_patience -= 1\n",
    "        if curr_patience <= -1:\n",
    "            print(\"Running out of patience, loading previous best model.\")\n",
    "            num_trials -= 1\n",
    "            curr_patience = patience\n",
    "            model.load_state_dict(torch.load('model.std'))\n",
    "            optimizer.load_state_dict(torch.load('optim.std'))\n",
    "            lr_scheduler.step()\n",
    "            print(f\"Current learning rate: {optimizer.state_dict()['param_groups'][0]['lr']}\")\n",
    "    \n",
    "    if num_trials <= 0:\n",
    "        print(\"Running out of patience, early stopping.\")\n",
    "        break\n",
    "\n",
    "model.load_state_dict(torch.load('model.std'))\n",
    "y_true = []\n",
    "y_pred = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    for batch in test_loader:\n",
    "        model.zero_grad()\n",
    "        t, v, a, y, l = batch\n",
    "        if CUDA:\n",
    "            t = t.cuda()\n",
    "            v = v.cuda()\n",
    "            a = a.cuda()\n",
    "            y = y.cuda()\n",
    "            l = l.cuda()\n",
    "        y_tilde = model(t, v, a, l)\n",
    "        loss = criterion_test(y_tilde, y)\n",
    "        y_true.append(y_tilde.detach().cpu().numpy())\n",
    "        y_pred.append(y.detach().cpu().numpy())\n",
    "        test_loss += loss.item()\n",
    "print(f\"Test set performance: {test_loss/len(test)}\")\n",
    "y_true = np.concatenate(y_true, axis=0)\n",
    "y_pred = np.concatenate(y_pred, axis=0)\n",
    "                  \n",
    "y_true_bin = y_true >= 0\n",
    "y_pred_bin = y_pred >= 0\n",
    "bin_acc = accuracy_score(y_true_bin, y_pred_bin)\n",
    "print(f\"Test set accuracy is {bin_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T10:04:48.261071200Z",
     "start_time": "2024-11-28T10:04:48.219883200Z"
    }
   },
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # ARE\n",
    "# \n",
    "# #-*- coding: utf-8 -*-\n",
    "# \n",
    "# \"\"\"\n",
    "# what    : Single Encoder Model for audio\n",
    "# \"\"\"\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.contrib import rnn\n",
    "# from tensorflow.contrib.rnn import DropoutWrapper \n",
    "# \n",
    "# from tensorflow.core.framework import summary_pb2\n",
    "# from random import shuffle\n",
    "# from project_config import *\n",
    "# \n",
    "# class SingleEncoderModelAudio:\n",
    "# \n",
    "#     def __init__(self, batch_size,\n",
    "#                  encoder_size,\n",
    "#                  num_layer, lr,\n",
    "#                  hidden_dim,\n",
    "#                  dr):\n",
    "# \n",
    "#         self.batch_size = batch_size\n",
    "#         self.encoder_size = encoder_size\n",
    "#         self.num_layers = num_layer\n",
    "#         self.lr = lr\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.dr = dr\n",
    "# \n",
    "#         self.encoder_inputs = []\n",
    "#         self.encoder_seq_length =[]\n",
    "#         self.y_labels =[]\n",
    "# \n",
    "#         self.M = None\n",
    "#         self.b = None\n",
    "# \n",
    "#         self.y = None\n",
    "#         self.optimizer = None\n",
    "# \n",
    "#         self.batch_loss = None\n",
    "#         self.loss = 0\n",
    "#         self.batch_prob = None\n",
    "# \n",
    "#         # for global counter\n",
    "#         self.global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "# \n",
    "# \n",
    "#     def _create_placeholders(self):\n",
    "#         print '[launch-audio] placeholders'\n",
    "#         with tf.name_scope('audio_placeholder'):\n",
    "# \n",
    "#             self.encoder_inputs  = tf.placeholder(tf.float32, shape=[self.batch_size, self.encoder_size, N_AUDIO_MFCC], name=\"encoder\")  # [batch, time_step, audio]\n",
    "#             self.encoder_seq     = tf.placeholder(tf.int32, shape=[self.batch_size], name=\"encoder_seq\")   # [batch] - valid audio step\n",
    "#             self.encoder_prosody = tf.placeholder(tf.float32, shape=[self.batch_size, N_AUDIO_PROSODY], name=\"encoder_prosody\")   \n",
    "#             self.y_labels        = tf.placeholder(tf.float32, shape=[self.batch_size, N_CATEGORY], name=\"label\")\n",
    "#             self.dr_prob         = tf.placeholder(tf.float32, name=\"dropout\")\n",
    "# \n",
    "#     # cell instance\n",
    "#     def gru_cell(self):\n",
    "#         return tf.contrib.rnn.GRUCell(num_units=self.hidden_dim)\n",
    "# \n",
    "# \n",
    "#     # cell instance with drop-out wrapper applied\n",
    "#     def gru_drop_out_cell(self):\n",
    "#         return tf.contrib.rnn.DropoutWrapper(self.gru_cell(), input_keep_prob=self.dr_prob, output_keep_prob=self.dr_prob)                    \n",
    "# \n",
    "# \n",
    "#     def test_cross_entropy_with_logit(self, logits, labels):\n",
    "#         x = logits\n",
    "#         z = labels\n",
    "#         return tf.maximum(x, 0) - x * z + tf.log(1 + tf.exp(-tf.abs(x)))\n",
    "# \n",
    "# \n",
    "#     def _create_gru_model(self):\n",
    "#         print '[launch-audio] create gru cell'\n",
    "# \n",
    "#         with tf.name_scope('audio_RNN') as scope:\n",
    "# \n",
    "#             with tf.variable_scope(\"audio_GRU\", reuse=False, initializer=tf.orthogonal_initializer()):\n",
    "# \n",
    "#                 cells_en = tf.contrib.rnn.MultiRNNCell( [ self.gru_drop_out_cell() for _ in range(self.num_layers) ] )\n",
    "# \n",
    "#                 (self.outputs_en, last_states_en) = tf.nn.dynamic_rnn(\n",
    "#                                                     cell=cells_en,\n",
    "#                                                     inputs= self.encoder_inputs,\n",
    "#                                                     dtype=tf.float32,\n",
    "#                                                     sequence_length=self.encoder_seq,\n",
    "#                                                     time_major=False)\n",
    "# \n",
    "#                 self.final_encoder = last_states_en[-1]\n",
    "# \n",
    "#         self.final_encoder_dimension   = self.hidden_dim\n",
    "# \n",
    "# \n",
    "#     def _add_prosody(self):\n",
    "#         print '[launch-audio] add prosody feature, dim: ' + str(N_AUDIO_PROSODY)\n",
    "#         self.final_encoder = tf.concat( [self.final_encoder, self.encoder_prosody], axis=1 )\n",
    "#         self.final_encoder_dimension = self.hidden_dim + N_AUDIO_PROSODY\n",
    "# \n",
    "# \n",
    "#     def _create_output_layers(self):\n",
    "#         print '[launch-audio] create output projection layer'        \n",
    "# \n",
    "#         with tf.name_scope('audio_output_layer') as scope:\n",
    "# \n",
    "#             self.M = tf.Variable(tf.random_uniform([self.final_encoder_dimension, N_CATEGORY],\n",
    "#                                                    minval= -0.25,\n",
    "#                                                    maxval= 0.25,\n",
    "#                                                    dtype=tf.float32,\n",
    "#                                                    seed=None),\n",
    "#                                                 trainable=True,\n",
    "#                                                 name=\"similarity_matrix\")\n",
    "# \n",
    "#             self.b = tf.Variable(tf.zeros([1], dtype=tf.float32), \n",
    "#                                                  trainable=True, \n",
    "#                                                  name=\"output_bias\")\n",
    "# \n",
    "#             # e * M + b\n",
    "#             self.batch_pred = tf.matmul(self.final_encoder, self.M) + self.b\n",
    "# \n",
    "#         with tf.name_scope('loss') as scope:\n",
    "# \n",
    "#             self.batch_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=self.batch_pred, labels=self.y_labels )\n",
    "#             self.loss = tf.reduce_mean( self.batch_loss  )\n",
    "# \n",
    "# \n",
    "#     def _create_output_layers_for_multi(self):\n",
    "#         print '[launch-audio] create output projection layer for multi'        \n",
    "# \n",
    "#         with tf.name_scope('audio_output_layer') as scope:\n",
    "# \n",
    "#             self.M = tf.Variable(tf.random_uniform([self.final_encoder_dimension, (self.final_encoder_dimension/2)],\n",
    "#                                                    minval= -0.25,\n",
    "#                                                    maxval= 0.25,\n",
    "#                                                    dtype=tf.float32,\n",
    "#                                                    seed=None),\n",
    "#                                                 trainable=True,\n",
    "#                                                 name=\"similarity_matrix\")\n",
    "# \n",
    "#             self.b = tf.Variable(tf.zeros([1], dtype=tf.float32), \n",
    "#                                                  trainable=True, \n",
    "#                                                  name=\"output_bias\")\n",
    "# \n",
    "#             # e * M + b\n",
    "#             self.batch_pred = tf.matmul(self.final_encoder, self.M) + self.b\n",
    "# \n",
    "# \n",
    "#     def _create_optimizer(self):\n",
    "#         print '[launch-audio] create optimizer'\n",
    "# \n",
    "#         with tf.name_scope('audio_optimizer') as scope:\n",
    "#             opt_func = tf.train.AdamOptimizer(learning_rate=self.lr)\n",
    "#             gvs = opt_func.compute_gradients(self.loss)\n",
    "#             capped_gvs = [(tf.clip_by_value(t=grad, clip_value_min=-10, clip_value_max=10), var) for grad, var in gvs]\n",
    "#             self.optimizer = opt_func.apply_gradients(grads_and_vars=capped_gvs, global_step=self.global_step)\n",
    "# \n",
    "# \n",
    "#     def _create_summary(self):\n",
    "#         print '[launch-audio] create summary'\n",
    "# \n",
    "#         with tf.name_scope('summary'):\n",
    "#             tf.summary.scalar('mean_loss', self.loss)\n",
    "#             self.summary_op = tf.summary.merge_all()\n",
    "# \n",
    "# \n",
    "#     def build_graph(self):\n",
    "#         self._create_placeholders()\n",
    "#         self._create_gru_model()\n",
    "#         self._add_prosody()\n",
    "#         self._create_output_layers()\n",
    "#         self._create_optimizer()\n",
    "#         self._create_summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T10:04:48.857960Z",
     "start_time": "2024-11-28T10:04:48.816940900Z"
    }
   },
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def multi_collate_acoustic(batch):\n",
    "    '''\n",
    "    Collate function for acoustic data only. Batch will be sorted based on the sequence length of the acoustic features.\n",
    "    '''\n",
    "    # Sort batch in descending order based on the length of the acoustic feature sequence\n",
    "    batch = sorted(batch, key=lambda x: x[0][2].shape[0], reverse=True)\n",
    "    \n",
    "    # Extract labels and acoustic features from the batch\n",
    "    labels = torch.cat([torch.from_numpy(sample[1]) for sample in batch], dim=0).float()\n",
    "    acoustic = pad_sequence([torch.FloatTensor(sample[0][2]) for sample in batch], batch_first=True)\n",
    "    \n",
    "    # Sequence lengths (useful for RNNs)\n",
    "    lengths = torch.LongTensor([sample[0][2].shape[0] for sample in batch])\n",
    "    return acoustic, labels, lengths\n",
    "\n",
    "\n",
    "batch_sz = 56\n",
    "train_loader = DataLoader(train, shuffle=True, batch_size=batch_sz, collate_fn=multi_collate_acoustic)\n",
    "dev_loader = DataLoader(dev, shuffle=False, batch_size=batch_sz*3, collate_fn=multi_collate_acoustic)\n",
    "test_loader = DataLoader(test, shuffle=False, batch_size=batch_sz*3, collate_fn=multi_collate_acoustic)\n",
    "\n",
    "# let's create a temporary dataloader just to see how the batch looks like\n",
    "temp_loader = iter(DataLoader(test, shuffle=True, batch_size=8, collate_fn=multi_collate_acoustic))\n",
    "batch = next(temp_loader)\n",
    "\n",
    "# print(batch[0].shape) # word vectors, padded to maxlen\n",
    "print(batch[0].shape) # acoustic features\n",
    "print(batch[1]) # labels\n",
    "print(batch[2]) # lengths"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-02T19:13:09.406591800Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "class SingleEncoderModelAudio(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, num_layers, dropout_rate,num_categories, output_size):\n",
    "        super(SingleEncoderModelAudio, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout_rate    \n",
    "        self.num_categories = num_categories\n",
    "        self.output_size = output_size\n",
    "        # GRU layer\n",
    "        self.gru = nn.GRU(input_size=self.input_size, \n",
    "                          hidden_size=self.hidden_dim,  # Correct parameter is hidden_size\n",
    "                          num_layers=self.num_layers, \n",
    "                          batch_first=True,  # Input is [batch_size, seq_length, input_size]\n",
    "                          dropout=self.dropout_rate if self.num_layers > 1 else 0)\n",
    "\n",
    "        # Fully connected output layer\n",
    "        self.fc1 = nn.Linear((self.hidden_dim), num_categories)\n",
    "        self.fc2 = nn.Linear(num_categories, output_size)\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        batch_size = lengths.size(0)\n",
    "\n",
    "        # GRU forward pass\n",
    "        _, hidden = self.gru(x)  # `hidden` shape: (num_layers, batch_size, hidden_dim)\n",
    "        hidden = hidden[-1]  # Use the last hidden state\n",
    "        \n",
    "        # Fully connected layers\n",
    "        fc1_out = self.fc1(hidden)  # Output of shape [batch_size, num_categories]\n",
    "        output = self.fc2(fc1_out)  # Output of shape [batch_size, output_size]\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "    def compute_loss(self, batch_pred, y_labels):\n",
    "        # Use Mean Squared Error loss for regression\n",
    "        loss_fn = nn.MSELoss()\n",
    "        loss = loss_fn(batch_pred, y_labels)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def create_optimizer(self, lr):\n",
    "        # Optimizer (Adam) with the specified learning rate\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        return optimizer\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T19:08:41.765258400Z",
     "start_time": "2024-12-02T19:08:41.590593900Z"
    }
   },
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ???\n",
      "Model created\n",
      "Optimizer created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\.venv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 50\u001B[0m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(MAX_EPOCH):\n\u001B[0;32m     49\u001B[0m     model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m---> 50\u001B[0m     train_iter \u001B[38;5;241m=\u001B[39m tqdm_notebook(\u001B[43mtrain_loader\u001B[49m)\n\u001B[0;32m     51\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[0;32m     53\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m train_iter:\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed_all(123)\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "MAX_EPOCH = 1000\n",
    "\n",
    "input_size = 74  # Example: Number of features per time step (adjust as per your data)\n",
    "hidden_sizes = int(input_size)  # Number of GRU units\n",
    "num_layers = 2  # Number of layers in GRU\n",
    "num_categories = 7  # Number of categories for classification (adjust as needed)\n",
    "output_size = 1  # Output size (e.g., 1 for binary classification)\n",
    "\n",
    "\n",
    "fc1_size = hidden_sizes\n",
    "dropout = 0.5\n",
    "curr_patience = patience = 8\n",
    "num_trials = 3\n",
    "grad_clip_value = 1.0\n",
    "weight_decay = 0.1\n",
    "\n",
    "print(\"Model ???\")\n",
    "model = SingleEncoderModelAudio(input_size=input_size, \n",
    "                                hidden_dim=hidden_sizes,\n",
    "                                num_layers=num_layers,\n",
    "                                dropout_rate=dropout,\n",
    "                                num_categories=num_categories,\n",
    "                                output_size=output_size)\n",
    "print(\"Model created\")\n",
    "\n",
    "# model.embed.requires_grad = False\n",
    "optimizer = model.create_optimizer(lr=0.001)\n",
    "print(\"Optimizer created\")\n",
    "\n",
    "\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "    \n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "criterion_test = nn.MSELoss(reduction='sum')\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "lr_scheduler.step() # for some reason it seems the StepLR needs to be stepped once first\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "for e in range(MAX_EPOCH):\n",
    "    model.train()\n",
    "    train_iter = tqdm_notebook(train_loader)\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch in train_iter:\n",
    "        model.zero_grad()\n",
    "        a, y, l = batch\n",
    "        batch_size = a.size(0)\n",
    "        if CUDA:\n",
    "            a = a.cuda()\n",
    "            y = y.cuda()\n",
    "            l = l.cuda()\n",
    "        \n",
    "        y_tilde = model(a, l)\n",
    "        # print(f\"batch_pred: {y_tilde.shape}\")\n",
    "        # print(f\"labels: {y.shape}\")\n",
    "        \n",
    "        loss = criterion(y_tilde, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_value_([param for param in model.parameters() if param.requires_grad], grad_clip_value)\n",
    "        optimizer.step()\n",
    "        train_iter.set_description(f\"Epoch {e}/{MAX_EPOCH}, current batch loss: {round(loss.item()/batch_size, 4)}\")\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train)\n",
    "    train_losses.append(train_loss)\n",
    "    print(f\"Training loss: {round(train_loss, 4)}\")\n",
    "    \n",
    "    # print(\"LOOP COMPLETED\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = 0.0\n",
    "        for batch in dev_loader:\n",
    "            model.zero_grad()\n",
    "            a, y, l = batch\n",
    "            if CUDA:\n",
    "                a = a.cuda()\n",
    "                y = y.cuda()\n",
    "                l = l.cuda()\n",
    "            y_tilde = model(a, l)\n",
    "            loss = criterion(y_tilde, y)\n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "    valid_loss = valid_loss/len(dev)\n",
    "    valid_losses.append(valid_loss)\n",
    "    print(f\"Validation loss: {round(valid_loss, 4)}\")\n",
    "    print(f\"Current patience: {curr_patience}, current trial: {num_trials}.\")\n",
    "    if valid_loss <= best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        print(\"Found new best model on dev set!\")\n",
    "        torch.save(model.state_dict(), 'model.std')\n",
    "        torch.save(optimizer.state_dict(), 'optim.std')\n",
    "        curr_patience = patience\n",
    "    else:\n",
    "        curr_patience -= 1\n",
    "        if curr_patience <= -1:\n",
    "            print(\"Running out of patience, loading previous best model.\")\n",
    "            num_trials -= 1\n",
    "            curr_patience = patience\n",
    "            model.load_state_dict(torch.load('model.std'))\n",
    "            optimizer.load_state_dict(torch.load('optim.std'))\n",
    "            lr_scheduler.step()\n",
    "            print(f\"Current learning rate: {optimizer.state_dict()['param_groups'][0]['lr']}\")\n",
    "    \n",
    "    if num_trials <= 0:\n",
    "        print(\"Running out of patience, early stopping.\")\n",
    "        break\n",
    "\n",
    "model.load_state_dict(torch.load('model.std'))\n",
    "y_true = []\n",
    "y_pred = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    for batch in test_loader:\n",
    "        model.zero_grad()\n",
    "        a, y, l = batch\n",
    "        if CUDA:\n",
    "            a = a.cuda()\n",
    "            y = y.cuda()\n",
    "            l = l.cuda()\n",
    "        y_tilde = model(a, l)\n",
    "        loss = criterion_test(y_tilde, y)\n",
    "        y_true.append(y_tilde.detach().cpu().numpy())\n",
    "        y_pred.append(y.detach().cpu().numpy())\n",
    "        test_loss += loss.item()\n",
    "print(f\"Test set performance: {test_loss/len(test)}\")\n",
    "y_true = np.concatenate(y_true, axis=0)\n",
    "y_pred = np.concatenate(y_pred, axis=0)\n",
    "                  \n",
    "y_true_bin = y_true >= 0\n",
    "y_pred_bin = y_pred >= 0\n",
    "bin_acc = accuracy_score(y_true_bin, y_pred_bin)\n",
    "print(f\"Test set accuracy is {bin_acc}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T19:08:47.588605400Z",
     "start_time": "2024-12-02T19:08:42.727859800Z"
    }
   },
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # TRE\n",
    "# \n",
    "# #-*- coding: utf-8 -*-\n",
    "# \n",
    "# \"\"\"\n",
    "# what    : Single Encoder Model for text\n",
    "# \"\"\"\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.contrib import rnn\n",
    "# from tensorflow.contrib.rnn import DropoutWrapper \n",
    "# \n",
    "# from tensorflow.core.framework import summary_pb2\n",
    "# from random import shuffle\n",
    "# import numpy as np\n",
    "# from project_config import *\n",
    "# \n",
    "# class SingleEncoderModelText:\n",
    "# \n",
    "#     def __init__(self, dic_size,\n",
    "#                  use_glove,\n",
    "#                  batch_size,\n",
    "#                  encoder_size,\n",
    "#                  num_layer, lr,\n",
    "#                  hidden_dim,\n",
    "#                  dr):\n",
    "# \n",
    "#         self.dic_size = dic_size\n",
    "#         self.use_glove = use_glove\n",
    "#         self.batch_size = batch_size\n",
    "#         self.encoder_size = encoder_size\n",
    "#         self.num_layers = num_layer\n",
    "#         self.lr = lr\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.dr = dr\n",
    "# \n",
    "#         self.encoder_inputs = []\n",
    "#         self.encoder_seq_length =[]\n",
    "#         self.y_labels =[]\n",
    "# \n",
    "#         self.M = None\n",
    "#         self.b = None\n",
    "# \n",
    "#         self.y = None\n",
    "#         self.optimizer = None\n",
    "# \n",
    "#         self.batch_loss = None\n",
    "#         self.loss = 0\n",
    "#         self.batch_prob = None\n",
    "# \n",
    "#         if self.use_glove == 1:\n",
    "#             self.embed_dim = 300\n",
    "#         else:\n",
    "#             self.embed_dim = DIM_WORD_EMBEDDING\n",
    "# \n",
    "#         # for global counter\n",
    "#         self.global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "# \n",
    "# \n",
    "#     def _create_placeholders(self):\n",
    "#         print '[launch-text] placeholders'\n",
    "#         with tf.name_scope('text_placeholder'):\n",
    "# \n",
    "#             self.encoder_inputs  = tf.placeholder(tf.int32, shape=[self.batch_size, self.encoder_size], name=\"encoder\")  # [batch,time_step]\n",
    "#             self.encoder_seq     = tf.placeholder(tf.int32, shape=[self.batch_size], name=\"encoder_seq\")   # [batch] - valid word step\n",
    "#             self.y_labels        = tf.placeholder(tf.float32, shape=[self.batch_size, N_CATEGORY], name=\"label\")\n",
    "#             self.dr_prob         = tf.placeholder(tf.float32, name=\"dropout\")\n",
    "# \n",
    "#              # for using pre-trained embedding\n",
    "#             self.embedding_placeholder = tf.placeholder(tf.float32, shape=[self.dic_size, self.embed_dim], name=\"embedding_placeholder\")\n",
    "# \n",
    "#     def _create_embedding(self):\n",
    "#         print '[launch-text] create embedding'\n",
    "#         with tf.name_scope('embed_layer'):\n",
    "#             self.embed_matrix = tf.Variable(tf.random_normal([self.dic_size, self.embed_dim],\n",
    "#                                                             mean=0.0,\n",
    "#                                                             stddev=0.01,\n",
    "#                                                             dtype=tf.float32,                                                             \n",
    "#                                                             seed=None),\n",
    "#                                                             trainable = EMBEDDING_TRAIN,\n",
    "#                                                             name='embed_matrix')\n",
    "# \n",
    "#             self.embed_en       = tf.nn.embedding_lookup(self.embed_matrix, self.encoder_inputs, name='embed_encoder')\n",
    "# \n",
    "# \n",
    "#     def _use_external_embedding(self):\n",
    "#         if self.use_glove == 1:\n",
    "#             print '[launch-text] use pre-trained embedding'\n",
    "#             self.embedding_init = self.embed_matrix.assign(self.embedding_placeholder)\n",
    "# \n",
    "# \n",
    "#     # cell instance\n",
    "#     def gru_cell(self):\n",
    "#         return tf.contrib.rnn.GRUCell(num_units=self.hidden_dim)\n",
    "# \n",
    "# \n",
    "#     # cell instance with drop-out wrapper applied\n",
    "#     def gru_drop_out_cell(self):\n",
    "#         return tf.contrib.rnn.DropoutWrapper(self.gru_cell(), input_keep_prob=self.dr_prob, output_keep_prob=self.dr_prob)                    \n",
    "# \n",
    "# \n",
    "#     def test_cross_entropy_with_logit(self, logits, labels):\n",
    "#         x = logits\n",
    "#         z = labels\n",
    "#         return tf.maximum(x, 0) - x * z + tf.log(1 + tf.exp(-tf.abs(x)))\n",
    "# \n",
    "# \n",
    "#     def _create_gru_model(self):\n",
    "#         print '[launch-text] create gru cell'\n",
    "# \n",
    "#         with tf.name_scope('text_RNN') as scope:\n",
    "# \n",
    "#             with tf.variable_scope(\"text_GRU\", reuse=False, initializer=tf.orthogonal_initializer()):\n",
    "# \n",
    "#                 cells_en = tf.contrib.rnn.MultiRNNCell( [ self.gru_drop_out_cell() for _ in range(self.num_layers) ] )\n",
    "# \n",
    "#                 (self.outputs_en, last_states_en) = tf.nn.dynamic_rnn(\n",
    "#                                                     cell=cells_en,\n",
    "#                                                     inputs= self.embed_en,\n",
    "#                                                     dtype=tf.float32,\n",
    "#                                                     sequence_length=self.encoder_seq,\n",
    "#                                                     time_major=False)\n",
    "# \n",
    "#                 self.final_encoder = last_states_en[-1]\n",
    "# \n",
    "#         self.final_encoder_dimension   = self.hidden_dim\n",
    "# \n",
    "# \n",
    "#     def _create_output_layers(self):\n",
    "#         print '[launch-text] create output projection layer'        \n",
    "# \n",
    "#         with tf.name_scope('text_output_layer') as scope:\n",
    "# \n",
    "#             self.M = tf.Variable(tf.random_uniform([self.final_encoder_dimension, N_CATEGORY],\n",
    "#                                                    minval= -0.25,\n",
    "#                                                    maxval= 0.25,\n",
    "#                                                    dtype=tf.float32,\n",
    "#                                                    seed=None),\n",
    "#                                                  trainable=True,\n",
    "#                                                  name=\"similarity_matrix\")\n",
    "# \n",
    "#             self.b = tf.Variable(tf.zeros([1], dtype=tf.float32),\n",
    "#                                                  trainable=True,\n",
    "#                                                  name=\"output_bias\")\n",
    "# \n",
    "#             # e * M + b\n",
    "#             self.batch_pred = tf.matmul(self.final_encoder, self.M) + self.b\n",
    "# \n",
    "#         with tf.name_scope('loss') as scope:\n",
    "# \n",
    "#             self.batch_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=self.batch_pred, labels=self.y_labels )\n",
    "#             self.loss = tf.reduce_mean( self.batch_loss  )\n",
    "# \n",
    "# \n",
    "#     def _create_output_layers_for_multi(self):\n",
    "#         print '[launch-text] create output projection layer for multi'        \n",
    "# \n",
    "#         with tf.name_scope('text_output_layer') as scope:\n",
    "# \n",
    "#             self.M = tf.Variable(tf.random_uniform([self.final_encoder_dimension, (self.final_encoder_dimension/2)],\n",
    "#                                                    minval= -0.25,\n",
    "#                                                    maxval= 0.25,\n",
    "#                                                    dtype=tf.float32,\n",
    "#                                                    seed=None),\n",
    "#                                                  trainable=True,\n",
    "#                                                  name=\"similarity_matrix\")\n",
    "# \n",
    "#             self.b = tf.Variable(tf.zeros([1], dtype=tf.float32),\n",
    "#                                                  trainable=True,\n",
    "#                                                  name=\"output_bias\")\n",
    "# \n",
    "#             # e * M + b\n",
    "#             self.batch_pred = tf.matmul(self.final_encoder, self.M) + self.b\n",
    "# \n",
    "# \n",
    "#     def _create_optimizer(self):\n",
    "#         print '[launch-text] create optimizer'\n",
    "# \n",
    "#         with tf.name_scope('text_optimizer') as scope:\n",
    "#             opt_func = tf.train.AdamOptimizer(learning_rate=self.lr)\n",
    "#             gvs = opt_func.compute_gradients(self.loss)\n",
    "#             capped_gvs = [(tf.clip_by_value(t=grad, clip_value_min=-10, clip_value_max=10), var) for grad, var in gvs]\n",
    "#             self.optimizer = opt_func.apply_gradients(grads_and_vars=capped_gvs, global_step=self.global_step)\n",
    "# \n",
    "# \n",
    "#     def _create_summary(self):\n",
    "#         print '[launch-text] create summary'\n",
    "# \n",
    "#         with tf.name_scope('summary'):\n",
    "#             tf.summary.scalar('mean_loss', self.loss)\n",
    "#             self.summary_op = tf.summary.merge_all()\n",
    "# \n",
    "# \n",
    "#     def build_graph(self):\n",
    "#         self._create_placeholders()\n",
    "#         self._create_embedding()\n",
    "#         self._use_external_embedding()\n",
    "#         self._create_gru_model()\n",
    "#         self._create_output_layers()\n",
    "#         self._create_optimizer()\n",
    "#         self._create_summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-27T23:32:56.644201800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# define a function that loads data from GloVe-like embedding files\n",
    "\n",
    "# 2196017 is the vocab size of GloVe here.\n",
    "\n",
    "def load_emb(w2i, path_to_embedding, embedding_size=300, embedding_vocab=2196017, init_emb=None):\n",
    "    print(\"Len w2i start:\", len(w2i))\n",
    "    if init_emb is None:\n",
    "        emb_mat = np.random.randn(len(w2i), embedding_size)\n",
    "    else:\n",
    "        emb_mat = init_emb\n",
    "    f = open(path_to_embedding, 'r', encoding='utf-8', errors='replace')\n",
    "    found = 0\n",
    "    for line in tqdm_notebook(f, total=embedding_vocab):\n",
    "        try:\n",
    "            content = line.strip().split()\n",
    "            vector = np.asarray(list(map(lambda x: float(x), content[-300:])))\n",
    "            word = ' '.join(content[:-300])\n",
    "            if word in w2i:\n",
    "                idx = w2i[word]\n",
    "                emb_mat[idx, :] = vector\n",
    "                found += 1\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping invalid line: {line}\")\n",
    "    \n",
    "    print(\"Len w2i end:\", len(w2i))\n",
    "\n",
    "    print(f\"Found {found} words in the embedding file.\")\n",
    "    return torch.tensor(emb_mat).float()\n",
    "\n",
    "# After processing the entire file, it returns the embedding matrix as a PyTorch tensor.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T18:36:31.855917200Z",
     "start_time": "2024-12-02T18:36:31.729383100Z"
    }
   },
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# if os.path.exists(CACHE_PATH):\n",
    "#     pretrained_emb, word2id = torch.load(CACHE_PATH)\n",
    "# elif WORD_EMB_PATH is not None:\n",
    "#     pretrained_emb = load_emb(word2id, WORD_EMB_PATH)\n",
    "#     torch.save((pretrained_emb, word2id), CACHE_PATH)\n",
    "# else:\n",
    "#     pretrained_emb = None\n",
    "# \n",
    "# model = #here I should have the Single Encoder for Text Model\n",
    "# if pretrained_emb is not None:\n",
    "#     model.embed.weight.data = pretrained_emb\n",
    "# model.embed.requires_grad = False\n",
    "# optimizer = Adam([param for param in model.parameters() if param.requires_grad], weight_decay=weight_decay)\n",
    "# \n",
    "# embedding_matrix = model.embed.weight.data\n",
    "# print(embedding_matrix.shape)\n",
    "# \n",
    "# embedding_matrix_np = embedding_matrix.cpu().numpy()\n",
    "# print(embedding_matrix_np[:10])  # First 10 rows\n",
    "# \n",
    "# word = \"example\"\n",
    "# word_idx = word2id[word]\n",
    "# word_embedding = embedding_matrix[word_idx]\n",
    "# print(f\"Embedding for '{word}': {word_embedding}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T18:36:34.441394900Z",
     "start_time": "2024-12-02T18:36:34.314218100Z"
    }
   },
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# \n",
    "# plt.figure(figsize=(18, 14))  # Set the figure size to 12x8 inches\n",
    "# sns.heatmap(embedding_matrix_np[:10], annot=False)  # Visualize first 10 embeddings\n",
    "# plt.xlabel(\"Dimensions\")\n",
    "# plt.ylabel(\"Words (Index)\")\n",
    "# plt.title(\"Embedding Matrix Heatmap\")\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T18:36:35.210167700Z",
     "start_time": "2024-12-02T18:36:35.088255400Z"
    }
   },
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# \n",
    "# # Reduce dimensionality of the first 100 embeddings\n",
    "# pca = PCA(n_components=2)\n",
    "# reduced_embeddings = pca.fit_transform(embedding_matrix_np[:200])\n",
    "# \n",
    "# plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1])\n",
    "# for i, word in enumerate(list(word2id.keys())[:200]):\n",
    "#     plt.annotate(word, (reduced_embeddings[i, 0], reduced_embeddings[i, 1]))\n",
    "# plt.show()\n",
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T18:36:35.992355900Z",
     "start_time": "2024-12-02T18:36:35.815799400Z"
    }
   },
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.save(\"embedding_matrix.npy\", embedding_matrix_np)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T18:36:36.629180Z",
     "start_time": "2024-12-02T18:36:36.480103800Z"
    }
   },
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# embedding_matrix_loaded = np.load(\"embedding_matrix.npy\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T18:36:37.133204400Z",
     "start_time": "2024-12-02T18:36:37.000001900Z"
    }
   },
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 58])\n",
      "tensor([[-1.2000],\n",
      "        [ 0.2000],\n",
      "        [ 0.6000],\n",
      "        [-2.0000],\n",
      "        [ 1.8000],\n",
      "        [ 0.6000],\n",
      "        [ 0.0000],\n",
      "        [-1.0000]])\n",
      "tensor([58, 37, 29, 23, 14, 14,  7,  5])\n"
     ]
    }
   ],
   "source": [
    "def multi_collate_textual(batch):\n",
    "    '''\n",
    "    Collate functions assume batch = [Dataset[i] for i in index_set]\n",
    "    '''\n",
    "    # for later use we sort the batch in descending order of length\n",
    "    batch = sorted(batch, key=lambda x: x[0][0].shape[0], reverse=True)\n",
    "    \n",
    "    # get the data out of the batch - use pad sequence util functions from PyTorch to pad things\n",
    "    labels = torch.cat([torch.from_numpy(sample[1]) for sample in batch], dim=0).float()\n",
    "    sentences = pad_sequence([torch.LongTensor(sample[0][0]) for sample in batch], padding_value=PAD, batch_first=True)\n",
    "    \n",
    "    lengths = torch.LongTensor([sample[0][0].shape[0] for sample in batch])\n",
    "    return sentences, labels, lengths\n",
    "        \n",
    "\n",
    "batch_sz = 56\n",
    "train_loader = DataLoader(train, shuffle=True, batch_size=batch_sz, collate_fn=multi_collate_textual)\n",
    "dev_loader = DataLoader(dev, shuffle=False, batch_size=batch_sz*3, collate_fn=multi_collate_textual)\n",
    "test_loader = DataLoader(test, shuffle=False, batch_size=batch_sz*3, collate_fn=multi_collate_textual)\n",
    "\n",
    "# let's create a temporary dataloader just to see how the batch looks like\n",
    "temp_loader = iter(DataLoader(test, shuffle=True, batch_size=8, collate_fn=multi_collate_textual))\n",
    "batch = next(temp_loader)\n",
    "\n",
    "# print(batch[0].shape) # word vectors, padded to maxlen\n",
    "print(batch[0].shape) # textual features\n",
    "print(batch[1]) # labels\n",
    "print(batch[2]) # lengths\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T18:36:37.655766200Z",
     "start_time": "2024-12-02T18:36:37.506202500Z"
    }
   },
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 2733\n"
     ]
    }
   ],
   "source": [
    "# Check how many words are in the vocabulary\n",
    "vocab_size = len(word2id)\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T18:36:38.745477900Z",
     "start_time": "2024-12-02T18:36:38.625998400Z"
    }
   },
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class SingleEncoderModelText(nn.Module):\n",
    "    def __init__(self, dic_size, use_glove, encoder_size, num_layers, lr, hidden_dim, dr, num_categories, output_size, embedding_path=WORD_EMB_PATH):\n",
    "        super(SingleEncoderModelText, self).__init__()\n",
    "        \n",
    "        # Parameters\n",
    "        self.dic_size = dic_size\n",
    "        self.use_glove = use_glove\n",
    "        self.encoder_size = encoder_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lr = lr\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dr = dr\n",
    "        self.num_categories = num_categories\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Embedding size is 300 if using GloVe, else defined elsewhere\n",
    "        self.embed_dim = 300 if self.use_glove else 128  # Adjust accordingly\n",
    "    \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(self.dic_size, self.embed_dim)\n",
    "        \n",
    "        if self.use_glove:\n",
    "            print(\"Using glove\")\n",
    "            \n",
    "\n",
    "    \n",
    "        # GRU layer\n",
    "        self.gru = nn.GRU(input_size=self.embed_dim, \n",
    "                          hidden_size=self.hidden_dim, \n",
    "                          num_layers=self.num_layers, \n",
    "                          dropout=self.dr, \n",
    "                          batch_first=True)\n",
    "        \n",
    "        # Fully connected output layer\n",
    "        # self.fc1 = nn.Linear(self.hidden_dim, self.num_categories)  \n",
    "        self.fc2 = nn.Linear(self.hidden_dim, self.output_size)\n",
    "    # \n",
    "    # # Debugging - before passing data to the model, print out some input examples\n",
    "    # # Check if all indices in the input are valid\n",
    "    # def check_input_indices(input_tensor, vocab_size):\n",
    "    #     if input_tensor.max().item() >= vocab_size:\n",
    "    #         print(f\"Warning: Input contains indices out of range! Max index: {input_tensor.max().item()} but vocab size is {vocab_size}.\")\n",
    "    #     else:\n",
    "    #         print(f\"Input indices are within valid range. Max index: {input_tensor.max().item()}.\")\n",
    "    # \n",
    "    # # Example usage:\n",
    "    # check_input_indices(input_tensor, self.dic_size)\n",
    "    \n",
    "\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        batch_size = lengths.size(0)\n",
    "\n",
    "        if (x.min() < 0 or x.max() >= self.dic_size):\n",
    "            raise ValueError(\n",
    "                f\"Input indices out of range! Min index: {x.min()}, Max index: {x.max()}, Vocabulary size: {self.dic_size}\"\n",
    "            )\n",
    "        # Step 1: Embedding layer\n",
    "        embedded = self.embedding(x)  # [batch_size, seq_length] -> [batch_size, seq_length, embed_dim]\n",
    "        \n",
    "        # Step 2: GRU layer\n",
    "        gru_out, hidden = self.gru(embedded)  # gru_out: [batch_size, seq_length, hidden_dim], hidden: [num_layers, batch_size, hidden_dim]\n",
    "        \n",
    "        # Step 3: Use the last hidden state (or apply pooling, e.g., mean pooling)\n",
    "        # We'll use the hidden state from the last time step of the last GRU layer\n",
    "        last_hidden = hidden[-1]  # Shape: [batch_size, hidden_dim]\n",
    "        \n",
    "        # Step 4: Pass through fully connected layers\n",
    "        # fc1_out = self.fc1(last_hidden)  # [batch_size, num_categories]\n",
    "        output = self.fc2(last_hidden)  # [batch_size, output_size]\n",
    "        \n",
    "        return output\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T18:36:41.712040800Z",
     "start_time": "2024-12-02T18:36:41.532166800Z"
    }
   },
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor min: 1, max: 2488\n",
      "Vocabulary size: 2733\n"
     ]
    }
   ],
   "source": [
    "\n",
    "temp_loader = iter(DataLoader(test, shuffle=True, batch_size=8, collate_fn=multi_collate_textual))\n",
    "batch = next(temp_loader)\n",
    "\n",
    "t, y, l = batch\n",
    "print(f\"Input tensor min: {t.min()}, max: {t.max()}\")\n",
    "\n",
    "# Check how many words are in the vocabulary\n",
    "vocab_size = len(word2id)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "# print(f\"vocabulary: {list(word2id.keys())}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T18:36:43.162052900Z",
     "start_time": "2024-12-02T18:36:42.985898Z"
    }
   },
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall maximum value in the dataset: 2732\n"
     ]
    }
   ],
   "source": [
    "max_value = float('-inf')  # Initialize to negative infinity\n",
    "for batch in DataLoader(test, shuffle=True, batch_size=8, collate_fn=multi_collate_textual):\n",
    "    t, y, l = batch\n",
    "    batch_max = t.max().item()  # Find the max in the current batch\n",
    "    max_value = max(max_value, batch_max)  # Update the overall max\n",
    "\n",
    "print(f\"Overall maximum value in the dataset: {max_value}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T18:36:48.293381300Z",
     "start_time": "2024-12-02T18:36:48.115728600Z"
    }
   },
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 2733\n",
      "vocabulary: ['<unk>', '<pad>', '<eos>', '<bos>', '<sep>', '<dummy>', 'anyhow', 'it', 'was', 'really', 'good', 'they', 'didnt', 'do', 'a', 'whole', 'bunch', 'of', 'background', 'info', 'on', 'why', 'she', 'has', 'to', 'fight', 'and', 'be', 'prepared', 'i', 'mean', 'did', 'little', 'bit', 'but', 'not', 'guess', 'live', 'up', 'with', 'more', 'besides', 'that', 'all', 'over', 'pretty', 'there', 'is', 'like', 'someone', 'while', 'lot', 'action', 'oh', 'my', 'god', 'sad', 'part', 'parts', 'awesome', 'its', 'funny', 'now', 'the', 'title', 'movie', 'basically', 'says', 'im', 'even', 'gonna', 'sugar', 'coat', 'this', 'frustrated', 'me', 'such', 'an', 'extreme', 'extent', 'loudly', 'exclaiming', 'at', 'end', 'film', 'reason', 'comic', 'book', 'fan', 'see', 'characters', 'treated', 'responsibly', 'huh', 'before', 'we', 'go', 'must', 'say', 'had', 'surprisingly', 'decent', 'cast', 'strange', 'since', 'one', 'biggest', 'grapes', 'series', 'always', 'hugh', 'jackman', 'best', 'choice', 'play', 'wolverine', 'will', 'admit', 'in', 'opinion', 'he', 'carried', 'fine', 'you', 'know', 'nothing', 'great', 'hes', 'star', 'special', 'which', 'smart', 'move', 'have', 'real', 'get', 'what', 'name', 'supposed', 'um', 'actually', 'think', 'schreiber', 'actor', 'almost', 'looks', 'exactly', 'same', 'as', 'character', 'defiance', 'too', 'lazy', 'take', 'off', 'costume', 'or', 'something', 'other', 'performances', 'are', 'borderline', 'ok', 'two', 'big', 'appearances', 'easily', 'gambit', 'liked', 'him', 'thought', 'made', 'for', 'dead', 'poor', 'seen', 'beginning', 'sold', 'impressive', 'scene', 'where', 'swords', 'theres', 'people', 'shoot', 'boom', 'down', 'bam', 'magical', 'just', 'feel', 'loved', 'very', 'first', 'alvin', 'because', 'nostalgic', 'reminded', 'getting', 'saturday', 'morning', 'eating', 'fruit', 'loops', 'watching', 'cartoons', 'care', 'saw', 'no', 'needed', 'bring', 'back', 'villain', 'from', 'trailer', 'look', 'nice', 'cute', 'flat', 'sure', 'kids', 'love', 'bored', 'were', 'money', 'otherwise', 'dont', 'average', 'lets', 'face', 'master', 'pieces', 'twilight', 'directed', 'by', 'catherine', 'hardwicke', 'rather', 'enjoyable', 'obviously', 'flaws', 'quite', 'thinking', 'hearing', 'chris', 'weitz', 'start', 'new', 'moon', 'destruction', 'phillip', 'pullman', 'golden', 'awful', 'expect', 'terms', 'his', 'direction', 'overall', 'thing', 'translation', 'loyal', 'appreciate', 'loyalty', 'however', 'original', 'source', 'gives', 'necessarily', 'most', 'thrilling', 'ever', 'entire', 'bella', 'swan', 'kristen', 'stewards', 'around', 'completely', 'depressed', 'read', 'ill', 'so', 'bigger', 'better', 'budgets', 'still', 'long', 'moments', 'withdrawn', 'out', 'max', 'far', 'can', 'script', 'left', 'key', 'plots', 'emotion', 'exposed', 'through', 'dialogue', 'empire', 'magazines', 'review', 'said', 'relied', 'heavily', 'tactic', 'blinking', 'does', 'goes', 'rob', 'pattinson', 'edward', 'taylor', 'lautner', 'jacob', 'frowning', 'manly', 'man', 'frown', 'moment', 'cinema', 'knew', 'laughing', 'favorite', 'would', 'then', 'wins', 'screen', 'worn', 'lots', 'shame', 'michael', 'sheen', 'aro', 'well', 'watch', 'exciting', 'rest', 'mob', 'boring', 'much', 'enjoyed', 'cowboys', 'aliens', 'fun', 'guys', 'youre', 'when', 'walk', 'into', 'called', 'if', 'expecting', 'some', 'artsy', 'serious', 'oscar', 'contender', 'than', 'wrong', 'only', 'maybe', 'cinematography', 'visual', 'effects', 'coz', 'cool', 'again', 'cant', 'huge', 'surreal', 'mind', 'bender', 'yo', 'satisfactory', 'intense', 'surprised', 'scenes', 'especially', 'invade', 'crazy', 'gave', 'chills', 'weak', 'links', 'hide', 'behind', 'technology', 'theyre', 'strong', 'kind', 'scary', 'looking', 'also', 'how', 'upfront', 'show', 'them', 'us', 'instead', 'hiding', 'showing', 'arm', 'straight', 'daniel', 'craig', 'job', 'here', 'channels', 'clint', 'eastwood', 'been', 'saying', 'bad', 'ass', 'hard', 'core', 'doesnt', 'crap', 'anybody', 'innocent', 'accent', 'convincing', 'harrison', 'ford', 'entertaining', 'performance', 'leader', 'town', 'grumpy', 'old', 'guy', 'becomes', 'likeable', 'guts', 'developed', 'about', 'olivia', 'wild', 'everything', 'nowadays', 'glaring', 'sometimes', 'western', 'setting', 'goofy', 'stupid', 'veers', 'cliche', 'territory', 'entirely', 'flaw', 'give', 'eight', 'ten', 'time', 'recommend', 'check', 'theaters', 'went', 'green', 'lantern', 'ive', 'these', 'critics', 'trashing', 'right', 'wanna', 'sort', 'spectacle', 'summer', 'probably', 'movies', 'year', 'opening', 'portion', 'dark', 'anything', 'light', 'hearted', 'perfect', 'teenagers', 'who', 'explosions', 'stuff', 'going', 'trailers', 'head', 'hesitant', 'seeing', 'place', 'cartoon', 'having', 'make', 'talk', 'thats', 'seemed', 'tone', 'within', 'actual', 'powers', 'himself', 'project', 'life', 'superpower', 'power', 'imagine', 'helped', 'passed', 'set', 'playground', 'their', 'imaginary', 'happen', 'whats', 'coming', 'next', 'happened', 'understand', 'worth', 'able', 'put', 'force', 'push', 'level', 'destroy', 'lea', 'helps', 'alleviate', 'fighting', 'ultimate', 'enemy', 'threat', 'potentially', 'speaking', 'interesting', 'forward', 'got', 'batman', 'begins', 'sundance', 'way', 'describe', 'bold', 'makes', 'statements', 'hold', 'being', 'released', 'story', 'itself', 'absolutely', 'top', 'done', 'break', 'kevin', 'smith', 'different', 'weve', 'john', 'goodman', 'amazing', 'melissa', 'leo', 'your', 'inner', 'her', 'tiny', 'smile', 'those', 'hating', 'complaining', 'horror', 'ia', 'true', 'sense', 'horrifying', 'films', 'easy', 'find', 'whenever', 'comes', 'miss', 'dare', 'messed', 'laugh', 'finished', 'excellent', 'mars', 'needs', 'moms', 'milo', 'milos', 'mother', 'gribble', 'away', 'save', 'ages', 'depends', 'age', 'example', 'brother', 'five', 'years', 'am', 's', 'scared', 'lost', 'own', 'turns', 'curious', 'disney', 'bet', 'style', 'similar', 'enough', 'wouldnt', 'tell', 'difference', 'remember', 'simple', 'jokes', 'pooh', 'owl', 'sick', 'issue', 'wanted', 'could', 'frame', 'winnie', 'family', 'things', 'vice', 'verse', 'harder', 'number', 'four', 'yeah', 'explaining', 'lorain', 'numbers', 'stuck', 'hollywood', 'th', 'deal', 'fact', 'priority', 'survival', 'worried', 'latest', 'financial', 'situation', 'scraping', 'totally', 'rich', 'trends', 'lieutenant', 'commercial', 'aspect', 'hurt', 'another', 'bother', 'graphics', 'incredible', 'acting', 'popcorn', 'hear', 'ripple', 'effect', 'whispering', 'less', 'blue', 'nudity', 'weird', 'wearing', 'medal', 'wear', 'command', 'though', 'classic', 'superhero', 'sucked', 'malin', 'akerman', 'girl', 'plays', 'silk', 'spectre', 'junior', 'lady', 'looked', 'fantastic', 'phenomenal', 'acted', 'ranger', 'vast', 'between', 'kick', 'played', 'our', 'rorschach', 'anyways', 'jeffrey', 'dean', 'morgan', 'impressed', 'blend', 'youve', 'alternative', 'history', 'extremely', 'warn', 'balance', 'evil', 'overwhelmingly', 'redeeming', 'value', 'come', 'relationships', 'should', 'chaotic', 'literally', 'loud', 'que', 'confused', 'terrible', 'mistake', 'provoking', 'inception', 'thanks', 'constantly', 'comparing', 'shoes', 'fill', 'chance', 'shot', 'waiting', 'joseph', 'gordon', 'levitt', 'jump', 'any', 'paradox', 'found', 'thirty', 'minutes', 'matt', 'damon', 'discovers', 'bureau', 'ruins', 'suspense', 'convenient', 'fedora', 'yes', 'excited', 'anymore', 'interestingly', 'turned', 'romantic', 'comedy', 'thriller', 'writing', 'times', 'aside', 'dropped', 'ball', 'many', 'plot', 'holes', 'depth', 'thompson', 'stands', 'asleep', 'staring', 'reasons', 'mostly', 'predator', 'sequel', 'equivalent', 'alien', 'point', 'pulled', 'try', 'enjoy', 'agent', 'drawn', 'cared', 'israeli', 'sniper', 'russian', 'few', 'lines', 'once', 'unfortunately', 'somewhere', 'fear', 'includes', 'graces', 'include', 'laurence', 'wrote', 'mo', 'marlon', 'brando', 'type', 'slowed', 'problem', 'predators', 'compared', 'paced', 'picks', 'speed', 'never', 'ev', 'slow', 'meant', 'felt', 'middle', 'fishburne', 'inclusion', 'necessary', 'written', 'figured', 'fall', 'falling', 'high', 'expectations', 'met', 'low', 'three', 'major', 'complaints', 'pay', 'closer', 'attention', 'might', 'followed', 'half', 'checking', 'hours', 'ji', 'joe', 'need', 'hour', 'mini', 'last', 'army', 'military', 'propaganda', 'fell', 'commercials', 'course', 'making', 'despite', 'ended', 'liking', 'realized', 'disappointed', 'wars', 'close', 'war', 'heavy', 'human', 'computer', 'adorable', 'voice', 'visuals', 'used', 'toy', 'elements', 'ways', 'steve', 'voices', 'russell', 'brand', 'doctor', 'couldnt', 'believe', 'kept', 'listening', 'heard', 'cheap', 'tricks', 'roller', 'coaster', 'motion', 'stomach', 'drop', 'child', 'everyone', 'relate', 'hilarious', 'adult', 'jabs', 'fucking', 'particularly', 'gotten', 'nominated', 'let', 'split', 'certain', 'deadpan', 'nature', 'audience', 'explore', 'themes', 'tightly', 'profound', 'deep', 'fully', 'explored', 'rely', 'figure', 'ideas', 'yourself', 'regardless', 'young', 'actors', 'today', 'grace', 'fluidity', 'everybody', 'knows', 'pirates', 'carribean', 'works', 'pride', 'prejudice', 'andrew', 'garfield', 'form', 'social', 'network', 'act', 'takes', 'sometime', 'present', 'day', 'modern', 'period', 'piece', 'early', 'twist', 'revealed', 'appeal', 'younger', 'myself', 'enjoying', 'depicted', 'liveliness', 'york', 'city', 'yorker', 'storyline', 'worked', 'together', 'smoothly', 'delivers', 'meaningful', 'messages', 'cat', 'facial', 'expressions', 'person', 'children', 'six', 'parents', 'themselves', 'reminisce', 'childhood', 'smurfs', 'adventures', 'call', 'leather', 'shoe', 'suit', 'porn', 'shit', 'anyway', 'personally', 'rachel', 'withers', 'suits', 'ryan', 'fat', 'material', 'wish', 'spoil', 'rude', 'standing', 'pizza', 'hu', 'zooming', 'sitting', 'emma', 'stone', 'hardly', 'upset', 'apparently', 'according', 'internet', 'aka', 'tumbler', 'crack', 'sound', 'both', 'male', 'sounding', 'penis', 'animal', 'thinkin', 'giant', 'twisted', 'fuck', 'skins', 'manny', 'rick', 'related', 'dreaming', 'soundtrack', 'express', 'thoughts', 'feelings', 'without', 'describing', 'specific', 'third', 'widely', 'believed', 'lead', 'warner', 'brothers', 'adapt', 'flash', 'wonder', 'woman', 'among', 'possibly', 'others', 'justice', 'ritual', 'superman', 'burden', 'telling', 'inevitable', 'sequels', 'fans', 'sorry', 'owes', 'secondly', 'marvell', 'geek', 'experienced', 'fair', 'share', 'disappointments', 'decade', 'negatives', 'list', 'positives', 'rush', 'clarke', 'duncan', 'roles', 'additions', 'casting', 'mark', 'role', 'finally', 'particular', 'stand', 'fighter', 'jet', 'sequence', 'spite', 'mention', 'working', 'significant', 'starts', 'chewing', 'scenery', 'dollar', 'steak', 'jordan', 'flies', 'planet', 'baiting', 'developments', 'caused', 'noble', 'effort', 'apart', 'seams', 'painful', 'begin', 'listing', 'superficial', 'ranges', 'mediocrity', 'blame', 'seth', 'rogan', 'car', 'black', 'beauty', 'guns', 'sweet', 'kato', 'whose', 'j', 'perfectly', 'friends', 'hornet', 'expected', 'seriousness', 'gets', 'teams', 'talent', 'super', 'bowl', 'champion', 'ends', 'cart', 'team', 'dismissed', 'round', 'playoffs', 'potential', 'table', 'describes', 'grateful', 'given', 'strikes', 'against', 'production', 'worse', 'decisions', 'camara', 'started', 'rolling', 'unfortunate', 'side', 'raising', 'unreasonable', 'levels', 'november', 'immediately', 'near', 'final', 'product', 'ultimately', 'order', 'ride', 'wanting', 'battle', 'jon', 'favreau', 'hire', 'director', 'competent', 'sequences', 'certainly', 'incoherent', 'impossible', 'follow', 'slope', 'typical', 'bay', 'memorable', 'fondly', 'remembered', 'robert', 'jr', 'steels', 'damn', 'playing', 'variation', 'famous', 'current', 'trying', 'ot', 'pull', 'blast', 'second', 'rounded', 'sam', 'rockwell', 'doc', 'cliched', 'stock', 'walking', 'cliches', 'carrying', 'arcs', 'screenplay', 'credit', 'results', 'snap', 'heh', 'pet', 'carrie', 'wore', 'horrendous', 'hideous', 'hats', 'catching', 'fashion', 'bumped', 'clowns', 'desert', 'premise', 'cut', 'wedding', 'riding', 'camels', 'troup', 'stopped', 'charlotte', 'closet', 'id', 'tron', 'computers', 'every', 'kinda', 'controls', 'lives', 'writers', 'wavelength', 'lip', 'smacking', 'pacing', 'uh', 'references', 'connection', 'ones', 'flynn', 'enters', 'grid', 'draws', 'waste', 'exposition', 'minute', 'games', 'involving', 'cho', 'choreography', 'fights', 'happy', 'meets', 'father', 'after', 'disconnection', 'happens', 'finds', 'whatever', 'wise', 'naive', 'clue', 'program', 'created', 'pulls', 'bunny', 'boiler', 'jealous', 'psycho', 'stalker', 'bitch', 'idiotic', 'villains', 'cause', 'freaky', 'okay', 'want', 'world', 'using', 'worst', 'infiltrate', 'system', 'detonate', 'nukes', 'work', 'creative', 'inventive', 'brought', 'equal', 'brush', 'mey', 'hated', 'wooden', 'places', 'witty', 'may', 'police', 'cop', 'kim', 'kimberly', 'doing', 'seem', 'learn', 'further', 'mary', 'elizabeth', 'winstead', 'actress', 'hers', 'beautiful', 'talented', 'displays', 'emotional', 'distress', 'stress', 'help', 'notice', 'hyped', 'irrelevant', 'hoffman', 'tying', 'loose', 'strangers', 'missed', 'tied', 'tie', 'introduced', 'luckily', 'general', 'ending', 'shocking', 'usual', 'surprising', 'se', 'seriously', 'leading', 'closure', 'door', 'wide', 'open', 'wind', 'blow', 'fit', 'congratulations', 'smack', 'hell', 'excuse', 'traps', 'balances', 'jumpy', 'loves', 'immune', 'small', 'soldiers', 'insidious', 'cracked', 'streight', 'cringe', 'jumped', 'friend', 'home', 'likes', 'atmosphere', 'hah', 'everytime', 'afterwards', 'cope', 'fake', 'yet', 'video', 'allright', 'threw', 'dry', 'couple', 'redeemed', 'department', 'whoever', 'writer', 'short', 'above', 'reviews', 'seems', 'companies', 'pushing', 'ahead', 'means', 'pleasantly', 'thoroughly', 'line', 'tug', 'heart', 'baby', 'animals', 'predictable', 'anne', 'hathaway', 'singing', 'idea', 'sing', 'normally', 'animated', 'hurry', 'dying', 'house', 'night', 'blockbuster', 'hit', 'cap', 'captain', 'america', 'thor', 'catapult', 'charlie', 'winning', 'establish', 'shows', 'recent', 'flop', 'cape', 'established', 'sitcoms', 'books', 'build', 'tights', 'hammer', 'mission', 'fairly', 'quickly', 'directors', 'comics', 'pompous', 'individual', 'building', 'jane', 'foster', 'natalie', 'portman', 'crew', 'belabored', 'earth', 'sounded', 'earthlings', 'shield', 'involvement', 'cooler', 'reference', 'gama', 'radiation', 'christina', 'swear', 'else', 'noone', 'moves', 'feels', 'dancers', 'wonderful', 'sexy', 'gorgeous', 'songs', 'matches', 'theme', 'cabaret', 'stars', 'considering', 'spend', 'premiere', 'dickens', 'changed', 'delightful', 'explain', 'animation', 'forget', 'concerns', 'english', 'annoyed', 'american', 'generally', 'accents', 'doubt', 'screenings', 'chosen', 'glad', 'hate', 'christmas', 'commercialization', 'families', 'soon', 'previews', 'honest', 'convince', 'sixteen', 'dudes', 'theatre', 'beyond', 'gotta', 'blown', 'epic', 'regret', 'eric', 'decides', 'train', 'paranoid', 'chick', 'skipping', 'past', 'attitude', 'festival', 'polished', 'convinced', 'dude', 'seeded', 'bourne', 'identity', 'willy', 'add', 'visually', 'confusion', 'grows', 'woods', 'music', 'drove', 'engaging', 'hanna', 'case', 'ronan', 'cate', 'blanchett', 'puts', 'unusual', 'soundtracks', 'pulse', 'pounding', 'colorful', 'b', 'unique', 'respect', 'wright', 'tried', 'non', 'stop', 'took', 'compare', 'priscilla', 'suggest', 'surpassed', 'usually', 'plan', 'glory', 'details', 'wait', 'hands', 'until', 'james', 'fray', 'alex', 'unbelievable', 'eyes', 'justin', 'timberlake', 'duo', 'bedroom', 'weight', 'women', 'steamy', 'amount', 'skin', 'showed', 'taste', 'woody', 'harelson', 'added', 'dimension', 'picture', 'alone', 'unless', 'ladies', 'thumbs', 'talking', 'finding', 'silly', 'threadbare', 'development', 'nil', 'none', 'matter', 'd', 'ideal', 'seats', 'sit', 'theater', 'improved', 'color', 'mess', 'least', 'tempted', 'winds', 'dolby', 'hope', 'eventually', 'burned', 'society', 'gimmick', 'quality', 'regular', 'dramatic', 'ridiculously', 'expensive', 'dragon', 'consider', 'currently', 'beautifully', 'problems', 'awkward', 'boy', 'tired', 'angry', 'laughter', 'massive', 'hole', 'size', 'mountain', 'explanation', 'creepy', 'grade', 'minus', 'spectacular', 'flying', 'owls', 'complaint', 'slumber', 'mood', 'bed', 'somehow', 'armor', 'skip', 'term', 'clash', 'titans', 'came', 'release', 'rushed', 'medusa', 'kid', 'scar', 'scarier', 'lay', 'nap', 'taking', 'dozing', 'lobby', 'red', 'box', 'buck', 'hey', 'disappointment', 'duty', 'suck', 'fest', 'zeus', 'sparkly', 'distracting', 'preview', 'hype', 'pretend', 'lasts', 'ne', 'disappointing', 'buy', 'scorpion', 'driftwood', 'fire', 'percy', 'jackson', 'glandon', 'laws', 've', 'free', 'pair', 'glasses', 'tom', 'cruise', 'dumb', 'million', 'kate', 'hudson', 'rise', 'trouble', 'blah', 'rain', 'yea', 'unpredictable', 'rent', 'sucker', 'punch', 'entertained', 'la', 'slog', 'uninteresting', 'ambitious', 'idiosyncratic', 'failure', 'knock', 'conventionally', 'satisfying', 'drama', 'path', 'freedom', 'compelling', 'told', 'musical', 'broad', 'mainstream', 'cult', 'common', 'opera', 'ballet', 'narrative', 'remains', 'spending', 'momentum', 'romance', 'sex', 'keep', 'engaged', 'holders', 'spectacles', 'lake', 'movement', 'dancing', 'sets', 'white', 'girls', 'wa', 'rated', 'won', 'supporting', 'humor', 'chuckled', 'laughs', 'lie', 'along', 'viewing', 'dreamworks', 'hoping', 'ants', 'kung', 'fu', 'panda', 'main', 'draw', 'ridiculous', 'bright', 'colors', 'legacy', 'possible', 'counts', 'judge', 'fails', 'nah', 'horrible', 'mixed', 'bag', 'wobbly', 'lacks', 'areas', 'sheer', 'prettier', 'framed', 'lit', 'tunnel', 'kinetic', 'william', 'fichtner', 'hysterical', 'liners', 'tacky', 'gun', 'date', 'goer', 'benefits', 'strings', 'attached', 'during', 'brilliant', 'crying', 'breaks', 'definitely', 'sister', 'natural', 'renee', 'helen', 'hunt', 'twister', 'talks', 'healthy', 'relationship', 'positive', 'depressing', 'countryside', 'across', 'ireland', 'astoundingly', 'destroyed', 'castle', 'badly', 'although', 'honestly', 'flick', 'under', 'inspection', 'destination', 'plausible', 'based', 'whether', 'dublin', 'brings', 'amy', 'adams', 'matthew', 'goode', 'each', 'banter', 'dislike', 'poop', 'theatres', 'starring', 'guardians', 'land', 'suckers', 'panned', 'garbage', 'stuttering', 't', 'thematically', 'heroism', 'ownership', 'resonated', 'appreciated', 'essential', 'comedian', 'named', 'dave', 'chapelle', 'rock', 'african', 'culture', 'perceive', 'essentially', 'acceptable', 'hispanic', 'inappropriate', 'racist', 'zach', 'snyder', 'ostensibly', 'female', 'empowerment', 'clearing', 'throat', 'slapping', 'violence', 'clapping', 'comment', 'empowered', 'dominated', 'societies', 'men', 'distract', 'damage', 'prevent', 'asserting', 'sh', 'haters', 'club', 'benefit', 'offer', 'offered', 'giggle', 'puss', 'boots', 'donkey', 'rivalry', 'plain', 'simply', 'dull', 'highly', 'discouraged', 'anyone', 'forced', 'parent', 'spiderman', 'agree', 'negative', 'remotely', 'introduction', 'justine', 'already', 'minor', 'addition', 'pointless', 'pissed', 'walked', 'rate', 'points', 'eagle', 'barrels', 'pointed', 'stereotypical', 'traits', 'asking', 'questions', 'staying', 'sunsets', 'landscapes', 'realistic', 'aw', 'ronny', 'johnny', 'posse', 'chased', 'possums', 'prairie', 'dogs', 'covered', 'wagon', 'horse', 'cowboy', 'chase', 'late', 'held', 'philly', 'depp', 'corpse', 'bride', 'falls', 'bounced', 'highway', 'run', 'henry', 'chameleon', 'quirky', 'perverted', 'passes', 'ramble', 'sigh', 'missing', 'wit', 'arent', 'adults', 'lack', 'lackluster', 'chuckle', 'forewarned', 'til', 'rental', 'future', 'ben', 'stiller', 'museum', 'saving', 'renting', 'tongue', 'clicking', 'nine', 'ninety', 'screening', 'plus', 'dig', 'connected', 'cheesy', 'blood', 'likable', 'important', 'pick', 'solid', 'normal', 'willing', 'rainy', 'price', 'midnight', 'weekend', 'safely', 'assure', 'inclined', 'differs', 'radio', 'observer', 'surprise', 'inserted', 'wouldve', 'nailed', 'stylized', 'developing', 'hero', 'butt', 'interpret', 'extra', 'spark', 'truly', 'appealing', 'engages', 'spin', 'longer', 'shorter', 'browning', 'mediocre', 'feeling', 'frankly', 'implausible', 'uninvited', 'stunning', 'deliver', 'upstaged', 'either', 'hits', 'isaak', 'jena', 'malone', 'soft', 'spoken', 'rocket', 'stealing', 'abby', 'cornish', 'pea', 'troubled', 'reluctant', 'pack', 'misses', 'vanessa', 'hudgens', 'presents', 'greatness', 'atrocious', 'carla', 'gugino', 'vera', 'gorski', 'whos', 'undeveloped', 'hamm', 'scott', 'glenn', 'stories', 'hurts', 'drastically', 'medio', 'stellar', 'superb', 'lows', 'stabilize', 'concerned', 'excitement', 'wont', 'joke', 'attract', 'viewers', 'please', 'resist', 'intestinal', 'journey', 'rectum', 'swimming', 'pool', 'drain', 'tire', 'decapitation', 'wow', 'death', 'nearly', 'harsh', 'race', 'stadium', 'mall', 'amounts', 'die', 'craziest', 'buddy', 'unbelievably', 'shocked', 'full', 'warming', 'violent', 'dad', 'protecting', 'bend', 'outsiders', 'protective', 'safe', 'touching', 'brad', 'bird', 'boyfriend', 'picked', 'moving', 'handle', 'emotions', 'overcome', 'buzz', 'lately', 'controversy', 'friendly', 'warm', 'fuzzy', 'incredibly', 'humongous', 'tale', 'complicated', 'formula', 'obvious', 'silvestre', 'terrific', 'shape', 'twice', 'significantly', 'twenty', 'ago', 'billed', 'triple', 'arnold', 'bruce', 'willis', 'hollow', 'knowing', 'prime', 'breath', 'monumental', 'cinematic', 'ship', 'u', 'uniting', 'planning', 'earlier', 'careers', 'instantly', 'kiss', 'concept', 'execute', 'separate', 'gosh', 'charm', 'obnoxious', 'protagonist', 'unlike', 'tham', 'slightly', 'endearing', 'jack', 'kicks', 'handsome', 'w', 'skills', 'cameron', 'diaz', 'plucky', 'useless', 'hi', 'weather', 'lived', 'died', 'whatsoever', 'motivation', 'genuine', 'affection', 'beings', 'princess', 'frog', 'o', 'per', 'speechless', 'smooth', 'hand', 'bear', 'atlantis', 'stich', 'range', 'considered', 'failed', 'franchise', 'jimmy', 'freaked', 'spent', 'freaking', 'sic', 'wade', 'reynolds', 'bill', 'marvel', 'zero', 'busts', 'caps', 'air', 'rans', 'bodies', 'wades', 'sword', 'decided', 'toss', 'random', 'nobody', 'insist', 'torturing', 'sabre', 'tooth', 'lieb', 'schriever', 'tremendously', 'portrayal', 'hair', 'throws', 'truck', 'fred', 'dukes', 'blob', 'hood', 'wolf', 'louis', 'guessed', 'narrow', 'mad', 'wished', 'peter', 'cleaning', 'amanda', 'pretending', 'married', 'marry', 'hundred', 'nicer', 'annoying', 'traveled', 'cross', 'personality', 'charismatic', 'dynamic', 'trust', 'contains', 'rea', 'faithful', 'zombie', 'sub', 'maintains', 'detached', 'satire', 'genre', 'events', 'watchman', 'uses', 'apply', 'use', 'features', 'columbus', 'rules', 'surviving', 'stylistic', 'edge', 'imagining', 'tarantino', 'streams', 'cooks', 'ask', 'nicholas', 'cage', 'kinds', 'sorcerer', 'witch', 'voodoo', 'tiring', 'onscreen', 'sleeping', 'g', 'orgasm', 'spewing', 'single', 'season', 'changes', 'growth', 'discovery', 'confusing', 'solved', 'dilemma', 'removing', 'betty', 'wiped', 'magic', 'joy', 'view', 'gone', 'wickedly', 'satirical', 'ups', 'fairy', 'tales', 'wings', 'pop', 'mill', 'adventure', 'chuckles', 'creators', 'award', 'voiced', 'mike', 'myers', 'eddie', 'murphy', 'antonio', 'banderas', 'bust', 'forever', 'mitchell', 'channing', 'tatum', 'transporting', 'ambushed', 'cobra', 'technologies', 'ruin', 'transformers', 'hasbro', 'toys', 'com', 'situations', 'killed', 'daddy', 'taught', 'win', 'camera', 'doll', 'depths', 'eye', 'heads', 'explode', 'torso', 'hanging', 'jumping', 'flashback', 'katrina', 'orleans', 'element', 'span', 'birth', 'choke', 'scale', 'popular', 'days', 'polyurethane', 'coating', 'tilda', 'swinton', 'sandwich', 'mayonnaise', 'tomato', 'lettuce', 'david', 'finch', 'clap', 'pass', 'neighbor', 'thinks', 'yelling', 'killers', 'thankfully', 'killer', 'everywhere', 'process', 'scream', 'underrated', 'beat', 'stab', 'experiences', 'sidney', 'universe', 'following', 'become', 'packed', 'ugly', 'sadistic', 'exercise', 'pain', 'inferred', 'trapped', 'vocation', 'emily', 'underage', 'game', 'japanese', 'temple', 'later', 'battlefield', 'lord', 'rings', 'matrix', 'comparison', 'pans', 'labyrinth', 'comedies', 'dread', 'borrowed', 'goodwin', 'yells', 'screams', 'tolerate', 'batter', 'follows', 'julia', 'roberts', 'except', 'deviate', 'scripts', 'predict', 'ourselves', 'krasinski', 'funniest', 'district', 'watched', 'turn', 'nor', 'hawk', 'nevertheless', 'designed', 'mechanical', 'explained', 'information', 'attacking', 'keeps', 'interests', 'cleverly', 'sounds', 'sell', 'erin', 'eckart', 'sells', 'names', 'bland', 'forgettable', 'theyve', 'overrated', 'fourth', 'vibe', 'bringing', 'kiddy', 'quote', 'dirty', 'waffle', 'cousins', 'chuckling', 'biased', 'oldies', 'older', 'pixar', 'woke', 'wondering', 'di', 'kidding', 'towards', 'fast', 'attempting', 'jesus', 'reached', 'diabolical', 'clearly', 'dragged', 'girlfriends', 'sew', 'balls', 'voluntarily', 'willingly', 'goo', 'candle', 'prayer', 'continuation', 'lies', 'rustle', 'miranda', 'channeling', 'consistency', 'swiss', 'cheese', 'glossed', 'grew', 'rating', 'wayans', 'watered', 'version', 'busting', 'airplane', 'campy', 'cheerleader', 'barely', 'neat', 'intensity', 'definite', 'nerves', 'sneak', 'george', 'lopez', 'neil', 'patrick', 'harris', 'katy', 'perry', 'stay', 'surprises', 'finish', 'tease', 'mystery', 'clear', 'remake', 'identical', 'pops', 'group', 'interact', 'poorly', 'personalities', 'dies', 'mourn', 'attachment', 'sucks', 'gains', 'unknown', 'co', 'tells', 'known', 'f', 'exact', 'insight', 'sa', 'finale', 'media', 'word', 'mouth', 'spreading', 'interviews', 'shia', 'lacked', 'built', 'matters', 'forty', 'titanic', 'passionate', 'verdict', 'complete', 'experience', 'budget', 'wasting', 'holding', 'awake', 'device', 'killing', 'amnesia', 'kills', 'unnecessary', 'disagree', 'hot', 'page', 'sat', 'sparks', 'notebook', 'dear', 'fond', 'wary', 'miley', 'cyrus', 'hannah', 'montana', 'percent', 'overboard', 'exaggerated', 'expression', 'throughout', 'pouty', 'eyebrows', 'shed', 'tho', 'arms', 'crossed', 'distance', 'beach', 'shock', 'sadness', 'presumed', 'bugged', 'prepare', 'ruined', 'cars', 'nemo', 'wally', 'artistic', 'channel', 'machete', 'taken', 'exploitation', 'terror', 'several', 'lips', 'amused', 'quick', 'slash', 'church', 'shootout', 'brief', 'alright', 'seconds', 'brooke', 'tuesday', 'amazingly', 'awards', 'steven', 'russel', 'jim', 'carry', 'ian', 'favorites', 'faked', 'aids', 'prison', 'lover', 'aspects', 'overlooked', 'academy', 'kings', 'speech', 'valentine', 'heartbreaking', 'contrasted', 'state', 'dynamics', 'contrived', 'pleaser', 'dramas', 'thumping', 'audiences', 'priest', 'insane', 'touches', 'vampires', 'appear', 'grads', 'trilogy', 'notable', 'christopher', 'plumber', 'types', 'melodramatic', 'cave', 'monster', 'reminds', 'mines', 'moria', 'laughed', 'kin', 'tv', 'collector', 'figures', 'rough', 'corny', 'm', 'terminator', 'salvation', 'write', 'nichols', 'dennis', 'quaid', 'eccleston', 'ray', 'park', 'snake', 'international', 'slavishly', 'devoted', 'nov', 'novella', 'charles', 'terrified', 'terrifying', 'christianity', 'legalistic', 'burn', 'christian', 'devotion', 'therefore', 'commentary', 'debtors', 'instance', 'jive', 'century', 'slavish', 'amusement', 'likely', 'london', 'demon', 'horses', 'chasing', 'polar', 'welcome', 'robin', 'crow', 'dreading', 'lowered', 'foremost', 'spoof', 'costner', 'prince', 'fee', 'edgy', 'thirteen', 'fourteen', 'focus', 'suffers', 'kingdom', 'heaven', 'builds', 'catastrophic', 'instances', 'blanchette', 'buying', 'mid', 'thirties', 'oldest', 'chipper', 'twenties', 'meanwhile', 'papa', 'travel', 'overly', 'discourage', 'footage', 'wasted', 'upbeat', 'issues', 'stressed', 'somebody', 'critiquing']\n"
     ]
    }
   ],
   "source": [
    "# Check how many words are in the vocabulary\n",
    "vocab_size = len(word2id)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"vocabulary: {list(word2id.keys())}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T18:36:52.465737300Z",
     "start_time": "2024-12-02T18:36:52.326594800Z"
    }
   },
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T18:37:10.130188100Z",
     "start_time": "2024-12-02T18:37:10.038482300Z"
    }
   },
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary size: 2733\n",
      "Size of vocabulary (word2id) after pretrained 1: 2724\n",
      "Size of pre-trained embeddings: torch.Size([2724, 300])\n",
      "Size of vocabulary (word2id): 2724\n",
      "Using glove\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Viki\\AppData\\Local\\Temp\\ipykernel_34144\\4287430988.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_emb, word2id = torch.load(CACHE_PATH)\n",
      "C:\\Users\\Viki\\Documents\\Thesis\\tryout3\\.venv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "C:\\Users\\Viki\\AppData\\Local\\Temp\\ipykernel_34144\\4287430988.py:70: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  train_iter = tqdm_notebook(train_loader)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95baff09d77a4b2895c13a3ce35e67ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.3099\n",
      "Loop completed\n",
      "Validation loss: 2.7348\n",
      "Current patience: 8, current trial: 3.\n",
      "Found new best model on dev set!\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2067249ee62d4fbaa8a0a2c2882162f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.279\n",
      "Loop completed\n",
      "Validation loss: 2.7384\n",
      "Current patience: 8, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cec82df2102e444cbbc021631c59dd98"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.27\n",
      "Loop completed\n",
      "Validation loss: 2.7254\n",
      "Current patience: 7, current trial: 3.\n",
      "Found new best model on dev set!\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b5b2b01032e4dc79bbf630f7315bc60"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.2806\n",
      "Loop completed\n",
      "Validation loss: 2.7313\n",
      "Current patience: 8, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88dd0ed44a254da898e2abd3c328cd4c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.2716\n",
      "Loop completed\n",
      "Validation loss: 2.7278\n",
      "Current patience: 7, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8811031558c423e896990085f609801"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.2666\n",
      "Loop completed\n",
      "Validation loss: 2.7232\n",
      "Current patience: 6, current trial: 3.\n",
      "Found new best model on dev set!\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd9036fc66e34ffeaf34cd188c3e5401"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.2681\n",
      "Loop completed\n",
      "Validation loss: 2.7185\n",
      "Current patience: 8, current trial: 3.\n",
      "Found new best model on dev set!\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b78d44670e474fbb9bdf2c2e015d397b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.269\n",
      "Loop completed\n",
      "Validation loss: 2.7178\n",
      "Current patience: 8, current trial: 3.\n",
      "Found new best model on dev set!\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "43f1eb27678445cc843f9d73081b4bff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.2576\n",
      "Loop completed\n",
      "Validation loss: 2.7037\n",
      "Current patience: 8, current trial: 3.\n",
      "Found new best model on dev set!\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "445460974ea543fdaba95be7c94453b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.2432\n",
      "Loop completed\n",
      "Validation loss: 2.6953\n",
      "Current patience: 8, current trial: 3.\n",
      "Found new best model on dev set!\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56f04162374540499d38426fd6f063f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.2197\n",
      "Loop completed\n",
      "Validation loss: 2.6703\n",
      "Current patience: 8, current trial: 3.\n",
      "Found new best model on dev set!\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62a2d7cb657a4a01b8ae4fe44d51c119"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.1803\n",
      "Loop completed\n",
      "Validation loss: 2.6357\n",
      "Current patience: 8, current trial: 3.\n",
      "Found new best model on dev set!\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6d5bb1e22a64b749368e2a5c450e828"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.1145\n",
      "Loop completed\n",
      "Validation loss: 2.5633\n",
      "Current patience: 8, current trial: 3.\n",
      "Found new best model on dev set!\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a9a1c7b311b463fb886f512a8e36069"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.061\n",
      "Loop completed\n",
      "Validation loss: 2.4995\n",
      "Current patience: 8, current trial: 3.\n",
      "Found new best model on dev set!\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b1b191fa586b4570a23cf95f62a3fa68"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.8947\n",
      "Loop completed\n",
      "Validation loss: 2.4277\n",
      "Current patience: 8, current trial: 3.\n",
      "Found new best model on dev set!\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f78266ce06014712a553a5af7bd09203"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.8211\n",
      "Loop completed\n",
      "Validation loss: 2.4744\n",
      "Current patience: 8, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4da693f6447a427793f8f25125a2e741"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.6541\n",
      "Loop completed\n",
      "Validation loss: 2.3861\n",
      "Current patience: 7, current trial: 3.\n",
      "Found new best model on dev set!\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "170d7c800e9c4cd39d2693f4bebfa80d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.53\n",
      "Loop completed\n",
      "Validation loss: 2.3833\n",
      "Current patience: 8, current trial: 3.\n",
      "Found new best model on dev set!\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b9cc0689159f4251ae2aa578fc65cc79"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.4564\n",
      "Loop completed\n",
      "Validation loss: 2.4367\n",
      "Current patience: 8, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e0ae77bf1c04f85950de914dceba56d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.3384\n",
      "Loop completed\n",
      "Validation loss: 2.381\n",
      "Current patience: 7, current trial: 3.\n",
      "Found new best model on dev set!\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9bd708a4fac54f2ea5f7f66acd487e34"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.2027\n",
      "Loop completed\n",
      "Validation loss: 2.3755\n",
      "Current patience: 8, current trial: 3.\n",
      "Found new best model on dev set!\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e1907ff7d174439866d655444c028b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.1635\n",
      "Loop completed\n",
      "Validation loss: 2.4042\n",
      "Current patience: 8, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "312bac1f94fb4cca9389be47b5b4b7e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0418\n",
      "Loop completed\n",
      "Validation loss: 2.5616\n",
      "Current patience: 7, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cab7436511e3422ea0da5df3db634197"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.9554\n",
      "Loop completed\n",
      "Validation loss: 2.4299\n",
      "Current patience: 6, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c883e89e2d3e487b9585bb569ec25a59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.8724\n",
      "Loop completed\n",
      "Validation loss: 2.5664\n",
      "Current patience: 5, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "96ff8a83173849bfa4c34d0aca15458d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.8298\n",
      "Loop completed\n",
      "Validation loss: 2.3848\n",
      "Current patience: 4, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2628f78a5e5f41e1b97b7d3c9c2a5ba9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7701\n",
      "Loop completed\n",
      "Validation loss: 2.5144\n",
      "Current patience: 3, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b331662e53b411ca4b8f78cdd76f413"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7304\n",
      "Loop completed\n",
      "Validation loss: 2.4101\n",
      "Current patience: 2, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3bdc326e871a41438a5ec92b10c95342"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6185\n",
      "Loop completed\n",
      "Validation loss: 2.4966\n",
      "Current patience: 1, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14df52f4609b45e9ab23c30a82b3fe24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5717\n",
      "Loop completed\n",
      "Validation loss: 2.4526\n",
      "Current patience: 0, current trial: 3.\n",
      "Running out of patience, loading previous best model.\n",
      "Current learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Viki\\AppData\\Local\\Temp\\ipykernel_34144\\4287430988.py:128: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model.std'))\n",
      "C:\\Users\\Viki\\AppData\\Local\\Temp\\ipykernel_34144\\4287430988.py:129: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  optimizer.load_state_dict(torch.load('optim.std'))\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23103cf83e434e858421de3c770a4b7b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.1179\n",
      "Loop completed\n",
      "Validation loss: 2.3812\n",
      "Current patience: 8, current trial: 2.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f80884104f0242388b355df7027317a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.1248\n",
      "Loop completed\n",
      "Validation loss: 2.3833\n",
      "Current patience: 7, current trial: 2.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4d70d1ebf7f448fb3c1e8679b94f07a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.1108\n",
      "Loop completed\n",
      "Validation loss: 2.3894\n",
      "Current patience: 6, current trial: 2.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7377ac4e7a204299b5cbbdae5823c1ae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.1068\n",
      "Loop completed\n",
      "Validation loss: 2.384\n",
      "Current patience: 5, current trial: 2.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fb843bb23f56486faa5bb0f780828235"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0736\n",
      "Loop completed\n",
      "Validation loss: 2.3819\n",
      "Current patience: 4, current trial: 2.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb9ea8ee5c0f49869610b9927ee639c1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0712\n",
      "Loop completed\n",
      "Validation loss: 2.3887\n",
      "Current patience: 3, current trial: 2.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b605b4aaeed244988a70d74d05351d67"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0708\n",
      "Loop completed\n",
      "Validation loss: 2.3864\n",
      "Current patience: 2, current trial: 2.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06cbd6f24325495fb78bacade46a8834"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0435\n",
      "Loop completed\n",
      "Validation loss: 2.3922\n",
      "Current patience: 1, current trial: 2.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d5b058bd860744f0a678c8ee4a704c98"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.043\n",
      "Loop completed\n",
      "Validation loss: 2.3924\n",
      "Current patience: 0, current trial: 2.\n",
      "Running out of patience, loading previous best model.\n",
      "Current learning rate: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92e601060a824fcabcd9c9a87987091b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.1067\n",
      "Loop completed\n",
      "Validation loss: 2.3806\n",
      "Current patience: 8, current trial: 1.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac96874f94f54e72b150b3ff2033c46c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.1182\n",
      "Loop completed\n",
      "Validation loss: 2.3854\n",
      "Current patience: 7, current trial: 1.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "03c81983cc8b4e688d6b58480eea6b95"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0947\n",
      "Loop completed\n",
      "Validation loss: 2.3893\n",
      "Current patience: 6, current trial: 1.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba642f91c4974fd1b4575b34994ebc54"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0993\n",
      "Loop completed\n",
      "Validation loss: 2.3845\n",
      "Current patience: 5, current trial: 1.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "44cc37a6b54341c39ec3d4311e7ce05e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0874\n",
      "Loop completed\n",
      "Validation loss: 2.385\n",
      "Current patience: 4, current trial: 1.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46bbf6db68b448a69c5faeb7fb56c206"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0777\n",
      "Loop completed\n",
      "Validation loss: 2.3902\n",
      "Current patience: 3, current trial: 1.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8116160677ea4e9f9a742f41df4862ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0669\n",
      "Loop completed\n",
      "Validation loss: 2.3962\n",
      "Current patience: 2, current trial: 1.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d3de08ac0434e808ad1a16b2ffbe9da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0479\n",
      "Loop completed\n",
      "Validation loss: 2.4004\n",
      "Current patience: 1, current trial: 1.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2bd5ad43b1a04d658d8cd7cf939a29fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0413\n",
      "Loop completed\n",
      "Validation loss: 2.3967\n",
      "Current patience: 0, current trial: 1.\n",
      "Running out of patience, loading previous best model.\n",
      "Current learning rate: 1e-05\n",
      "Running out of patience, early stopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Viki\\AppData\\Local\\Temp\\ipykernel_34144\\4287430988.py:137: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model.std'))\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[47], line 150\u001B[0m\n\u001B[0;32m    148\u001B[0m     y \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mcuda()\n\u001B[0;32m    149\u001B[0m     l \u001B[38;5;241m=\u001B[39m l\u001B[38;5;241m.\u001B[39mcuda()\n\u001B[1;32m--> 150\u001B[0m y_tilde \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ml\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    151\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion_test(y_tilde, y)\n\u001B[0;32m    152\u001B[0m y_true\u001B[38;5;241m.\u001B[39mappend(y_tilde\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy())\n",
      "File \u001B[1;32m~\\Documents\\Thesis\\tryout3\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\Thesis\\tryout3\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[1;32mIn[42], line 59\u001B[0m, in \u001B[0;36mSingleEncoderModelText.forward\u001B[1;34m(self, x, lengths)\u001B[0m\n\u001B[0;32m     55\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m     56\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInput indices out of range! Min index: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mmin()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Max index: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mmax()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Vocabulary size: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdic_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     57\u001B[0m     )\n\u001B[0;32m     58\u001B[0m \u001B[38;5;66;03m# Step 1: Embedding layer\u001B[39;00m\n\u001B[1;32m---> 59\u001B[0m embedded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# [batch_size, seq_length] -> [batch_size, seq_length, embed_dim]\u001B[39;00m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;66;03m# Step 2: GRU layer\u001B[39;00m\n\u001B[0;32m     62\u001B[0m gru_out, hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgru(embedded)  \u001B[38;5;66;03m# gru_out: [batch_size, seq_length, hidden_dim], hidden: [num_layers, batch_size, hidden_dim]\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Thesis\\tryout3\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\Thesis\\tryout3\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\Documents\\Thesis\\tryout3\\.venv\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:190\u001B[0m, in \u001B[0;36mEmbedding.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    189\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    191\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    192\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    193\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    194\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    195\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    196\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    197\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Thesis\\tryout3\\.venv\\lib\\site-packages\\torch\\nn\\functional.py:2551\u001B[0m, in \u001B[0;36membedding\u001B[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[0;32m   2545\u001B[0m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[0;32m   2546\u001B[0m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[0;32m   2547\u001B[0m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[0;32m   2548\u001B[0m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[0;32m   2549\u001B[0m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[0;32m   2550\u001B[0m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[1;32m-> 2551\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mIndexError\u001B[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed_all(123)\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "MAX_EPOCH = 1000\n",
    "\n",
    "dic_size = len(word2id)\n",
    "print(f\"Dictionary size: {dic_size}\")\n",
    "\n",
    "# define some model settings and hyper-parameters\n",
    "input_sizes = dic_size\n",
    "hidden_sizes = int(dic_size)\n",
    "fc1_size = hidden_sizes\n",
    "dropout = 0.25\n",
    "output_size = 1\n",
    "curr_patience = patience = 8\n",
    "num_trials = 3\n",
    "grad_clip_value = 1.0\n",
    "weight_decay = 0.1\n",
    "\n",
    "if os.path.exists(CACHE_PATH):\n",
    "    pretrained_emb, word2id = torch.load(CACHE_PATH)\n",
    "    print(f\"Size of vocabulary (word2id) after pretrained 1: {len(word2id)}\")\n",
    "\n",
    "elif WORD_EMB_PATH is not None:\n",
    "    pretrained_emb = load_emb(word2id, WORD_EMB_PATH)\n",
    "    torch.save((pretrained_emb, word2id), CACHE_PATH)\n",
    "    print(f\"Size of vocabulary (word2id) after pretrained 2: {len(word2id)}\")\n",
    "    print(list(word2id.keys()))\n",
    "else:\n",
    "    pretrained_emb = None\n",
    "    \n",
    "print(f\"Size of pre-trained embeddings: {pretrained_emb.shape}\")\n",
    "print(f\"Size of vocabulary (word2id): {len(word2id)}\")\n",
    "\n",
    "\n",
    "\n",
    "model = SingleEncoderModelText(dic_size=dic_size,\n",
    "                                use_glove=True,\n",
    "                                encoder_size=300,\n",
    "                                num_layers=2,\n",
    "                                lr=0.001,\n",
    "                                hidden_dim=128,\n",
    "                                dr=0.2,\n",
    "                                num_categories=64,\n",
    "                                output_size=output_size)\n",
    "\n",
    "\n",
    "if pretrained_emb is not None:\n",
    "    model.embedding.weight.data = pretrained_emb\n",
    "model.embedding.requires_grad = False\n",
    "\n",
    "optimizer = Adam([param for param in model.parameters() if param.requires_grad], weight_decay=weight_decay)\n",
    "\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "    \n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "criterion_test = nn.MSELoss(reduction='sum')\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "lr_scheduler.step() # for some reason it seems the StepLR needs to be stepped once first\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "for e in range(MAX_EPOCH):\n",
    "    model.train()\n",
    "    train_iter = tqdm_notebook(train_loader)\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch in train_iter:\n",
    "        model.zero_grad()\n",
    "        t, y, l = batch\n",
    "        batch_size = t.size(0)\n",
    "        if CUDA:\n",
    "            t = t.cuda()\n",
    "            y = y.cuda()\n",
    "            l = l.cuda()\n",
    "        \n",
    "        y_tilde = model(t, l)\n",
    "        # print(f\"batch_pred: {y_tilde.shape}\")\n",
    "        # print(f\"labels: {y.shape}\")\n",
    "        \n",
    "        loss = criterion(y_tilde, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_value_([param for param in model.parameters() if param.requires_grad], grad_clip_value)\n",
    "        optimizer.step()\n",
    "        train_iter.set_description(f\"Epoch {e}/{MAX_EPOCH}, current batch loss: {round(loss.item()/batch_size, 4)}\")\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train)\n",
    "    train_losses.append(train_loss)\n",
    "    print(f\"Training loss: {round(train_loss, 4)}\")\n",
    "    \n",
    "    print (\"Loop completed\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = 0.0\n",
    "        for batch in dev_loader:\n",
    "            model.zero_grad()\n",
    "            t, y, l = batch\n",
    "            if CUDA:\n",
    "                t = t.cuda()\n",
    "                y = y.cuda()\n",
    "                l = l.cuda()\n",
    "            y_tilde = model(t, l)\n",
    "            loss = criterion(y_tilde, y)\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "    valid_loss = valid_loss/len(dev)\n",
    "    valid_losses.append(valid_loss)\n",
    "    print(f\"Validation loss: {round(valid_loss, 4)}\")\n",
    "    print(f\"Current patience: {curr_patience}, current trial: {num_trials}.\")\n",
    "    if valid_loss <= best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        print(\"Found new best model on dev set!\")\n",
    "        torch.save(model.state_dict(), 'model.std')\n",
    "        torch.save(optimizer.state_dict(), 'optim.std')\n",
    "        curr_patience = patience\n",
    "    else:\n",
    "        curr_patience -= 1\n",
    "        if curr_patience <= -1:\n",
    "            print(\"Running out of patience, loading previous best model.\")\n",
    "            num_trials -= 1\n",
    "            curr_patience = patience\n",
    "            model.load_state_dict(torch.load('model.std'))\n",
    "            optimizer.load_state_dict(torch.load('optim.std'))\n",
    "            lr_scheduler.step()\n",
    "            print(f\"Current learning rate: {optimizer.state_dict()['param_groups'][0]['lr']}\")\n",
    "\n",
    "    if num_trials <= 0:\n",
    "        print(\"Running out of patience, early stopping.\")\n",
    "        break\n",
    "\n",
    "model.load_state_dict(torch.load('model.std'))\n",
    "y_true = []\n",
    "y_pred = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    for batch in test_loader:\n",
    "        model.zero_grad()\n",
    "        t, y, l = batch\n",
    "        if CUDA:\n",
    "            t = t.cuda()\n",
    "            y = y.cuda()\n",
    "            l = l.cuda()\n",
    "        y_tilde = model(t, l)\n",
    "        loss = criterion_test(y_tilde, y)\n",
    "        y_true.append(y_tilde.detach().cpu().numpy())\n",
    "        y_pred.append(y.detach().cpu().numpy())\n",
    "        test_loss += loss.item()\n",
    "print(f\"Test set performance: {test_loss/len(test)}\")\n",
    "y_true = np.concatenate(y_true, axis=0)\n",
    "y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "y_true_bin = y_true >= 0\n",
    "y_pred_bin = y_pred >= 0\n",
    "bin_acc = accuracy_score(y_true_bin, y_pred_bin)\n",
    "print(f\"Test set accuracy is {bin_acc}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T18:40:09.356587Z",
     "start_time": "2024-12-02T18:37:10.520071Z"
    }
   },
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# \n",
    "# class SingleEncoderModelText(nn.Module):\n",
    "#     def __init__(self, dic_size, use_glove, batch_size, encoder_size, num_layer, lr, hidden_dim, dr):\n",
    "#         super(SingleEncoderModelText, self).__init__()\n",
    "# \n",
    "#         self.dic_size = dic_size\n",
    "#         self.use_glove = use_glove\n",
    "#         self.batch_size = batch_size\n",
    "#         self.encoder_size = encoder_size\n",
    "#         self.num_layers = num_layer\n",
    "#         self.lr = lr\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.dr = dr\n",
    "#         self.embed_dim = 300 if self.use_glove else DIM_WORD_EMBEDDING\n",
    "#         self.global_step = 0  # Global step for tracking\n",
    "# \n",
    "#         # Embedding layer\n",
    "#         self.embedding = nn.Embedding(dic_size, self.embed_dim)\n",
    "# \n",
    "#         # GRU layer\n",
    "#         self.gru = nn.GRU(input_size=self.embed_dim,\n",
    "#                           hidden_size=self.hidden_dim,\n",
    "#                           num_layers=self.num_layers,\n",
    "#                           batch_first=True,\n",
    "#                           dropout=dr if self.num_layers > 1 else 0)\n",
    "# \n",
    "#         # Output layers\n",
    "#         self.fc = nn.Linear(self.hidden_dim, N_CATEGORY)\n",
    "#         self.dropout = nn.Dropout(p=self.dr)\n",
    "# \n",
    "#         # Optimizer\n",
    "#         self.optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "# \n",
    "#     def forward(self, encoder_inputs, encoder_seq_length):\n",
    "#         # Embedding lookup\n",
    "#         embedded = self.embedding(encoder_inputs)  # [batch_size, encoder_size, embed_dim]\n",
    "# \n",
    "#         # Pack padded sequence for GRU\n",
    "#         packed_input = nn.utils.rnn.pack_padded_sequence(embedded, encoder_seq_length, batch_first=True, enforce_sorted=False)\n",
    "#         packed_output, hidden = self.gru(packed_input)\n",
    "# \n",
    "#         # Take the last hidden state of the GRU\n",
    "#         # (hidden[-1] if multi-layered GRU)\n",
    "#         final_hidden = hidden[-1]  # [batch_size, hidden_dim]\n",
    "# \n",
    "#         # Fully connected layer with dropout\n",
    "#         output = self.fc(self.dropout(final_hidden))  # [batch_size, N_CATEGORY]\n",
    "#         return output\n",
    "# \n",
    "#     def compute_loss(self, logits, labels):\n",
    "#         # Binary Cross-Entropy with Logits\n",
    "#         return F.binary_cross_entropy_with_logits(logits, labels)\n",
    "# \n",
    "#     def train_batch(self, encoder_inputs, encoder_seq_length, y_labels):\n",
    "#         self.train()  # Set the model to training mode\n",
    "# \n",
    "#         # Forward pass\n",
    "#         logits = self(encoder_inputs, encoder_seq_length)\n",
    "#         loss = self.compute_loss(logits, y_labels)\n",
    "# \n",
    "#         # Backward pass and optimization\n",
    "#         self.optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         nn.utils.clip_grad_value_(self.parameters(), clip_value=10)  # Gradient clipping\n",
    "#         self.optimizer.step()\n",
    "# \n",
    "#         # Update global step\n",
    "#         self.global_step += 1\n",
    "# \n",
    "#         return loss.item()\n",
    "# \n",
    "#     def evaluate(self, encoder_inputs, encoder_seq_length, y_labels):\n",
    "#         self.eval()  # Set the model to evaluation mode\n",
    "#         with torch.no_grad():\n",
    "#             logits = self(encoder_inputs, encoder_seq_length)\n",
    "#             loss = self.compute_loss(logits, y_labels)\n",
    "#         return loss.item(), torch.sigmoid(logits)  # Return probabilities\n",
    "# \n",
    "#     def load_pretrained_embeddings(self, embeddings):\n",
    "#         # Load pre-trained embedding weights\n",
    "#         self.embedding.weight.data.copy_(torch.tensor(embeddings))\n",
    "#         self.embedding.weight.requires_grad = EMBEDDING_TRAIN\n",
    "# \n",
    "# \n",
    "# # Usage Example\n",
    "# # model = SingleEncoderModelText(dic_size=5000, use_glove=True, batch_size=32, encoder_size=50, \n",
    "# #                                num_layer=2, lr=0.001, hidden_dim=128, dr=0.5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-30T13:51:20.541825Z",
     "start_time": "2024-11-30T13:51:20.505058900Z"
    }
   },
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # FIGURE OUT HOW TO DO MDRE \n",
    "# \n",
    "# \"\"\"\n",
    "# what    : Single Encoder Model for Multi (Audio + Text)\n",
    "# \"\"\"\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.contrib import rnn\n",
    "# from tensorflow.contrib.rnn import DropoutWrapper \n",
    "# \n",
    "# from tensorflow.core.framework import summary_pb2\n",
    "# from random import shuffle\n",
    "# import numpy as np\n",
    "# from project_config import *\n",
    "# \n",
    "# from SE_model_audio import *\n",
    "# from SE_model_text import *\n",
    "# \n",
    "# \n",
    "# class SingleEncoderModelMulti:\n",
    "#     \n",
    "#     def __init__(self,\n",
    "#                  batch_size,\n",
    "#                  lr,\n",
    "#                  encoder_size_audio,  # for audio\n",
    "#                  num_layer_audio,\n",
    "#                  hidden_dim_audio,\n",
    "#                  dr_audio,\n",
    "#                  dic_size,             # for text\n",
    "#                  use_glove,\n",
    "#                  encoder_size_text,\n",
    "#                  num_layer_text,\n",
    "#                  hidden_dim_text,\n",
    "#                  dr_text\n",
    "#                 ):\n",
    "# \n",
    "#         # for audio\n",
    "#         self.encoder_size_audio = encoder_size_audio\n",
    "#         self.num_layers_audio = num_layer_audio\n",
    "#         self.hidden_dim_audio = hidden_dim_audio\n",
    "#         self.dr_audio = dr_audio\n",
    "#         \n",
    "#         self.encoder_inputs_audio = []\n",
    "#         self.encoder_seq_length_audio =[]\n",
    "#         \n",
    "#         # for text        \n",
    "#         self.dic_size = dic_size\n",
    "#         self.use_glove = use_glove\n",
    "#         self.encoder_size_text = encoder_size_text\n",
    "#         self.num_layers_text = num_layer_text\n",
    "#         self.hidden_dim_text = hidden_dim_text\n",
    "#         self.dr_text = dr_text\n",
    "#         \n",
    "#         self.encoder_inputs_text = []\n",
    "#         self.encoder_seq_length_text =[]\n",
    "# \n",
    "#         # common        \n",
    "#         self.batch_size = batch_size\n",
    "#         self.lr = lr\n",
    "#         self.y_labels =[]\n",
    "#         \n",
    "#         self.M = None\n",
    "#         self.b = None\n",
    "#         \n",
    "#         self.y = None\n",
    "#         self.optimizer = None\n",
    "# \n",
    "#         self.batch_loss = None\n",
    "#         self.loss = 0\n",
    "#         self.batch_prob = None\n",
    "#         \n",
    "#         if self.use_glove == 1:\n",
    "#             self.embed_dim = 300\n",
    "#         else:\n",
    "#             self.embed_dim = DIM_WORD_EMBEDDING\n",
    "#         \n",
    "#         # for global counter\n",
    "#         self.global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "# \n",
    "# \n",
    "#     def _create_placeholders(self):\n",
    "#         print '[launch-multi] placeholders'\n",
    "#         with tf.name_scope('multi_placeholder'):\n",
    "#             \n",
    "#             # for audio\n",
    "#             self.encoder_inputs_audio  = self.model_audio.encoder_inputs  # [batch, time_step, audio]\n",
    "#             self.encoder_seq_audio     = self.model_audio.encoder_seq\n",
    "#             self.encoder_prosody       = self.model_audio.encoder_prosody\n",
    "#             self.dr_prob_audio         = self.model_audio.dr_prob\n",
    "#             \n",
    "#             # for text\n",
    "#             self.encoder_inputs_text  = self.model_text.encoder_inputs\n",
    "#             self.encoder_seq_text     = self.model_text.encoder_seq\n",
    "#             self.dr_prob_text         = self.model_text.dr_prob\n",
    "# \n",
    "#             # common\n",
    "#             self.y_labels             = tf.placeholder(tf.float32, shape=[self.batch_size, N_CATEGORY], name=\"label\")\n",
    "#             \n",
    "#             # for using pre-trained embedding\n",
    "#             self.embedding_placeholder = self.model_text.embedding_placeholder\n",
    "# \n",
    "# \n",
    "#     def _create_model_audio(self):\n",
    "#         print '[launch-multi] create audio model'\n",
    "#         self.model_audio =  SingleEncoderModelAudio(\n",
    "#                                                         batch_size=self.batch_size,\n",
    "#                                                         encoder_size=self.encoder_size_audio,\n",
    "#                                                         num_layer=self.num_layers_audio,\n",
    "#                                                         hidden_dim=self.hidden_dim_audio,\n",
    "#                                                         lr = self.lr,\n",
    "#                                                         dr= self.dr_audio\n",
    "#                                                         )\n",
    "#         self.model_audio._create_placeholders()\n",
    "#         self.model_audio._create_gru_model()\n",
    "#         self.model_audio._add_prosody()\n",
    "#         self.model_audio._create_output_layers_for_multi()\n",
    "#         \n",
    "# \n",
    "# \n",
    "#     def _create_model_text(self):\n",
    "#         print '[launch-multi] create text model'        \n",
    "#         self.model_text = SingleEncoderModelText(\n",
    "#                                                         batch_size=self.batch_size,\n",
    "#                                                         dic_size=self.dic_size,\n",
    "#                                                         use_glove=self.use_glove,\n",
    "#                                                         encoder_size=self.encoder_size_text,\n",
    "#                                                         num_layer=self.num_layers_text,\n",
    "#                                                         hidden_dim=self.hidden_dim_text,\n",
    "#                                                         lr = self.lr,\n",
    "#                                                         dr= self.dr_text\n",
    "#                                                         )\n",
    "#         \n",
    "#         self.model_text._create_placeholders()\n",
    "#         self.model_text._create_embedding()\n",
    "#         self.model_text._use_external_embedding()\n",
    "#         self.model_text._create_gru_model()\n",
    "#         self.model_text._create_output_layers_for_multi()\n",
    "# \n",
    "# \n",
    "#     def _create_output_layers(self):\n",
    "#         print '[launch-multi] create output projection layer from (audio_final_dim/2) + (text_final_dim/2)'\n",
    "#         \n",
    "#         with tf.name_scope('multi_output_layer') as scope:\n",
    "# \n",
    "#             self.M = tf.Variable(tf.random_uniform([(self.model_audio.final_encoder_dimension/2)+(self.model_text.final_encoder_dimension/2), N_CATEGORY],\n",
    "#                                                    minval= -0.25,\n",
    "#                                                    maxval= 0.25,\n",
    "#                                                    dtype=tf.float32,\n",
    "#                                                    seed=None),\n",
    "#                                                  trainable=True,\n",
    "#                                                  name=\"similarity_matrix\")\n",
    "#             \n",
    "#             self.b = tf.Variable(tf.zeros([1], dtype=tf.float32),\n",
    "#                                                  trainable=True,\n",
    "#                                                  name=\"output_bias\")\n",
    "#             \n",
    "#             self.final_encoder = tf.concat( [self.model_audio.batch_pred, self.model_text.batch_pred], axis=1 )\n",
    "#             \n",
    "#             # e * M + b\n",
    "#             self.batch_pred = tf.matmul(self.final_encoder, self.M) + self.b\n",
    "#         \n",
    "#         with tf.name_scope('loss') as scope:\n",
    "#             \n",
    "#             self.batch_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=self.batch_pred, labels=self.y_labels )\n",
    "#             self.loss = tf.reduce_mean( self.batch_loss  )\n",
    "# \n",
    "#     \n",
    "#     def _create_optimizer(self):\n",
    "#         print '[launch-multi] create optimizer'\n",
    "#         \n",
    "#         with tf.name_scope('multi_optimizer') as scope:\n",
    "#             opt_func = tf.train.AdamOptimizer(learning_rate=self.lr)\n",
    "#             gvs = opt_func.compute_gradients(self.loss)\n",
    "#             capped_gvs = [(tf.clip_by_value(t=grad, clip_value_min=-10, clip_value_max=10), var) for grad, var in gvs]\n",
    "#             self.optimizer = opt_func.apply_gradients(grads_and_vars=capped_gvs, global_step=self.global_step)\n",
    "#     \n",
    "#     \n",
    "#     def _create_summary(self):\n",
    "#         print '[launch-multi] create summary'\n",
    "#         \n",
    "#         with tf.name_scope('summary'):\n",
    "#             tf.summary.scalar('mean_loss', self.loss)\n",
    "#             self.summary_op = tf.summary.merge_all()\n",
    "#     \n",
    "#     \n",
    "#     def build_graph(self):\n",
    "#         self._create_model_audio()\n",
    "#         self._create_model_text()\n",
    "#         self._create_placeholders()\n",
    "#         self._create_output_layers()\n",
    "#         self._create_optimizer()\n",
    "#         self._create_summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-30T13:51:20.694042900Z",
     "start_time": "2024-11-30T13:51:20.646974100Z"
    }
   },
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # FIGURE OUT HOW TO DO MDREA\n",
    "# #-*- coding: utf-8 -*-\n",
    "# \n",
    "# \"\"\"\n",
    "# what    : Single Encoder Model for Multi (Audio + Text) with attention\n",
    "# \"\"\"\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.contrib import rnn\n",
    "# from tensorflow.contrib.rnn import DropoutWrapper \n",
    "# \n",
    "# from tensorflow.core.framework import summary_pb2\n",
    "# from random import shuffle\n",
    "# import numpy as np\n",
    "# from project_config import *\n",
    "# \n",
    "# from SE_model_audio import *\n",
    "# from SE_model_text import *\n",
    "# # from model_util import luong_attention\n",
    "# from model_luong_attention import luong_attention\n",
    "# \n",
    "# \n",
    "# class SingleEncoderModelMultiAttn:\n",
    "#     \n",
    "#     def __init__(self,\n",
    "#                  batch_size,\n",
    "#                  lr,\n",
    "#                  encoder_size_audio,  # for audio\n",
    "#                  num_layer_audio,\n",
    "#                  hidden_dim_audio,\n",
    "#                  dr_audio,\n",
    "#                  dic_size,             # for text\n",
    "#                  use_glove,\n",
    "#                  encoder_size_text,\n",
    "#                  num_layer_text,\n",
    "#                  hidden_dim_text,\n",
    "#                  dr_text\n",
    "#                 ):\n",
    "# \n",
    "#         # for audio\n",
    "#         self.encoder_size_audio = encoder_size_audio\n",
    "#         self.num_layers_audio = num_layer_audio\n",
    "#         self.hidden_dim_audio = hidden_dim_audio\n",
    "#         self.dr_audio = dr_audio\n",
    "#         \n",
    "#         self.encoder_inputs_audio = []\n",
    "#         self.encoder_seq_length_audio =[]\n",
    "#         \n",
    "#         # for text        \n",
    "#         self.dic_size = dic_size\n",
    "#         self.use_glove = use_glove\n",
    "#         self.encoder_size_text = encoder_size_text\n",
    "#         self.num_layers_text = num_layer_text\n",
    "#         self.hidden_dim_text = hidden_dim_text\n",
    "#         self.dr_text = dr_text\n",
    "#         \n",
    "#         self.encoder_inputs_text = []\n",
    "#         self.encoder_seq_length_text =[]\n",
    "# \n",
    "#         # common        \n",
    "#         self.batch_size = batch_size\n",
    "#         self.lr = lr\n",
    "#         self.y_labels =[]\n",
    "#         \n",
    "#         self.M = None\n",
    "#         self.b = None\n",
    "#         \n",
    "#         self.y = None\n",
    "#         self.optimizer = None\n",
    "# \n",
    "#         self.batch_loss = None\n",
    "#         self.loss = 0\n",
    "#         self.batch_prob = None\n",
    "#         \n",
    "#         if self.use_glove == 1:\n",
    "#             self.embed_dim = 300\n",
    "#         else:\n",
    "#             self.embed_dim = DIM_WORD_EMBEDDING\n",
    "#         \n",
    "#         # for global counter\n",
    "#         self.global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "# \n",
    "# \n",
    "#     def _create_placeholders(self):\n",
    "#         print '[launch-multi] placeholders'\n",
    "#         with tf.name_scope('multi_placeholder'):\n",
    "#             \n",
    "#             # for audio\n",
    "#             self.encoder_inputs_audio  = self.model_audio.encoder_inputs  # [batch, time_step, audio]\n",
    "#             self.encoder_seq_audio     = self.model_audio.encoder_seq\n",
    "#             self.encoder_prosody       = self.model_audio.encoder_prosody\n",
    "#             self.dr_prob_audio         = self.model_audio.dr_prob\n",
    "#             \n",
    "#             # for text\n",
    "#             self.encoder_inputs_text  = self.model_text.encoder_inputs\n",
    "#             self.encoder_seq_text     = self.model_text.encoder_seq\n",
    "#             self.dr_prob_text         = self.model_text.dr_prob\n",
    "# \n",
    "#             # common\n",
    "#             self.y_labels             = tf.placeholder(tf.float32, shape=[self.batch_size, N_CATEGORY], name=\"label\")\n",
    "#             \n",
    "#             # for using pre-trained embedding\n",
    "#             self.embedding_placeholder = self.model_text.embedding_placeholder\n",
    "# \n",
    "# \n",
    "#     def _create_model_audio(self):\n",
    "#         print '[launch-multi] create audio model'\n",
    "#         self.model_audio =  SingleEncoderModelAudio(\n",
    "#                                                         batch_size=self.batch_size,\n",
    "#                                                         encoder_size=self.encoder_size_audio,\n",
    "#                                                         num_layer=self.num_layers_audio,\n",
    "#                                                         hidden_dim=self.hidden_dim_audio,\n",
    "#                                                         lr = self.lr,\n",
    "#                                                         dr= self.dr_audio\n",
    "#                                                         )\n",
    "#         self.model_audio._create_placeholders()\n",
    "#         self.model_audio._create_gru_model()\n",
    "#         self.model_audio._add_prosody()\n",
    "#         #self.model_audio._create_output_layers_for_multi()\n",
    "#         \n",
    "# \n",
    "# \n",
    "#     def _create_model_text(self):\n",
    "#         print '[launch-multi] create text model'        \n",
    "#         self.model_text = SingleEncoderModelText(\n",
    "#                                                     batch_size=self.batch_size,\n",
    "#                                                     dic_size=self.dic_size,\n",
    "#                                                     use_glove=self.use_glove,\n",
    "#                                                     encoder_size=self.encoder_size_text,\n",
    "#                                                     num_layer=self.num_layers_text,\n",
    "#                                                     hidden_dim=self.hidden_dim_text,\n",
    "#                                                     lr = self.lr,\n",
    "#                                                     dr= self.dr_text\n",
    "#                                                 )\n",
    "#         \n",
    "#         self.model_text._create_placeholders()\n",
    "#         self.model_text._create_embedding()\n",
    "#         self.model_text._use_external_embedding()\n",
    "#         self.model_text._create_gru_model()\n",
    "#         #self.model_text._create_output_layers_for_multi()\n",
    "# \n",
    "# \n",
    "#     def _create_attention_module(self):\n",
    "#         print '[launch-multi] create attention module'\n",
    "#         # project audio dimension_size to text dimension_size\n",
    "#         self.attnM = tf.Variable(tf.random_uniform([self.model_audio.final_encoder_dimension, self.model_text.final_encoder_dimension],\n",
    "#                                                    minval= -0.25,\n",
    "#                                                    maxval= 0.25,\n",
    "#                                                    dtype=tf.float32,\n",
    "#                                                    seed=None),\n",
    "#                                                  trainable=True,\n",
    "#                                                  name=\"attn_projection_helper\")\n",
    "#             \n",
    "#         self.attnb = tf.Variable(tf.zeros([1], dtype=tf.float32),\n",
    "#                                                  trainable=True,\n",
    "#                                                  name=\"attn_bias\")\n",
    "#         \n",
    "# \n",
    "#         self.attn_audio_final_encoder = tf.matmul(self.model_audio.final_encoder, self.attnM) + self.attnb\n",
    "#         \n",
    "#         self.final_encoder, self.tmp_norm = luong_attention (\n",
    "#                                                 batch_size = self.batch_size,\n",
    "#                                                 target = self.model_text.outputs_en,\n",
    "#                                                 condition = self.attn_audio_final_encoder,\n",
    "#                                                 batch_seq = self.encoder_seq_text,\n",
    "#                                                 max_len = self.model_text.encoder_size,\n",
    "#                                                 hidden_dim = self.model_text.final_encoder_dimension\n",
    "#                                             )\n",
    "# \n",
    "#         \n",
    "#     def _create_output_layers(self):\n",
    "#         print '[launch-multi] create output projection layer from (text_final_dim(==audio) + text_final_dim)'\n",
    "#         \n",
    "#         with tf.name_scope('multi_output_layer') as scope:\n",
    "# \n",
    "#             self.final_encoder = tf.concat( [self.final_encoder, self.attn_audio_final_encoder], axis=1 )\n",
    "#             \n",
    "#             self.M = tf.Variable(tf.random_uniform([(self.model_text.final_encoder_dimension)+(self.model_text.final_encoder_dimension), N_CATEGORY],\n",
    "#                                                    minval= -0.25,\n",
    "#                                                    maxval= 0.25,\n",
    "#                                                    dtype=tf.float32,\n",
    "#                                                    seed=None),\n",
    "#                                                  trainable=True,\n",
    "#                                                  name=\"similarity_matrix\")\n",
    "#             \n",
    "#             self.b = tf.Variable(tf.zeros([1], dtype=tf.float32),\n",
    "#                                                  trainable=True,\n",
    "#                                                  name=\"output_bias\")\n",
    "#             \n",
    "#             # e * M + b\n",
    "#             self.batch_pred = tf.matmul(self.final_encoder, self.M) + self.b\n",
    "#         \n",
    "#         with tf.name_scope('loss') as scope:\n",
    "#             \n",
    "#             self.batch_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=self.batch_pred, labels=self.y_labels )\n",
    "#             self.loss = tf.reduce_mean( self.batch_loss  )\n",
    "# \n",
    "#     \n",
    "#     def _create_optimizer(self):\n",
    "#         print '[launch-multi] create optimizer'\n",
    "#         \n",
    "#         with tf.name_scope('multi_optimizer') as scope:\n",
    "#             opt_func = tf.train.AdamOptimizer(learning_rate=self.lr)\n",
    "#             gvs = opt_func.compute_gradients(self.loss)\n",
    "#             capped_gvs = [(tf.clip_by_value(t=grad, clip_value_min=-10, clip_value_max=10), var) for grad, var in gvs]\n",
    "#             self.optimizer = opt_func.apply_gradients(grads_and_vars=capped_gvs, global_step=self.global_step)\n",
    "#     \n",
    "#     \n",
    "#     def _create_summary(self):\n",
    "#         print '[launch-multi] create summary'\n",
    "#         \n",
    "#         with tf.name_scope('summary'):\n",
    "#             tf.summary.scalar('mean_loss', self.loss)\n",
    "#             self.summary_op = tf.summary.merge_all()\n",
    "#     \n",
    "#     \n",
    "#     def build_graph(self):\n",
    "#         self._create_model_audio()\n",
    "#         self._create_model_text()\n",
    "#         self._create_placeholders()\n",
    "#         self._create_attention_module()\n",
    "#         self._create_output_layers()\n",
    "#         self._create_optimizer()\n",
    "#         self._create_summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# FIGURE OUT HOW TO DO EMOTION SHIFT?"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# FIGURE OUT FUSION TECHNIQUES"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
